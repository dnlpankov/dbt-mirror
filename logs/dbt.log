[0m22:56:07.621998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73E4F9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABDC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABC70>]}


============================== 22:56:07.739088 | e658d13a-3aea-45ae-96c8-380c5b933b1f ==============================
[0m22:56:07.739088 [info ] [MainThread]: Running with dbt=1.7.11
[0m22:56:07.760077 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'quiet': 'False', 'write_json': 'True', 'use_colors': 'True', 'invocation_command': 'dbt init', 'fail_fast': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_format': 'default', 'debug': 'False', 'partial_parse': 'True', 'target_path': 'None'}
[0m22:56:07.774041 [warn ] [MainThread]: [ConfigFolderDirectory]: Unable to parse dict {'dir': WindowsPath('C:/Users/Danila/.dbt')}
[0m22:56:07.774997 [info ] [MainThread]: Creating dbt configuration folder at 
[0m22:56:51.233243 [debug] [MainThread]: Starter project path: D:\Users\Danila\anaconda3\envs\dbt_env\lib\site-packages\dbt\include\starter_project
[0m22:56:51.541752 [info ] [MainThread]: 
Your new dbt project "campaign_performance" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m22:56:51.542948 [info ] [MainThread]: Setting up your profile.
[0m23:05:35.210962 [info ] [MainThread]: Profile campaign_performance written to C:\Users\Danila\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m23:05:35.626903 [debug] [MainThread]: Command `dbt init` succeeded at 23:05:35.258368 after 567.86 seconds
[0m23:05:35.672312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73E4F9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABB80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABCD0>]}
[0m23:05:35.708216 [debug] [MainThread]: Flushing usage events
[0m23:15:15.432463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D63469D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C820>]}


============================== 23:15:15.573512 | 61319262-bf15-452b-a2d5-9e67fe184b2b ==============================
[0m23:15:15.573512 [info ] [MainThread]: Running with dbt=1.7.11
[0m23:15:15.604971 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'log_format': 'default', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'debug': 'False', 'printer_width': '80', 'warn_error': 'None', 'indirect_selection': 'eager', 'static_parser': 'True', 'invocation_command': 'dbt test', 'quiet': 'False', 'fail_fast': 'False'}
[0m23:15:15.631123 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m23:15:15.683477 [debug] [MainThread]: Command `dbt test` failed at 23:15:15.634122 after 0.40 seconds
[0m23:15:15.684472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D63469D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2CD60>]}
[0m23:15:15.688463 [debug] [MainThread]: Flushing usage events
[0m01:12:41.668518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA6DF6AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA5F9A0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DDA00>]}


============================== 01:12:41.786091 | 1d747f0f-2e9f-4533-b232-cb7d88e2ca7d ==============================
[0m01:12:41.786091 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:12:41.806607 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'debug': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'introspect': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'no_print': 'None', 'printer_width': '80', 'quiet': 'False', 'fail_fast': 'False', 'log_path': 'logs'}
[0m01:12:41.808604 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m01:12:41.829961 [debug] [MainThread]: Command `dbt run` failed at 01:12:41.810604 after 0.31 seconds
[0m01:12:41.830960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA6DF6AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DD490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DD5E0>]}
[0m01:12:41.831958 [debug] [MainThread]: Flushing usage events
[0m01:13:05.616119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418E031A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000241904667F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D9A0>]}


============================== 01:13:05.619147 | ced84743-8c0c-4886-a8f2-13495d16fd33 ==============================
[0m01:13:05.619147 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:13:05.621104 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'warn_error': 'None', 'log_format': 'default', 'fail_fast': 'False', 'log_path': 'logs', 'write_json': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'partial_parse': 'True', 'debug': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'invocation_command': 'dbt run', 'printer_width': '80', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'use_colors': 'True'}
[0m01:13:05.784488 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m01:13:05.792792 [debug] [MainThread]: Command `dbt run` failed at 01:13:05.791806 after 0.26 seconds
[0m01:13:05.795750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418E031A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D190>]}
[0m01:13:05.798743 [debug] [MainThread]: Flushing usage events
[0m22:27:09.431445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105991f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f23d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f2a90>]}


============================== 22:27:09.433023 | 498f5558-7911-4fbb-b56d-65eed82ab48f ==============================
[0m22:27:09.433023 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:27:09.433342 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'version_check': 'True', 'introspect': 'True', 'log_format': 'default', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'static_parser': 'True', 'debug': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'write_json': 'True', 'use_colors': 'True', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'target_path': 'None'}
[0m22:27:09.499429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059cdb90>]}
[0m22:27:09.529467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c8990>]}
[0m22:27:09.530170 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m22:27:09.537501 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:27:09.555599 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:27:09.555842 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:27:09.556321 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m22:27:09.558974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105979a10>]}
[0m22:27:09.564032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106044e90>]}
[0m22:27:09.564291 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m22:27:09.564472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061bbed0>]}
[0m22:27:09.565511 [info ] [MainThread]: 
[0m22:27:09.565882 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:27:09.566597 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:27:09.570892 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:27:09.571081 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:27:09.571240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:27:10.030199 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m22:27:10.034852 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:27:10.038907 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:27:10.048096 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:27:10.048758 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:27:10.049098 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:27:10.394963 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.397244 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:27:10.398436 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m22:27:10.441925 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m22:27:10.446698 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:27:10.506304 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:27:10.523310 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.523779 [debug] [MainThread]: On master: BEGIN
[0m22:27:10.524242 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:27:10.783865 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.784930 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.785553 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:27:10.827627 [debug] [MainThread]: SQL status: SELECT 47 in 0.0 seconds
[0m22:27:10.834200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fab0d0>]}
[0m22:27:10.835227 [debug] [MainThread]: On master: ROLLBACK
[0m22:27:10.866107 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.867503 [debug] [MainThread]: On master: BEGIN
[0m22:27:10.929870 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.931303 [debug] [MainThread]: On master: COMMIT
[0m22:27:10.932480 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.933570 [debug] [MainThread]: On master: COMMIT
[0m22:27:10.964373 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:27:10.965807 [debug] [MainThread]: On master: Close
[0m22:27:10.968224 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:27:10.968965 [info ] [MainThread]: 
[0m22:27:10.974877 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m22:27:10.975770 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m22:27:10.976963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m22:27:10.977531 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m22:27:10.991359 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:10.992510 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 22:27:10.977902 => 22:27:10.992250
[0m22:27:10.992913 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m22:27:11.018801 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.019386 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.019620 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m22:27:11.019832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:11.490323 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:11.492501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.494195 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m22:27:36.140173 [debug] [Thread-1 (]: SQL status: SELECT 2110 in 25.0 seconds
[0m22:27:36.153822 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.154661 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m22:27:36.198635 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.205893 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.206616 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m22:27:36.250434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.279251 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m22:27:36.279807 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.280166 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m22:27:36.323367 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:36.329861 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m22:27:36.334102 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.334465 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m22:27:36.389864 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:36.391886 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 22:27:10.993127 => 22:27:36.391596
[0m22:27:36.392422 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m22:27:36.393596 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f71d10>]}
[0m22:27:36.394376 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2110[0m in 25.42s]
[0m22:27:36.395106 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m22:27:36.395638 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m22:27:36.396264 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m22:27:36.397000 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m22:27:36.397389 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m22:27:36.400382 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m22:27:36.401215 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 22:27:36.397655 => 22:27:36.400990
[0m22:27:36.401600 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m22:27:36.405512 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m22:27:36.406166 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.406484 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m22:27:36.406791 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:36.752487 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:36.753172 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.753701 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m22:27:36.802391 [debug] [Thread-1 (]: SQL status: SELECT 1442 in 0.0 seconds
[0m22:27:36.809155 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.809888 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m22:27:36.841758 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.848824 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.849676 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m22:27:36.881765 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.887442 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m22:27:36.888156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.888757 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m22:27:36.920643 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:36.930397 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m22:27:36.931937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.932588 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m22:27:36.984267 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:36.985947 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 22:27:36.401835 => 22:27:36.985740
[0m22:27:36.986343 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m22:27:36.987346 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10627db50>]}
[0m22:27:36.987902 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1442[0m in 0.59s]
[0m22:27:36.988370 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m22:27:36.988705 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.989150 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m22:27:36.989812 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m22:27:36.990147 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.992671 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.993349 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 22:27:36.990333 => 22:27:36.993180
[0m22:27:36.993656 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.996816 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.997273 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.997523 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m22:27:36.997755 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:37.749776 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:27:37.750496 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.750943 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m22:27:37.810303 [debug] [Thread-1 (]: SQL status: SELECT 1442 in 0.0 seconds
[0m22:27:37.815932 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.816533 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m22:27:37.856775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:37.862846 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.863490 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m22:27:37.903660 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:37.908087 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m22:27:37.908799 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.909560 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m22:27:37.950714 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:37.957719 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m22:27:37.959572 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.960324 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m22:27:38.018347 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:38.022183 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 22:27:36.993837 => 22:27:38.021744
[0m22:27:38.023082 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m22:27:38.025207 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106292f10>]}
[0m22:27:38.026223 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1442[0m in 1.04s]
[0m22:27:38.027144 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m22:27:38.027882 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m22:27:38.028676 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m22:27:38.029613 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m22:27:38.030103 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m22:27:38.035094 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m22:27:38.036202 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 22:27:38.030390 => 22:27:38.035933
[0m22:27:38.036638 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m22:27:38.041364 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m22:27:38.042086 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.042406 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m22:27:38.042708 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:38.395142 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:38.396538 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.397451 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m22:27:38.448016 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m22:27:38.457384 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.458069 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m22:27:38.501335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:38.508761 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.509412 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m22:27:38.552608 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:38.558811 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m22:27:38.559593 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.560292 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m22:27:38.603016 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:38.608975 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m22:27:38.610388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.610990 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m22:27:38.674369 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:38.679053 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 22:27:38.036899 => 22:27:38.678596
[0m22:27:38.679866 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m22:27:38.681755 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106219310>]}
[0m22:27:38.682761 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.65s]
[0m22:27:38.683643 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m22:27:38.684297 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.685285 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m22:27:38.686273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m22:27:38.686751 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.691324 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.692365 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 22:27:38.687048 => 22:27:38.692083
[0m22:27:38.692836 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.699634 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.700297 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.700616 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m22:27:38.700921 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:38.958826 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:38.960690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.961627 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:27:38.996621 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m22:27:39.005573 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.006424 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:27:39.039001 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:39.046848 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.047816 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:27:39.080223 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:39.085020 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m22:27:39.085869 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.086442 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m22:27:39.116866 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:39.124271 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m22:27:39.126016 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.126791 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m22:27:39.175824 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:39.180214 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 22:27:38.693123 => 22:27:39.179792
[0m22:27:39.180995 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m22:27:39.182621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062cd390>]}
[0m22:27:39.183549 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.50s]
[0m22:27:39.184420 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m22:27:39.185098 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.186032 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m22:27:39.187033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:27:39.187511 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.194169 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.195111 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:27:39.187816 => 22:27:39.194881
[0m22:27:39.195512 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.199733 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.200271 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.200597 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:27:39.200909 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:39.561948 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:39.563388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.564503 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
  );
  
[0m22:27:48.970380 [debug] [Thread-1 (]: SQL status: SELECT 143735 in 9.0 seconds
[0m22:27:48.979568 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:48.980462 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:27:49.025107 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:49.032166 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.032851 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:27:49.077241 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:49.080983 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:27:49.081646 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.082198 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:27:49.127129 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:49.134047 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m22:27:49.135304 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.135818 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:27:49.195903 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:49.200151 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:27:39.195756 => 22:27:49.199740
[0m22:27:49.201052 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:27:49.203040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b16d0>]}
[0m22:27:49.204196 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 143735[0m in 10.02s]
[0m22:27:49.205341 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:49.206233 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.207200 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m22:27:49.208240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:27:49.208795 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.215458 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.217016 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:27:49.209117 => 22:27:49.216675
[0m22:27:49.217565 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.222502 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.223301 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.223686 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:27:49.224060 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:49.503377 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:49.505435 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.506533 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2023-12-31' --matomo
    group by day, country_code, campaign_name, ga_campaign_name
  );
  
[0m22:27:54.396656 [debug] [Thread-1 (]: SQL status: SELECT 39884 in 5.0 seconds
[0m22:27:54.404128 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.404808 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:27:54.438311 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:54.443205 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:27:54.444016 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.444715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:27:54.478406 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:54.488162 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m22:27:54.489292 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.489777 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:27:54.544836 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:54.549017 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:27:49.217868 => 22:27:54.548622
[0m22:27:54.549782 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:27:54.551605 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10628af10>]}
[0m22:27:54.552547 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 39884[0m in 5.34s]
[0m22:27:54.553384 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:27:54.554048 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m22:27:54.554844 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m22:27:54.555949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m22:27:54.556455 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m22:27:54.561518 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m22:27:54.562834 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 22:27:54.556780 => 22:27:54.562536
[0m22:27:54.563335 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m22:27:54.579594 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m22:27:54.580232 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:54.580517 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m22:27:54.580783 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:54.953823 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:54.955952 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:54.956853 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m22:27:54.992211 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:27:55.000558 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.001196 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m22:27:55.032479 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.038158 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.038921 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m22:27:55.070505 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.074660 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m22:27:55.075274 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.075784 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m22:27:55.106482 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:55.112418 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m22:27:55.118306 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.118858 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m22:27:55.150298 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:27:55.153524 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 22:27:54.563621 => 22:27:55.152911
[0m22:27:55.154354 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m22:27:55.156298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062886d0>]}
[0m22:27:55.157407 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.60s]
[0m22:27:55.158535 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m22:27:55.159381 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m22:27:55.160222 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m22:27:55.161196 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m22:27:55.161747 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m22:27:55.166048 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m22:27:55.167873 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 22:27:55.162105 => 22:27:55.167232
[0m22:27:55.168544 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m22:27:55.174169 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m22:27:55.174943 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.175328 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m22:27:55.175700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:55.429467 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:55.431706 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.432901 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m22:27:55.467155 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:27:55.475750 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.476403 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m22:27:55.507789 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.514638 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.515417 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m22:27:55.546692 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.552879 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m22:27:55.553525 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.554020 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m22:27:55.584809 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:55.589659 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m22:27:55.590796 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.591731 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m22:27:55.639605 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:55.642923 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 22:27:55.168864 => 22:27:55.642495
[0m22:27:55.643815 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m22:27:55.645779 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060925d0>]}
[0m22:27:55.646976 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.48s]
[0m22:27:55.647868 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m22:27:55.648558 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m22:27:55.649333 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m22:27:55.650341 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m22:27:55.650891 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m22:27:55.656342 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.657570 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 22:27:55.651213 => 22:27:55.657270
[0m22:27:55.658074 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m22:27:55.701483 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.702086 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.702298 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m22:27:55.702484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:55.956890 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:55.958644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.959516 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m22:27:56.560323 [debug] [Thread-1 (]: SQL status: SELECT 55542 in 1.0 seconds
[0m22:27:56.568384 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.569031 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m22:27:56.599768 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:56.605821 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.606436 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m22:27:56.637886 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:56.642342 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m22:27:56.643105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.643798 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m22:27:56.675719 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:56.682573 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m22:27:56.684150 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.684704 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m22:27:56.732900 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:56.736683 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 22:27:55.658359 => 22:27:56.736245
[0m22:27:56.737493 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m22:27:56.739385 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105023b10>]}
[0m22:27:56.740560 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 55542[0m in 1.09s]
[0m22:27:56.741677 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m22:27:56.742605 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.743739 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m22:27:56.744750 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m22:27:56.745292 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.750222 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.751620 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 22:27:56.745629 => 22:27:56.751370
[0m22:27:56.752461 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.758093 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.759054 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.759444 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m22:27:56.759801 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:57.012525 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:57.014534 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.015326 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m22:27:57.049577 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:27:57.057609 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.058294 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:27:57.090077 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.094153 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m22:27:57.095088 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.095823 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m22:27:57.126762 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:57.130333 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m22:27:57.131296 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.131708 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m22:27:57.162380 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:27:57.165101 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 22:27:56.752775 => 22:27:57.164791
[0m22:27:57.165699 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m22:27:57.167269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062938d0>]}
[0m22:27:57.168067 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.42s]
[0m22:27:57.168792 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m22:27:57.169318 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.169837 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m22:27:57.170773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m22:27:57.171264 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.174971 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.175936 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 22:27:57.171524 => 22:27:57.175686
[0m22:27:57.176340 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.180232 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.180820 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.181142 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m22:27:57.181442 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:57.538668 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:57.540802 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.541953 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m22:27:57.614303 [debug] [Thread-1 (]: SQL status: SELECT 64 in 0.0 seconds
[0m22:27:57.623154 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.623855 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m22:27:57.667648 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.674181 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.674801 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m22:27:57.718255 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.724088 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m22:27:57.724878 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.725488 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m22:27:57.769695 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:57.779761 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m22:27:57.781024 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.781481 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m22:27:57.841645 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:57.845896 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 22:27:57.176573 => 22:27:57.845491
[0m22:27:57.846658 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m22:27:57.848219 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106268d90>]}
[0m22:27:57.849090 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 64[0m in 0.68s]
[0m22:27:57.849855 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.851935 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:57.852369 [debug] [MainThread]: On master: BEGIN
[0m22:27:57.852738 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:27:58.137308 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:58.139581 [debug] [MainThread]: On master: COMMIT
[0m22:27:58.140891 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:58.141547 [debug] [MainThread]: On master: COMMIT
[0m22:27:58.175882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:27:58.177329 [debug] [MainThread]: On master: Close
[0m22:27:58.180189 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:27:58.180783 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m22:27:58.181570 [info ] [MainThread]: 
[0m22:27:58.182466 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 48.62 seconds (48.62s).
[0m22:27:58.185794 [debug] [MainThread]: Command end result
[0m22:27:58.198322 [info ] [MainThread]: 
[0m22:27:58.198913 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:27:58.199276 [info ] [MainThread]: 
[0m22:27:58.199651 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m22:27:58.201977 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 48.805172, "process_user_time": 1.794044, "process_kernel_time": 0.182757, "process_mem_max_rss": "126418944", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:27:58.202496 [debug] [MainThread]: Command `dbt run` succeeded at 22:27:58.202384 after 48.81 seconds
[0m22:27:58.202844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f1650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1012fdf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101238850>]}
[0m22:27:58.203180 [debug] [MainThread]: Flushing usage events
[0m11:29:27.824869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109947450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099be010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099be690>]}


============================== 11:29:27.826720 | 7a3f9496-6a36-43cd-b22b-d360356d14b7 ==============================
[0m11:29:27.826720 [info ] [MainThread]: Running with dbt=1.7.0
[0m11:29:27.827110 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'no_print': 'None', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'use_colors': 'True', 'debug': 'False', 'target_path': 'None', 'quiet': 'False', 'printer_width': '80', 'warn_error': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'fail_fast': 'False', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'indirect_selection': 'eager'}
[0m11:29:27.900579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a80d510>]}
[0m11:29:27.930763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e67650>]}
[0m11:29:27.931151 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m11:29:27.938707 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m11:29:27.959472 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:29:27.959731 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:29:27.960186 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m11:29:27.962766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e9eb90>]}
[0m11:29:27.969266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa37fd0>]}
[0m11:29:27.969493 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m11:29:27.969673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a819750>]}
[0m11:29:27.970675 [info ] [MainThread]: 
[0m11:29:27.971065 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:29:27.971771 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m11:29:27.976589 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m11:29:27.976854 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m11:29:27.977151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:28.309454 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m11:29:28.313475 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m11:29:28.318370 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m11:29:28.327934 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m11:29:28.328530 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m11:29:28.328955 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:28.688080 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:29:28.689890 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m11:29:28.691385 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m11:29:28.758382 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m11:29:28.764126 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m11:29:28.806919 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m11:29:28.823788 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:28.824530 [debug] [MainThread]: On master: BEGIN
[0m11:29:28.825007 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:29:29.154978 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.157369 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.158729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:29:29.208972 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m11:29:29.213748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109944fd0>]}
[0m11:29:29.214763 [debug] [MainThread]: On master: ROLLBACK
[0m11:29:29.253883 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.254823 [debug] [MainThread]: On master: BEGIN
[0m11:29:29.332746 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.334415 [debug] [MainThread]: On master: COMMIT
[0m11:29:29.335703 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.336397 [debug] [MainThread]: On master: COMMIT
[0m11:29:29.375648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:29:29.377049 [debug] [MainThread]: On master: Close
[0m11:29:29.380195 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:29:29.381272 [info ] [MainThread]: 
[0m11:29:29.387196 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.388055 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m11:29:29.389084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m11:29:29.389791 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.402061 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.403341 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 11:29:29.390202 => 11:29:29.403100
[0m11:29:29.403725 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.428342 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.429320 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.429568 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m11:29:29.429788 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:29.683814 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.685975 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.687759 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m11:29:56.189010 [debug] [Thread-1 (]: SQL status: SELECT 2111 in 26.0 seconds
[0m11:29:56.202850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.203719 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m11:29:56.260397 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.269071 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.269901 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m11:29:56.301182 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.336736 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m11:29:56.337480 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.337981 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m11:29:56.369530 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:56.380629 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m11:29:56.386373 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.386885 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m11:29:56.431511 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:56.435743 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 11:29:29.403937 => 11:29:56.435150
[0m11:29:56.436835 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m11:29:56.438869 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa93890>]}
[0m11:29:56.440068 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2111[0m in 27.05s]
[0m11:29:56.441285 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m11:29:56.442166 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m11:29:56.443411 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m11:29:56.444697 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m11:29:56.445304 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m11:29:56.449939 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m11:29:56.452731 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 11:29:56.445689 => 11:29:56.452366
[0m11:29:56.453278 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m11:29:56.458949 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m11:29:56.459970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.460395 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m11:29:56.460766 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:56.834919 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:56.837210 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.837984 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m11:29:56.886982 [debug] [Thread-1 (]: SQL status: SELECT 1473 in 0.0 seconds
[0m11:29:56.894810 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.895420 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m11:29:56.929220 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.934831 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.935404 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m11:29:56.968533 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.972961 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m11:29:56.974360 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.974893 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m11:29:57.008795 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:57.022097 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m11:29:57.023822 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:57.024770 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m11:29:57.079088 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:57.084269 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 11:29:56.453603 => 11:29:57.083920
[0m11:29:57.084985 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m11:29:57.087428 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac4fbd0>]}
[0m11:29:57.088417 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1473[0m in 0.64s]
[0m11:29:57.089710 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m11:29:57.091069 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.091808 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m11:29:57.093018 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m11:29:57.093886 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.098944 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.099975 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 11:29:57.094520 => 11:29:57.099723
[0m11:29:57.100549 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.106875 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.108709 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.109251 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m11:29:57.109741 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:57.417280 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:57.419062 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.420479 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m11:29:57.481452 [debug] [Thread-1 (]: SQL status: SELECT 1473 in 0.0 seconds
[0m11:29:57.484991 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.485417 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m11:29:57.522643 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:57.524151 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.524332 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m11:29:57.560942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:57.563484 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m11:29:57.563969 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.564375 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m11:29:57.601034 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:57.606092 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m11:29:57.607644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.608317 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m11:29:57.666246 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:57.670418 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 11:29:57.100920 => 11:29:57.669580
[0m11:29:57.671877 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m11:29:57.675042 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac5cf10>]}
[0m11:29:57.676689 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1473[0m in 0.58s]
[0m11:29:57.678217 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.679641 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m11:29:57.680788 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m11:29:57.682097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m11:29:57.682782 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m11:29:57.688100 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m11:29:57.689822 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 11:29:57.683230 => 11:29:57.689459
[0m11:29:57.690599 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m11:29:57.696860 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m11:29:57.697795 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:57.698020 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m11:29:57.698234 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:57.977130 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:57.978604 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:57.979396 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m11:29:58.017308 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m11:29:58.027390 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.028262 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m11:29:58.060659 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.072085 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.073204 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m11:29:58.104931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.108959 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m11:29:58.109580 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.110320 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m11:29:58.141092 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:58.147300 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m11:29:58.149547 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.150426 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m11:29:58.200278 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:58.204063 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 11:29:57.690967 => 11:29:58.203646
[0m11:29:58.204808 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m11:29:58.207595 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac24110>]}
[0m11:29:58.208700 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.53s]
[0m11:29:58.210162 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m11:29:58.211228 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.212446 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m11:29:58.215020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m11:29:58.216323 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.221734 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.223560 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 11:29:58.216756 => 11:29:58.223150
[0m11:29:58.224310 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.236054 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.237015 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.237478 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m11:29:58.237906 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:58.513810 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:58.515859 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.517408 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m11:29:58.555230 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m11:29:58.568101 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.569718 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m11:29:58.603968 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.613631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.614789 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m11:29:58.649645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.655279 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m11:29:58.656759 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.658095 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m11:29:58.692407 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:58.702810 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m11:29:58.706053 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.707263 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m11:29:58.760056 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:58.765608 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 11:29:58.224760 => 11:29:58.764851
[0m11:29:58.767134 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m11:29:58.770743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac7af10>]}
[0m11:29:58.771825 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.56s]
[0m11:29:58.772771 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.773806 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.775139 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m11:29:58.776753 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m11:29:58.777554 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.786247 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.788272 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 11:29:58.777979 => 11:29:58.787805
[0m11:29:58.788967 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.796147 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.797305 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.797832 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m11:29:58.798306 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:59.119924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:59.121186 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:59.122231 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m11:30:08.887801 [debug] [Thread-1 (]: SQL status: SELECT 153021 in 10.0 seconds
[0m11:30:08.894791 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.895469 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m11:30:08.935243 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:08.942405 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.943125 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m11:30:08.983043 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:08.987700 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m11:30:08.988536 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.989229 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m11:30:09.028142 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:09.033859 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m11:30:09.035545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:09.036152 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m11:30:09.092780 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:09.096194 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 11:29:58.789466 => 11:30:09.095875
[0m11:30:09.097181 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m11:30:09.099503 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac98510>]}
[0m11:30:09.100722 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153021[0m in 10.32s]
[0m11:30:09.101881 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m11:30:09.102791 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.103771 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m11:30:09.105221 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m11:30:09.106054 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.113080 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.114843 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 11:30:09.106480 => 11:30:09.114415
[0m11:30:09.115643 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.122562 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.123807 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.124308 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m11:30:09.124834 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:09.407733 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:09.409736 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.411659 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m11:30:14.314088 [debug] [Thread-1 (]: SQL status: SELECT 45760 in 5.0 seconds
[0m11:30:14.321838 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.322711 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m11:30:14.354506 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.365802 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.366362 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m11:30:14.397524 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.403253 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m11:30:14.403876 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.404359 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m11:30:14.435499 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:14.442024 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m11:30:14.443479 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.444451 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m11:30:14.491125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:14.494592 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 11:30:09.116217 => 11:30:14.494296
[0m11:30:14.495263 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m11:30:14.497559 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa82510>]}
[0m11:30:14.498469 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45760[0m in 5.39s]
[0m11:30:14.500028 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m11:30:14.501182 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m11:30:14.502162 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m11:30:14.504074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m11:30:14.504956 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m11:30:14.511300 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m11:30:14.513079 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 11:30:14.505345 => 11:30:14.512750
[0m11:30:14.513693 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m11:30:14.537425 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m11:30:14.538501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.538921 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m11:30:14.539276 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:14.795907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:14.797576 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.798894 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m11:30:14.834301 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m11:30:14.842027 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.842807 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m11:30:14.874751 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.883465 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.884292 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m11:30:14.916070 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.921521 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m11:30:14.922408 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.923107 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m11:30:14.954788 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:14.960990 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m11:30:14.968663 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.969519 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m11:30:15.075894 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m11:30:15.080825 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 11:30:14.514072 => 11:30:15.080267
[0m11:30:15.081979 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m11:30:15.083855 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac6e510>]}
[0m11:30:15.085452 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.58s]
[0m11:30:15.087215 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m11:30:15.088098 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m11:30:15.089206 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m11:30:15.090669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m11:30:15.091213 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m11:30:15.096344 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m11:30:15.098885 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 11:30:15.091465 => 11:30:15.098359
[0m11:30:15.099770 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m11:30:15.107568 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m11:30:15.109042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.109721 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m11:30:15.110231 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:15.490905 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:15.492533 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.493936 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m11:30:15.527561 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:30:15.537596 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.538458 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m11:30:15.570592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:15.577545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.578667 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m11:30:15.609718 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:15.618308 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m11:30:15.619711 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.620661 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m11:30:15.651696 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:15.666560 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m11:30:15.668994 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.670033 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m11:30:15.717891 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:15.722520 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 11:30:15.100140 => 11:30:15.721782
[0m11:30:15.723918 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m11:30:15.727056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8891d0>]}
[0m11:30:15.729367 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.64s]
[0m11:30:15.730950 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m11:30:15.732126 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m11:30:15.733601 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m11:30:15.735032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m11:30:15.735959 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m11:30:15.742502 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.745186 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 11:30:15.736663 => 11:30:15.744833
[0m11:30:15.745824 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m11:30:15.796031 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.796727 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.796954 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m11:30:15.797157 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:16.054991 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:16.056443 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.057178 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m11:30:16.330722 [debug] [Thread-1 (]: SQL status: SELECT 56297 in 0.0 seconds
[0m11:30:16.339403 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.340765 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m11:30:16.372645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.382747 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.383850 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m11:30:16.415893 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.423753 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m11:30:16.425267 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.426648 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m11:30:16.458904 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:16.468553 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m11:30:16.470814 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.471805 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m11:30:16.523724 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:16.527865 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 11:30:15.746211 => 11:30:16.527511
[0m11:30:16.528500 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m11:30:16.530006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac796d0>]}
[0m11:30:16.531645 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 56297[0m in 0.80s]
[0m11:30:16.533671 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m11:30:16.535189 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.536237 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m11:30:16.537800 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m11:30:16.538626 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.543714 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.545302 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 11:30:16.539048 => 11:30:16.544993
[0m11:30:16.545927 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.553004 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.554631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.555163 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m11:30:16.555949 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:16.813202 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:16.815419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.816669 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m11:30:16.851753 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m11:30:16.860310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.861202 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m11:30:16.892612 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.896878 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m11:30:16.898342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.899444 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m11:30:16.930847 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:16.937237 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m11:30:16.939156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.940478 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m11:30:16.972299 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m11:30:16.976486 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 11:30:16.546335 => 11:30:16.976003
[0m11:30:16.977345 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m11:30:16.979786 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac8d3d0>]}
[0m11:30:16.980930 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.44s]
[0m11:30:16.982531 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.983550 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m11:30:16.984573 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m11:30:16.986027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m11:30:16.987027 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m11:30:16.992992 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:16.994533 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 11:30:16.987564 => 11:30:16.994215
[0m11:30:16.995116 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m11:30:17.001230 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.002753 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.003264 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m11:30:17.003721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:17.332084 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:17.333369 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.334568 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m11:30:17.402329 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m11:30:17.412270 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.413050 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m11:30:17.453306 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:17.463483 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.464506 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m11:30:17.504569 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:17.510484 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m11:30:17.511415 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.512121 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m11:30:17.552547 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:17.558917 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m11:30:17.560996 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.562252 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m11:30:17.619876 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:17.624823 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 11:30:16.995503 => 11:30:17.624118
[0m11:30:17.626071 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m11:30:17.628856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acba690>]}
[0m11:30:17.630384 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.64s]
[0m11:30:17.632120 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m11:30:17.635763 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:17.636759 [debug] [MainThread]: On master: BEGIN
[0m11:30:17.637677 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:30:17.892995 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:30:17.894611 [debug] [MainThread]: On master: COMMIT
[0m11:30:17.895784 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:17.896466 [debug] [MainThread]: On master: COMMIT
[0m11:30:17.926850 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:30:17.927704 [debug] [MainThread]: On master: Close
[0m11:30:17.929878 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:30:17.930894 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m11:30:17.931790 [info ] [MainThread]: 
[0m11:30:17.932743 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 49.96 seconds (49.96s).
[0m11:30:17.938161 [debug] [MainThread]: Command end result
[0m11:30:17.959081 [info ] [MainThread]: 
[0m11:30:17.959858 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:30:17.960319 [info ] [MainThread]: 
[0m11:30:17.960790 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m11:30:17.963604 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 50.16285, "process_user_time": 1.989993, "process_kernel_time": 0.227356, "process_mem_max_rss": "126500864", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m11:30:17.964431 [debug] [MainThread]: Command `dbt run` succeeded at 11:30:17.964254 after 50.16 seconds
[0m11:30:17.964921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047e0850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ec5250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048a5f50>]}
[0m11:30:17.965442 [debug] [MainThread]: Flushing usage events
[0m19:08:14.417633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119ee8b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f5e710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f5ee10>]}


============================== 19:08:14.419333 | 143f72ab-9505-480a-8ae9-c5a87e3af9e2 ==============================
[0m19:08:14.419333 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:08:14.419694 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'invocation_command': 'dbt run', 'version_check': 'True', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'no_print': 'None', 'static_parser': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'quiet': 'False', 'partial_parse': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'introspect': 'True'}
[0m19:08:14.493378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f5ecd0>]}
[0m19:08:14.524106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a31e9d0>]}
[0m19:08:14.524559 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:08:14.533196 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:08:14.556163 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:08:14.556490 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:08:14.558190 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:08:14.561616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a560290>]}
[0m19:08:14.569897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3e8050>]}
[0m19:08:14.570240 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:08:14.570526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1192bbfd0>]}
[0m19:08:14.572236 [info ] [MainThread]: 
[0m19:08:14.573062 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:08:14.574058 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:08:14.580221 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:08:14.580548 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:08:14.580727 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:08:14.945437 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:08:14.948359 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:08:14.953117 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:08:14.962937 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:08:14.963806 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:08:14.964124 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:08:15.290448 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:08:15.291948 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:08:15.293486 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:08:15.338974 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:08:15.341917 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:08:15.381485 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:08:15.393378 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.394019 [debug] [MainThread]: On master: BEGIN
[0m19:08:15.394492 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:08:15.654424 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:08:15.656182 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.657666 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:08:15.699697 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:08:15.705123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a439e50>]}
[0m19:08:15.706853 [debug] [MainThread]: On master: ROLLBACK
[0m19:08:15.738108 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.738717 [debug] [MainThread]: On master: BEGIN
[0m19:08:15.799927 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:08:15.801516 [debug] [MainThread]: On master: COMMIT
[0m19:08:15.802733 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.803897 [debug] [MainThread]: On master: COMMIT
[0m19:08:15.835706 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:08:15.837096 [debug] [MainThread]: On master: Close
[0m19:08:15.840365 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:08:15.841608 [info ] [MainThread]: 
[0m19:08:15.849371 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m19:08:15.850768 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m19:08:15.852145 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m19:08:15.852786 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m19:08:15.868672 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:15.870654 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 19:08:15.854049 => 19:08:15.870315
[0m19:08:15.871198 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m19:08:15.905425 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:15.906177 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:15.906444 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m19:08:15.906681 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:16.190660 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:16.191914 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:16.192820 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m19:08:46.426028 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 30.0 seconds
[0m19:08:46.434453 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.434924 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m19:08:46.465908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:46.471311 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.471759 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m19:08:46.503415 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:46.523702 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:08:46.524048 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.524333 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:08:46.554632 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:46.560195 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m19:08:46.564143 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.564460 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m19:08:46.609415 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:46.611074 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 19:08:15.871499 => 19:08:46.610850
[0m19:08:46.611508 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m19:08:46.612468 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a4b1310>]}
[0m19:08:46.613117 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 30.76s]
[0m19:08:46.613741 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m19:08:46.614220 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m19:08:46.614776 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m19:08:46.615476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m19:08:46.615842 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m19:08:46.618689 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m19:08:46.619477 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 19:08:46.616071 => 19:08:46.619283
[0m19:08:46.619827 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m19:08:46.623185 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m19:08:46.623676 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:46.623957 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m19:08:46.624215 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:46.989692 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:46.991172 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:46.992076 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:08:47.053129 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:08:47.061007 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.061699 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m19:08:47.101775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.107265 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.107856 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m19:08:47.147714 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.152659 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:08:47.153526 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.154130 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:08:47.193415 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:47.200192 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m19:08:47.202055 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.203097 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m19:08:47.263314 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:47.268235 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 19:08:46.620033 => 19:08:47.267729
[0m19:08:47.269221 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m19:08:47.271538 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a475c10>]}
[0m19:08:47.272713 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.66s]
[0m19:08:47.273745 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m19:08:47.274477 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.275364 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m19:08:47.276437 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m19:08:47.277092 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.282073 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.283282 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 19:08:47.277574 => 19:08:47.282983
[0m19:08:47.283773 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.288412 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.289388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.289797 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m19:08:47.290113 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:47.549193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:47.551159 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.552385 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:08:47.606517 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:08:47.613426 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.614056 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m19:08:47.645888 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.648449 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.648718 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m19:08:47.678958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.680404 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:08:47.680647 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.680872 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:08:47.711058 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:47.714402 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m19:08:47.715040 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.715321 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m19:08:47.766708 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:47.768078 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 19:08:47.284027 => 19:08:47.767865
[0m19:08:47.768473 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m19:08:47.769318 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b0696d0>]}
[0m19:08:47.769886 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.49s]
[0m19:08:47.770479 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.770930 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m19:08:47.771505 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m19:08:47.772274 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m19:08:47.772682 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m19:08:47.775534 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m19:08:47.776293 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 19:08:47.772922 => 19:08:47.776104
[0m19:08:47.776620 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m19:08:47.780162 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m19:08:47.780647 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:47.780920 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m19:08:47.781173 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:48.063959 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:48.065411 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.066485 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m19:08:48.110678 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m19:08:48.118083 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.118775 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m19:08:48.153900 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.159552 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.160120 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m19:08:48.193687 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.195374 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:08:48.195671 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.195924 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:08:48.229127 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:48.231237 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m19:08:48.231907 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.232188 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m19:08:48.287136 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:48.288760 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 19:08:47.776817 => 19:08:48.288521
[0m19:08:48.289188 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m19:08:48.290153 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b074f10>]}
[0m19:08:48.290771 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.52s]
[0m19:08:48.291391 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m19:08:48.291843 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.292439 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m19:08:48.293353 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m19:08:48.293770 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.296357 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.297047 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 19:08:48.293988 => 19:08:48.296858
[0m19:08:48.297379 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.300926 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.301407 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.301681 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m19:08:48.301940 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:48.560392 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:48.560806 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.561074 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m19:08:48.595148 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m19:08:48.597401 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.597641 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m19:08:48.628555 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.630596 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.630868 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m19:08:48.661693 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.663307 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:08:48.663591 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.663863 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:08:48.694056 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:48.696711 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m19:08:48.697575 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.697954 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m19:08:48.749023 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:48.750021 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 19:08:48.297576 => 19:08:48.749874
[0m19:08:48.750292 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m19:08:48.750905 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b03d990>]}
[0m19:08:48.751290 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.46s]
[0m19:08:48.751681 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.751983 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:48.752277 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m19:08:48.752810 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:08:48.753207 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:48.756513 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:48.758582 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:08:48.753437 => 19:08:48.758383
[0m19:08:48.758860 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:48.762689 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:48.763457 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:48.763703 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:08:48.763920 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:49.113393 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:49.114633 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:49.115615 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m19:08:59.444840 [debug] [Thread-1 (]: SQL status: SELECT 153241 in 10.0 seconds
[0m19:08:59.447572 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.447900 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:08:59.490525 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:59.493060 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.493414 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:08:59.535238 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:59.536941 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:08:59.537252 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.537526 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:08:59.579536 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:59.582437 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m19:08:59.583322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.583710 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:08:59.647297 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:59.651190 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:08:48.759011 => 19:08:59.650828
[0m19:08:59.651952 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:08:59.653622 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a643350>]}
[0m19:08:59.654594 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153241[0m in 10.90s]
[0m19:08:59.655422 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:59.656065 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:08:59.656824 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m19:08:59.657753 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:08:59.658315 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:08:59.663658 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.664678 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:08:59.658909 => 19:08:59.664435
[0m19:08:59.665103 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:08:59.669362 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.669925 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.670266 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:08:59.670576 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:59.944363 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:59.944907 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.945452 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:09:12.404147 [debug] [Thread-1 (]: SQL status: SELECT 45889 in 12.0 seconds
[0m19:09:12.412996 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.413917 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:09:12.449007 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:12.454870 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.455670 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:09:12.551829 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:12.555642 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:09:12.556498 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.557012 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:09:12.600194 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:12.602880 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:09:12.603689 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.604020 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:09:12.702900 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:12.706766 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:08:59.665347 => 19:09:12.706295
[0m19:09:12.707672 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:09:12.709719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b087450>]}
[0m19:09:12.710843 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45889[0m in 13.05s]
[0m19:09:12.711971 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:09:12.712671 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m19:09:12.713520 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m19:09:12.714498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m19:09:12.715002 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m19:09:12.720063 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m19:09:12.721333 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 19:09:12.715312 => 19:09:12.721015
[0m19:09:12.721842 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m19:09:12.738970 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m19:09:12.739683 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:12.739979 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m19:09:12.740252 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:13.089230 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:13.090894 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.091869 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m19:09:13.129165 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:09:13.136310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.137142 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m19:09:13.168904 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.179170 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.179953 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m19:09:13.212212 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.261915 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:09:13.262356 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.262609 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:09:13.293914 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:13.295737 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m19:09:13.298067 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.298338 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m19:09:13.330071 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:09:13.331289 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 19:09:12.722144 => 19:09:13.331110
[0m19:09:13.331625 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m19:09:13.332394 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a2afc10>]}
[0m19:09:13.332886 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.62s]
[0m19:09:13.333400 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m19:09:13.333734 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m19:09:13.334183 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m19:09:13.334774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m19:09:13.335082 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m19:09:13.337110 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m19:09:13.337737 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 19:09:13.335267 => 19:09:13.337571
[0m19:09:13.338032 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m19:09:13.341021 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m19:09:13.341502 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.341755 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m19:09:13.341991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:13.651857 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:13.654000 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.655446 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m19:09:13.695823 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:09:13.704364 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.704961 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m19:09:13.742376 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.744877 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.745160 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m19:09:13.781234 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.782753 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:09:13.783012 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.783251 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:09:13.819442 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:13.821660 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m19:09:13.822402 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.822723 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m19:09:13.878652 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:13.881438 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 19:09:13.338202 => 19:09:13.881146
[0m19:09:13.882066 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m19:09:13.883609 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b02d550>]}
[0m19:09:13.884491 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.55s]
[0m19:09:13.885362 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m19:09:13.885951 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m19:09:13.886598 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m19:09:13.887493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m19:09:13.887972 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m19:09:13.891825 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m19:09:13.893458 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 19:09:13.888260 => 19:09:13.893219
[0m19:09:13.893855 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m19:09:13.897953 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m19:09:13.898473 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:13.898787 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m19:09:13.899085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:14.151562 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:14.153112 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.154315 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m19:09:14.401676 [debug] [Thread-1 (]: SQL status: SELECT 56717 in 0.0 seconds
[0m19:09:14.408414 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.409154 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m19:09:14.440450 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:14.446619 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.447251 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m19:09:14.477984 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:14.480386 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:09:14.480911 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.481318 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:09:14.511897 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:14.518271 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m19:09:14.519677 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.520224 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m19:09:14.573190 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:14.575430 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 19:09:13.894096 => 19:09:14.575175
[0m19:09:14.575940 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m19:09:14.577463 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a5620d0>]}
[0m19:09:14.578478 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 56717[0m in 0.69s]
[0m19:09:14.579260 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m19:09:14.579827 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m19:09:14.580658 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m19:09:14.581593 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m19:09:14.581987 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m19:09:14.587443 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.588276 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 19:09:14.582221 => 19:09:14.588084
[0m19:09:14.588605 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m19:09:14.592626 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.593240 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.593521 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m19:09:14.593790 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:14.855924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:14.857673 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.858544 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m19:09:14.893458 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:09:14.901357 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.902061 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m19:09:14.933674 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:14.938865 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:09:14.939710 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.940496 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:09:14.972718 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:14.978291 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m19:09:14.980127 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.980736 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m19:09:15.012195 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:09:15.015078 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 19:09:14.588802 => 19:09:15.014739
[0m19:09:15.015820 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m19:09:15.017649 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6535d0>]}
[0m19:09:15.018635 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.44s]
[0m19:09:15.019595 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m19:09:15.020341 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.021388 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m19:09:15.022416 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m19:09:15.022962 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.027972 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.029254 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 19:09:15.023313 => 19:09:15.028941
[0m19:09:15.029761 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.035448 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.036666 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.037123 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m19:09:15.037471 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:15.343990 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:15.345589 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.346567 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m19:09:15.427110 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m19:09:15.434367 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.435146 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m19:09:15.471802 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:15.476982 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.477642 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m19:09:15.514790 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:15.519674 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:09:15.520602 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.521358 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:09:15.559351 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:15.567064 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m19:09:15.568896 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.569733 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m19:09:15.630265 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:15.634762 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 19:09:15.030057 => 19:09:15.634336
[0m19:09:15.635608 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m19:09:15.637539 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a544110>]}
[0m19:09:15.638489 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.62s]
[0m19:09:15.639454 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.641906 [debug] [MainThread]: Using postgres connection "master"
[0m19:09:15.642401 [debug] [MainThread]: On master: BEGIN
[0m19:09:15.642814 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:09:15.902324 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:09:15.904016 [debug] [MainThread]: On master: COMMIT
[0m19:09:15.905115 [debug] [MainThread]: Using postgres connection "master"
[0m19:09:15.905791 [debug] [MainThread]: On master: COMMIT
[0m19:09:15.937100 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:09:15.937997 [debug] [MainThread]: On master: Close
[0m19:09:15.940149 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:09:15.940854 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m19:09:15.941748 [info ] [MainThread]: 
[0m19:09:15.942490 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 1 minutes and 1.37 seconds (61.37s).
[0m19:09:15.946364 [debug] [MainThread]: Command end result
[0m19:09:15.962965 [info ] [MainThread]: 
[0m19:09:15.963517 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:09:15.963887 [info ] [MainThread]: 
[0m19:09:15.964247 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m19:09:15.966803 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 61.576817, "process_user_time": 1.721446, "process_kernel_time": 0.233992, "process_mem_max_rss": "132644864", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:09:15.967352 [debug] [MainThread]: Command `dbt run` succeeded at 19:09:15.967229 after 61.58 seconds
[0m19:09:15.967714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119e06e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10483e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047701d0>]}
[0m19:09:15.968051 [debug] [MainThread]: Flushing usage events
[0m19:11:53.987191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff0dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff2410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108017090>]}


============================== 19:11:53.988731 | 387094f3-a07b-4c6e-a334-0e77e60eda45 ==============================
[0m19:11:53.988731 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:11:53.989047 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_format': 'default', 'introspect': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'write_json': 'True', 'debug': 'False', 'static_parser': 'True', 'use_colors': 'True', 'printer_width': '80', 'quiet': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'no_print': 'None'}
[0m19:11:54.059448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '387094f3-a07b-4c6e-a334-0e77e60eda45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fb22d0>]}
[0m19:11:54.089151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '387094f3-a07b-4c6e-a334-0e77e60eda45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fb22d0>]}
[0m19:11:54.089570 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:11:54.096323 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:11:54.102040 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:11:54.102356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '387094f3-a07b-4c6e-a334-0e77e60eda45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086e5590>]}
[0m19:11:54.478880 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.records_gap_campaigns' which was not found
[0m19:11:54.481263 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5157985, "process_user_time": 1.187947, "process_kernel_time": 0.098062, "process_mem_max_rss": "124321792", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:11:54.481518 [debug] [MainThread]: Command `dbt run` failed at 19:11:54.481458 after 0.52 seconds
[0m19:11:54.481703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078661d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108612c10>]}
[0m19:11:54.481872 [debug] [MainThread]: Flushing usage events
[0m19:13:10.297547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e9410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106656c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106657310>]}


============================== 19:13:10.299176 | 99d3c192-6345-4ed3-9344-b0e17e3f1cc9 ==============================
[0m19:13:10.299176 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:13:10.299545 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'debug': 'False', 'introspect': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'cache_selected_only': 'False', 'static_parser': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'version_check': 'True', 'log_format': 'default', 'target_path': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'no_print': 'None', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False'}
[0m19:13:10.370986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '99d3c192-6345-4ed3-9344-b0e17e3f1cc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a53a90>]}
[0m19:13:10.400658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '99d3c192-6345-4ed3-9344-b0e17e3f1cc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bea3d0>]}
[0m19:13:10.401526 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:13:10.411971 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:13:10.417727 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:13:10.418008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '99d3c192-6345-4ed3-9344-b0e17e3f1cc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bac550>]}
[0m19:13:10.780614 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.matomo_visits' which was not found
[0m19:13:10.783088 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.50804085, "process_user_time": 1.172625, "process_kernel_time": 0.110443, "process_mem_max_rss": "124682240", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:13:10.783378 [debug] [MainThread]: Command `dbt run` failed at 19:13:10.783319 after 0.51 seconds
[0m19:13:10.783568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10663a490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100aa67d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d81910>]}
[0m19:13:10.783736 [debug] [MainThread]: Flushing usage events
[0m19:13:25.808452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eebf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11103b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11105f2d0>]}


============================== 19:13:25.809715 | b6f973aa-1e52-45f7-8e40-622b8f07a972 ==============================
[0m19:13:25.809715 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:13:25.810038 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'write_json': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'use_colors': 'True', 'target_path': 'None', 'fail_fast': 'False', 'log_format': 'default', 'log_path': '/Users/danila/github/dbt/logs', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'invocation_command': 'dbt run', 'version_check': 'True', 'debug': 'False', 'cache_selected_only': 'False'}
[0m19:13:25.876555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b6f973aa-1e52-45f7-8e40-622b8f07a972', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111379090>]}
[0m19:13:25.907960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b6f973aa-1e52-45f7-8e40-622b8f07a972', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110598310>]}
[0m19:13:25.908317 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:13:25.915041 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:13:25.920447 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:13:25.920745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b6f973aa-1e52-45f7-8e40-622b8f07a972', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115c9090>]}
[0m19:13:26.284691 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.campaign_names_mapping' which was not found
[0m19:13:26.285709 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.49869424, "process_user_time": 1.194139, "process_kernel_time": 0.087028, "process_mem_max_rss": "123961344", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:13:26.285957 [debug] [MainThread]: Command `dbt run` failed at 19:13:26.285902 after 0.50 seconds
[0m19:13:26.286152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110752e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111605a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111038910>]}
[0m19:13:26.286314 [debug] [MainThread]: Flushing usage events
[0m19:14:02.206893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113177c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131779d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111aa5ad0>]}


============================== 19:14:02.208764 | 340e1672-0899-47d9-b672-15092f4ae495 ==============================
[0m19:14:02.208764 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:14:02.209152 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'quiet': 'False', 'profiles_dir': '/Users/danila/.dbt', 'log_path': '/Users/danila/github/dbt/logs', 'partial_parse': 'True', 'target_path': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'no_print': 'None', 'write_json': 'True', 'warn_error': 'None', 'introspect': 'True', 'printer_width': '80', 'cache_selected_only': 'False', 'use_colors': 'True', 'version_check': 'True', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False'}
[0m19:14:02.281251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '340e1672-0899-47d9-b672-15092f4ae495', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c72090>]}
[0m19:14:02.311099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '340e1672-0899-47d9-b672-15092f4ae495', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113672690>]}
[0m19:14:02.311520 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:14:02.319209 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:14:02.324873 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:14:02.325189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '340e1672-0899-47d9-b672-15092f4ae495', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139053d0>]}
[0m19:14:02.687426 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.campaign_names_mapping' which was not found
[0m19:14:02.689518 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.50559705, "process_user_time": 1.174515, "process_kernel_time": 0.106441, "process_mem_max_rss": "124436480", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:14:02.689779 [debug] [MainThread]: Command `dbt run` failed at 19:14:02.689719 after 0.51 seconds
[0m19:14:02.689958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b6710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131743d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134e5cd0>]}
[0m19:14:02.690128 [debug] [MainThread]: Flushing usage events
[0m19:16:52.928015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f38fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d83e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f4f890>]}


============================== 19:16:52.929390 | 71e341ba-87b1-4a9d-9603-755684863732 ==============================
[0m19:16:52.929390 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:16:52.929703 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'no_print': 'None', 'quiet': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'debug': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'target_path': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'version_check': 'True', 'warn_error': 'None', 'printer_width': '80', 'log_format': 'default', 'indirect_selection': 'eager'}
[0m19:16:52.997245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '71e341ba-87b1-4a9d-9603-755684863732', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f83610>]}
[0m19:16:53.028057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '71e341ba-87b1-4a9d-9603-755684863732', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d6c610>]}
[0m19:16:53.028419 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:16:53.034899 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:16:53.040423 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:16:53.040712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '71e341ba-87b1-4a9d-9603-755684863732', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c6e3d0>]}
[0m19:16:53.417164 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.matomo_actions' which was not found
[0m19:16:53.418178 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5110858, "process_user_time": 1.200149, "process_kernel_time": 0.088562, "process_mem_max_rss": "123994112", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:16:53.418437 [debug] [MainThread]: Command `dbt run` failed at 19:16:53.418377 after 0.51 seconds
[0m19:16:53.418620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100f62710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107efda90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f4fc50>]}
[0m19:16:53.418803 [debug] [MainThread]: Flushing usage events
[0m19:17:13.460710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d76910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dc5390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ddbf10>]}


============================== 19:17:13.461892 | 33eaf512-5717-4d2c-9490-9306761a1db6 ==============================
[0m19:17:13.461892 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:17:13.462210 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs', 'introspect': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'target_path': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'no_print': 'None', 'write_json': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'printer_width': '80', 'debug': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None'}
[0m19:17:13.525914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33eaf512-5717-4d2c-9490-9306761a1db6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a219890>]}
[0m19:17:13.555467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33eaf512-5717-4d2c-9490-9306761a1db6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1dd050>]}
[0m19:17:13.555785 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:17:13.562115 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:17:13.567399 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:17:13.567697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '33eaf512-5717-4d2c-9490-9306761a1db6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a296550>]}
[0m19:17:13.927579 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.records_gap_campaigns' which was not found
[0m19:17:13.928611 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.48801166, "process_user_time": 1.161291, "process_kernel_time": 0.081912, "process_mem_max_rss": "123797504", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:17:13.928873 [debug] [MainThread]: Command `dbt run` failed at 19:17:13.928815 after 0.49 seconds
[0m19:17:13.929052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbe710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a439390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e03b10>]}
[0m19:17:13.929223 [debug] [MainThread]: Flushing usage events
[0m19:17:31.225538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108777ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e2dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e34d0>]}


============================== 19:17:31.226745 | 6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b ==============================
[0m19:17:31.226745 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:17:31.227066 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'quiet': 'False', 'static_parser': 'True', 'target_path': 'None', 'write_json': 'True', 'invocation_command': 'dbt run', 'indirect_selection': 'eager', 'partial_parse': 'True', 'introspect': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'version_check': 'True'}
[0m19:17:31.290724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087756d0>]}
[0m19:17:31.320306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d77150>]}
[0m19:17:31.320625 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:17:31.326956 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:17:31.332261 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:17:31.332549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ebd410>]}
[0m19:17:31.693164 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.campaign_names_mapping' which was not found
[0m19:17:31.694171 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.4886916, "process_user_time": 1.160946, "process_kernel_time": 0.082532, "process_mem_max_rss": "123305984", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:17:31.694426 [debug] [MainThread]: Command `dbt run` failed at 19:17:31.694369 after 0.49 seconds
[0m19:17:31.694607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e2b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1037be710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087c50d0>]}
[0m19:17:31.694778 [debug] [MainThread]: Flushing usage events
[0m19:18:09.281768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e06910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e55950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e48250>]}


============================== 19:18:09.283017 | d371243f-2b4c-4072-aa3c-d3c5092e1cae ==============================
[0m19:18:09.283017 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:18:09.283341 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'use_colors': 'True', 'warn_error': 'None', 'version_check': 'True', 'target_path': 'None', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'quiet': 'False', 'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'printer_width': '80'}
[0m19:18:09.347417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108316050>]}
[0m19:18:09.376797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c52090>]}
[0m19:18:09.377126 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:18:09.383780 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:18:09.396515 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:18:09.396729 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:18:09.397176 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:18:09.399662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e05390>]}
[0m19:18:09.405222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108441750>]}
[0m19:18:09.405480 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:18:09.405661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085bbe50>]}
[0m19:18:09.406837 [info ] [MainThread]: 
[0m19:18:09.407280 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:18:09.408037 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:18:09.412397 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:18:09.412572 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:18:09.412718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:18:10.325131 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m19:18:10.329309 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:18:10.334537 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:18:10.344245 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:18:10.344879 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:18:10.345278 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:18:11.018498 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m19:18:11.020128 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:18:11.020910 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:18:11.123846 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:18:11.128644 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:18:11.169462 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:18:11.185675 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:11.186400 [debug] [MainThread]: On master: BEGIN
[0m19:18:11.186825 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:18:11.840546 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m19:18:11.842577 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:11.843913 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:18:11.959994 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:18:11.965274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107130910>]}
[0m19:18:11.966603 [debug] [MainThread]: On master: ROLLBACK
[0m19:18:12.062845 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:12.064206 [debug] [MainThread]: On master: BEGIN
[0m19:18:12.198201 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:18:12.199882 [debug] [MainThread]: On master: COMMIT
[0m19:18:12.201122 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:12.202284 [debug] [MainThread]: On master: COMMIT
[0m19:18:12.249078 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:18:12.250692 [debug] [MainThread]: On master: Close
[0m19:18:12.253387 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:18:12.254258 [info ] [MainThread]: 
[0m19:18:12.261250 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m19:18:12.262237 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m19:18:12.263411 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m19:18:12.264010 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m19:18:12.277131 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.278134 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 19:18:12.264415 => 19:18:12.277902
[0m19:18:12.278511 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m19:18:12.303471 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.304252 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.304543 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m19:18:12.304768 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:12.609951 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:12.612104 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.614238 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m19:18:43.233642 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 31.0 seconds
[0m19:18:43.241263 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.241709 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m19:18:43.273502 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.278447 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.278838 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m19:18:43.309338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.326297 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:18:43.326661 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.326950 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:18:43.358093 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:43.363524 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m19:18:43.367380 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.367706 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m19:18:43.411053 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:43.412587 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 19:18:12.278717 => 19:18:43.412360
[0m19:18:43.413019 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m19:18:43.414013 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082a96d0>]}
[0m19:18:43.414680 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 31.15s]
[0m19:18:43.415324 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m19:18:43.415744 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m19:18:43.416266 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m19:18:43.417001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m19:18:43.417373 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m19:18:43.420201 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m19:18:43.420983 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 19:18:43.417600 => 19:18:43.420788
[0m19:18:43.421341 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m19:18:43.424707 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m19:18:43.425235 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.425516 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m19:18:43.425777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:43.713089 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:43.714417 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.715306 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:18:43.761756 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:18:43.770036 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.770971 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m19:18:43.802967 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.806926 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.807451 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m19:18:43.838155 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.843591 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:18:43.844483 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.845421 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:18:43.876264 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:43.882909 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m19:18:43.884777 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.885565 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m19:18:43.935117 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:43.938299 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 19:18:43.421541 => 19:18:43.937877
[0m19:18:43.939140 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m19:18:43.941711 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10844b690>]}
[0m19:18:43.942989 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.52s]
[0m19:18:43.944237 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m19:18:43.945215 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m19:18:43.946227 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m19:18:43.947330 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m19:18:43.947915 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m19:18:43.952903 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:43.954133 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 19:18:43.948300 => 19:18:43.953831
[0m19:18:43.954629 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m19:18:43.959834 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:43.960686 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:43.961071 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m19:18:43.961429 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:44.222185 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:44.224348 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.225325 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:18:44.274693 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:18:44.283800 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.284690 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m19:18:44.316708 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.322613 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.323414 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m19:18:44.355301 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.360416 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:18:44.361253 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.362001 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:18:44.393573 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:44.402393 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m19:18:44.403602 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.404067 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m19:18:44.456302 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:44.457427 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 19:18:43.954907 => 19:18:44.457290
[0m19:18:44.457691 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m19:18:44.458292 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086b2b50>]}
[0m19:18:44.458661 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.51s]
[0m19:18:44.459031 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m19:18:44.459296 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m19:18:44.459536 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m19:18:44.459908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m19:18:44.460124 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m19:18:44.461979 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m19:18:44.462677 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 19:18:44.460257 => 19:18:44.462489
[0m19:18:44.462936 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m19:18:44.465582 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m19:18:44.466042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.466255 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m19:18:44.466448 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:44.815890 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:44.817961 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.819478 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m19:18:44.871133 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m19:18:44.879668 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.880833 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m19:18:44.924132 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.931503 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.932107 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m19:18:44.974640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.979891 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:18:44.980796 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.981551 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:18:45.024244 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:45.031393 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m19:18:45.033247 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:45.034015 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m19:18:45.094472 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:45.099467 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 19:18:44.463097 => 19:18:45.098630
[0m19:18:45.100912 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m19:18:45.103006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f290>]}
[0m19:18:45.104112 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.64s]
[0m19:18:45.105200 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m19:18:45.105848 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.106881 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m19:18:45.107857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m19:18:45.108327 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.111842 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.112806 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 19:18:45.108615 => 19:18:45.112572
[0m19:18:45.113222 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.117492 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.118194 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.118518 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m19:18:45.118823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:45.446800 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:45.448938 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.450050 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m19:18:45.493039 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m19:18:45.501937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.502798 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m19:18:45.542952 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:45.548309 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.548852 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m19:18:45.587945 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:45.591877 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:18:45.592631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.593363 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:18:45.633313 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:45.639094 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m19:18:45.640321 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.641056 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m19:18:45.700051 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:45.705255 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 19:18:45.113453 => 19:18:45.704493
[0m19:18:45.706691 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m19:18:45.708808 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108449b10>]}
[0m19:18:45.709663 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.60s]
[0m19:18:45.710715 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.711273 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:45.711983 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m19:18:45.713068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:18:45.713581 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:45.719226 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:45.721583 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:18:45.713890 => 19:18:45.721342
[0m19:18:45.721964 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:45.727647 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:45.728238 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:45.728529 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:18:45.728800 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:46.030827 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:46.032653 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:46.033894 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m19:18:55.767915 [debug] [Thread-1 (]: SQL status: SELECT 153288 in 10.0 seconds
[0m19:18:55.776427 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:55.777447 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:18:55.851976 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:55.856219 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:55.856687 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:18:55.954922 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:55.959743 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:18:55.960561 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:55.961165 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:18:56.286352 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:56.292508 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m19:18:56.293991 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:56.294543 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:18:56.372490 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:56.374518 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:18:45.722195 => 19:18:56.374244
[0m19:18:56.375046 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:18:56.376231 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086c1bd0>]}
[0m19:18:56.376957 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153288[0m in 10.66s]
[0m19:18:56.377686 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:56.378219 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:18:56.378894 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m19:18:56.379736 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:18:56.380172 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:18:56.384619 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.386480 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:18:56.380427 => 19:18:56.386275
[0m19:18:56.386823 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:18:56.390640 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.391187 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.391469 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:18:56.391740 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:56.907388 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:18:56.908096 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.908769 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:19:03.754421 [debug] [Thread-1 (]: SQL status: SELECT 45890 in 7.0 seconds
[0m19:19:03.762496 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.763214 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:19:03.795503 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:03.801018 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.801880 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:19:03.841646 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:03.846346 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:19:03.847171 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.847902 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:19:03.893569 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:03.900281 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:19:03.902026 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.902797 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:19:03.960780 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:03.965618 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:18:56.387028 => 19:19:03.965316
[0m19:19:03.966236 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:19:03.967789 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10864a550>]}
[0m19:19:03.968668 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45890[0m in 7.59s]
[0m19:19:03.969783 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:19:03.970548 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m19:19:03.971243 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m19:19:03.972145 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m19:19:03.972610 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m19:19:03.976481 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m19:19:03.977433 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 19:19:03.972899 => 19:19:03.977190
[0m19:19:03.977841 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m19:19:03.993411 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m19:19:03.993982 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:03.994235 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m19:19:03.994485 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:04.636149 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:19:04.638109 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.639603 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m19:19:04.700570 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:19:04.709111 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.709728 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m19:19:04.775000 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:04.785143 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.786021 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m19:19:04.837502 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:04.889598 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:19:04.889914 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.890129 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:19:04.984689 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:04.987834 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m19:19:04.991310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.991726 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m19:19:05.076225 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:19:05.080156 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 19:19:03.978078 => 19:19:05.079708
[0m19:19:05.080902 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m19:19:05.082810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086bc390>]}
[0m19:19:05.083806 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 1.11s]
[0m19:19:05.084698 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m19:19:05.085320 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m19:19:05.086319 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m19:19:05.087461 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m19:19:05.088000 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m19:19:05.091524 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m19:19:05.092585 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 19:19:05.088305 => 19:19:05.092338
[0m19:19:05.092995 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m19:19:05.097530 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m19:19:05.098218 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:05.098549 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m19:19:05.098843 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:07.595690 [debug] [Thread-1 (]: SQL status: BEGIN in 2.0 seconds
[0m19:19:07.597732 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.599395 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m19:19:07.769142 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:19:07.777649 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.778229 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m19:19:07.832736 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:07.839297 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.839978 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m19:19:07.900943 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:07.906539 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:19:07.907419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.908329 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:19:07.997965 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:08.005464 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m19:19:08.007390 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:08.008240 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m19:19:08.151114 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:08.155451 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 19:19:05.093246 => 19:19:08.155024
[0m19:19:08.156323 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m19:19:08.158274 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10869d050>]}
[0m19:19:08.159418 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 3.07s]
[0m19:19:08.160322 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m19:19:08.161039 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m19:19:08.161879 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m19:19:08.162970 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m19:19:08.163519 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m19:19:08.169470 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.170677 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 19:19:08.163966 => 19:19:08.170373
[0m19:19:08.171174 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m19:19:08.176198 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.177038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.177383 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m19:19:08.177692 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:08.912645 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:19:08.916258 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.917165 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m19:19:09.188480 [debug] [Thread-1 (]: SQL status: SELECT 56722 in 0.0 seconds
[0m19:19:09.197291 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.198137 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m19:19:09.235089 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:09.241503 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.242199 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m19:19:09.285064 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:09.289989 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:19:09.290817 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.291574 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:19:09.426145 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:09.431733 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m19:19:09.433033 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.433814 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m19:19:09.540961 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:09.546128 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 19:19:08.171455 => 19:19:09.545381
[0m19:19:09.547386 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m19:19:09.549378 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10863dcd0>]}
[0m19:19:09.550534 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 56722[0m in 1.39s]
[0m19:19:09.551752 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m19:19:09.552611 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m19:19:09.553700 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m19:19:09.554760 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m19:19:09.555307 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m19:19:09.563936 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.565347 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 19:19:09.555631 => 19:19:09.565069
[0m19:19:09.565783 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m19:19:09.570580 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.571240 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.571578 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m19:19:09.571888 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:09.936313 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:19:09.937635 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.939251 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m19:19:09.980481 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:19:09.988513 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.989520 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m19:19:10.031030 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:10.035070 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:19:10.035860 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:10.036595 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:19:10.073796 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:10.079468 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m19:19:10.081336 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:10.082061 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m19:19:10.130279 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:19:10.132192 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 19:19:09.566031 => 19:19:10.131927
[0m19:19:10.132689 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m19:19:10.133736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10844e750>]}
[0m19:19:10.134345 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.58s]
[0m19:19:10.134953 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m19:19:10.135422 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.135922 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m19:19:10.136582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m19:19:10.136967 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.140022 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.140644 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 19:19:10.137205 => 19:19:10.140458
[0m19:19:10.140967 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.144884 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.145733 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.146093 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m19:19:10.146381 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:10.456770 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:19:10.458062 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.458753 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m19:19:10.517213 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m19:19:10.525378 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.525972 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m19:19:10.557215 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:10.562720 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.563494 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m19:19:10.595920 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:10.601941 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:19:10.602714 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.603424 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:19:10.634770 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:10.641286 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m19:19:10.642554 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.643138 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m19:19:10.695293 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:10.699396 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 19:19:10.141162 => 19:19:10.699127
[0m19:19:10.699910 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m19:19:10.701412 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085136d0>]}
[0m19:19:10.702395 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.56s]
[0m19:19:10.703119 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.704846 [debug] [MainThread]: Using postgres connection "master"
[0m19:19:10.705252 [debug] [MainThread]: On master: BEGIN
[0m19:19:10.705574 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:19:10.959314 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:19:10.961183 [debug] [MainThread]: On master: COMMIT
[0m19:19:10.962135 [debug] [MainThread]: Using postgres connection "master"
[0m19:19:10.962857 [debug] [MainThread]: On master: COMMIT
[0m19:19:10.993416 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:19:10.994931 [debug] [MainThread]: On master: Close
[0m19:19:10.997327 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:19:10.998009 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m19:19:10.998909 [info ] [MainThread]: 
[0m19:19:10.999714 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 1 minutes and 1.59 seconds (61.59s).
[0m19:19:11.003365 [debug] [MainThread]: Command end result
[0m19:19:11.018847 [info ] [MainThread]: 
[0m19:19:11.019361 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:19:11.019678 [info ] [MainThread]: 
[0m19:19:11.020017 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m19:19:11.023095 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 61.762623, "process_user_time": 1.765803, "process_kernel_time": 0.19053, "process_mem_max_rss": "130023424", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:19:11.023657 [debug] [MainThread]: Command `dbt run` succeeded at 19:19:11.023531 after 61.76 seconds
[0m19:19:11.024030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e4e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108289a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d801d0>]}
[0m19:19:11.024381 [debug] [MainThread]: Flushing usage events
[0m19:19:43.075981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106deb990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104553e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e5f890>]}


============================== 19:19:43.077433 | 4335b8d5-fe91-45f4-bb26-0b2151a9c8e1 ==============================
[0m19:19:43.077433 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:19:43.077756 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'write_json': 'True', 'no_print': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'version_check': 'True', 'target_path': 'None', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'quiet': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m19:19:43.146234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4335b8d5-fe91-45f4-bb26-0b2151a9c8e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c6750>]}
[0m19:19:43.178022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4335b8d5-fe91-45f4-bb26-0b2151a9c8e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071c6e90>]}
[0m19:19:43.179346 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:19:43.186255 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:19:43.191547 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:19:43.191850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4335b8d5-fe91-45f4-bb26-0b2151a9c8e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073c55d0>]}
[0m19:19:43.568159 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.matomo_visits' which was not found
[0m19:19:43.569172 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5151364, "process_user_time": 1.186117, "process_kernel_time": 0.097423, "process_mem_max_rss": "123764736", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:19:43.569425 [debug] [MainThread]: Command `dbt run` failed at 19:19:43.569367 after 0.52 seconds
[0m19:19:43.569606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101232710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e7afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e39cd0>]}
[0m19:19:43.569770 [debug] [MainThread]: Flushing usage events
[0m19:20:18.689997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106153390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061a3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b7590>]}


============================== 19:20:18.691300 | 537ed143-9187-4149-97a0-5d164a8f1242 ==============================
[0m19:20:18.691300 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:20:18.691610 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'no_print': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'static_parser': 'True', 'log_format': 'default', 'debug': 'False'}
[0m19:20:18.755662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061eb150>]}
[0m19:20:18.785229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066a7b10>]}
[0m19:20:18.785557 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:20:18.791994 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:20:18.805150 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:20:18.805366 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:20:18.805809 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:20:18.808607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106654fd0>]}
[0m19:20:18.813506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e0550>]}
[0m19:20:18.813744 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:20:18.813924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065c66d0>]}
[0m19:20:18.814616 [info ] [MainThread]: 
[0m19:20:18.814988 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:20:18.815513 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:20:18.819720 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:20:18.819923 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:20:18.820075 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:20:19.285666 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:20:19.290074 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:20:19.295057 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:20:19.304418 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:20:19.305120 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:20:19.305539 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:20:19.668964 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:20:19.670137 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:20:19.670849 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:20:19.719834 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:20:19.723226 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:20:19.782668 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:20:19.796717 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:19.797256 [debug] [MainThread]: On master: BEGIN
[0m19:20:19.797608 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:20:20.218294 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:20:20.219529 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:20.220307 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:20:20.325486 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:20:20.329576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c0250>]}
[0m19:20:20.330439 [debug] [MainThread]: On master: ROLLBACK
[0m19:20:20.380408 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:20.381300 [debug] [MainThread]: On master: BEGIN
[0m19:20:20.461447 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:20:20.463236 [debug] [MainThread]: On master: COMMIT
[0m19:20:20.464142 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:20.464793 [debug] [MainThread]: On master: COMMIT
[0m19:20:20.536784 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:20:20.537279 [debug] [MainThread]: On master: Close
[0m19:20:20.538556 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:20:20.539022 [info ] [MainThread]: 
[0m19:20:20.543036 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:20:20.543700 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:20:20.544604 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:20:20.545017 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:20:20.552500 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:20:20.553217 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:20:20.545303 => 19:20:20.553036
[0m19:20:20.553517 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:20:20.577379 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:20:20.577895 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:20.578115 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:20:20.578312 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:20:21.066744 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:20:21.068667 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:21.069945 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:20:27.621223 [debug] [Thread-1 (]: SQL status: SELECT 45890 in 7.0 seconds
[0m19:20:27.634156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.634853 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:20:27.734849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:20:27.742342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.742967 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:20:27.799674 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:20:27.830530 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:20:27.830980 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.831318 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:20:27.927583 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:20:27.941333 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:20:27.948478 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.949094 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:20:28.030283 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:20:28.035601 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:20:20.553698 => 19:20:28.035041
[0m19:20:28.036573 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:20:28.038975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661f090>]}
[0m19:20:28.040485 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45890[0m in 7.49s]
[0m19:20:28.041687 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:20:28.044392 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:28.045123 [debug] [MainThread]: On master: BEGIN
[0m19:20:28.045679 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:20:28.924955 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m19:20:28.926768 [debug] [MainThread]: On master: COMMIT
[0m19:20:28.927582 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:28.928296 [debug] [MainThread]: On master: COMMIT
[0m19:20:28.976572 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:20:28.977552 [debug] [MainThread]: On master: Close
[0m19:20:28.979581 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:20:28.980256 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:20:28.981046 [info ] [MainThread]: 
[0m19:20:28.981840 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 10.17 seconds (10.17s).
[0m19:20:28.983214 [debug] [MainThread]: Command end result
[0m19:20:28.998007 [info ] [MainThread]: 
[0m19:20:28.998803 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:20:28.999159 [info ] [MainThread]: 
[0m19:20:28.999553 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:20:29.002012 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 10.332784, "process_user_time": 1.076476, "process_kernel_time": 0.119128, "process_mem_max_rss": "128073728", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:20:29.002628 [debug] [MainThread]: Command `dbt run` succeeded at 19:20:29.002499 after 10.33 seconds
[0m19:20:29.003064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10119a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10119a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1011116d0>]}
[0m19:20:29.003456 [debug] [MainThread]: Flushing usage events
[0m19:20:59.466501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bfd490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055591d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c6b450>]}


============================== 19:20:59.467784 | ac0ac777-5ae7-4daf-a900-067f25c8440d ==============================
[0m19:20:59.467784 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:20:59.468089 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'write_json': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'printer_width': '80', 'invocation_command': 'dbt run -m outclick_cost_int', 'debug': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'version_check': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'fail_fast': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m19:20:59.533038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060bf7d0>]}
[0m19:20:59.562436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c41890>]}
[0m19:20:59.562766 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:20:59.569302 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:20:59.582011 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:20:59.582229 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:20:59.582674 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:20:59.585179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca16d0>]}
[0m19:20:59.590320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060e5a10>]}
[0m19:20:59.590563 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:20:59.590736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063b3e50>]}
[0m19:20:59.591419 [info ] [MainThread]: 
[0m19:20:59.591832 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:20:59.592429 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:20:59.596900 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:20:59.597095 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:20:59.597261 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:21:00.684118 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m19:21:00.688102 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:21:00.692573 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:21:00.702078 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:21:00.702805 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:21:00.703245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:21:01.163543 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:21:01.165839 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:21:01.167379 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:21:01.202129 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:21:01.205809 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:21:01.257530 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:21:01.272621 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.273163 [debug] [MainThread]: On master: BEGIN
[0m19:21:01.273559 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:21:01.645130 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:21:01.646820 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.647685 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:21:01.701350 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:21:01.706333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106062b50>]}
[0m19:21:01.707140 [debug] [MainThread]: On master: ROLLBACK
[0m19:21:01.744622 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.745331 [debug] [MainThread]: On master: BEGIN
[0m19:21:01.816802 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:21:01.817507 [debug] [MainThread]: On master: COMMIT
[0m19:21:01.817952 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.818356 [debug] [MainThread]: On master: COMMIT
[0m19:21:01.851594 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:21:01.852520 [debug] [MainThread]: On master: Close
[0m19:21:01.854353 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:21:01.854961 [info ] [MainThread]: 
[0m19:21:01.861040 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:21:01.861768 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:21:01.862727 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:21:01.863217 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:21:01.871891 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:21:01.872673 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:21:01.863516 => 19:21:01.872460
[0m19:21:01.873026 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:21:01.898315 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:21:01.898850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:01.899082 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:21:01.899294 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:21:02.194934 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:21:02.197106 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:02.198796 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:21:07.144599 [debug] [Thread-1 (]: SQL status: SELECT 45890 in 5.0 seconds
[0m19:21:07.157115 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.158097 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:21:07.199561 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:21:07.206110 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.207003 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:21:07.240766 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:21:07.267776 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:21:07.268248 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.268597 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:21:07.301887 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:21:07.307759 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:21:07.311575 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.311895 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:21:07.412833 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:21:07.417470 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:21:01.873228 => 19:21:07.417006
[0m19:21:07.418369 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:21:07.420623 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106413950>]}
[0m19:21:07.421925 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45890[0m in 5.56s]
[0m19:21:07.422941 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:21:07.425585 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:07.426176 [debug] [MainThread]: On master: BEGIN
[0m19:21:07.426631 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:21:07.923783 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:21:07.924135 [debug] [MainThread]: On master: COMMIT
[0m19:21:07.924351 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:07.924552 [debug] [MainThread]: On master: COMMIT
[0m19:21:07.997310 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:21:07.997731 [debug] [MainThread]: On master: Close
[0m19:21:07.998692 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:21:07.999064 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:21:07.999497 [info ] [MainThread]: 
[0m19:21:07.999928 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 8.41 seconds (8.41s).
[0m19:21:08.000716 [debug] [MainThread]: Command end result
[0m19:21:08.009824 [info ] [MainThread]: 
[0m19:21:08.010204 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:21:08.010482 [info ] [MainThread]: 
[0m19:21:08.010794 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:21:08.013422 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.56893, "process_user_time": 1.033299, "process_kernel_time": 0.110566, "process_mem_max_rss": "129433600", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:21:08.014083 [debug] [MainThread]: Command `dbt run` succeeded at 19:21:08.013954 after 8.57 seconds
[0m19:21:08.014474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10620ec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10562ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c69bd0>]}
[0m19:21:08.014822 [debug] [MainThread]: Flushing usage events
[0m19:33:44.240583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3e9290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a43add0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a45f310>]}


============================== 19:33:44.242513 | 848244b4-5945-4dea-a12a-5dadfe5015ed ==============================
[0m19:33:44.242513 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:33:44.242861 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'quiet': 'False', 'version_check': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'invocation_command': 'dbt run -m outclick_cost_int', 'no_print': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'partial_parse': 'True', 'target_path': 'None', 'use_colors': 'True', 'warn_error': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'use_experimental_parser': 'False'}
[0m19:33:44.317580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '848244b4-5945-4dea-a12a-5dadfe5015ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7eb150>]}
[0m19:33:44.347313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '848244b4-5945-4dea-a12a-5dadfe5015ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3f3210>]}
[0m19:33:44.347808 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:33:44.355000 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:33:44.368081 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m19:33:44.368406 [debug] [MainThread]: Partial parsing: added file: campaign_perfomance://models/brand_performance/schema.yml
[0m19:33:44.368596 [debug] [MainThread]: Partial parsing: updated file: campaign_perfomance://models/brand_performance/outclick_cost_int.sql
[0m19:33:44.442843 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "brand_performance_deals".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("brand_performance", "deals").
  
  To fix this, change the name of one of these resources:
  - source.campaign_perfomance.brand_performance.deals (models/brand_performance/schema.yml)
  - source.campaign_perfomance.brand_performance.deals (models/brand_performance/source.yml)
[0m19:33:44.445197 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.2280547, "process_user_time": 0.89629, "process_kernel_time": 0.105185, "process_mem_max_rss": "124649472", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:33:44.445561 [debug] [MainThread]: Command `dbt run` failed at 19:33:44.445495 after 0.23 seconds
[0m19:33:44.445759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10490a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048816d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5270d0>]}
[0m19:33:44.445952 [debug] [MainThread]: Flushing usage events
[0m19:34:01.793514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b2610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b1510>]}


============================== 19:34:01.794794 | 0f3c5916-97fb-46de-8c73-1a273418c7da ==============================
[0m19:34:01.794794 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:34:01.795118 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'debug': 'False', 'log_cache_events': 'False', 'use_colors': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'indirect_selection': 'eager', 'version_check': 'True', 'printer_width': '80', 'warn_error': 'None', 'introspect': 'True', 'partial_parse': 'True', 'quiet': 'False', 'write_json': 'True', 'fail_fast': 'False', 'target_path': 'None', 'no_print': 'None', 'log_path': '/Users/danila/github/dbt/logs'}
[0m19:34:01.859380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105994590>]}
[0m19:34:01.888996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f72d10>]}
[0m19:34:01.889339 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:34:01.896205 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:34:01.908962 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:01.909176 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:01.909623 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:34:01.912169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052bd5d0>]}
[0m19:34:01.918363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f9150>]}
[0m19:34:01.918634 [info ] [MainThread]: Found 12 models, 6 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:34:01.918813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e61410>]}
[0m19:34:01.919548 [info ] [MainThread]: 
[0m19:34:01.919936 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:34:01.920477 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:34:01.925040 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:34:01.925241 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:34:01.925403 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:02.341039 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:34:02.345624 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:34:02.350749 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:34:02.360783 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:34:02.361410 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:34:02.361800 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:34:02.688149 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:34:02.690050 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:34:02.691315 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:34:02.735160 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:34:02.740644 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:34:02.780499 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:34:02.798842 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:02.799371 [debug] [MainThread]: On master: BEGIN
[0m19:34:02.799751 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:03.060224 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:34:03.062157 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.063839 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:34:03.106022 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:34:03.111829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101d4c8d0>]}
[0m19:34:03.112728 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:03.143397 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.144305 [debug] [MainThread]: On master: BEGIN
[0m19:34:03.206464 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:34:03.208037 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.208937 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.209634 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.241277 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:34:03.242158 [debug] [MainThread]: On master: Close
[0m19:34:03.244231 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:03.244953 [info ] [MainThread]: 
[0m19:34:03.251407 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:34:03.252544 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:34:03.253841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:34:03.254484 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:34:03.267651 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:34:03.254944 => 19:34:03.267249
[0m19:34:03.272747 [debug] [Thread-1 (]: Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m19:34:03.273262 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fcf210>]}
[0m19:34:03.273816 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model danila.outclick_cost_int ................. [[31mERROR[0m in 0.02s]
[0m19:34:03.274333 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:34:03.275490 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.275744 [debug] [MainThread]: On master: BEGIN
[0m19:34:03.275972 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:03.551962 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:34:03.553830 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.555033 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.556180 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.590199 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:34:03.592045 [debug] [MainThread]: On master: Close
[0m19:34:03.594141 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:03.594758 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:34:03.595473 [info ] [MainThread]: 
[0m19:34:03.596178 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.68 seconds (1.68s).
[0m19:34:03.597435 [debug] [MainThread]: Command end result
[0m19:34:03.612923 [info ] [MainThread]: 
[0m19:34:03.613485 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:34:03.613831 [info ] [MainThread]: 
[0m19:34:03.614173 [error] [MainThread]:   Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m19:34:03.614519 [info ] [MainThread]: 
[0m19:34:03.614889 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:34:03.617046 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 1.8445531, "process_user_time": 0.983938, "process_kernel_time": 0.112046, "process_mem_max_rss": "128581632", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:03.617676 [debug] [MainThread]: Command `dbt run` failed at 19:34:03.617546 after 1.85 seconds
[0m19:34:03.618138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105222490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c7390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009aa790>]}
[0m19:34:03.618493 [debug] [MainThread]: Flushing usage events
[0m19:36:15.311760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129e9710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a55c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a56d50>]}


============================== 19:36:15.313070 | 203fa131-ae22-415c-8451-c481be0a34e7 ==============================
[0m19:36:15.313070 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:36:15.313396 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'quiet': 'False', 'log_format': 'default', 'debug': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'static_parser': 'True', 'fail_fast': 'False', 'introspect': 'True', 'write_json': 'True', 'printer_width': '80', 'invocation_command': 'dbt deps', 'version_check': 'True'}
[0m19:36:15.347373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '203fa131-ae22-415c-8451-c481be0a34e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112aff150>]}
[0m19:36:15.348126 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-k7dvyc_i'
[0m19:36:15.348372 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:36:15.469361 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:36:15.470772 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:36:15.676120 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:36:15.680912 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:36:15.681591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '203fa131-ae22-415c-8451-c481be0a34e7', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b1ba50>]}
[0m19:36:15.687754 [info ] [MainThread]: Updating lock file in file path: /Users/danila/github/dbt/package-lock.yml
[0m19:36:15.689493 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-ccli1z6a'
[0m19:36:15.691803 [info ] [MainThread]: Installing fishtown-analytics/dbt_utils
[0m19:36:16.336391 [info ] [MainThread]: Installed from version 0.7.0
[0m19:36:16.336688 [info ] [MainThread]: Up to date!
[0m19:36:16.336925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '203fa131-ae22-415c-8451-c481be0a34e7', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129f35d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ae7790>]}
[0m19:36:16.338285 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.0485277, "process_user_time": 0.833093, "process_kernel_time": 0.10982, "process_mem_max_rss": "117899264", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:36:16.338614 [debug] [MainThread]: Command `dbt deps` succeeded at 19:36:16.338540 after 1.05 seconds
[0m19:36:16.338838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117e6590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a56d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100102d0>]}
[0m19:36:16.339048 [debug] [MainThread]: Flushing usage events
[0m19:36:22.581509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109925110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109927850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109943490>]}


============================== 19:36:22.582753 | 3728903c-4a0f-46e1-b294-f78b50791534 ==============================
[0m19:36:22.582753 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:36:22.583095 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'fail_fast': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'invocation_command': 'dbt run -m outclick_cost_int', 'use_experimental_parser': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'use_colors': 'True', 'static_parser': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'debug': 'False', 'version_check': 'True', 'printer_width': '80', 'target_path': 'None', 'write_json': 'True'}
[0m19:36:22.647118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3728903c-4a0f-46e1-b294-f78b50791534', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996c950>]}
[0m19:36:22.676628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3728903c-4a0f-46e1-b294-f78b50791534', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e4950>]}
[0m19:36:22.676979 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:36:22.684138 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =1.7.0
      Required version of dbt for 'dbt_utils': ['>=0.20.0', '<0.21.0']
    Check for a different version of the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils/dbt_project.yml

Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils
[0m19:36:22.685272 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.12385917, "process_user_time": 0.800731, "process_kernel_time": 0.076541, "process_mem_max_rss": "117080064", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:36:22.685589 [debug] [MainThread]: Command `dbt run` failed at 19:36:22.685524 after 0.12 seconds
[0m19:36:22.685812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109943950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10491e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996c8d0>]}
[0m19:36:22.686046 [debug] [MainThread]: Flushing usage events
[0m19:36:46.542801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10785e910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078d2790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078d2e90>]}


============================== 19:36:46.544338 | 47d772f3-be1b-42c5-b317-59b492db4fbc ==============================
[0m19:36:46.544338 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:36:46.544664 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'invocation_command': 'dbt deps', 'use_colors': 'True', 'version_check': 'True', 'warn_error': 'None', 'write_json': 'True', 'quiet': 'False', 'no_print': 'None', 'profiles_dir': '/Users/danila/.dbt', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'log_format': 'default'}
[0m19:36:46.578202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47d772f3-be1b-42c5-b317-59b492db4fbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10796fa90>]}
[0m19:36:46.579160 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-85t472to'
[0m19:36:46.579401 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:36:46.629731 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:36:46.630674 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:36:46.668290 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:36:46.669362 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:36:46.669573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '47d772f3-be1b-42c5-b317-59b492db4fbc', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078f7690>]}
[0m19:36:46.670523 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package fishtown-analytics/dbt_utils
  Requested range: =0.20.0, =0.20.0
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.5.1', '0.6.0', '0.6.1', '0.6.2', '0.6.3', '0.6.4', '0.6.5', '0.6.6', '0.7.0']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:36:46.672380 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.15191038, "process_user_time": 0.766156, "process_kernel_time": 0.084368, "process_mem_max_rss": "117456896", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:36:46.672682 [debug] [MainThread]: Command `dbt deps` failed at 19:36:46.672615 after 0.15 seconds
[0m19:36:46.672872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078d3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071b9b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1028a66d0>]}
[0m19:36:46.673049 [debug] [MainThread]: Flushing usage events
[0m19:41:36.731717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151e8ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1152339d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11525ed50>]}


============================== 19:41:36.733779 | f58a8b25-d6aa-4f6e-ae68-051433c19f95 ==============================
[0m19:41:36.733779 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:41:36.734200 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'invocation_command': 'dbt deps', 'profiles_dir': '/Users/danila/.dbt', 'log_format': 'default', 'version_check': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'printer_width': '80', 'use_colors': 'True', 'write_json': 'True', 'target_path': 'None', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'no_print': 'None'}
[0m19:41:36.771551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f58a8b25-d6aa-4f6e-ae68-051433c19f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11525e510>]}
[0m19:41:36.772522 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-qzfwe3wp'
[0m19:41:36.772784 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:41:36.882235 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:41:36.883510 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:41:37.263776 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:41:37.270405 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:41:37.271417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'f58a8b25-d6aa-4f6e-ae68-051433c19f95', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115317e90>]}
[0m19:41:37.275159 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package fishtown-analytics/dbt_utils
  Requested range: =2.6.2, =2.6.2
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.5.1', '0.6.0', '0.6.1', '0.6.2', '0.6.3', '0.6.4', '0.6.5', '0.6.6', '0.7.0']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:41:37.280176 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.57329375, "process_user_time": 0.782675, "process_kernel_time": 0.103694, "process_mem_max_rss": "119275520", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:41:37.281339 [debug] [MainThread]: Command `dbt deps` failed at 19:41:37.281012 after 0.57 seconds
[0m19:41:37.281988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f014d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11525f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f8a6d0>]}
[0m19:41:37.282497 [debug] [MainThread]: Flushing usage events
[0m19:42:59.304348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106700a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106750250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676f0d0>]}


============================== 19:42:59.306220 | 8145626e-de7b-4b00-bf55-06abcc22bf64 ==============================
[0m19:42:59.306220 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:42:59.306558 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'introspect': 'True', 'no_print': 'None', 'log_format': 'default', 'debug': 'False', 'log_cache_events': 'False', 'target_path': 'None', 'use_colors': 'True', 'printer_width': '80', 'partial_parse': 'True', 'indirect_selection': 'eager', 'quiet': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False'}
[0m19:42:59.345045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8145626e-de7b-4b00-bf55-06abcc22bf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10453da10>]}
[0m19:42:59.346025 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-_ohnk1pp'
[0m19:42:59.346315 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:42:59.449737 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:42:59.450902 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:42:59.641532 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:42:59.647037 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:42:59.647975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '8145626e-de7b-4b00-bf55-06abcc22bf64', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067f7e10>]}
[0m19:42:59.651423 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package fishtown-analytics/dbt_utils
  Requested range: =2.6.2, =2.6.2
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.5.1', '0.6.0', '0.6.1', '0.6.2', '0.6.3', '0.6.4', '0.6.5', '0.6.6', '0.7.0']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:42:59.656106 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.37705475, "process_user_time": 0.797001, "process_kernel_time": 0.097975, "process_mem_max_rss": "117981184", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:42:59.657086 [debug] [MainThread]: Command `dbt deps` failed at 19:42:59.656881 after 0.38 seconds
[0m19:42:59.657621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10174a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1016c1510>]}
[0m19:42:59.658111 [debug] [MainThread]: Flushing usage events
[0m19:43:15.150524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a070e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0de1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0de8d0>]}


============================== 19:43:15.151854 | 51a88c38-80c5-4773-b2cc-881c9bf76a67 ==============================
[0m19:43:15.151854 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:43:15.152170 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'no_print': 'None', 'debug': 'False', 'warn_error': 'None', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'quiet': 'False', 'target_path': 'None', 'write_json': 'True', 'profiles_dir': '/Users/danila/.dbt', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default'}
[0m19:43:15.185065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '51a88c38-80c5-4773-b2cc-881c9bf76a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a11c4d0>]}
[0m19:43:15.196670 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-4adp7v20'
[0m19:43:15.196928 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:43:15.240092 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:43:15.241014 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:43:15.277281 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:43:15.278528 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:43:15.278765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '51a88c38-80c5-4773-b2cc-881c9bf76a67', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0c6750>]}
[0m19:43:15.279826 [info ] [MainThread]: Installing fishtown-analytics/dbt_utils
[0m19:43:16.016643 [info ] [MainThread]: Installed from version 0.7.0
[0m19:43:16.016940 [info ] [MainThread]: Up to date!
[0m19:43:16.017192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '51a88c38-80c5-4773-b2cc-881c9bf76a67', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a072350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a15f650>]}
[0m19:43:16.018573 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.8881659, "process_user_time": 0.789453, "process_kernel_time": 0.122442, "process_mem_max_rss": "118980608", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:43:16.018918 [debug] [MainThread]: Command `dbt deps` succeeded at 19:43:16.018839 after 0.89 seconds
[0m19:43:16.019145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0de750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0dee90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0ff490>]}
[0m19:43:16.019354 [debug] [MainThread]: Flushing usage events
[0m19:43:22.059235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e90a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eb3410>]}


============================== 19:43:22.060477 | ed66f062-4a00-433a-9c8c-88ee7ca95fbc ==============================
[0m19:43:22.060477 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:43:22.060796 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'log_format': 'default', 'no_print': 'None', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt', 'warn_error': 'None', 'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'write_json': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'fail_fast': 'False', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m19:43:22.130549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed66f062-4a00-433a-9c8c-88ee7ca95fbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062eea10>]}
[0m19:43:22.160136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed66f062-4a00-433a-9c8c-88ee7ca95fbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e90450>]}
[0m19:43:22.160840 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:43:22.169336 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =1.7.0
      Required version of dbt for 'dbt_utils': ['>=0.20.0', '<0.21.0']
    Check for a different version of the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils/dbt_project.yml

Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils
[0m19:43:22.170505 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.13210842, "process_user_time": 0.800864, "process_kernel_time": 0.076938, "process_mem_max_rss": "117407744", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:43:22.170862 [debug] [MainThread]: Command `dbt run` failed at 19:43:22.170790 after 0.13 seconds
[0m19:43:22.171140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057121d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100dc8290>]}
[0m19:43:22.171392 [debug] [MainThread]: Flushing usage events
[0m19:44:36.963557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a33f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a81e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9f0d0>]}


============================== 19:44:36.965161 | 0fa99d17-7359-4ec8-89bc-1da9f439c740 ==============================
[0m19:44:36.965161 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:44:36.965489 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'printer_width': '80', 'warn_error': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'use_colors': 'True', 'log_format': 'default', 'version_check': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt deps', 'cache_selected_only': 'False', 'no_print': 'None', 'target_path': 'None', 'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'write_json': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs'}
[0m19:44:37.000164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0fa99d17-7359-4ec8-89bc-1da9f439c740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a40250>]}
[0m19:44:37.011289 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-yf_t8p7j'
[0m19:44:37.011551 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:44:37.185068 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:44:37.187014 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:44:37.438848 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:44:37.444724 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:44:37.445509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0fa99d17-7359-4ec8-89bc-1da9f439c740', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9e050>]}
[0m19:44:37.448448 [info ] [MainThread]: Installing fishtown-analytics/dbt_utils
[0m19:44:37.942134 [info ] [MainThread]: Installed from version 0.7.0
[0m19:44:37.942433 [info ] [MainThread]: Up to date!
[0m19:44:37.942674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '0fa99d17-7359-4ec8-89bc-1da9f439c740', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b1b690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b5db50>]}
[0m19:44:37.944587 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.0035342, "process_user_time": 0.842155, "process_kernel_time": 0.140499, "process_mem_max_rss": "121225216", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:44:37.944962 [debug] [MainThread]: Command `dbt deps` succeeded at 19:44:37.944878 after 1.00 seconds
[0m19:44:37.945200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a7a650>]}
[0m19:44:37.945426 [debug] [MainThread]: Flushing usage events
[0m19:45:35.040648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113cfbad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ce9150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11368ed10>]}


============================== 19:45:35.041983 | ba78e6f3-b477-473e-b608-d3a11723e026 ==============================
[0m19:45:35.041983 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:45:35.042316 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'invocation_command': 'dbt deps', 'version_check': 'True', 'use_colors': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'introspect': 'True', 'warn_error': 'None', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt'}
[0m19:45:35.075619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba78e6f3-b477-473e-b608-d3a11723e026', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113381a10>]}
[0m19:45:35.076539 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-q3kk5vmt'
[0m19:45:35.076778 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:45:35.173519 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:45:35.174694 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m19:45:35.263601 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m19:45:35.268217 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package dbt-labs/dbt_utils
  Requested range: =0.6.4, =0.6.4
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.8.0', '0.8.1', '0.8.2', '0.8.3', '0.8.4', '0.8.5', '0.8.6', '0.9.0', '0.9.1', '0.9.2', '0.9.5', '0.9.6', '1.0.0', '1.1.0', '1.1.1']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:45:35.269873 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.25079504, "process_user_time": 0.764574, "process_kernel_time": 0.089649, "process_mem_max_rss": "118063104", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:45:35.270368 [debug] [MainThread]: Command `dbt deps` failed at 19:45:35.270248 after 0.25 seconds
[0m19:45:35.270693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d57190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10577d4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11324c350>]}
[0m19:45:35.270999 [debug] [MainThread]: Flushing usage events
[0m19:45:51.738302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b6210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661a690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661ad90>]}


============================== 19:45:51.739511 | 6f52328f-965e-4f80-8b7f-45954d048f1d ==============================
[0m19:45:51.739511 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:45:51.739862 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'introspect': 'True', 'quiet': 'False', 'invocation_command': 'dbt deps', 'debug': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'no_print': 'None', 'log_format': 'default', 'warn_error': 'None', 'cache_selected_only': 'False', 'version_check': 'True', 'write_json': 'True', 'fail_fast': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False'}
[0m19:45:51.773865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f52328f-965e-4f80-8b7f-45954d048f1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10663e610>]}
[0m19:45:51.775508 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-85lf1z07'
[0m19:45:51.775762 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:45:51.862151 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:45:51.863355 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m19:45:51.947878 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m19:45:51.954070 [info ] [MainThread]: Updating lock file in file path: /Users/danila/github/dbt/package-lock.yml
[0m19:45:51.967195 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-57ohp72r'
[0m19:45:51.969180 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m19:45:52.413076 [info ] [MainThread]: Installed from version 1.1.1
[0m19:45:52.413374 [info ] [MainThread]: Up to date!
[0m19:45:52.413607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6f52328f-965e-4f80-8b7f-45954d048f1d', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661a1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ab410>]}
[0m19:45:52.414898 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.6973875, "process_user_time": 0.825896, "process_kernel_time": 0.117432, "process_mem_max_rss": "119095296", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:45:52.415212 [debug] [MainThread]: Command `dbt deps` succeeded at 19:45:52.415140 after 0.70 seconds
[0m19:45:52.415424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fd30d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e66550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105222650>]}
[0m19:45:52.415632 [debug] [MainThread]: Flushing usage events
[0m19:45:55.671996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10861c8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f791d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10868b810>]}


============================== 19:45:55.673244 | 55de2acf-c61d-4440-952a-6b3a5e92aef0 ==============================
[0m19:45:55.673244 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:45:55.673564 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'quiet': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'partial_parse': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'introspect': 'True', 'target_path': 'None', 'printer_width': '80', 'version_check': 'True', 'log_cache_events': 'False'}
[0m19:45:55.743630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '55de2acf-c61d-4440-952a-6b3a5e92aef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b5add0>]}
[0m19:45:55.774754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '55de2acf-c61d-4440-952a-6b3a5e92aef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108aac210>]}
[0m19:45:55.775420 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:45:55.785148 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:45:55.790904 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m19:45:55.791178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '55de2acf-c61d-4440-952a-6b3a5e92aef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d66e10>]}
[0m19:45:56.229394 [error] [MainThread]: Encountered an error:
Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  macro 'dbt_macro__default__surrogate_key' takes not more than 1 argument(s)
  
  > in macro surrogate_key (macros/sql/surrogate_key.sql)
  > called by model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
[0m19:45:56.230779 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5803096, "process_user_time": 1.231565, "process_kernel_time": 0.091648, "process_mem_max_rss": "123404288", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:45:56.231072 [debug] [MainThread]: Command `dbt run` failed at 19:45:56.231009 after 0.58 seconds
[0m19:45:56.231259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10804f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10868b150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e5f150>]}
[0m19:45:56.231430 [debug] [MainThread]: Flushing usage events
[0m19:47:09.656108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fe8850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11413b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11413a950>]}


============================== 19:47:09.657396 | 47f3e834-670f-4c66-a1a7-c3b3e332c27f ==============================
[0m19:47:09.657396 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:47:09.657715 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'use_colors': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'debug': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'version_check': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'profiles_dir': '/Users/danila/.dbt', 'printer_width': '80', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False'}
[0m19:47:09.724110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47f3e834-670f-4c66-a1a7-c3b3e332c27f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145de910>]}
[0m19:47:09.755939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47f3e834-670f-4c66-a1a7-c3b3e332c27f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145fccd0>]}
[0m19:47:09.756595 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:47:09.765266 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:47:09.770706 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m19:47:09.770974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47f3e834-670f-4c66-a1a7-c3b3e332c27f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411d1d0>]}
[0m19:47:10.220833 [error] [MainThread]: Encountered an error:
Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  
  Warning: `dbt_utils.surrogate_key` has been replaced by `dbt_utils.generate_surrogate_key`. The new macro treats null values differently to empty strings. To restore the behaviour of the original macro, add a global variable in dbt_project.yml called `surrogate_key_treat_nulls_as_empty_strings` to your dbt_project.yml file with a value of True. The campaign_perfomance.outclick_cost_int model triggered this warning. 
  
  > in macro default__surrogate_key (macros/sql/surrogate_key.sql)
  > called by macro surrogate_key (macros/sql/surrogate_key.sql)
  > called by model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
[0m19:47:10.222688 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.58815664, "process_user_time": 1.289059, "process_kernel_time": 0.09479, "process_mem_max_rss": "124174336", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:47:10.222980 [debug] [MainThread]: Command `dbt run` failed at 19:47:10.222921 after 0.59 seconds
[0m19:47:10.223171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c1550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129e5850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11541fd10>]}
[0m19:47:10.223337 [debug] [MainThread]: Flushing usage events
[0m19:47:58.486731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a747c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7467d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084f7e90>]}


============================== 19:47:58.487943 | c11cc0a5-4168-473a-82c7-337a4174103c ==============================
[0m19:47:58.487943 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:47:58.488274 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'no_print': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'partial_parse': 'True', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'write_json': 'True', 'version_check': 'True', 'quiet': 'False', 'log_format': 'default', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'send_anonymous_usage_stats': 'True'}
[0m19:47:58.551682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c11cc0a5-4168-473a-82c7-337a4174103c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab79ad0>]}
[0m19:47:58.581146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c11cc0a5-4168-473a-82c7-337a4174103c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a762750>]}
[0m19:47:58.581466 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:47:58.589755 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:47:58.595145 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m19:47:58.595421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c11cc0a5-4168-473a-82c7-337a4174103c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fba310>]}
[0m19:47:59.022600 [error] [MainThread]: Encountered an error:
Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  
  Warning: `dbt_utils.surrogate_key` has been replaced by `dbt_utils.generate_surrogate_key`. The new macro treats null values differently to empty strings. To restore the behaviour of the original macro, add a global variable in dbt_project.yml called `surrogate_key_treat_nulls_as_empty_strings` to your dbt_project.yml file with a value of True. The campaign_perfomance.outclick_cost_int model triggered this warning. 
  
  > in macro default__surrogate_key (macros/sql/surrogate_key.sql)
  > called by macro surrogate_key (macros/sql/surrogate_key.sql)
  > called by model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
[0m19:47:59.023549 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.55720663, "process_user_time": 1.227179, "process_kernel_time": 0.089247, "process_mem_max_rss": "122568704", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:47:59.023801 [debug] [MainThread]: Command `dbt run` failed at 19:47:59.023743 after 0.56 seconds
[0m19:47:59.023979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a786fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fba1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7450d0>]}
[0m19:47:59.024146 [debug] [MainThread]: Flushing usage events
[0m19:48:07.459192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d17250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d66410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d67850>]}


============================== 19:48:07.460508 | 62bb71e5-695e-4756-aa97-f6f76fb8eb0d ==============================
[0m19:48:07.460508 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:48:07.460851 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'write_json': 'True', 'no_print': 'None', 'target_path': 'None', 'quiet': 'False', 'partial_parse': 'True', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'warn_error': 'None', 'static_parser': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'use_colors': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run -m outclick_cost_int'}
[0m19:48:07.526686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10818acd0>]}
[0m19:48:07.556946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108178bd0>]}
[0m19:48:07.557343 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:48:07.565885 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:48:07.581126 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:48:07.581342 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:48:07.581840 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:48:07.584965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10848e550>]}
[0m19:48:07.591181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108178650>]}
[0m19:48:07.591386 [info ] [MainThread]: Found 12 models, 6 tests, 14 sources, 0 exposures, 0 metrics, 515 macros, 0 groups, 0 semantic models
[0m19:48:07.591573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d48450>]}
[0m19:48:07.592203 [info ] [MainThread]: 
[0m19:48:07.592570 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:48:07.593058 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:48:07.597504 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:48:07.597723 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:48:07.597894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:48:08.114536 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m19:48:08.118004 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:48:08.122549 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:48:08.132507 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:48:08.133143 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:48:08.133560 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:48:08.392689 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:48:08.394685 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:48:08.395850 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:48:08.431437 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:48:08.437046 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:48:08.469692 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:48:08.487794 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.488332 [debug] [MainThread]: On master: BEGIN
[0m19:48:08.488694 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:48:08.798849 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:08.800628 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.801627 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:48:08.843557 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:48:08.847610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081cf410>]}
[0m19:48:08.848511 [debug] [MainThread]: On master: ROLLBACK
[0m19:48:08.879646 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.880596 [debug] [MainThread]: On master: BEGIN
[0m19:48:08.942467 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:08.943861 [debug] [MainThread]: On master: COMMIT
[0m19:48:08.945117 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.946182 [debug] [MainThread]: On master: COMMIT
[0m19:48:08.976515 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:48:08.978056 [debug] [MainThread]: On master: Close
[0m19:48:08.981072 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:48:08.981885 [info ] [MainThread]: 
[0m19:48:08.987911 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:48:08.988819 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:48:08.990100 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:48:08.990769 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:48:09.014229 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.015397 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:48:08.991204 => 19:48:09.015151
[0m19:48:09.015748 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:48:09.038640 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.039189 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.039413 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:48:09.039616 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:48:09.303889 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:48:09.305852 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.307780 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m19:48:16.485559 [debug] [Thread-1 (]: SQL status: SELECT 45891 in 7.0 seconds
[0m19:48:16.499409 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.500292 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:48:16.534658 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:48:16.541681 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.542527 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:48:16.574546 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:48:16.601860 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:48:16.602399 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.602760 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:48:16.633800 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:48:16.641139 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:48:16.646022 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.646380 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:48:16.707186 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:48:16.710603 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:48:09.015936 => 19:48:16.710188
[0m19:48:16.711342 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:48:16.713246 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ab790>]}
[0m19:48:16.714365 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45891[0m in 7.72s]
[0m19:48:16.715422 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:48:16.717353 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:16.717818 [debug] [MainThread]: On master: BEGIN
[0m19:48:16.718195 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:48:17.047111 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:17.048916 [debug] [MainThread]: On master: COMMIT
[0m19:48:17.050074 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:17.051227 [debug] [MainThread]: On master: COMMIT
[0m19:48:17.090815 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:48:17.092348 [debug] [MainThread]: On master: Close
[0m19:48:17.094796 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:48:17.095525 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:48:17.096200 [info ] [MainThread]: 
[0m19:48:17.097190 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 9.50 seconds (9.50s).
[0m19:48:17.098593 [debug] [MainThread]: Command end result
[0m19:48:17.116535 [info ] [MainThread]: 
[0m19:48:17.117100 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:48:17.117446 [info ] [MainThread]: 
[0m19:48:17.117817 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:48:17.120337 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.683342, "process_user_time": 1.113902, "process_kernel_time": 0.11493, "process_mem_max_rss": "128106496", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:48:17.121043 [debug] [MainThread]: Command `dbt run` succeeded at 19:48:17.120912 after 9.68 seconds
[0m19:48:17.121410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d89bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d5e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d5e710>]}
[0m19:48:17.121731 [debug] [MainThread]: Flushing usage events
[0m19:49:42.922107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108677b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108692a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086930d0>]}


============================== 19:49:42.923859 | 76ed4a1d-2c60-4e6d-b75a-b0d024bf064c ==============================
[0m19:49:42.923859 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:49:42.924221 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'static_parser': 'True', 'quiet': 'False', 'partial_parse': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'use_experimental_parser': 'False', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'debug': 'False', 'use_colors': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'write_json': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'printer_width': '80', 'introspect': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True'}
[0m19:49:42.996964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '76ed4a1d-2c60-4e6d-b75a-b0d024bf064c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108692f10>]}
[0m19:49:43.027188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '76ed4a1d-2c60-4e6d-b75a-b0d024bf064c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089d5b10>]}
[0m19:49:43.027706 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:49:43.036865 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:49:43.054648 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:49:43.055087 [debug] [MainThread]: Partial parsing: updated file: campaign_perfomance://models/brand_performance/source.yml
[0m19:49:43.084243 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "main_deals".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("main", "deals").
  
  To fix this, change the name of one of these resources:
  - source.campaign_perfomance.main.deals (models/brand_performance/source.yml)
  - source.campaign_perfomance.main.deals (models/users/source.yml)
[0m19:49:43.085534 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.18596888, "process_user_time": 0.867111, "process_kernel_time": 0.093774, "process_mem_max_rss": "120602624", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:49:43.085802 [debug] [MainThread]: Command `dbt run` failed at 19:49:43.085742 after 0.19 seconds
[0m19:49:43.085991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108691bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032ee7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e1d1d0>]}
[0m19:49:43.086170 [debug] [MainThread]: Flushing usage events
[0m19:49:58.091865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aa6590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ae5c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b03210>]}


============================== 19:49:58.093072 | aefd3acb-ac63-47a7-8540-8eea18ac9111 ==============================
[0m19:49:58.093072 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:49:58.093428 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'version_check': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'warn_error': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'invocation_command': 'dbt run -m outclick_cost_int', 'log_cache_events': 'False', 'fail_fast': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'log_format': 'default', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'write_json': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True'}
[0m19:49:58.159954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aefd3acb-ac63-47a7-8540-8eea18ac9111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aa66d0>]}
[0m19:49:58.190760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aefd3acb-ac63-47a7-8540-8eea18ac9111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106097150>]}
[0m19:49:58.191131 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:49:58.199511 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:49:58.215581 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:49:58.215990 [debug] [MainThread]: Partial parsing: updated file: campaign_perfomance://models/brand_performance/source.yml
[0m19:49:58.245631 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "main_deals".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("main", "deals").
  
  To fix this, change the name of one of these resources:
  - source.campaign_perfomance.main.deals (models/brand_performance/source.yml)
  - source.campaign_perfomance.main.deals (models/users/source.yml)
[0m19:49:58.246605 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.17539833, "process_user_time": 0.856108, "process_kernel_time": 0.074442, "process_mem_max_rss": "121143296", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:49:58.246871 [debug] [MainThread]: Command `dbt run` failed at 19:49:58.246813 after 0.18 seconds
[0m19:49:58.247065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b01bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ade7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f1910>]}
[0m19:49:58.247246 [debug] [MainThread]: Flushing usage events
[0m19:50:48.577650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d46590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d46350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d63250>]}


============================== 19:50:48.579279 | 2a780604-85a3-485e-b0fd-fe6343d78d0c ==============================
[0m19:50:48.579279 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:50:48.579600 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'log_format': 'default', 'debug': 'False', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'introspect': 'True', 'version_check': 'True', 'fail_fast': 'False', 'static_parser': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'use_experimental_parser': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'target_path': 'None', 'warn_error': 'None', 'profiles_dir': '/Users/danila/.dbt', 'indirect_selection': 'eager', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m19:50:48.655516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d46910>]}
[0m19:50:48.685251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108230550>]}
[0m19:50:48.685751 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:50:48.694469 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:50:48.715852 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:50:48.716094 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:50:48.716660 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:50:48.719885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082c2810>]}
[0m19:50:48.726496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082077d0>]}
[0m19:50:48.726732 [info ] [MainThread]: Found 12 models, 6 tests, 14 sources, 0 exposures, 0 metrics, 515 macros, 0 groups, 0 semantic models
[0m19:50:48.726914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10826eb10>]}
[0m19:50:48.727561 [info ] [MainThread]: 
[0m19:50:48.727930 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:50:48.728381 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:50:48.732500 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:50:48.732657 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:50:48.732819 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:50:49.106813 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:50:49.111583 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:50:49.116250 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:50:49.125751 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:50:49.126540 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:50:49.126985 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:50:49.424562 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:50:49.426322 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:50:49.428019 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:50:49.484120 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:50:49.488130 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:50:49.521551 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:50:49.536157 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.536681 [debug] [MainThread]: On master: BEGIN
[0m19:50:49.537029 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:50:49.823683 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:50:49.825755 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.827460 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:50:49.874719 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:50:49.880165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d8c310>]}
[0m19:50:49.881232 [debug] [MainThread]: On master: ROLLBACK
[0m19:50:49.912496 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.913133 [debug] [MainThread]: On master: BEGIN
[0m19:50:49.975571 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:50:49.977125 [debug] [MainThread]: On master: COMMIT
[0m19:50:49.978341 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.979449 [debug] [MainThread]: On master: COMMIT
[0m19:50:50.010738 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:50:50.011556 [debug] [MainThread]: On master: Close
[0m19:50:50.013443 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:50:50.014358 [info ] [MainThread]: 
[0m19:50:50.020010 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:50:50.021047 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:50:50.022207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:50:50.022808 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:50:50.047028 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.048385 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:50:50.023213 => 19:50:50.048145
[0m19:50:50.048711 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:50:50.070668 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.071237 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.071451 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:50:50.071648 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:50:50.398680 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:50:50.400399 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.401874 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m19:50:57.096875 [debug] [Thread-1 (]: SQL status: SELECT 45891 in 7.0 seconds
[0m19:50:57.109651 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.110254 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:50:57.149947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:50:57.156003 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.156615 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:50:57.196830 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:50:57.222237 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:50:57.222686 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.223022 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:50:57.263616 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:50:57.272877 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:50:57.277724 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.278108 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:50:57.332615 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:50:57.335738 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:50:50.048891 => 19:50:57.335425
[0m19:50:57.336297 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:50:57.337714 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108421190>]}
[0m19:50:57.338898 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45891[0m in 7.32s]
[0m19:50:57.339793 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:50:57.341478 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:57.341882 [debug] [MainThread]: On master: BEGIN
[0m19:50:57.342189 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:50:57.769871 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:50:57.771701 [debug] [MainThread]: On master: COMMIT
[0m19:50:57.772891 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:57.774005 [debug] [MainThread]: On master: COMMIT
[0m19:50:57.817826 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:50:57.819224 [debug] [MainThread]: On master: Close
[0m19:50:57.822425 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:50:57.823372 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:50:57.823975 [info ] [MainThread]: 
[0m19:50:57.824544 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 9.10 seconds (9.10s).
[0m19:50:57.825616 [debug] [MainThread]: Command end result
[0m19:50:57.843846 [info ] [MainThread]: 
[0m19:50:57.844244 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:50:57.844529 [info ] [MainThread]: 
[0m19:50:57.844830 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:50:57.847099 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.291962, "process_user_time": 1.086413, "process_kernel_time": 0.129775, "process_mem_max_rss": "130875392", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:50:57.847575 [debug] [MainThread]: Command `dbt run` succeeded at 19:50:57.847464 after 9.29 seconds
[0m19:50:57.847901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d3e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c70290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cb5590>]}
[0m19:50:57.848199 [debug] [MainThread]: Flushing usage events
[0m23:43:19.624321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065785d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106581d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10658c850>]}


============================== 23:43:19.625958 | 2f8c971d-976d-4778-8c8f-bcfa3264c9a1 ==============================
[0m23:43:19.625958 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:43:19.626308 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'version_check': 'True', 'printer_width': '80', 'log_format': 'default', 'quiet': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'write_json': 'True', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'debug': 'False', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False'}
[0m23:43:19.636891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f8c971d-976d-4778-8c8f-bcfa3264c9a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b8a90>]}
[0m23:43:19.637622 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-z5q4fhqo'
[0m23:43:19.637840 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m23:43:19.750573 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m23:43:19.751834 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m23:43:19.782977 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m23:43:19.788357 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m23:43:20.271602 [info ] [MainThread]: Installed from version 1.1.1
[0m23:43:20.271868 [info ] [MainThread]: Up to date!
[0m23:43:20.272066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '2f8c971d-976d-4778-8c8f-bcfa3264c9a1', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106076cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065bfe10>]}
[0m23:43:20.272606 [debug] [MainThread]: Command `dbt deps` succeeded at 23:43:20.272543 after 0.66 seconds
[0m23:43:20.272771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106584b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100c1ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100cb1dd0>]}
[0m23:43:20.272919 [debug] [MainThread]: Flushing usage events
[0m23:43:33.140678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c428d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c49650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c56410>]}


============================== 23:43:33.141860 | 2340448f-a362-4287-85d2-357a2b2cf434 ==============================
[0m23:43:33.141860 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:43:33.142163 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/danila/.dbt', 'log_format': 'default', 'debug': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'target_path': 'None', 'partial_parse': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'printer_width': '80', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'introspect': 'True'}
[0m23:43:33.612590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b08250>]}
[0m23:43:33.619920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10908bc10>]}
[0m23:43:33.620375 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:43:33.634404 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:43:33.655330 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m23:43:33.655610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c65810>]}
[0m23:43:33.967004 [debug] [MainThread]: 1699: static parser successfully parsed example/test.sql
[0m23:43:33.971814 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m23:43:33.973548 [debug] [MainThread]: 1603: static parser failed on example/brand_performance_replacement.sql
[0m23:43:33.976366 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/brand_performance_replacement.sql
[0m23:43:33.976901 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m23:43:33.978033 [debug] [MainThread]: 1699: static parser successfully parsed users/deals_dim.sql
[0m23:43:33.979296 [debug] [MainThread]: 1699: static parser successfully parsed users/campaign_dim.sql
[0m23:43:33.980553 [debug] [MainThread]: 1699: static parser successfully parsed users/brand_comparison_fi.sql
[0m23:43:33.981696 [debug] [MainThread]: 1699: static parser successfully parsed users/daily_campaign_fct.sql
[0m23:43:33.983041 [debug] [MainThread]: 1699: static parser successfully parsed users/test_write.sql
[0m23:43:33.984266 [debug] [MainThread]: 1699: static parser successfully parsed users/outclicks_fct.sql
[0m23:43:33.985370 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m23:43:33.992215 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m23:43:33.993122 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m23:43:33.995295 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m23:43:34.037297 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m23:43:34.039347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c49f10>]}
[0m23:43:34.043586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090e5e90>]}
[0m23:43:34.043767 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:43:34.043931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c48b90>]}
[0m23:43:34.044862 [info ] [MainThread]: 
[0m23:43:34.045171 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:43:34.045762 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:43:34.050139 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:43:34.050369 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:43:34.050492 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:43:34.512343 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m23:43:34.516826 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:43:34.520462 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:43:34.528281 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:43:34.528701 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:43:34.528993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:43:34.811559 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:43:34.813057 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:43:34.814104 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:43:34.853875 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m23:43:34.859756 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:43:34.892960 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:43:34.905894 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:34.906371 [debug] [MainThread]: On master: BEGIN
[0m23:43:34.906664 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:43:35.311595 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:43:35.313294 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:35.314619 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:43:35.364755 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m23:43:35.367859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4a890>]}
[0m23:43:35.368600 [debug] [MainThread]: On master: ROLLBACK
[0m23:43:35.408169 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:35.408632 [debug] [MainThread]: On master: BEGIN
[0m23:43:35.482284 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:43:35.482623 [debug] [MainThread]: On master: COMMIT
[0m23:43:35.482797 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:35.482951 [debug] [MainThread]: On master: COMMIT
[0m23:43:35.519094 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:43:35.519326 [debug] [MainThread]: On master: Close
[0m23:43:35.519947 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:43:35.520240 [info ] [MainThread]: 
[0m23:43:35.525240 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m23:43:35.525624 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m23:43:35.526143 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m23:43:35.526380 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m23:43:35.533600 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.534466 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 23:43:35.526529 => 23:43:35.534276
[0m23:43:35.534730 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m23:43:35.552233 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.553130 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.553427 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m23:43:35.553594 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:35.850434 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:35.852637 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.855175 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m23:43:55.431627 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 20.0 seconds
[0m23:43:55.448849 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.449526 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m23:43:55.488208 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:55.498146 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.499027 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m23:43:55.535745 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:55.570833 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m23:43:55.571605 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.572032 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m23:43:55.608571 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:55.617784 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.618367 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m23:43:55.669188 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:55.675196 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 23:43:35.534879 => 23:43:55.674407
[0m23:43:55.676515 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m23:43:55.679873 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10915a290>]}
[0m23:43:55.681604 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 20.15s]
[0m23:43:55.683274 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m23:43:55.684274 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m23:43:55.685369 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m23:43:55.686716 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m23:43:55.687303 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m23:43:55.693976 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m23:43:55.697111 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 23:43:55.687710 => 23:43:55.696807
[0m23:43:55.697636 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m23:43:55.703631 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m23:43:55.704896 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:55.705371 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m23:43:55.705741 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:56.028744 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:56.030445 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.031654 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m23:43:56.077577 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m23:43:56.089621 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.090913 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m23:43:56.122624 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.137833 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.138758 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m23:43:56.171193 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.178630 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m23:43:56.179758 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.180771 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m23:43:56.211498 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:56.219397 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.220553 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m23:43:56.269736 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:56.274891 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 23:43:55.698003 => 23:43:56.274280
[0m23:43:56.276036 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m23:43:56.278886 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090cb890>]}
[0m23:43:56.280920 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.59s]
[0m23:43:56.282848 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m23:43:56.284043 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.285395 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m23:43:56.287012 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m23:43:56.287701 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.294435 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.295984 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 23:43:56.288259 => 23:43:56.295627
[0m23:43:56.296535 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.302205 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.303258 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.303671 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m23:43:56.303998 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:56.589695 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:56.591250 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.592338 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m23:43:56.641603 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m23:43:56.648563 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.649264 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m23:43:56.681045 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.691479 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.692296 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m23:43:56.723625 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.726113 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m23:43:56.726455 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.726753 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m23:43:56.756888 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:56.758412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.758598 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m23:43:56.806670 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:56.807716 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 23:43:56.296813 => 23:43:56.807562
[0m23:43:56.807995 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m23:43:56.808686 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090e0390>]}
[0m23:43:56.809127 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.52s]
[0m23:43:56.809627 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.809949 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m23:43:56.810449 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m23:43:56.811123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m23:43:56.811409 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m23:43:56.813952 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m23:43:56.814578 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 23:43:56.811588 => 23:43:56.814428
[0m23:43:56.814852 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m23:43:56.818185 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m23:43:56.818655 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:56.818869 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m23:43:56.819061 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:57.074508 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:57.076453 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.077767 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m23:43:57.115991 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m23:43:57.127125 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.127997 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m23:43:57.160249 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.169453 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.170393 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m23:43:57.243915 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.251592 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m23:43:57.252724 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.253670 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m23:43:57.286118 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:57.294562 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.295374 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m23:43:57.348253 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:57.352941 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 23:43:56.815016 => 23:43:57.352304
[0m23:43:57.354088 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m23:43:57.357047 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928c2d0>]}
[0m23:43:57.358660 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.55s]
[0m23:43:57.360167 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m23:43:57.361176 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.362515 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m23:43:57.364097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m23:43:57.364886 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.373476 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.374905 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 23:43:57.365459 => 23:43:57.374688
[0m23:43:57.375346 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.380573 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.381873 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.382288 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m23:43:57.382630 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:57.642995 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:57.645105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.646407 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m23:43:57.680841 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m23:43:57.692821 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.694054 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m23:43:57.726992 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.736355 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.737222 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m23:43:57.768562 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.775907 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m23:43:57.777000 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.777971 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m23:43:57.809441 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:57.818340 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.819355 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m23:43:57.868150 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:57.871221 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 23:43:57.375631 => 23:43:57.870882
[0m23:43:57.871977 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m23:43:57.873830 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093e0410>]}
[0m23:43:57.874870 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.51s]
[0m23:43:57.875975 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.876691 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:43:57.877557 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m23:43:57.878899 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:43:57.879406 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:43:57.886516 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:57.887841 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:43:57.879741 => 23:43:57.887444
[0m23:43:57.888543 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:43:57.895578 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:57.897052 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:57.897676 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:43:57.898055 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:58.154727 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:58.156594 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:58.158543 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m23:44:06.244779 [debug] [Thread-1 (]: SQL status: SELECT 153700 in 8.0 seconds
[0m23:44:06.250792 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.251389 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:44:06.283528 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:06.288794 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.289441 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:44:06.320378 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:06.323321 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:44:06.323772 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.324153 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:44:06.355842 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:06.359655 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.360013 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:44:06.407069 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:06.408128 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:43:57.888981 => 23:44:06.407993
[0m23:44:06.408385 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:44:06.408977 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109242750>]}
[0m23:44:06.409359 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153700[0m in 8.53s]
[0m23:44:06.409748 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:44:06.410019 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:44:06.410248 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m23:44:06.410758 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:44:06.411014 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:44:06.415307 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.416922 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:44:06.411164 => 23:44:06.416783
[0m23:44:06.417146 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:44:06.421528 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.421997 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.422190 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:44:06.422367 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:06.750657 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:06.752369 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.753601 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m23:44:11.759562 [debug] [Thread-1 (]: SQL status: SELECT 45919 in 5.0 seconds
[0m23:44:11.769077 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.770167 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:44:11.811282 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:11.818060 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.818785 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:44:11.858145 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:11.865051 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:11.865758 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.866284 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:11.906103 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:11.912690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.913590 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:44:11.969812 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:11.974286 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:44:06.417276 => 23:44:11.973697
[0m23:44:11.975441 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:44:11.978208 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109351410>]}
[0m23:44:11.979561 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45919[0m in 5.57s]
[0m23:44:11.981080 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:44:11.982030 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m23:44:11.983184 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m23:44:11.984783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m23:44:11.985548 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m23:44:11.991536 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m23:44:11.994080 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 23:44:11.986136 => 23:44:11.993798
[0m23:44:11.994595 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m23:44:12.015622 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m23:44:12.016342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.016615 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m23:44:12.016860 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:12.279957 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:12.281640 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.282940 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m23:44:12.319176 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:44:12.329850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.330777 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m23:44:12.363238 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:12.372381 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.373517 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m23:44:12.405307 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:12.408226 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:44:12.408738 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.409183 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:44:12.439561 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:12.443715 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.444277 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m23:44:12.475848 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:44:12.477121 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 23:44:11.994918 => 23:44:12.476985
[0m23:44:12.477370 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m23:44:12.477947 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092c8690>]}
[0m23:44:12.478271 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.49s]
[0m23:44:12.478624 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m23:44:12.478851 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m23:44:12.479173 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m23:44:12.479628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m23:44:12.479829 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m23:44:12.481488 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m23:44:12.482644 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 23:44:12.479956 => 23:44:12.482539
[0m23:44:12.482826 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m23:44:12.485154 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m23:44:12.485892 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.486058 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m23:44:12.486202 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:12.835498 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:12.837279 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.838459 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m23:44:12.884048 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:44:12.895391 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.896339 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m23:44:12.939778 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:12.954803 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.955924 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m23:44:12.999895 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:13.006932 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m23:44:13.008065 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:13.009236 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m23:44:13.052438 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:13.059755 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:13.060663 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m23:44:13.133203 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:13.137476 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 23:44:12.482938 => 23:44:13.136890
[0m23:44:13.138579 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m23:44:13.140882 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093b8690>]}
[0m23:44:13.142282 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.66s]
[0m23:44:13.143921 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m23:44:13.144881 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m23:44:13.146039 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m23:44:13.147593 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m23:44:13.148180 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m23:44:13.154016 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.156321 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 23:44:13.148623 => 23:44:13.156089
[0m23:44:13.156799 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m23:44:13.162332 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.163840 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.164320 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m23:44:13.164675 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:13.423998 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:13.425727 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.427129 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m23:44:13.683516 [debug] [Thread-1 (]: SQL status: SELECT 57027 in 0.0 seconds
[0m23:44:13.695486 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.696477 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m23:44:13.728937 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:13.738148 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.739339 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m23:44:13.772861 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:13.779572 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m23:44:13.780682 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.781740 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m23:44:13.814591 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:13.822676 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.823767 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m23:44:13.873719 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:13.877948 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 23:44:13.157122 => 23:44:13.877217
[0m23:44:13.879473 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m23:44:13.882238 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090d7c10>]}
[0m23:44:13.883810 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 57027[0m in 0.73s]
[0m23:44:13.885240 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m23:44:13.886187 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m23:44:13.887519 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m23:44:13.888931 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m23:44:13.889605 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m23:44:13.894646 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:13.896141 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 23:44:13.890026 => 23:44:13.895914
[0m23:44:13.896608 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m23:44:13.902163 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:13.903332 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:13.903711 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m23:44:13.904071 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:14.212092 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:14.213752 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.214949 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m23:44:14.255284 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:44:14.267336 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.268728 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m23:44:14.306474 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:14.312175 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m23:44:14.313318 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.314327 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m23:44:14.352132 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:14.360368 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.361286 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m23:44:14.399618 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:44:14.404824 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 23:44:13.896911 => 23:44:14.404186
[0m23:44:14.406059 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m23:44:14.408914 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10940fd90>]}
[0m23:44:14.410668 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.52s]
[0m23:44:14.412583 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m23:44:14.413621 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m23:44:14.414771 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m23:44:14.416423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m23:44:14.417215 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m23:44:14.424105 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.425663 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 23:44:14.417794 => 23:44:14.425393
[0m23:44:14.426188 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m23:44:14.436370 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.437197 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.437540 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m23:44:14.437815 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:14.727179 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:14.729037 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.730352 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m23:44:14.829861 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m23:44:14.840809 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.841600 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m23:44:14.874388 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:14.884666 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.885591 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m23:44:14.917305 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:14.924730 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m23:44:14.925895 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.926942 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m23:44:14.958110 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:14.967006 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.968195 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m23:44:15.019640 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:15.024063 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 23:44:14.426540 => 23:44:15.023450
[0m23:44:15.025181 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m23:44:15.027918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10943a290>]}
[0m23:44:15.029594 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.61s]
[0m23:44:15.031143 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m23:44:15.034446 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:15.034984 [debug] [MainThread]: On master: BEGIN
[0m23:44:15.035425 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:44:15.296997 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:15.298484 [debug] [MainThread]: On master: COMMIT
[0m23:44:15.299423 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:15.300272 [debug] [MainThread]: On master: COMMIT
[0m23:44:15.331054 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:44:15.332354 [debug] [MainThread]: On master: Close
[0m23:44:15.335144 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:44:15.336116 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m23:44:15.337226 [info ] [MainThread]: 
[0m23:44:15.338402 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 41.29 seconds (41.29s).
[0m23:44:15.345108 [debug] [MainThread]: Command end result
[0m23:44:15.363738 [info ] [MainThread]: 
[0m23:44:15.364593 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:44:15.364831 [info ] [MainThread]: 
[0m23:44:15.365052 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m23:44:15.365499 [debug] [MainThread]: Command `dbt run` succeeded at 23:44:15.365433 after 42.23 seconds
[0m23:44:15.365799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ce3fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cecfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ced210>]}
[0m23:44:15.366008 [debug] [MainThread]: Flushing usage events
[0m23:44:45.980610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112684c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11268aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11268ba90>]}


============================== 23:44:45.982065 | 14011815-505d-47bb-88d8-260bdfa8c389 ==============================
[0m23:44:45.982065 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:44:45.982378 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/danila/.dbt', 'printer_width': '80', 'log_format': 'default', 'write_json': 'True', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'no_print': 'None', 'cache_selected_only': 'False', 'quiet': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'target_path': 'None', 'version_check': 'True'}
[0m23:44:46.011897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126ad290>]}
[0m23:44:46.017998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d9550>]}
[0m23:44:46.018441 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:44:46.028954 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:44:46.064062 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:44:46.064257 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:44:46.064599 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m23:44:46.067022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b0d790>]}
[0m23:44:46.070846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129f9e90>]}
[0m23:44:46.071005 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:44:46.071154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e4150>]}
[0m23:44:46.071762 [info ] [MainThread]: 
[0m23:44:46.072088 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:44:46.072539 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:44:46.077149 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:44:46.077370 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:44:46.077505 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:44:46.418421 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m23:44:46.420258 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:44:46.422359 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:44:46.427497 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:44:46.427748 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:44:46.427944 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:44:46.681047 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:44:46.682253 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:44:46.682843 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:44:46.717162 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m23:44:46.721669 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:44:46.752713 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:44:46.768378 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:46.768894 [debug] [MainThread]: On master: BEGIN
[0m23:44:46.769252 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:44:47.096009 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:47.096921 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:47.097664 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:44:47.148321 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m23:44:47.155656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129aa910>]}
[0m23:44:47.156331 [debug] [MainThread]: On master: ROLLBACK
[0m23:44:47.195839 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:47.196864 [debug] [MainThread]: On master: BEGIN
[0m23:44:47.275610 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:47.276537 [debug] [MainThread]: On master: COMMIT
[0m23:44:47.276905 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:47.277219 [debug] [MainThread]: On master: COMMIT
[0m23:44:47.317420 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:44:47.318402 [debug] [MainThread]: On master: Close
[0m23:44:47.320489 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:44:47.321263 [info ] [MainThread]: 
[0m23:44:47.330072 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:44:47.330866 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:44:47.332153 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m23:44:47.332632 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:44:47.352592 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.353272 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:44:47.333242 => 23:44:47.353106
[0m23:44:47.353546 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:44:47.373303 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.373764 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.373934 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:44:47.374091 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:47.637463 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:47.639093 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.640500 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m23:44:52.667403 [debug] [Thread-1 (]: SQL status: SELECT 45919 in 5.0 seconds
[0m23:44:52.680321 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.680931 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:44:52.713135 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:52.718520 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.719156 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:44:52.750613 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:52.763786 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:52.763996 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.764140 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:52.795715 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:52.800400 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.800655 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:44:52.847173 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:52.848480 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:44:47.353700 => 23:44:52.848302
[0m23:44:52.848808 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:44:52.849578 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c59650>]}
[0m23:44:52.850107 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45919[0m in 5.52s]
[0m23:44:52.850684 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:44:52.851925 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:52.852270 [debug] [MainThread]: On master: BEGIN
[0m23:44:52.852522 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:44:53.241372 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:53.242961 [debug] [MainThread]: On master: COMMIT
[0m23:44:53.243915 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:53.244809 [debug] [MainThread]: On master: COMMIT
[0m23:44:53.288417 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:44:53.289773 [debug] [MainThread]: On master: Close
[0m23:44:53.292565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:44:53.293030 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m23:44:53.293485 [info ] [MainThread]: 
[0m23:44:53.294025 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 7.22 seconds (7.22s).
[0m23:44:53.294940 [debug] [MainThread]: Command end result
[0m23:44:53.305618 [info ] [MainThread]: 
[0m23:44:53.306156 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:44:53.306462 [info ] [MainThread]: 
[0m23:44:53.306808 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:44:53.307403 [debug] [MainThread]: Command `dbt run` succeeded at 23:44:53.307305 after 7.34 seconds
[0m23:44:53.307792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105410410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10540e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10540e750>]}
[0m23:44:53.308134 [debug] [MainThread]: Flushing usage events
[0m23:46:35.326237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067863d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106785650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106790c90>]}


============================== 23:46:35.327903 | c4b63de9-26c5-4c60-885c-dfc8c3678f3e ==============================
[0m23:46:35.327903 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:46:35.328263 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'version_check': 'True', 'partial_parse': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error': 'None', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m23:46:35.329665 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'piter' does not have a target named 'prod'. The valid target names for this profile are:
   - dev
[0m23:46:35.329968 [debug] [MainThread]: Command `dbt ls` failed at 23:46:35.329908 after 0.01 seconds
[0m23:46:35.330119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106788090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106788110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106784710>]}
[0m23:46:35.330265 [debug] [MainThread]: Flushing usage events
[0m23:58:09.604431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bea350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106be9650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf4c50>]}


============================== 23:58:09.606101 | 83c1c129-8616-493c-93cc-d402a7bd7b86 ==============================
[0m23:58:09.606101 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:58:09.606453 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'introspect': 'True', 'use_colors': 'True', 'printer_width': '80', 'partial_parse': 'True', 'version_check': 'True', 'quiet': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'log_format': 'default'}
[0m23:58:09.639408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c0e9d0>]}
[0m23:58:09.645598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070612d0>]}
[0m23:58:09.646057 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:58:09.657071 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m23:58:09.678460 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m23:58:09.678751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10594ebd0>]}
[0m23:58:10.005747 [debug] [MainThread]: 1699: static parser successfully parsed example/test.sql
[0m23:58:10.010666 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m23:58:10.012484 [debug] [MainThread]: 1603: static parser failed on example/brand_performance_replacement.sql
[0m23:58:10.015332 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/brand_performance_replacement.sql
[0m23:58:10.015869 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m23:58:10.017033 [debug] [MainThread]: 1699: static parser successfully parsed users/deals_dim.sql
[0m23:58:10.018249 [debug] [MainThread]: 1699: static parser successfully parsed users/campaign_dim.sql
[0m23:58:10.019518 [debug] [MainThread]: 1699: static parser successfully parsed users/brand_comparison_fi.sql
[0m23:58:10.020654 [debug] [MainThread]: 1699: static parser successfully parsed users/daily_campaign_fct.sql
[0m23:58:10.021824 [debug] [MainThread]: 1699: static parser successfully parsed users/test_write.sql
[0m23:58:10.022907 [debug] [MainThread]: 1699: static parser successfully parsed users/outclicks_fct.sql
[0m23:58:10.023999 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m23:58:10.030641 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m23:58:10.031504 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m23:58:10.033681 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m23:58:10.074041 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m23:58:10.076026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071a9950>]}
[0m23:58:10.081368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10723bbd0>]}
[0m23:58:10.081560 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:58:10.081722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070cee10>]}
[0m23:58:10.082407 [debug] [MainThread]: Command `dbt ls` succeeded at 23:58:10.082343 after 0.49 seconds
[0m23:58:10.082560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10727ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d18390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d166d0>]}
[0m23:58:10.082684 [debug] [MainThread]: Flushing usage events
[0m00:00:24.539998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10489bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048b1650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048bb190>]}


============================== 00:00:24.541672 | 737f4946-080e-455a-b452-9b7e0144f265 ==============================
[0m00:00:24.541672 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:00:24.541981 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'quiet': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'target_path': 'None', 'introspect': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'version_check': 'True', 'partial_parse': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'use_colors': 'True'}
[0m00:00:24.574761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10489b690>]}
[0m00:00:24.580922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d3d290>]}
[0m00:00:24.581370 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:00:24.593051 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:00:24.616141 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m00:00:24.616425 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m00:00:24.616545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043fc790>]}
[0m00:00:24.935681 [debug] [MainThread]: 1699: static parser successfully parsed example/test.sql
[0m00:00:24.940608 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m00:00:24.942327 [debug] [MainThread]: 1603: static parser failed on example/brand_performance_replacement.sql
[0m00:00:24.945364 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/brand_performance_replacement.sql
[0m00:00:24.945927 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m00:00:24.947050 [debug] [MainThread]: 1699: static parser successfully parsed users/deals_dim.sql
[0m00:00:24.948308 [debug] [MainThread]: 1699: static parser successfully parsed users/campaign_dim.sql
[0m00:00:24.949712 [debug] [MainThread]: 1699: static parser successfully parsed users/brand_comparison_fi.sql
[0m00:00:24.951106 [debug] [MainThread]: 1699: static parser successfully parsed users/daily_campaign_fct.sql
[0m00:00:24.952262 [debug] [MainThread]: 1699: static parser successfully parsed users/test_write.sql
[0m00:00:24.953364 [debug] [MainThread]: 1699: static parser successfully parsed users/outclicks_fct.sql
[0m00:00:24.954459 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m00:00:24.961178 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m00:00:24.962072 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m00:00:24.964399 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m00:00:25.007124 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m00:00:25.009140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea6d10>]}
[0m00:00:25.013214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048b04d0>]}
[0m00:00:25.013384 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m00:00:25.013540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101d63b90>]}
[0m00:00:25.014497 [info ] [MainThread]: 
[0m00:00:25.014817 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:00:25.015366 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:00:25.019591 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:00:25.019761 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:00:25.019876 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:25.458051 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:00:25.463224 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:00:25.468768 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:00:25.478394 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:00:25.478871 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:00:25.479236 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:00:25.795632 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:00:25.797552 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:00:25.798547 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:00:25.841637 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m00:00:25.843049 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:00:25.881519 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:00:25.890145 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:25.890508 [debug] [MainThread]: On master: BEGIN
[0m00:00:25.890800 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:00:26.198262 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:00:26.198575 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:26.198833 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:00:26.245828 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m00:00:26.247957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d02990>]}
[0m00:00:26.248372 [debug] [MainThread]: On master: ROLLBACK
[0m00:00:26.300997 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:26.301711 [debug] [MainThread]: On master: BEGIN
[0m00:00:26.376536 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:00:26.376886 [debug] [MainThread]: On master: COMMIT
[0m00:00:26.377061 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:26.377211 [debug] [MainThread]: On master: COMMIT
[0m00:00:26.413241 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:00:26.413476 [debug] [MainThread]: On master: Close
[0m00:00:26.414126 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:00:26.414418 [info ] [MainThread]: 
[0m00:00:26.419050 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m00:00:26.419441 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m00:00:26.419984 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m00:00:26.420243 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m00:00:26.427386 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.428304 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 00:00:26.420396 => 00:00:26.428153
[0m00:00:26.428531 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m00:00:26.450089 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.451115 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.451299 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m00:00:26.451447 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:26.707423 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:26.707893 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.708634 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m00:00:48.622716 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 22.0 seconds
[0m00:00:48.636814 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.637612 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m00:00:48.669924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:48.676974 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.677509 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m00:00:48.708977 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:48.736398 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:00:48.736931 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.737214 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:00:48.767929 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:48.773626 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.773963 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m00:00:48.818354 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:48.821722 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 00:00:26.428653 => 00:00:48.821330
[0m00:00:48.822405 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m00:00:48.824261 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e05410>]}
[0m00:00:48.825457 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 22.40s]
[0m00:00:48.826536 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m00:00:48.827165 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m00:00:48.828029 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m00:00:48.828905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m00:00:48.829279 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m00:00:48.832537 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m00:00:48.834325 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 00:00:48.829510 => 00:00:48.834111
[0m00:00:48.834659 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m00:00:48.838750 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m00:00:48.839402 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:48.839653 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m00:00:48.839887 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:49.256343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:49.257460 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.258044 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:00:49.328619 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:00:49.337925 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.338302 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m00:00:49.382661 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.385413 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.385721 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m00:00:49.430340 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.434557 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:00:49.435154 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.435644 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:00:49.480035 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:49.485509 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.486157 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m00:00:49.550997 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:49.555585 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 00:00:48.834853 => 00:00:49.554970
[0m00:00:49.556749 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m00:00:49.559590 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e06790>]}
[0m00:00:49.560917 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.73s]
[0m00:00:49.561976 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m00:00:49.562623 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m00:00:49.563357 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m00:00:49.564282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m00:00:49.564723 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m00:00:49.571969 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.573058 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 00:00:49.564998 => 00:00:49.572838
[0m00:00:49.573397 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m00:00:49.577725 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.578418 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.578682 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m00:00:49.578927 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:49.860969 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:49.861264 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.861467 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:00:49.914161 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:00:49.916322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.916544 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m00:00:49.950734 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.953195 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.953497 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m00:00:49.986926 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.989088 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:00:49.989432 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.989746 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:00:50.023735 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:50.028790 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:50.029377 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m00:00:50.085354 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:50.090144 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 00:00:49.573599 => 00:00:50.089510
[0m00:00:50.091083 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m00:00:50.092580 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd7990>]}
[0m00:00:50.093386 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.53s]
[0m00:00:50.094158 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m00:00:50.094681 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m00:00:50.095495 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m00:00:50.096483 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m00:00:50.096874 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m00:00:50.100534 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m00:00:50.101404 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 00:00:50.097127 => 00:00:50.101216
[0m00:00:50.101709 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m00:00:50.105717 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m00:00:50.106370 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.106630 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m00:00:50.106878 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:50.364495 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:50.366142 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.367196 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m00:00:50.405690 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m00:00:50.413175 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.413845 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m00:00:50.445539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:50.450377 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.450793 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m00:00:50.482332 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:50.485434 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:00:50.485919 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.486193 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:00:50.516746 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:50.522031 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.522787 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m00:00:50.571675 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:50.575557 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 00:00:50.101902 => 00:00:50.575166
[0m00:00:50.576264 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m00:00:50.577989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fb8410>]}
[0m00:00:50.579002 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.48s]
[0m00:00:50.580042 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m00:00:50.580719 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m00:00:50.581667 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m00:00:50.582642 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m00:00:50.583050 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m00:00:50.587666 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.588923 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 00:00:50.583318 => 00:00:50.588606
[0m00:00:50.589360 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m00:00:50.594571 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.595522 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.595853 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m00:00:50.596140 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:50.925121 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:50.927238 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.928754 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m00:00:50.971147 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m00:00:50.981598 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.982162 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m00:00:51.023441 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:51.029940 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:51.030452 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m00:00:51.070551 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:51.074976 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:00:51.075478 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:51.075914 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:00:51.116668 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:51.122861 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:51.123372 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m00:00:51.179370 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:51.183358 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 00:00:50.589595 => 00:00:51.183007
[0m00:00:51.184036 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m00:00:51.185803 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f1c4d0>]}
[0m00:00:51.186800 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.60s]
[0m00:00:51.187879 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m00:00:51.188598 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:51.189693 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m00:00:51.190863 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:00:51.191345 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:51.198418 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.199669 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:00:51.191671 => 00:00:51.199415
[0m00:00:51.200084 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:51.204579 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.205157 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.205446 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:00:51.205724 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:51.482446 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:51.484303 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.486262 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:00:59.252308 [debug] [Thread-1 (]: SQL status: SELECT 153711 in 8.0 seconds
[0m00:00:59.260208 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.260590 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:00:59.294663 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:59.299591 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.300078 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:00:59.333778 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:59.341196 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:00:59.342552 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.344059 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:00:59.377290 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:59.382446 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.383324 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:00:59.434223 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:59.438890 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:00:51.200333 => 00:00:59.438153
[0m00:00:59.440393 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:00:59.443172 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fc2290>]}
[0m00:00:59.444535 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153711[0m in 8.25s]
[0m00:00:59.446013 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:59.446974 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:00:59.448162 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m00:00:59.450013 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:00:59.450702 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:00:59.461113 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.463481 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:00:59.451152 => 00:00:59.463226
[0m00:00:59.463928 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:00:59.469857 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.470746 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.471133 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:00:59.471467 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:59.822546 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:59.824525 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.826262 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m00:01:04.392964 [debug] [Thread-1 (]: SQL status: SELECT 45930 in 5.0 seconds
[0m00:01:04.404485 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.405854 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:01:04.443720 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:04.450774 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.452107 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:01:04.490836 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:04.501833 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:01:04.502632 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.503042 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:01:04.540110 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:04.548435 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.549797 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:01:04.602857 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:04.607585 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:00:59.464250 => 00:01:04.607013
[0m00:01:04.608846 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:01:04.611492 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e2e410>]}
[0m00:01:04.613231 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45930[0m in 5.16s]
[0m00:01:04.615206 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:01:04.616466 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m00:01:04.617501 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m00:01:04.619334 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m00:01:04.620035 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m00:01:04.626646 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m00:01:04.628264 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 00:01:04.620512 => 00:01:04.627781
[0m00:01:04.628917 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m00:01:04.651319 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m00:01:04.653284 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.653636 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m00:01:04.653926 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:04.910598 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:04.911798 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.912446 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m00:01:04.948608 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:01:04.956113 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.956625 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m00:01:04.987799 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:04.995210 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.995643 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m00:01:05.026333 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:05.030333 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:01:05.030878 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:05.031415 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:01:05.062513 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:05.067358 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:05.067945 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m00:01:05.100004 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:01:05.104897 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 00:01:04.629264 => 00:01:05.104310
[0m00:01:05.106202 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m00:01:05.109071 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050400d0>]}
[0m00:01:05.110834 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.49s]
[0m00:01:05.112676 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m00:01:05.113834 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m00:01:05.114821 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m00:01:05.116245 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m00:01:05.117039 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m00:01:05.122169 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m00:01:05.123866 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 00:01:05.117560 => 00:01:05.123436
[0m00:01:05.124408 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m00:01:05.131051 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m00:01:05.132192 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.132676 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m00:01:05.133014 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:05.415052 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:05.416315 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.416798 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m00:01:05.451023 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:01:05.459597 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.460264 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m00:01:05.492042 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:05.494030 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.494250 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m00:01:05.525045 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:05.526667 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:01:05.526915 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.527107 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:01:05.558226 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:05.560585 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.560881 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m00:01:05.610356 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:05.613561 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 00:01:05.124743 => 00:01:05.613140
[0m00:01:05.614315 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m00:01:05.616242 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d7c9d0>]}
[0m00:01:05.617413 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.50s]
[0m00:01:05.618574 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m00:01:05.619151 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m00:01:05.619838 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m00:01:05.620896 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m00:01:05.621385 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m00:01:05.628243 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.629720 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 00:01:05.621700 => 00:01:05.629453
[0m00:01:05.630150 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m00:01:05.635254 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.635970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.636198 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m00:01:05.636388 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:05.894384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:05.895038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.895349 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m00:01:06.137705 [debug] [Thread-1 (]: SQL status: SELECT 57045 in 0.0 seconds
[0m00:01:06.147136 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.147955 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m00:01:06.179958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:06.188408 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.189277 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m00:01:06.220947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:06.224772 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:01:06.225288 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.225549 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:01:06.256425 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:06.263244 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.264283 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m00:01:06.315870 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:06.320665 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 00:01:05.630416 => 00:01:06.320072
[0m00:01:06.321777 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m00:01:06.324327 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050299d0>]}
[0m00:01:06.326005 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 57045[0m in 0.70s]
[0m00:01:06.327797 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m00:01:06.328794 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.330050 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m00:01:06.331160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m00:01:06.331551 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.338055 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.339428 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 00:01:06.332029 => 00:01:06.339114
[0m00:01:06.340009 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.346872 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.348006 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.348481 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m00:01:06.348807 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:06.720876 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:06.722644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.724062 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m00:01:06.760556 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:01:06.771617 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.772565 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m00:01:06.804711 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:06.807836 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m00:01:06.808516 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.809087 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m00:01:06.840667 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:06.849069 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.850197 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m00:01:06.881650 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:01:06.885074 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 00:01:06.340348 => 00:01:06.884749
[0m00:01:06.885734 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m00:01:06.887878 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e23a50>]}
[0m00:01:06.889567 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.56s]
[0m00:01:06.891187 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.892135 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m00:01:06.893201 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m00:01:06.894721 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m00:01:06.895484 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m00:01:06.900800 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:06.902148 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 00:01:06.895937 => 00:01:06.901924
[0m00:01:06.902610 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m00:01:06.909635 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:06.911498 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:06.912128 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m00:01:06.912512 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:07.174128 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:07.175162 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.175773 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m00:01:07.237409 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m00:01:07.248037 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.249436 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m00:01:07.281454 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:07.297030 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.297926 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m00:01:07.329028 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:07.336623 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:01:07.337461 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.338198 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:01:07.368962 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:07.376121 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.377232 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m00:01:07.426413 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:07.430656 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 00:01:06.902953 => 00:01:07.430078
[0m00:01:07.431789 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m00:01:07.433769 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104230d50>]}
[0m00:01:07.434742 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.54s]
[0m00:01:07.436318 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m00:01:07.439619 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:07.440177 [debug] [MainThread]: On master: BEGIN
[0m00:01:07.440635 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:01:07.793563 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:01:07.795160 [debug] [MainThread]: On master: COMMIT
[0m00:01:07.796117 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:07.796970 [debug] [MainThread]: On master: COMMIT
[0m00:01:07.839882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:01:07.840995 [debug] [MainThread]: On master: Close
[0m00:01:07.842936 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:01:07.843840 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m00:01:07.844601 [info ] [MainThread]: 
[0m00:01:07.845464 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 42.83 seconds (42.83s).
[0m00:01:07.851498 [debug] [MainThread]: Command end result
[0m00:01:07.870779 [info ] [MainThread]: 
[0m00:01:07.871748 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:01:07.872557 [info ] [MainThread]: 
[0m00:01:07.873160 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m00:01:07.873854 [debug] [MainThread]: Command `dbt run` succeeded at 00:01:07.873727 after 43.34 seconds
[0m00:01:07.874191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009e02d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ece510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009de5d0>]}
[0m00:01:07.874490 [debug] [MainThread]: Flushing usage events
[0m00:04:56.774465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c5550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075d5650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075dfa10>]}


============================== 00:04:56.776182 | 83b3cb88-fbe7-4fe8-981e-5d1922bed09f ==============================
[0m00:04:56.776182 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:04:56.776495 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'fail_fast': 'False', 'log_format': 'default', 'use_experimental_parser': 'False', 'version_check': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'static_parser': 'True', 'use_colors': 'True', 'write_json': 'True', 'quiet': 'False'}
[0m00:04:56.787075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '83b3cb88-fbe7-4fe8-981e-5d1922bed09f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075e74d0>]}
[0m00:04:56.787765 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-kdq9lt81'
[0m00:04:56.787972 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m00:04:56.874332 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m00:04:56.875320 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m00:04:56.921357 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m00:04:56.925950 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m00:04:57.503125 [info ] [MainThread]: Installed from version 1.1.1
[0m00:04:57.503394 [info ] [MainThread]: Up to date!
[0m00:04:57.503612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '83b3cb88-fbe7-4fe8-981e-5d1922bed09f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c5d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c7210>]}
[0m00:04:57.504133 [debug] [MainThread]: Command `dbt deps` succeeded at 00:04:57.504065 after 0.74 seconds
[0m00:04:57.504296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064d7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10370c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10370a5d0>]}
[0m00:04:57.504444 [debug] [MainThread]: Flushing usage events
[0m00:22:03.312346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062846d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107395650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107397990>]}


============================== 00:22:03.314067 | 13bab066-a2b1-4068-8ba7-7f4e0b831aa4 ==============================
[0m00:22:03.314067 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:22:03.314371 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'target_path': 'None', 'write_json': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'printer_width': '80', 'introspect': 'True', 'indirect_selection': 'eager', 'quiet': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False'}
[0m00:22:03.348551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107803150>]}
[0m00:22:03.354713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ac750>]}
[0m00:22:03.355161 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:22:03.367017 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:22:03.409632 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:22:03.409827 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:22:03.410164 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m00:22:03.412599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10739d250>]}
[0m00:22:03.417552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10782d2d0>]}
[0m00:22:03.417787 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m00:22:03.418878 [info ] [MainThread]: 
[0m00:22:03.419260 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:22:03.419937 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:22:03.424623 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:22:03.424777 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:22:03.424883 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:22:03.840710 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:22:03.844544 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:22:03.848973 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:22:03.857849 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:22:03.858326 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:22:03.858638 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:22:04.126514 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:22:04.128154 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:22:04.129345 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:22:04.166324 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m00:22:04.171139 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:22:04.202385 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:22:04.218081 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.218543 [debug] [MainThread]: On master: BEGIN
[0m00:22:04.218902 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:22:04.480637 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:22:04.481451 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.482081 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:22:04.523985 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m00:22:04.529649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079d5d10>]}
[0m00:22:04.530654 [debug] [MainThread]: On master: ROLLBACK
[0m00:22:04.561757 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.563174 [debug] [MainThread]: On master: BEGIN
[0m00:22:04.625318 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:22:04.625635 [debug] [MainThread]: On master: COMMIT
[0m00:22:04.625810 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.625959 [debug] [MainThread]: On master: COMMIT
[0m00:22:04.656968 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:22:04.657198 [debug] [MainThread]: On master: Close
[0m00:22:04.657756 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:22:04.658018 [info ] [MainThread]: 
[0m00:22:04.661280 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m00:22:04.661620 [info ] [Thread-1 (]: 1 of 18 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m00:22:04.662083 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m00:22:04.662299 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m00:22:04.669045 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:04.669522 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 00:22:04.662436 => 00:22:04.669401
[0m00:22:04.669717 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m00:22:04.690272 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:04.691222 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:04.691401 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m00:22:04.691570 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:05.013784 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:05.014392 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:05.015257 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m00:22:30.031321 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 25.0 seconds
[0m00:22:30.045425 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.046024 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m00:22:30.086183 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.093045 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.093644 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m00:22:30.134014 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.161455 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:22:30.161900 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.162181 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:22:30.201453 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:30.210792 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.211175 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m00:22:30.263357 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:30.266881 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 00:22:04.669839 => 00:22:30.266496
[0m00:22:30.267448 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m00:22:30.268989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078f0c90>]}
[0m00:22:30.269894 [info ] [Thread-1 (]: 1 of 18 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 25.61s]
[0m00:22:30.270708 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m00:22:30.271216 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m00:22:30.271864 [info ] [Thread-1 (]: 2 of 18 START sql table model danila.campaign_dim .............................. [RUN]
[0m00:22:30.272654 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m00:22:30.273007 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m00:22:30.277109 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m00:22:30.278259 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 00:22:30.273214 => 00:22:30.278023
[0m00:22:30.278675 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m00:22:30.283559 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m00:22:30.284470 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.284782 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m00:22:30.285034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:30.640694 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:30.642315 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.643537 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:22:30.689330 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:22:30.698276 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.698840 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m00:22:30.731282 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.736265 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.736819 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m00:22:30.768240 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.773070 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:22:30.773690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.774222 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:22:30.805703 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:30.814487 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.815513 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m00:22:30.863187 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:30.865614 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 00:22:30.278876 => 00:22:30.865357
[0m00:22:30.866127 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m00:22:30.867429 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e9c90>]}
[0m00:22:30.868320 [info ] [Thread-1 (]: 2 of 18 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.59s]
[0m00:22:30.869220 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m00:22:30.869717 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m00:22:30.870311 [info ] [Thread-1 (]: 3 of 18 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m00:22:30.871207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m00:22:30.871591 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m00:22:30.874480 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:30.876317 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 00:22:30.871839 => 00:22:30.876115
[0m00:22:30.876656 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m00:22:30.880670 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:30.881401 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:30.881686 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m00:22:30.881937 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:31.140149 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:31.141913 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.143107 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:22:31.193267 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:22:31.200691 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.201374 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m00:22:31.233169 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.242084 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.242629 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m00:22:31.274032 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.276897 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:22:31.277276 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.277608 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:22:31.308229 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:31.309804 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.309991 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m00:22:31.361451 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:31.362518 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 00:22:30.876861 => 00:22:31.362377
[0m00:22:31.362758 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m00:22:31.363331 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a7a4d0>]}
[0m00:22:31.363695 [info ] [Thread-1 (]: 3 of 18 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.49s]
[0m00:22:31.364111 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m00:22:31.364377 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m00:22:31.364642 [info ] [Thread-1 (]: 4 of 18 START sql table model danila.deals_dim ................................. [RUN]
[0m00:22:31.365212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m00:22:31.365475 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m00:22:31.367551 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m00:22:31.368138 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 00:22:31.365634 => 00:22:31.368006
[0m00:22:31.368374 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m00:22:31.372101 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m00:22:31.372514 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.372704 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m00:22:31.372887 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:31.678822 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:31.680361 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.681043 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m00:22:31.724324 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m00:22:31.731943 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.732535 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m00:22:31.769997 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.776587 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.777093 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m00:22:31.814135 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.818819 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:22:31.819412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.819932 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:22:31.857283 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:31.864954 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.865587 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m00:22:31.920279 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:31.923382 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 00:22:31.368517 => 00:22:31.922996
[0m00:22:31.924013 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m00:22:31.925711 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107868fd0>]}
[0m00:22:31.926747 [info ] [Thread-1 (]: 4 of 18 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.56s]
[0m00:22:31.927787 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m00:22:31.928764 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m00:22:31.929778 [info ] [Thread-1 (]: 5 of 18 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m00:22:31.930664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m00:22:31.931083 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m00:22:31.935736 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:31.936796 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 00:22:31.931355 => 00:22:31.936550
[0m00:22:31.937200 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m00:22:31.942649 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:31.943535 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:31.943845 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m00:22:31.944134 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:32.204335 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:32.206446 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.207520 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m00:22:32.242777 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m00:22:32.251038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.251559 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m00:22:32.283335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:32.288669 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.289228 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m00:22:32.321087 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:32.326314 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:22:32.327153 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.327756 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:22:32.360316 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:32.369038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.369765 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m00:22:32.419132 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:32.424020 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 00:22:31.937435 => 00:22:32.423371
[0m00:22:32.425146 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m00:22:32.426810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5f590>]}
[0m00:22:32.427435 [info ] [Thread-1 (]: 5 of 18 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.50s]
[0m00:22:32.427991 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m00:22:32.428336 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:32.428869 [info ] [Thread-1 (]: 6 of 18 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m00:22:32.429435 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:22:32.429703 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:32.433357 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.434143 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:22:32.429871 => 00:22:32.433987
[0m00:22:32.434394 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:32.437677 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.438139 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.438333 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:22:32.438525 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:32.718834 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:32.720591 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.722493 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:22:40.671595 [debug] [Thread-1 (]: SQL status: SELECT 153723 in 8.0 seconds
[0m00:22:40.679958 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.680692 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:22:40.711627 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:40.715598 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.716029 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:22:40.747088 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:40.755262 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:22:40.755933 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.756490 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:22:40.788336 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:40.794065 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.794701 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:22:40.845993 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:40.850608 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:22:32.434550 => 00:22:40.850001
[0m00:22:40.851715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:22:40.853516 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10787bad0>]}
[0m00:22:40.854339 [info ] [Thread-1 (]: 6 of 18 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153723[0m in 8.42s]
[0m00:22:40.855115 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:40.855643 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:22:40.856489 [info ] [Thread-1 (]: 7 of 18 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m00:22:40.857376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:22:40.857738 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:22:40.874953 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:22:40.876432 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:22:40.857964 => 00:22:40.876265
[0m00:22:40.876705 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:22:40.879768 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:22:40.880205 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:40.880434 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:22:40.880645 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:41.197173 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:41.199047 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:41.200039 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m00:22:46.201746 [debug] [Thread-1 (]: SQL status: SELECT 45942 in 5.0 seconds
[0m00:22:46.210049 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.210771 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:22:46.249536 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.259642 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.260297 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:22:46.298931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.303151 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:22:46.303678 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.304107 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:22:46.342963 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:46.350756 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.351466 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:22:46.405599 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:46.409752 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:22:40.876864 => 00:22:46.409520
[0m00:22:46.410209 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:22:46.411644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5c0d0>]}
[0m00:22:46.412521 [info ] [Thread-1 (]: 7 of 18 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45942[0m in 5.55s]
[0m00:22:46.413297 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:22:46.413764 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m00:22:46.414390 [info ] [Thread-1 (]: 8 of 18 START sql view model danila.test ....................................... [RUN]
[0m00:22:46.415311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m00:22:46.415650 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m00:22:46.418742 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m00:22:46.419549 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 00:22:46.415871 => 00:22:46.419368
[0m00:22:46.419856 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m00:22:46.434772 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m00:22:46.435371 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.435582 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m00:22:46.435770 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:46.719899 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:46.721571 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.722741 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m00:22:46.758518 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:22:46.766412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.766996 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m00:22:46.798508 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.804338 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.804985 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m00:22:46.836153 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.841268 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:22:46.841957 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.842380 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:22:46.872833 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:46.877341 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.877670 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m00:22:46.908899 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:22:46.909746 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 00:22:46.420058 => 00:22:46.909648
[0m00:22:46.909920 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m00:22:46.910369 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107af1c90>]}
[0m00:22:46.910636 [info ] [Thread-1 (]: 8 of 18 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.50s]
[0m00:22:46.910941 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m00:22:46.911133 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m00:22:46.911401 [info ] [Thread-1 (]: 9 of 18 START sql table model danila.test_write ................................ [RUN]
[0m00:22:46.911795 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m00:22:46.911966 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m00:22:46.913358 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m00:22:46.914618 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 00:22:46.912077 => 00:22:46.914521
[0m00:22:46.914777 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m00:22:46.916758 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m00:22:46.917044 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:46.917189 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m00:22:46.917330 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:47.189000 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:47.190676 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.191788 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m00:22:47.227907 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:47.236409 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.236848 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m00:22:47.270273 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:47.275240 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.275716 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m00:22:47.310521 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:47.314949 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:22:47.315577 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.316103 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:22:47.349858 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:47.356078 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.356738 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m00:22:47.407771 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:47.411167 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 00:22:46.914878 => 00:22:47.410894
[0m00:22:47.411739 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m00:22:47.413296 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b04f90>]}
[0m00:22:47.414392 [info ] [Thread-1 (]: 9 of 18 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.50s]
[0m00:22:47.415539 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m00:22:47.416297 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m00:22:47.417278 [info ] [Thread-1 (]: 10 of 18 START sql table model danila.outclicks_fct ............................ [RUN]
[0m00:22:47.418580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m00:22:47.419116 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m00:22:47.424677 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.426898 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 00:22:47.419417 => 00:22:47.426602
[0m00:22:47.427316 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m00:22:47.432269 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.433091 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.433388 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m00:22:47.433682 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:47.795822 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:47.797648 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.799092 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m00:22:48.069696 [debug] [Thread-1 (]: SQL status: SELECT 57065 in 0.0 seconds
[0m00:22:48.076322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.076928 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m00:22:48.121582 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:48.128501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.129021 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m00:22:48.173124 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:48.180850 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:22:48.181378 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.181767 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:22:48.225971 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:48.232480 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.232940 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m00:22:48.297282 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:48.302056 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 00:22:47.427564 => 00:22:48.301690
[0m00:22:48.302637 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m00:22:48.303913 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aba010>]}
[0m00:22:48.304620 [info ] [Thread-1 (]: 10 of 18 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 57065[0m in 0.89s]
[0m00:22:48.305361 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m00:22:48.305808 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.306353 [info ] [Thread-1 (]: 11 of 18 START test not_null_my_first_dbt_model_id ............................. [RUN]
[0m00:22:48.307039 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710)
[0m00:22:48.307570 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.322162 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.323854 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 00:22:48.308058 => 00:22:48.323692
[0m00:22:48.324113 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.331520 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.332028 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.332236 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m00:22:48.332432 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:48.593876 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:48.595621 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.596842 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:22:48.629982 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:48.636770 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 00:22:48.324260 => 00:22:48.636434
[0m00:22:48.637336 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m00:22:48.668786 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m00:22:48.670676 [error] [Thread-1 (]: 11 of 18 FAIL 1 not_null_my_first_dbt_model_id ................................. [[31mFAIL 1[0m in 0.36s]
[0m00:22:48.671901 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.672674 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:48.673526 [info ] [Thread-1 (]: 12 of 18 START test unique_my_first_dbt_model_id ............................... [RUN]
[0m00:22:48.674667 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710, now test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321)
[0m00:22:48.675509 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:48.686024 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.687055 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321 (compile): 00:22:48.675916 => 00:22:48.686825
[0m00:22:48.687485 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:48.690486 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.691422 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.691729 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m00:22:48.692013 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:48.953027 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:48.954923 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.955696 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:22:48.989122 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:48.992491 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321 (execute): 00:22:48.687730 => 00:22:48.992145
[0m00:22:48.993127 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m00:22:49.025047 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: Close
[0m00:22:49.028601 [info ] [Thread-1 (]: 12 of 18 PASS unique_my_first_dbt_model_id ..................................... [[32mPASS[0m in 0.35s]
[0m00:22:49.030096 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:49.030820 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.031733 [info ] [Thread-1 (]: 13 of 18 START test not_null_outclick_cost_int_id .............................. [RUN]
[0m00:22:49.032889 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m00:22:49.033382 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.040389 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.042084 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 00:22:49.033680 => 00:22:49.041728
[0m00:22:49.042588 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.045614 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.046518 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.046855 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m00:22:49.047150 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:49.324613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:49.326160 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.327060 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m00:22:49.374966 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:49.379766 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 00:22:49.042838 => 00:22:49.379311
[0m00:22:49.380504 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m00:22:49.413994 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m00:22:49.416596 [info ] [Thread-1 (]: 13 of 18 PASS not_null_outclick_cost_int_id .................................... [[32mPASS[0m in 0.38s]
[0m00:22:49.417826 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.418588 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.419385 [info ] [Thread-1 (]: 14 of 18 START test unique_outclick_cost_int_id ................................ [RUN]
[0m00:22:49.420639 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m00:22:49.421241 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.428966 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.430456 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 00:22:49.421942 => 00:22:49.430238
[0m00:22:49.431082 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.434344 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.435201 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.435552 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m00:22:49.435895 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:49.740150 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:49.741919 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.742707 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:22:49.797399 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:49.802645 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 00:22:49.431447 => 00:22:49.801899
[0m00:22:49.803850 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m00:22:49.840704 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m00:22:49.843376 [error] [Thread-1 (]: 14 of 18 FAIL 6892 unique_outclick_cost_int_id ................................. [[31mFAIL 6892[0m in 0.42s]
[0m00:22:49.844625 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.845347 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m00:22:49.846284 [info ] [Thread-1 (]: 15 of 18 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m00:22:49.847471 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f, now model.campaign_perfomance.brand_comparison_fi)
[0m00:22:49.848021 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m00:22:49.854312 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:49.855718 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 00:22:49.848653 => 00:22:49.855495
[0m00:22:49.856149 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m00:22:49.861519 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:49.862667 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:49.862982 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m00:22:49.863270 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:50.140428 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:50.142406 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.143867 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m00:22:50.206274 [debug] [Thread-1 (]: SQL status: SELECT 68 in 0.0 seconds
[0m00:22:50.215595 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.216321 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m00:22:50.250549 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:50.257817 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.258255 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m00:22:50.291484 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:50.295499 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:22:50.296213 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.296879 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:22:50.330390 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:50.341060 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.341520 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m00:22:50.392554 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:50.394888 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 00:22:49.856427 => 00:22:50.394665
[0m00:22:50.395328 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m00:22:50.396539 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b8c2d0>]}
[0m00:22:50.397252 [info ] [Thread-1 (]: 15 of 18 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 68[0m in 0.55s]
[0m00:22:50.398155 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m00:22:50.398761 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m00:22:50.399295 [info ] [Thread-1 (]: 16 of 18 SKIP relation danila.my_second_dbt_model .............................. [[33mSKIP[0m]
[0m00:22:50.399827 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m00:22:50.400588 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_my_second_dbt_model_id.151b76d778
[0m00:22:50.401023 [info ] [Thread-1 (]: 17 of 18 SKIP test not_null_my_second_dbt_model_id ............................. [[33mSKIP[0m]
[0m00:22:50.401623 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_my_second_dbt_model_id.151b76d778
[0m00:22:50.401966 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_my_second_dbt_model_id.57a0f8c493
[0m00:22:50.402319 [info ] [Thread-1 (]: 18 of 18 SKIP test unique_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m00:22:50.402723 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_my_second_dbt_model_id.57a0f8c493
[0m00:22:50.404024 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:50.404282 [debug] [MainThread]: On master: BEGIN
[0m00:22:50.404497 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:22:50.765967 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:22:50.767551 [debug] [MainThread]: On master: COMMIT
[0m00:22:50.768433 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:50.769233 [debug] [MainThread]: On master: COMMIT
[0m00:22:50.812876 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:22:50.813940 [debug] [MainThread]: On master: Close
[0m00:22:50.816297 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:22:50.817095 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m00:22:50.817789 [info ] [MainThread]: 
[0m00:22:50.818400 [info ] [MainThread]: Finished running 10 table models, 2 view models, 6 tests in 0 hours 0 minutes and 47.40 seconds (47.40s).
[0m00:22:50.822511 [debug] [MainThread]: Command end result
[0m00:22:50.835531 [info ] [MainThread]: 
[0m00:22:50.836083 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m00:22:50.836391 [info ] [MainThread]: 
[0m00:22:50.836708 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m00:22:50.836998 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m00:22:50.837146 [info ] [MainThread]: 
[0m00:22:50.837276 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m00:22:50.837418 [info ] [MainThread]: 
[0m00:22:50.837543 [error] [MainThread]: [31mFailure in test unique_outclick_cost_int_id (models/brand_performance/schema.yml)[0m
[0m00:22:50.837663 [error] [MainThread]:   Got 6892 results, configured to fail if != 0
[0m00:22:50.837779 [info ] [MainThread]: 
[0m00:22:50.837894 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_cost_int_id.sql
[0m00:22:50.838029 [info ] [MainThread]: 
[0m00:22:50.838188 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=2 SKIP=3 TOTAL=18
[0m00:22:50.838526 [debug] [MainThread]: Command `dbt build` failed at 00:22:50.838473 after 47.54 seconds
[0m00:22:50.838713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e84310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034c25d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107989290>]}
[0m00:22:50.838895 [debug] [MainThread]: Flushing usage events
[0m00:42:33.470759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e39dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e53bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e53f90>]}


============================== 00:42:33.472301 | e445f906-6e85-4069-8379-269a0f62fd9c ==============================
[0m00:42:33.472301 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:42:33.472598 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'log_path': '/Users/danila/github/dbt/logs', 'debug': 'False', 'target_path': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'version_check': 'True', 'introspect': 'True', 'static_parser': 'True', 'quiet': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'partial_parse': 'True', 'use_colors': 'True'}
[0m00:42:33.504938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e695d0>]}
[0m00:42:33.511225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e63590>]}
[0m00:42:33.511741 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:42:33.523288 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:42:33.564642 [debug] [MainThread]: Partial parsing enabled: 12 files deleted, 0 files added, 0 files changed.
[0m00:42:33.564966 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/test.sql
[0m00:42:33.565079 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/deals_dim.sql
[0m00:42:33.565173 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/my_first_dbt_model.sql
[0m00:42:33.565259 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/brand_comparison_fi.sql
[0m00:42:33.565341 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/brand_performance_replacement.sql
[0m00:42:33.565425 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/daily_campaign_fct.sql
[0m00:42:33.565505 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/campaign_dim.sql
[0m00:42:33.565585 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/my_second_dbt_model.sql
[0m00:42:33.565666 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/outclicks_fct.sql
[0m00:42:33.565743 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/test_write.sql
[0m00:42:33.567752 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m00:42:33.570014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e53390>]}
[0m00:42:33.574979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107449fd0>]}
[0m00:42:33.575179 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m00:42:33.575936 [info ] [MainThread]: 
[0m00:42:33.576294 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:42:33.576789 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:42:33.581097 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:42:33.581293 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:42:33.581411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:42:33.931486 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:42:33.936697 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:42:33.940881 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:42:33.950427 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:33.950913 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:42:33.951237 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:42:34.233093 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:42:34.235122 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:34.236347 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:42:34.274251 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m00:42:34.275951 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:42:34.308895 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:42:34.313285 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.313501 [debug] [MainThread]: On master: BEGIN
[0m00:42:34.313649 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:42:34.571756 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:34.573572 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.574554 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:42:34.615841 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m00:42:34.622269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10744aa50>]}
[0m00:42:34.623378 [debug] [MainThread]: On master: ROLLBACK
[0m00:42:34.655374 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.656605 [debug] [MainThread]: On master: BEGIN
[0m00:42:34.719085 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:34.720524 [debug] [MainThread]: On master: COMMIT
[0m00:42:34.721223 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.721770 [debug] [MainThread]: On master: COMMIT
[0m00:42:34.753951 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:42:34.755362 [debug] [MainThread]: On master: Close
[0m00:42:34.757843 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:42:34.758598 [info ] [MainThread]: 
[0m00:42:34.766043 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:34.766754 [info ] [Thread-1 (]: 1 of 4 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m00:42:34.767633 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:42:34.768033 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:34.777166 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:34.778401 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:42:34.768281 => 00:42:34.778188
[0m00:42:34.778732 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:34.803713 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:34.804262 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:34.804442 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:42:34.804608 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:35.066648 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:35.067985 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:35.069736 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:42:42.963080 [debug] [Thread-1 (]: SQL status: SELECT 153732 in 8.0 seconds
[0m00:42:42.977937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:42.978787 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:42:43.010667 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:43.017697 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:43.018299 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:42:43.050694 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:43.078058 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:42:43.078574 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:43.078848 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:42:43.109793 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:42:43.117042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:43.117385 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:42:43.165085 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:42:43.168141 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:42:34.778913 => 00:42:43.167852
[0m00:42:43.168731 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:42:43.170186 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074fcd50>]}
[0m00:42:43.170986 [info ] [Thread-1 (]: 1 of 4 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 153732[0m in 8.40s]
[0m00:42:43.171729 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:43.172202 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:42:43.172754 [info ] [Thread-1 (]: 2 of 4 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m00:42:43.173501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:42:43.173851 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:42:43.188828 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.190496 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:42:43.174082 => 00:42:43.190347
[0m00:42:43.190732 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:42:43.193579 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.194130 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.194327 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:42:43.194507 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:43.515254 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:43.516810 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.517888 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m00:42:48.387822 [debug] [Thread-1 (]: SQL status: SELECT 45951 in 5.0 seconds
[0m00:42:48.396987 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.397914 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:42:48.428993 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:48.436349 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.437028 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:42:48.468862 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:48.473918 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:42:48.474761 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.475416 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:42:48.527819 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:42:48.533986 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.534736 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:42:48.581861 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:42:48.585542 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:42:43.190875 => 00:42:48.585149
[0m00:42:48.586295 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:42:48.588188 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107518310>]}
[0m00:42:48.589367 [info ] [Thread-1 (]: 2 of 4 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45951[0m in 5.41s]
[0m00:42:48.590508 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:42:48.592245 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.592819 [info ] [Thread-1 (]: 3 of 4 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m00:42:48.593919 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m00:42:48.594399 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.608373 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.610063 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 00:42:48.594694 => 00:42:48.609867
[0m00:42:48.610373 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.620169 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.621330 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.621646 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m00:42:48.621871 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:48.899133 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:48.901127 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.902195 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m00:42:48.946756 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:42:48.952239 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 00:42:48.610574 => 00:42:48.951758
[0m00:42:48.953059 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m00:42:48.987139 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m00:42:48.990702 [info ] [Thread-1 (]: 3 of 4 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.40s]
[0m00:42:48.992212 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.993095 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:48.994023 [info ] [Thread-1 (]: 4 of 4 START test unique_outclick_cost_int_id .................................. [RUN]
[0m00:42:48.995437 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m00:42:48.996136 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:49.007322 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.009494 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 00:42:48.996846 => 00:42:49.009282
[0m00:42:49.009834 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:49.012207 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.013098 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.013396 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m00:42:49.013669 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:49.364644 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:49.365755 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.366351 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:42:49.425780 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:42:49.430018 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 00:42:49.010040 => 00:42:49.429544
[0m00:42:49.430812 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m00:42:49.473930 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m00:42:49.477136 [error] [Thread-1 (]: 4 of 4 FAIL 6895 unique_outclick_cost_int_id ................................... [[31mFAIL 6895[0m in 0.48s]
[0m00:42:49.478675 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:49.481870 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:49.482489 [debug] [MainThread]: On master: BEGIN
[0m00:42:49.483034 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:42:49.740767 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:49.742531 [debug] [MainThread]: On master: COMMIT
[0m00:42:49.743638 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:49.744345 [debug] [MainThread]: On master: COMMIT
[0m00:42:49.774839 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:42:49.776390 [debug] [MainThread]: On master: Close
[0m00:42:49.778428 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:42:49.778872 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m00:42:49.779413 [info ] [MainThread]: 
[0m00:42:49.780026 [info ] [MainThread]: Finished running 2 table models, 2 tests in 0 hours 0 minutes and 16.20 seconds (16.20s).
[0m00:42:49.781489 [debug] [MainThread]: Command end result
[0m00:42:49.794803 [info ] [MainThread]: 
[0m00:42:49.795327 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:42:49.795604 [info ] [MainThread]: 
[0m00:42:49.795882 [error] [MainThread]: [31mFailure in test unique_outclick_cost_int_id (models/brand_performance/schema.yml)[0m
[0m00:42:49.796141 [error] [MainThread]:   Got 6895 results, configured to fail if != 0
[0m00:42:49.796374 [info ] [MainThread]: 
[0m00:42:49.796615 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_cost_int_id.sql
[0m00:42:49.796866 [info ] [MainThread]: 
[0m00:42:49.797185 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m00:42:49.797684 [debug] [MainThread]: Command `dbt build` failed at 00:42:49.797604 after 16.34 seconds
[0m00:42:49.797958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102f7e5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102f7e650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e44090>]}
[0m00:42:49.798218 [debug] [MainThread]: Flushing usage events
[0m00:42:58.851966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e6fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e85650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8c4d0>]}


============================== 00:42:58.853826 | e4933fce-325e-470f-ad04-4095ab54e33c ==============================
[0m00:42:58.853826 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:42:58.854151 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'introspect': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'partial_parse': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False', 'static_parser': 'True', 'debug': 'False', 'write_json': 'True', 'warn_error': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None'}
[0m00:42:58.885049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eaa7d0>]}
[0m00:42:58.891386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8d1d0>]}
[0m00:42:58.891845 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:42:58.902487 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:42:58.931947 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:42:58.932136 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:42:58.932347 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m00:42:58.934673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c07c90>]}
[0m00:42:58.937847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea9a10>]}
[0m00:42:58.938003 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m00:42:58.938730 [info ] [MainThread]: 
[0m00:42:58.939054 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:42:58.939516 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:42:58.943747 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:42:58.943916 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:42:58.944042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:42:59.247059 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:42:59.251334 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:42:59.255425 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:42:59.264390 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:59.264940 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:42:59.265259 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:42:59.549892 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:42:59.551134 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:59.552008 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:42:59.587101 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m00:42:59.592339 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:42:59.624348 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:42:59.640037 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:59.640734 [debug] [MainThread]: On master: BEGIN
[0m00:42:59.641149 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:42:59.904419 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:59.905695 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:59.906790 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:42:59.950654 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m00:42:59.956036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e9e910>]}
[0m00:42:59.957140 [debug] [MainThread]: On master: ROLLBACK
[0m00:42:59.988480 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:59.989583 [debug] [MainThread]: On master: BEGIN
[0m00:43:00.051595 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:43:00.052785 [debug] [MainThread]: On master: COMMIT
[0m00:43:00.053706 [debug] [MainThread]: Using postgres connection "master"
[0m00:43:00.054426 [debug] [MainThread]: On master: COMMIT
[0m00:43:00.085800 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:43:00.086664 [debug] [MainThread]: On master: Close
[0m00:43:00.088783 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:43:00.089793 [info ] [MainThread]: 
[0m00:43:00.099754 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:00.100727 [info ] [Thread-1 (]: 1 of 4 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m00:43:00.101957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:43:00.102467 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:00.114560 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.115969 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:43:00.102800 => 00:43:00.115722
[0m00:43:00.116299 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:00.141640 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.142232 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.142421 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:43:00.142597 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:00.401345 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:00.402970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.404152 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:43:07.984866 [debug] [Thread-1 (]: SQL status: SELECT 153732 in 8.0 seconds
[0m00:43:07.998636 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:07.999381 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:43:08.030952 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:08.038456 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:08.039193 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:43:08.071185 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:08.096099 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:43:08.096640 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:08.096933 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:43:08.127984 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:43:08.133003 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:08.133331 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:43:08.181247 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:43:08.184389 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:43:00.116487 => 00:43:08.184050
[0m00:43:08.185056 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:43:08.186965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055e2150>]}
[0m00:43:08.187836 [info ] [Thread-1 (]: 1 of 4 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 153732[0m in 8.09s]
[0m00:43:08.188615 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:08.189101 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:43:08.189774 [info ] [Thread-1 (]: 2 of 4 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m00:43:08.190611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:43:08.190970 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:43:08.207467 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.209146 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:43:08.191182 => 00:43:08.208993
[0m00:43:08.209393 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:43:08.212241 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.212692 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.212899 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:43:08.213082 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:08.545006 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:08.546518 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.547815 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m00:43:13.286385 [debug] [Thread-1 (]: SQL status: SELECT 45951 in 5.0 seconds
[0m00:43:13.290532 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.291002 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:43:13.330987 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:13.334469 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.334850 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:43:13.375148 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:13.380907 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:43:13.381448 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.381823 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:43:13.422147 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:43:13.427418 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.427971 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:43:13.483615 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:43:13.487989 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:43:08.209546 => 00:43:13.487542
[0m00:43:13.488939 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:43:13.491258 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057a8390>]}
[0m00:43:13.492540 [info ] [Thread-1 (]: 2 of 4 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45951[0m in 5.30s]
[0m00:43:13.493803 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:43:13.495420 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.496159 [info ] [Thread-1 (]: 3 of 4 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m00:43:13.497298 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m00:43:13.497954 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.512109 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.514148 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 00:43:13.498349 => 00:43:13.513910
[0m00:43:13.514488 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.524397 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.525191 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.525423 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m00:43:13.525614 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:13.854482 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:13.856763 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.857940 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m00:43:13.909216 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:43:13.915404 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 00:43:13.514670 => 00:43:13.914939
[0m00:43:13.916148 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m00:43:13.956647 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m00:43:13.959895 [info ] [Thread-1 (]: 3 of 4 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.46s]
[0m00:43:13.961317 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.962231 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:13.963235 [info ] [Thread-1 (]: 4 of 4 START test unique_outclick_cost_int_id .................................. [RUN]
[0m00:43:13.964804 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m00:43:13.965532 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:13.976032 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:13.977134 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 00:43:13.965988 => 00:43:13.976916
[0m00:43:13.977517 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:13.980191 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:13.980932 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:13.981227 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m00:43:13.981506 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:14.243205 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:14.244962 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:14.246127 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:43:14.306567 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:43:14.310802 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 00:43:13.977752 => 00:43:14.310214
[0m00:43:14.311570 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m00:43:14.342711 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m00:43:14.345772 [info ] [Thread-1 (]: 4 of 4 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.38s]
[0m00:43:14.347234 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:14.350386 [debug] [MainThread]: Using postgres connection "master"
[0m00:43:14.351131 [debug] [MainThread]: On master: BEGIN
[0m00:43:14.351766 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:43:14.638298 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:43:14.639683 [debug] [MainThread]: On master: COMMIT
[0m00:43:14.640434 [debug] [MainThread]: Using postgres connection "master"
[0m00:43:14.641026 [debug] [MainThread]: On master: COMMIT
[0m00:43:14.675385 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:43:14.676905 [debug] [MainThread]: On master: Close
[0m00:43:14.679503 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:43:14.680182 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m00:43:14.680944 [info ] [MainThread]: 
[0m00:43:14.681708 [info ] [MainThread]: Finished running 2 table models, 2 tests in 0 hours 0 minutes and 15.74 seconds (15.74s).
[0m00:43:14.684027 [debug] [MainThread]: Command end result
[0m00:43:14.695392 [info ] [MainThread]: 
[0m00:43:14.696059 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:43:14.696460 [info ] [MainThread]: 
[0m00:43:14.696870 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m00:43:14.697582 [debug] [MainThread]: Command `dbt build` succeeded at 00:43:14.697456 after 15.86 seconds
[0m00:43:14.697993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104894d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e74290>]}
[0m00:43:14.698340 [debug] [MainThread]: Flushing usage events
[0m12:28:37.874713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ce7b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cfd650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cffd10>]}


============================== 12:28:37.876587 | faf1709a-8a57-4fd4-ad36-de6b0486eeef ==============================
[0m12:28:37.876587 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:28:37.876902 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'no_print': 'None', 'partial_parse': 'True', 'introspect': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'target_path': 'None', 'static_parser': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_format': 'default'}
[0m12:28:37.907433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ce4e10>]}
[0m12:28:37.913955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d04850>]}
[0m12:28:37.914467 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:28:37.924644 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:28:37.952262 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:28:37.952461 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:28:37.952694 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m12:28:37.955062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072b29d0>]}
[0m12:28:37.961501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10716bb90>]}
[0m12:28:37.961737 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m12:28:37.962484 [info ] [MainThread]: 
[0m12:28:37.962867 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:28:37.963326 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m12:28:37.967547 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m12:28:37.967701 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m12:28:37.967821 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:38.250548 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m12:28:38.253450 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m12:28:38.256353 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m12:28:38.264914 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m12:28:38.265535 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m12:28:38.265857 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:38.523925 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:38.524746 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m12:28:38.525403 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m12:28:38.560586 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m12:28:38.563732 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m12:28:38.593990 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m12:28:38.606697 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:38.607109 [debug] [MainThread]: On master: BEGIN
[0m12:28:38.607414 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:28:38.874234 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:38.875797 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:38.876772 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:28:38.923250 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m12:28:38.928626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667cdd0>]}
[0m12:28:38.929656 [debug] [MainThread]: On master: ROLLBACK
[0m12:28:38.962391 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:38.963538 [debug] [MainThread]: On master: BEGIN
[0m12:28:39.029100 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:39.030708 [debug] [MainThread]: On master: COMMIT
[0m12:28:39.031733 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:39.032309 [debug] [MainThread]: On master: COMMIT
[0m12:28:39.063648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:28:39.064598 [debug] [MainThread]: On master: Close
[0m12:28:39.066912 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:28:39.067635 [info ] [MainThread]: 
[0m12:28:39.076031 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:39.076821 [info ] [Thread-1 (]: 1 of 4 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m12:28:39.077660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m12:28:39.078047 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:39.097725 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.099173 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 12:28:39.078290 => 12:28:39.098953
[0m12:28:39.099437 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:39.122505 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.123095 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.123278 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m12:28:39.123433 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:39.415412 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:39.417022 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.418908 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m12:28:47.055209 [debug] [Thread-1 (]: SQL status: SELECT 156347 in 8.0 seconds
[0m12:28:47.068465 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.069181 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m12:28:47.103724 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:47.110419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.111150 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m12:28:47.142826 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:47.172062 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m12:28:47.172580 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.172863 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m12:28:47.203047 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:47.208433 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.208755 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m12:28:47.257848 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:47.261374 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 12:28:39.099551 => 12:28:47.261046
[0m12:28:47.261996 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m12:28:47.263710 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071ea7d0>]}
[0m12:28:47.264658 [info ] [Thread-1 (]: 1 of 4 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156347[0m in 8.19s]
[0m12:28:47.265754 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:47.266472 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m12:28:47.267167 [info ] [Thread-1 (]: 2 of 4 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m12:28:47.268081 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m12:28:47.268479 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m12:28:47.278259 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.279610 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 12:28:47.268723 => 12:28:47.279444
[0m12:28:47.279875 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m12:28:47.283217 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.283631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.283841 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m12:28:47.284041 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:47.645061 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:47.647178 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.648431 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m12:28:52.441799 [debug] [Thread-1 (]: SQL status: SELECT 46501 in 5.0 seconds
[0m12:28:52.451249 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.451933 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m12:28:52.494922 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:52.505219 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.505870 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m12:28:52.545776 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:52.551701 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m12:28:52.552445 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.552948 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m12:28:52.593015 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:52.599936 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.600722 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m12:28:52.656954 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:52.661155 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 12:28:47.280039 => 12:28:52.660759
[0m12:28:52.662047 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m12:28:52.664543 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073cbd90>]}
[0m12:28:52.665625 [info ] [Thread-1 (]: 2 of 4 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46501[0m in 5.40s]
[0m12:28:52.666822 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m12:28:52.668303 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:52.668960 [info ] [Thread-1 (]: 3 of 4 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m12:28:52.669947 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m12:28:52.670415 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:52.684126 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.686605 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 12:28:52.670707 => 12:28:52.686416
[0m12:28:52.686901 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:52.696129 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.696853 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.697085 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m12:28:52.697271 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:52.976716 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:52.978450 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.979607 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m12:28:53.027406 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m12:28:53.032690 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 12:28:52.687076 => 12:28:53.032258
[0m12:28:53.033518 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m12:28:53.067298 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m12:28:53.070302 [info ] [Thread-1 (]: 3 of 4 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.40s]
[0m12:28:53.071702 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:53.072605 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.073362 [info ] [Thread-1 (]: 4 of 4 START test unique_outclick_cost_int_id .................................. [RUN]
[0m12:28:53.074324 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m12:28:53.074806 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.084705 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.087205 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 12:28:53.075130 => 12:28:53.086929
[0m12:28:53.087593 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.090308 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.091013 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.091269 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m12:28:53.091505 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:53.351229 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:53.351537 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.351763 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m12:28:53.423489 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m12:28:53.426122 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 12:28:53.087815 => 12:28:53.425801
[0m12:28:53.426795 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m12:28:53.458452 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m12:28:53.460974 [info ] [Thread-1 (]: 4 of 4 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.39s]
[0m12:28:53.462060 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.464444 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:53.464899 [debug] [MainThread]: On master: BEGIN
[0m12:28:53.465201 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:28:53.819180 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:53.821113 [debug] [MainThread]: On master: COMMIT
[0m12:28:53.821806 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:53.822393 [debug] [MainThread]: On master: COMMIT
[0m12:28:53.866324 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:28:53.867712 [debug] [MainThread]: On master: Close
[0m12:28:53.869637 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:28:53.870208 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m12:28:53.870933 [info ] [MainThread]: 
[0m12:28:53.871660 [info ] [MainThread]: Finished running 2 table models, 2 tests in 0 hours 0 minutes and 15.91 seconds (15.91s).
[0m12:28:53.873700 [debug] [MainThread]: Command end result
[0m12:28:53.887950 [info ] [MainThread]: 
[0m12:28:53.888737 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:28:53.889066 [info ] [MainThread]: 
[0m12:28:53.889411 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:28:53.890027 [debug] [MainThread]: Command `dbt build` succeeded at 12:28:53.889924 after 16.03 seconds
[0m12:28:53.890366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e2c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e2a650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e2a5d0>]}
[0m12:28:53.890692 [debug] [MainThread]: Flushing usage events
