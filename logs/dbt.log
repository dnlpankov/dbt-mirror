[0m22:56:07.621998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73E4F9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABDC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABC70>]}


============================== 22:56:07.739088 | e658d13a-3aea-45ae-96c8-380c5b933b1f ==============================
[0m22:56:07.739088 [info ] [MainThread]: Running with dbt=1.7.11
[0m22:56:07.760077 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'quiet': 'False', 'write_json': 'True', 'use_colors': 'True', 'invocation_command': 'dbt init', 'fail_fast': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_format': 'default', 'debug': 'False', 'partial_parse': 'True', 'target_path': 'None'}
[0m22:56:07.774041 [warn ] [MainThread]: [ConfigFolderDirectory]: Unable to parse dict {'dir': WindowsPath('C:/Users/Danila/.dbt')}
[0m22:56:07.774997 [info ] [MainThread]: Creating dbt configuration folder at 
[0m22:56:51.233243 [debug] [MainThread]: Starter project path: D:\Users\Danila\anaconda3\envs\dbt_env\lib\site-packages\dbt\include\starter_project
[0m22:56:51.541752 [info ] [MainThread]: 
Your new dbt project "campaign_performance" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m22:56:51.542948 [info ] [MainThread]: Setting up your profile.
[0m23:05:35.210962 [info ] [MainThread]: Profile campaign_performance written to C:\Users\Danila\.dbt\profiles.yml using target's profile_template.yml and your supplied values. Run 'dbt debug' to validate the connection.
[0m23:05:35.626903 [debug] [MainThread]: Command `dbt init` succeeded at 23:05:35.258368 after 567.86 seconds
[0m23:05:35.672312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73E4F9AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABB80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F73DFABCD0>]}
[0m23:05:35.708216 [debug] [MainThread]: Flushing usage events
[0m23:15:15.432463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D63469D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C820>]}


============================== 23:15:15.573512 | 61319262-bf15-452b-a2d5-9e67fe184b2b ==============================
[0m23:15:15.573512 [info ] [MainThread]: Running with dbt=1.7.11
[0m23:15:15.604971 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'introspect': 'True', 'log_path': 'logs', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'log_format': 'default', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'debug': 'False', 'printer_width': '80', 'warn_error': 'None', 'indirect_selection': 'eager', 'static_parser': 'True', 'invocation_command': 'dbt test', 'quiet': 'False', 'fail_fast': 'False'}
[0m23:15:15.631123 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m23:15:15.683477 [debug] [MainThread]: Command `dbt test` failed at 23:15:15.634122 after 0.40 seconds
[0m23:15:15.684472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D63469D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2C850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000263D5E2CD60>]}
[0m23:15:15.688463 [debug] [MainThread]: Flushing usage events
[0m01:12:41.668518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA6DF6AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA5F9A0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DDA00>]}


============================== 01:12:41.786091 | 1d747f0f-2e9f-4533-b232-cb7d88e2ca7d ==============================
[0m01:12:41.786091 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:12:41.806607 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'debug': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'introspect': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt run', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'no_print': 'None', 'printer_width': '80', 'quiet': 'False', 'fail_fast': 'False', 'log_path': 'logs'}
[0m01:12:41.808604 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m01:12:41.829961 [debug] [MainThread]: Command `dbt run` failed at 01:12:41.810604 after 0.31 seconds
[0m01:12:41.830960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA6DF6AC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DD490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020EA68DD5E0>]}
[0m01:12:41.831958 [debug] [MainThread]: Flushing usage events
[0m01:13:05.616119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418E031A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000241904667F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D9A0>]}


============================== 01:13:05.619147 | ced84743-8c0c-4886-a8f2-13495d16fd33 ==============================
[0m01:13:05.619147 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:13:05.621104 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'warn_error': 'None', 'log_format': 'default', 'fail_fast': 'False', 'log_path': 'logs', 'write_json': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'partial_parse': 'True', 'debug': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'profiles_dir': 'C:\\Users\\Danila\\.dbt', 'invocation_command': 'dbt run', 'printer_width': '80', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'use_colors': 'True'}
[0m01:13:05.784488 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path D:\GitHub\dbt\dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m01:13:05.792792 [debug] [MainThread]: Command `dbt run` failed at 01:13:05.791806 after 0.26 seconds
[0m01:13:05.795750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418E031A60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002418DB1D190>]}
[0m01:13:05.798743 [debug] [MainThread]: Flushing usage events
[0m22:27:09.431445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105991f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f23d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f2a90>]}


============================== 22:27:09.433023 | 498f5558-7911-4fbb-b56d-65eed82ab48f ==============================
[0m22:27:09.433023 [info ] [MainThread]: Running with dbt=1.7.0
[0m22:27:09.433342 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'version_check': 'True', 'introspect': 'True', 'log_format': 'default', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'static_parser': 'True', 'debug': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'write_json': 'True', 'use_colors': 'True', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'target_path': 'None'}
[0m22:27:09.499429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059cdb90>]}
[0m22:27:09.529467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c8990>]}
[0m22:27:09.530170 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m22:27:09.537501 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m22:27:09.555599 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:27:09.555842 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:27:09.556321 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m22:27:09.558974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105979a10>]}
[0m22:27:09.564032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106044e90>]}
[0m22:27:09.564291 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m22:27:09.564472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061bbed0>]}
[0m22:27:09.565511 [info ] [MainThread]: 
[0m22:27:09.565882 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:27:09.566597 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:27:09.570892 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:27:09.571081 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:27:09.571240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:27:10.030199 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m22:27:10.034852 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:27:10.038907 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:27:10.048096 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:27:10.048758 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:27:10.049098 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:27:10.394963 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.397244 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:27:10.398436 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m22:27:10.441925 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m22:27:10.446698 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:27:10.506304 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:27:10.523310 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.523779 [debug] [MainThread]: On master: BEGIN
[0m22:27:10.524242 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:27:10.783865 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.784930 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.785553 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:27:10.827627 [debug] [MainThread]: SQL status: SELECT 47 in 0.0 seconds
[0m22:27:10.834200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fab0d0>]}
[0m22:27:10.835227 [debug] [MainThread]: On master: ROLLBACK
[0m22:27:10.866107 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.867503 [debug] [MainThread]: On master: BEGIN
[0m22:27:10.929870 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:10.931303 [debug] [MainThread]: On master: COMMIT
[0m22:27:10.932480 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:10.933570 [debug] [MainThread]: On master: COMMIT
[0m22:27:10.964373 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:27:10.965807 [debug] [MainThread]: On master: Close
[0m22:27:10.968224 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:27:10.968965 [info ] [MainThread]: 
[0m22:27:10.974877 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m22:27:10.975770 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m22:27:10.976963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m22:27:10.977531 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m22:27:10.991359 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:10.992510 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 22:27:10.977902 => 22:27:10.992250
[0m22:27:10.992913 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m22:27:11.018801 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.019386 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.019620 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m22:27:11.019832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:11.490323 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:11.492501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:11.494195 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m22:27:36.140173 [debug] [Thread-1 (]: SQL status: SELECT 2110 in 25.0 seconds
[0m22:27:36.153822 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.154661 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m22:27:36.198635 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.205893 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.206616 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m22:27:36.250434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.279251 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m22:27:36.279807 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.280166 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m22:27:36.323367 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:36.329861 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m22:27:36.334102 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m22:27:36.334465 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m22:27:36.389864 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:36.391886 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 22:27:10.993127 => 22:27:36.391596
[0m22:27:36.392422 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m22:27:36.393596 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f71d10>]}
[0m22:27:36.394376 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2110[0m in 25.42s]
[0m22:27:36.395106 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m22:27:36.395638 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m22:27:36.396264 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m22:27:36.397000 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m22:27:36.397389 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m22:27:36.400382 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m22:27:36.401215 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 22:27:36.397655 => 22:27:36.400990
[0m22:27:36.401600 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m22:27:36.405512 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m22:27:36.406166 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.406484 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m22:27:36.406791 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:36.752487 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:36.753172 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.753701 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m22:27:36.802391 [debug] [Thread-1 (]: SQL status: SELECT 1442 in 0.0 seconds
[0m22:27:36.809155 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.809888 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m22:27:36.841758 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.848824 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.849676 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m22:27:36.881765 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:36.887442 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m22:27:36.888156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.888757 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m22:27:36.920643 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:36.930397 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m22:27:36.931937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m22:27:36.932588 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m22:27:36.984267 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:36.985947 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 22:27:36.401835 => 22:27:36.985740
[0m22:27:36.986343 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m22:27:36.987346 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10627db50>]}
[0m22:27:36.987902 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1442[0m in 0.59s]
[0m22:27:36.988370 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m22:27:36.988705 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.989150 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m22:27:36.989812 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m22:27:36.990147 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.992671 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.993349 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 22:27:36.990333 => 22:27:36.993180
[0m22:27:36.993656 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m22:27:36.996816 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.997273 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:36.997523 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m22:27:36.997755 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:37.749776 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:27:37.750496 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.750943 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m22:27:37.810303 [debug] [Thread-1 (]: SQL status: SELECT 1442 in 0.0 seconds
[0m22:27:37.815932 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.816533 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m22:27:37.856775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:37.862846 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.863490 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m22:27:37.903660 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:37.908087 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m22:27:37.908799 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.909560 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m22:27:37.950714 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:37.957719 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m22:27:37.959572 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m22:27:37.960324 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m22:27:38.018347 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:38.022183 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 22:27:36.993837 => 22:27:38.021744
[0m22:27:38.023082 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m22:27:38.025207 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106292f10>]}
[0m22:27:38.026223 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1442[0m in 1.04s]
[0m22:27:38.027144 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m22:27:38.027882 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m22:27:38.028676 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m22:27:38.029613 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m22:27:38.030103 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m22:27:38.035094 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m22:27:38.036202 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 22:27:38.030390 => 22:27:38.035933
[0m22:27:38.036638 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m22:27:38.041364 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m22:27:38.042086 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.042406 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m22:27:38.042708 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:38.395142 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:38.396538 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.397451 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m22:27:38.448016 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m22:27:38.457384 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.458069 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m22:27:38.501335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:38.508761 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.509412 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m22:27:38.552608 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:38.558811 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m22:27:38.559593 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.560292 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m22:27:38.603016 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:38.608975 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m22:27:38.610388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m22:27:38.610990 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m22:27:38.674369 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:38.679053 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 22:27:38.036899 => 22:27:38.678596
[0m22:27:38.679866 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m22:27:38.681755 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106219310>]}
[0m22:27:38.682761 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.65s]
[0m22:27:38.683643 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m22:27:38.684297 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.685285 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m22:27:38.686273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m22:27:38.686751 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.691324 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.692365 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 22:27:38.687048 => 22:27:38.692083
[0m22:27:38.692836 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m22:27:38.699634 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.700297 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.700616 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m22:27:38.700921 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:38.958826 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:38.960690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:38.961627 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m22:27:38.996621 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m22:27:39.005573 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.006424 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m22:27:39.039001 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:39.046848 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.047816 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m22:27:39.080223 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:39.085020 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m22:27:39.085869 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.086442 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m22:27:39.116866 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:39.124271 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m22:27:39.126016 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m22:27:39.126791 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m22:27:39.175824 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:39.180214 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 22:27:38.693123 => 22:27:39.179792
[0m22:27:39.180995 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m22:27:39.182621 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062cd390>]}
[0m22:27:39.183549 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.50s]
[0m22:27:39.184420 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m22:27:39.185098 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.186032 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m22:27:39.187033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:27:39.187511 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.194169 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.195111 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:27:39.187816 => 22:27:39.194881
[0m22:27:39.195512 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:39.199733 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.200271 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.200597 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:27:39.200909 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:39.561948 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:39.563388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:39.564503 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
  );
  
[0m22:27:48.970380 [debug] [Thread-1 (]: SQL status: SELECT 143735 in 9.0 seconds
[0m22:27:48.979568 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:48.980462 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:27:49.025107 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:49.032166 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.032851 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:27:49.077241 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:49.080983 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:27:49.081646 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.082198 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:27:49.127129 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:49.134047 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m22:27:49.135304 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:27:49.135818 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:27:49.195903 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:49.200151 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:27:39.195756 => 22:27:49.199740
[0m22:27:49.201052 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:27:49.203040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b16d0>]}
[0m22:27:49.204196 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 143735[0m in 10.02s]
[0m22:27:49.205341 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:27:49.206233 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.207200 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m22:27:49.208240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:27:49.208795 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.215458 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.217016 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:27:49.209117 => 22:27:49.216675
[0m22:27:49.217565 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:27:49.222502 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.223301 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.223686 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:27:49.224060 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:49.503377 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:49.505435 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:49.506533 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2023-12-31' --matomo
    group by day, country_code, campaign_name, ga_campaign_name
  );
  
[0m22:27:54.396656 [debug] [Thread-1 (]: SQL status: SELECT 39884 in 5.0 seconds
[0m22:27:54.404128 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.404808 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:27:54.438311 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:54.443205 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:27:54.444016 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.444715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:27:54.478406 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:54.488162 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m22:27:54.489292 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:27:54.489777 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:27:54.544836 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:54.549017 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:27:49.217868 => 22:27:54.548622
[0m22:27:54.549782 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:27:54.551605 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10628af10>]}
[0m22:27:54.552547 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 39884[0m in 5.34s]
[0m22:27:54.553384 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:27:54.554048 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m22:27:54.554844 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m22:27:54.555949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m22:27:54.556455 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m22:27:54.561518 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m22:27:54.562834 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 22:27:54.556780 => 22:27:54.562536
[0m22:27:54.563335 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m22:27:54.579594 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m22:27:54.580232 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:54.580517 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m22:27:54.580783 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:54.953823 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:54.955952 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:54.956853 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m22:27:54.992211 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:27:55.000558 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.001196 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m22:27:55.032479 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.038158 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.038921 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m22:27:55.070505 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.074660 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m22:27:55.075274 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.075784 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m22:27:55.106482 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:55.112418 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m22:27:55.118306 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m22:27:55.118858 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m22:27:55.150298 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:27:55.153524 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 22:27:54.563621 => 22:27:55.152911
[0m22:27:55.154354 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m22:27:55.156298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062886d0>]}
[0m22:27:55.157407 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.60s]
[0m22:27:55.158535 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m22:27:55.159381 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m22:27:55.160222 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m22:27:55.161196 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m22:27:55.161747 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m22:27:55.166048 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m22:27:55.167873 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 22:27:55.162105 => 22:27:55.167232
[0m22:27:55.168544 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m22:27:55.174169 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m22:27:55.174943 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.175328 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m22:27:55.175700 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:55.429467 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:55.431706 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.432901 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m22:27:55.467155 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:27:55.475750 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.476403 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m22:27:55.507789 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.514638 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.515417 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m22:27:55.546692 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:55.552879 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m22:27:55.553525 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.554020 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m22:27:55.584809 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:55.589659 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m22:27:55.590796 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m22:27:55.591731 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m22:27:55.639605 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:55.642923 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 22:27:55.168864 => 22:27:55.642495
[0m22:27:55.643815 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m22:27:55.645779 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060925d0>]}
[0m22:27:55.646976 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.48s]
[0m22:27:55.647868 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m22:27:55.648558 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m22:27:55.649333 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m22:27:55.650341 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m22:27:55.650891 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m22:27:55.656342 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.657570 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 22:27:55.651213 => 22:27:55.657270
[0m22:27:55.658074 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m22:27:55.701483 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.702086 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.702298 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m22:27:55.702484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:55.956890 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:55.958644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:55.959516 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m22:27:56.560323 [debug] [Thread-1 (]: SQL status: SELECT 55542 in 1.0 seconds
[0m22:27:56.568384 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.569031 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m22:27:56.599768 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:56.605821 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.606436 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m22:27:56.637886 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:56.642342 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m22:27:56.643105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.643798 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m22:27:56.675719 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:56.682573 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m22:27:56.684150 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m22:27:56.684704 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m22:27:56.732900 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:56.736683 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 22:27:55.658359 => 22:27:56.736245
[0m22:27:56.737493 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m22:27:56.739385 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105023b10>]}
[0m22:27:56.740560 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 55542[0m in 1.09s]
[0m22:27:56.741677 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m22:27:56.742605 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.743739 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m22:27:56.744750 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m22:27:56.745292 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.750222 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.751620 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 22:27:56.745629 => 22:27:56.751370
[0m22:27:56.752461 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m22:27:56.758093 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.759054 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:56.759444 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m22:27:56.759801 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:57.012525 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:57.014534 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.015326 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m22:27:57.049577 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:27:57.057609 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.058294 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m22:27:57.090077 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.094153 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m22:27:57.095088 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.095823 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m22:27:57.126762 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:57.130333 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m22:27:57.131296 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m22:27:57.131708 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m22:27:57.162380 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:27:57.165101 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 22:27:56.752775 => 22:27:57.164791
[0m22:27:57.165699 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m22:27:57.167269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062938d0>]}
[0m22:27:57.168067 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.42s]
[0m22:27:57.168792 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m22:27:57.169318 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.169837 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m22:27:57.170773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m22:27:57.171264 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.174971 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.175936 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 22:27:57.171524 => 22:27:57.175686
[0m22:27:57.176340 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.180232 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.180820 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.181142 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m22:27:57.181442 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:27:57.538668 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:27:57.540802 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.541953 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m22:27:57.614303 [debug] [Thread-1 (]: SQL status: SELECT 64 in 0.0 seconds
[0m22:27:57.623154 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.623855 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m22:27:57.667648 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.674181 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.674801 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m22:27:57.718255 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:27:57.724088 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m22:27:57.724878 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.725488 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m22:27:57.769695 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:27:57.779761 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m22:27:57.781024 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m22:27:57.781481 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m22:27:57.841645 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:27:57.845896 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 22:27:57.176573 => 22:27:57.845491
[0m22:27:57.846658 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m22:27:57.848219 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '498f5558-7911-4fbb-b56d-65eed82ab48f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106268d90>]}
[0m22:27:57.849090 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 64[0m in 0.68s]
[0m22:27:57.849855 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m22:27:57.851935 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:57.852369 [debug] [MainThread]: On master: BEGIN
[0m22:27:57.852738 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:27:58.137308 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:27:58.139581 [debug] [MainThread]: On master: COMMIT
[0m22:27:58.140891 [debug] [MainThread]: Using postgres connection "master"
[0m22:27:58.141547 [debug] [MainThread]: On master: COMMIT
[0m22:27:58.175882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:27:58.177329 [debug] [MainThread]: On master: Close
[0m22:27:58.180189 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:27:58.180783 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m22:27:58.181570 [info ] [MainThread]: 
[0m22:27:58.182466 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 48.62 seconds (48.62s).
[0m22:27:58.185794 [debug] [MainThread]: Command end result
[0m22:27:58.198322 [info ] [MainThread]: 
[0m22:27:58.198913 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:27:58.199276 [info ] [MainThread]: 
[0m22:27:58.199651 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m22:27:58.201977 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 48.805172, "process_user_time": 1.794044, "process_kernel_time": 0.182757, "process_mem_max_rss": "126418944", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m22:27:58.202496 [debug] [MainThread]: Command `dbt run` succeeded at 22:27:58.202384 after 48.81 seconds
[0m22:27:58.202844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f1650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1012fdf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101238850>]}
[0m22:27:58.203180 [debug] [MainThread]: Flushing usage events
[0m11:29:27.824869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109947450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099be010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099be690>]}


============================== 11:29:27.826720 | 7a3f9496-6a36-43cd-b22b-d360356d14b7 ==============================
[0m11:29:27.826720 [info ] [MainThread]: Running with dbt=1.7.0
[0m11:29:27.827110 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'no_print': 'None', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'use_colors': 'True', 'debug': 'False', 'target_path': 'None', 'quiet': 'False', 'printer_width': '80', 'warn_error': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'fail_fast': 'False', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'indirect_selection': 'eager'}
[0m11:29:27.900579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a80d510>]}
[0m11:29:27.930763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e67650>]}
[0m11:29:27.931151 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m11:29:27.938707 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m11:29:27.959472 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:29:27.959731 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:29:27.960186 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m11:29:27.962766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e9eb90>]}
[0m11:29:27.969266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa37fd0>]}
[0m11:29:27.969493 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m11:29:27.969673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a819750>]}
[0m11:29:27.970675 [info ] [MainThread]: 
[0m11:29:27.971065 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:29:27.971771 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m11:29:27.976589 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m11:29:27.976854 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m11:29:27.977151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:29:28.309454 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m11:29:28.313475 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m11:29:28.318370 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m11:29:28.327934 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m11:29:28.328530 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m11:29:28.328955 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:29:28.688080 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m11:29:28.689890 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m11:29:28.691385 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m11:29:28.758382 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m11:29:28.764126 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m11:29:28.806919 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m11:29:28.823788 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:28.824530 [debug] [MainThread]: On master: BEGIN
[0m11:29:28.825007 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:29:29.154978 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.157369 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.158729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:29:29.208972 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m11:29:29.213748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109944fd0>]}
[0m11:29:29.214763 [debug] [MainThread]: On master: ROLLBACK
[0m11:29:29.253883 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.254823 [debug] [MainThread]: On master: BEGIN
[0m11:29:29.332746 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.334415 [debug] [MainThread]: On master: COMMIT
[0m11:29:29.335703 [debug] [MainThread]: Using postgres connection "master"
[0m11:29:29.336397 [debug] [MainThread]: On master: COMMIT
[0m11:29:29.375648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:29:29.377049 [debug] [MainThread]: On master: Close
[0m11:29:29.380195 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m11:29:29.381272 [info ] [MainThread]: 
[0m11:29:29.387196 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.388055 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m11:29:29.389084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m11:29:29.389791 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.402061 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.403341 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 11:29:29.390202 => 11:29:29.403100
[0m11:29:29.403725 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m11:29:29.428342 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.429320 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.429568 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m11:29:29.429788 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:29.683814 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:29.685975 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:29.687759 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m11:29:56.189010 [debug] [Thread-1 (]: SQL status: SELECT 2111 in 26.0 seconds
[0m11:29:56.202850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.203719 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m11:29:56.260397 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.269071 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.269901 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m11:29:56.301182 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.336736 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m11:29:56.337480 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.337981 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m11:29:56.369530 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:56.380629 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m11:29:56.386373 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m11:29:56.386885 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m11:29:56.431511 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:56.435743 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 11:29:29.403937 => 11:29:56.435150
[0m11:29:56.436835 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m11:29:56.438869 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa93890>]}
[0m11:29:56.440068 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2111[0m in 27.05s]
[0m11:29:56.441285 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m11:29:56.442166 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m11:29:56.443411 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m11:29:56.444697 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m11:29:56.445304 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m11:29:56.449939 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m11:29:56.452731 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 11:29:56.445689 => 11:29:56.452366
[0m11:29:56.453278 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m11:29:56.458949 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m11:29:56.459970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.460395 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m11:29:56.460766 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:56.834919 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:56.837210 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.837984 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m11:29:56.886982 [debug] [Thread-1 (]: SQL status: SELECT 1473 in 0.0 seconds
[0m11:29:56.894810 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.895420 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m11:29:56.929220 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.934831 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.935404 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m11:29:56.968533 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:56.972961 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m11:29:56.974360 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:56.974893 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m11:29:57.008795 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:57.022097 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m11:29:57.023822 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m11:29:57.024770 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m11:29:57.079088 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:57.084269 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 11:29:56.453603 => 11:29:57.083920
[0m11:29:57.084985 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m11:29:57.087428 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac4fbd0>]}
[0m11:29:57.088417 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1473[0m in 0.64s]
[0m11:29:57.089710 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m11:29:57.091069 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.091808 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m11:29:57.093018 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m11:29:57.093886 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.098944 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.099975 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 11:29:57.094520 => 11:29:57.099723
[0m11:29:57.100549 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.106875 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.108709 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.109251 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m11:29:57.109741 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:57.417280 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:57.419062 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.420479 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m11:29:57.481452 [debug] [Thread-1 (]: SQL status: SELECT 1473 in 0.0 seconds
[0m11:29:57.484991 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.485417 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m11:29:57.522643 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:57.524151 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.524332 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m11:29:57.560942 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:57.563484 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m11:29:57.563969 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.564375 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m11:29:57.601034 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:57.606092 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m11:29:57.607644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m11:29:57.608317 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m11:29:57.666246 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:57.670418 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 11:29:57.100920 => 11:29:57.669580
[0m11:29:57.671877 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m11:29:57.675042 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac5cf10>]}
[0m11:29:57.676689 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1473[0m in 0.58s]
[0m11:29:57.678217 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m11:29:57.679641 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m11:29:57.680788 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m11:29:57.682097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m11:29:57.682782 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m11:29:57.688100 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m11:29:57.689822 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 11:29:57.683230 => 11:29:57.689459
[0m11:29:57.690599 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m11:29:57.696860 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m11:29:57.697795 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:57.698020 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m11:29:57.698234 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:57.977130 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:57.978604 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:57.979396 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m11:29:58.017308 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m11:29:58.027390 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.028262 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m11:29:58.060659 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.072085 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.073204 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m11:29:58.104931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.108959 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m11:29:58.109580 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.110320 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m11:29:58.141092 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:58.147300 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m11:29:58.149547 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m11:29:58.150426 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m11:29:58.200278 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:58.204063 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 11:29:57.690967 => 11:29:58.203646
[0m11:29:58.204808 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m11:29:58.207595 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac24110>]}
[0m11:29:58.208700 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.53s]
[0m11:29:58.210162 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m11:29:58.211228 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.212446 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m11:29:58.215020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m11:29:58.216323 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.221734 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.223560 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 11:29:58.216756 => 11:29:58.223150
[0m11:29:58.224310 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.236054 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.237015 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.237478 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m11:29:58.237906 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:58.513810 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:58.515859 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.517408 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m11:29:58.555230 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m11:29:58.568101 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.569718 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m11:29:58.603968 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.613631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.614789 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m11:29:58.649645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:29:58.655279 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m11:29:58.656759 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.658095 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m11:29:58.692407 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:29:58.702810 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m11:29:58.706053 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m11:29:58.707263 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m11:29:58.760056 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:29:58.765608 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 11:29:58.224760 => 11:29:58.764851
[0m11:29:58.767134 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m11:29:58.770743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac7af10>]}
[0m11:29:58.771825 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.56s]
[0m11:29:58.772771 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m11:29:58.773806 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.775139 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m11:29:58.776753 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m11:29:58.777554 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.786247 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.788272 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 11:29:58.777979 => 11:29:58.787805
[0m11:29:58.788967 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m11:29:58.796147 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.797305 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:58.797832 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m11:29:58.798306 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:29:59.119924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:29:59.121186 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:29:59.122231 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m11:30:08.887801 [debug] [Thread-1 (]: SQL status: SELECT 153021 in 10.0 seconds
[0m11:30:08.894791 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.895469 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m11:30:08.935243 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:08.942405 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.943125 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m11:30:08.983043 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:08.987700 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m11:30:08.988536 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:08.989229 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m11:30:09.028142 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:09.033859 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m11:30:09.035545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m11:30:09.036152 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m11:30:09.092780 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:09.096194 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 11:29:58.789466 => 11:30:09.095875
[0m11:30:09.097181 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m11:30:09.099503 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac98510>]}
[0m11:30:09.100722 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153021[0m in 10.32s]
[0m11:30:09.101881 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m11:30:09.102791 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.103771 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m11:30:09.105221 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m11:30:09.106054 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.113080 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.114843 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 11:30:09.106480 => 11:30:09.114415
[0m11:30:09.115643 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m11:30:09.122562 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.123807 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.124308 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m11:30:09.124834 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:09.407733 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:09.409736 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:09.411659 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m11:30:14.314088 [debug] [Thread-1 (]: SQL status: SELECT 45760 in 5.0 seconds
[0m11:30:14.321838 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.322711 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m11:30:14.354506 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.365802 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.366362 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m11:30:14.397524 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.403253 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m11:30:14.403876 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.404359 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m11:30:14.435499 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:14.442024 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m11:30:14.443479 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m11:30:14.444451 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m11:30:14.491125 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:14.494592 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 11:30:09.116217 => 11:30:14.494296
[0m11:30:14.495263 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m11:30:14.497559 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa82510>]}
[0m11:30:14.498469 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45760[0m in 5.39s]
[0m11:30:14.500028 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m11:30:14.501182 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m11:30:14.502162 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m11:30:14.504074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m11:30:14.504956 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m11:30:14.511300 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m11:30:14.513079 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 11:30:14.505345 => 11:30:14.512750
[0m11:30:14.513693 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m11:30:14.537425 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m11:30:14.538501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.538921 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m11:30:14.539276 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:14.795907 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:14.797576 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.798894 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m11:30:14.834301 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m11:30:14.842027 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.842807 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m11:30:14.874751 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.883465 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.884292 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m11:30:14.916070 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:14.921521 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m11:30:14.922408 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.923107 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m11:30:14.954788 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:14.960990 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m11:30:14.968663 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m11:30:14.969519 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m11:30:15.075894 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m11:30:15.080825 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 11:30:14.514072 => 11:30:15.080267
[0m11:30:15.081979 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m11:30:15.083855 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac6e510>]}
[0m11:30:15.085452 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.58s]
[0m11:30:15.087215 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m11:30:15.088098 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m11:30:15.089206 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m11:30:15.090669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m11:30:15.091213 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m11:30:15.096344 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m11:30:15.098885 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 11:30:15.091465 => 11:30:15.098359
[0m11:30:15.099770 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m11:30:15.107568 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m11:30:15.109042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.109721 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m11:30:15.110231 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:15.490905 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:15.492533 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.493936 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m11:30:15.527561 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m11:30:15.537596 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.538458 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m11:30:15.570592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:15.577545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.578667 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m11:30:15.609718 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:15.618308 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m11:30:15.619711 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.620661 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m11:30:15.651696 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:15.666560 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m11:30:15.668994 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m11:30:15.670033 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m11:30:15.717891 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:15.722520 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 11:30:15.100140 => 11:30:15.721782
[0m11:30:15.723918 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m11:30:15.727056 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a8891d0>]}
[0m11:30:15.729367 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.64s]
[0m11:30:15.730950 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m11:30:15.732126 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m11:30:15.733601 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m11:30:15.735032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m11:30:15.735959 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m11:30:15.742502 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.745186 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 11:30:15.736663 => 11:30:15.744833
[0m11:30:15.745824 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m11:30:15.796031 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.796727 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:15.796954 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m11:30:15.797157 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:16.054991 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:16.056443 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.057178 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m11:30:16.330722 [debug] [Thread-1 (]: SQL status: SELECT 56297 in 0.0 seconds
[0m11:30:16.339403 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.340765 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m11:30:16.372645 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.382747 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.383850 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m11:30:16.415893 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.423753 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m11:30:16.425267 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.426648 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m11:30:16.458904 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:16.468553 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m11:30:16.470814 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m11:30:16.471805 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m11:30:16.523724 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:16.527865 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 11:30:15.746211 => 11:30:16.527511
[0m11:30:16.528500 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m11:30:16.530006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac796d0>]}
[0m11:30:16.531645 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 56297[0m in 0.80s]
[0m11:30:16.533671 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m11:30:16.535189 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.536237 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m11:30:16.537800 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m11:30:16.538626 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.543714 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.545302 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 11:30:16.539048 => 11:30:16.544993
[0m11:30:16.545927 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.553004 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.554631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.555163 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m11:30:16.555949 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:16.813202 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:16.815419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.816669 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m11:30:16.851753 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m11:30:16.860310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.861202 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m11:30:16.892612 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:16.896878 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m11:30:16.898342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.899444 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m11:30:16.930847 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:16.937237 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m11:30:16.939156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m11:30:16.940478 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m11:30:16.972299 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m11:30:16.976486 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 11:30:16.546335 => 11:30:16.976003
[0m11:30:16.977345 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m11:30:16.979786 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac8d3d0>]}
[0m11:30:16.980930 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.44s]
[0m11:30:16.982531 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m11:30:16.983550 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m11:30:16.984573 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m11:30:16.986027 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m11:30:16.987027 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m11:30:16.992992 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:16.994533 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 11:30:16.987564 => 11:30:16.994215
[0m11:30:16.995116 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m11:30:17.001230 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.002753 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.003264 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m11:30:17.003721 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:17.332084 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m11:30:17.333369 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.334568 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m11:30:17.402329 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m11:30:17.412270 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.413050 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m11:30:17.453306 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:17.463483 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.464506 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m11:30:17.504569 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m11:30:17.510484 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m11:30:17.511415 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.512121 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m11:30:17.552547 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m11:30:17.558917 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m11:30:17.560996 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m11:30:17.562252 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m11:30:17.619876 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m11:30:17.624823 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 11:30:16.995503 => 11:30:17.624118
[0m11:30:17.626071 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m11:30:17.628856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7a3f9496-6a36-43cd-b22b-d360356d14b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acba690>]}
[0m11:30:17.630384 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.64s]
[0m11:30:17.632120 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m11:30:17.635763 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:17.636759 [debug] [MainThread]: On master: BEGIN
[0m11:30:17.637677 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:30:17.892995 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m11:30:17.894611 [debug] [MainThread]: On master: COMMIT
[0m11:30:17.895784 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:17.896466 [debug] [MainThread]: On master: COMMIT
[0m11:30:17.926850 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m11:30:17.927704 [debug] [MainThread]: On master: Close
[0m11:30:17.929878 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:30:17.930894 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m11:30:17.931790 [info ] [MainThread]: 
[0m11:30:17.932743 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 49.96 seconds (49.96s).
[0m11:30:17.938161 [debug] [MainThread]: Command end result
[0m11:30:17.959081 [info ] [MainThread]: 
[0m11:30:17.959858 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:30:17.960319 [info ] [MainThread]: 
[0m11:30:17.960790 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m11:30:17.963604 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 50.16285, "process_user_time": 1.989993, "process_kernel_time": 0.227356, "process_mem_max_rss": "126500864", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m11:30:17.964431 [debug] [MainThread]: Command `dbt run` succeeded at 11:30:17.964254 after 50.16 seconds
[0m11:30:17.964921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047e0850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ec5250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048a5f50>]}
[0m11:30:17.965442 [debug] [MainThread]: Flushing usage events
[0m19:08:14.417633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119ee8b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f5e710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f5ee10>]}


============================== 19:08:14.419333 | 143f72ab-9505-480a-8ae9-c5a87e3af9e2 ==============================
[0m19:08:14.419333 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:08:14.419694 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'invocation_command': 'dbt run', 'version_check': 'True', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'no_print': 'None', 'static_parser': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'quiet': 'False', 'partial_parse': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'introspect': 'True'}
[0m19:08:14.493378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f5ecd0>]}
[0m19:08:14.524106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a31e9d0>]}
[0m19:08:14.524559 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:08:14.533196 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:08:14.556163 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:08:14.556490 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:08:14.558190 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:08:14.561616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a560290>]}
[0m19:08:14.569897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a3e8050>]}
[0m19:08:14.570240 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:08:14.570526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1192bbfd0>]}
[0m19:08:14.572236 [info ] [MainThread]: 
[0m19:08:14.573062 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:08:14.574058 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:08:14.580221 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:08:14.580548 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:08:14.580727 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:08:14.945437 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:08:14.948359 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:08:14.953117 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:08:14.962937 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:08:14.963806 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:08:14.964124 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:08:15.290448 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:08:15.291948 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:08:15.293486 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:08:15.338974 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:08:15.341917 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:08:15.381485 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:08:15.393378 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.394019 [debug] [MainThread]: On master: BEGIN
[0m19:08:15.394492 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:08:15.654424 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:08:15.656182 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.657666 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:08:15.699697 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:08:15.705123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a439e50>]}
[0m19:08:15.706853 [debug] [MainThread]: On master: ROLLBACK
[0m19:08:15.738108 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.738717 [debug] [MainThread]: On master: BEGIN
[0m19:08:15.799927 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:08:15.801516 [debug] [MainThread]: On master: COMMIT
[0m19:08:15.802733 [debug] [MainThread]: Using postgres connection "master"
[0m19:08:15.803897 [debug] [MainThread]: On master: COMMIT
[0m19:08:15.835706 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:08:15.837096 [debug] [MainThread]: On master: Close
[0m19:08:15.840365 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:08:15.841608 [info ] [MainThread]: 
[0m19:08:15.849371 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m19:08:15.850768 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m19:08:15.852145 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m19:08:15.852786 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m19:08:15.868672 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:15.870654 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 19:08:15.854049 => 19:08:15.870315
[0m19:08:15.871198 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m19:08:15.905425 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:15.906177 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:15.906444 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m19:08:15.906681 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:16.190660 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:16.191914 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:16.192820 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m19:08:46.426028 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 30.0 seconds
[0m19:08:46.434453 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.434924 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m19:08:46.465908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:46.471311 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.471759 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m19:08:46.503415 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:46.523702 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:08:46.524048 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.524333 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:08:46.554632 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:46.560195 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m19:08:46.564143 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:08:46.564460 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m19:08:46.609415 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:46.611074 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 19:08:15.871499 => 19:08:46.610850
[0m19:08:46.611508 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m19:08:46.612468 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a4b1310>]}
[0m19:08:46.613117 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 30.76s]
[0m19:08:46.613741 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m19:08:46.614220 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m19:08:46.614776 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m19:08:46.615476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m19:08:46.615842 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m19:08:46.618689 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m19:08:46.619477 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 19:08:46.616071 => 19:08:46.619283
[0m19:08:46.619827 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m19:08:46.623185 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m19:08:46.623676 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:46.623957 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m19:08:46.624215 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:46.989692 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:46.991172 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:46.992076 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:08:47.053129 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:08:47.061007 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.061699 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m19:08:47.101775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.107265 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.107856 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m19:08:47.147714 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.152659 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:08:47.153526 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.154130 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:08:47.193415 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:47.200192 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m19:08:47.202055 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:08:47.203097 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m19:08:47.263314 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:47.268235 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 19:08:46.620033 => 19:08:47.267729
[0m19:08:47.269221 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m19:08:47.271538 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a475c10>]}
[0m19:08:47.272713 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.66s]
[0m19:08:47.273745 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m19:08:47.274477 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.275364 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m19:08:47.276437 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m19:08:47.277092 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.282073 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.283282 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 19:08:47.277574 => 19:08:47.282983
[0m19:08:47.283773 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.288412 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.289388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.289797 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m19:08:47.290113 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:47.549193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:47.551159 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.552385 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:08:47.606517 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:08:47.613426 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.614056 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m19:08:47.645888 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.648449 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.648718 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m19:08:47.678958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:47.680404 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:08:47.680647 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.680872 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:08:47.711058 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:47.714402 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m19:08:47.715040 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:08:47.715321 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m19:08:47.766708 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:47.768078 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 19:08:47.284027 => 19:08:47.767865
[0m19:08:47.768473 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m19:08:47.769318 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b0696d0>]}
[0m19:08:47.769886 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.49s]
[0m19:08:47.770479 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m19:08:47.770930 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m19:08:47.771505 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m19:08:47.772274 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m19:08:47.772682 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m19:08:47.775534 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m19:08:47.776293 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 19:08:47.772922 => 19:08:47.776104
[0m19:08:47.776620 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m19:08:47.780162 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m19:08:47.780647 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:47.780920 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m19:08:47.781173 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:48.063959 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:48.065411 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.066485 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m19:08:48.110678 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m19:08:48.118083 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.118775 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m19:08:48.153900 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.159552 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.160120 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m19:08:48.193687 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.195374 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:08:48.195671 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.195924 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:08:48.229127 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:48.231237 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m19:08:48.231907 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:08:48.232188 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m19:08:48.287136 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:48.288760 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 19:08:47.776817 => 19:08:48.288521
[0m19:08:48.289188 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m19:08:48.290153 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b074f10>]}
[0m19:08:48.290771 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.52s]
[0m19:08:48.291391 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m19:08:48.291843 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.292439 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m19:08:48.293353 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m19:08:48.293770 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.296357 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.297047 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 19:08:48.293988 => 19:08:48.296858
[0m19:08:48.297379 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.300926 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.301407 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.301681 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m19:08:48.301940 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:48.560392 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:48.560806 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.561074 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m19:08:48.595148 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m19:08:48.597401 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.597641 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m19:08:48.628555 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.630596 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.630868 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m19:08:48.661693 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:48.663307 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:08:48.663591 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.663863 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:08:48.694056 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:48.696711 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m19:08:48.697575 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:08:48.697954 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m19:08:48.749023 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:48.750021 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 19:08:48.297576 => 19:08:48.749874
[0m19:08:48.750292 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m19:08:48.750905 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b03d990>]}
[0m19:08:48.751290 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.46s]
[0m19:08:48.751681 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m19:08:48.751983 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:48.752277 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m19:08:48.752810 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:08:48.753207 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:48.756513 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:48.758582 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:08:48.753437 => 19:08:48.758383
[0m19:08:48.758860 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:48.762689 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:48.763457 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:48.763703 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:08:48.763920 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:49.113393 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:49.114633 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:49.115615 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m19:08:59.444840 [debug] [Thread-1 (]: SQL status: SELECT 153241 in 10.0 seconds
[0m19:08:59.447572 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.447900 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:08:59.490525 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:59.493060 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.493414 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:08:59.535238 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:08:59.536941 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:08:59.537252 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.537526 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:08:59.579536 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:08:59.582437 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m19:08:59.583322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:08:59.583710 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:08:59.647297 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:08:59.651190 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:08:48.759011 => 19:08:59.650828
[0m19:08:59.651952 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:08:59.653622 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a643350>]}
[0m19:08:59.654594 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153241[0m in 10.90s]
[0m19:08:59.655422 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:08:59.656065 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:08:59.656824 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m19:08:59.657753 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:08:59.658315 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:08:59.663658 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.664678 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:08:59.658909 => 19:08:59.664435
[0m19:08:59.665103 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:08:59.669362 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.669925 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.670266 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:08:59.670576 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:08:59.944363 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:08:59.944907 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:08:59.945452 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:09:12.404147 [debug] [Thread-1 (]: SQL status: SELECT 45889 in 12.0 seconds
[0m19:09:12.412996 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.413917 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:09:12.449007 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:12.454870 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.455670 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:09:12.551829 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:12.555642 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:09:12.556498 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.557012 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:09:12.600194 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:12.602880 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:09:12.603689 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:09:12.604020 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:09:12.702900 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:12.706766 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:08:59.665347 => 19:09:12.706295
[0m19:09:12.707672 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:09:12.709719 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b087450>]}
[0m19:09:12.710843 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45889[0m in 13.05s]
[0m19:09:12.711971 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:09:12.712671 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m19:09:12.713520 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m19:09:12.714498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m19:09:12.715002 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m19:09:12.720063 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m19:09:12.721333 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 19:09:12.715312 => 19:09:12.721015
[0m19:09:12.721842 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m19:09:12.738970 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m19:09:12.739683 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:12.739979 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m19:09:12.740252 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:13.089230 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:13.090894 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.091869 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m19:09:13.129165 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:09:13.136310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.137142 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m19:09:13.168904 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.179170 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.179953 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m19:09:13.212212 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.261915 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:09:13.262356 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.262609 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:09:13.293914 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:13.295737 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m19:09:13.298067 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:09:13.298338 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m19:09:13.330071 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:09:13.331289 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 19:09:12.722144 => 19:09:13.331110
[0m19:09:13.331625 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m19:09:13.332394 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a2afc10>]}
[0m19:09:13.332886 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.62s]
[0m19:09:13.333400 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m19:09:13.333734 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m19:09:13.334183 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m19:09:13.334774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m19:09:13.335082 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m19:09:13.337110 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m19:09:13.337737 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 19:09:13.335267 => 19:09:13.337571
[0m19:09:13.338032 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m19:09:13.341021 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m19:09:13.341502 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.341755 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m19:09:13.341991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:13.651857 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:13.654000 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.655446 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m19:09:13.695823 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:09:13.704364 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.704961 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m19:09:13.742376 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.744877 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.745160 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m19:09:13.781234 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:13.782753 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:09:13.783012 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.783251 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:09:13.819442 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:13.821660 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m19:09:13.822402 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:09:13.822723 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m19:09:13.878652 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:13.881438 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 19:09:13.338202 => 19:09:13.881146
[0m19:09:13.882066 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m19:09:13.883609 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b02d550>]}
[0m19:09:13.884491 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.55s]
[0m19:09:13.885362 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m19:09:13.885951 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m19:09:13.886598 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m19:09:13.887493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m19:09:13.887972 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m19:09:13.891825 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m19:09:13.893458 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 19:09:13.888260 => 19:09:13.893219
[0m19:09:13.893855 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m19:09:13.897953 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m19:09:13.898473 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:13.898787 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m19:09:13.899085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:14.151562 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:14.153112 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.154315 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m19:09:14.401676 [debug] [Thread-1 (]: SQL status: SELECT 56717 in 0.0 seconds
[0m19:09:14.408414 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.409154 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m19:09:14.440450 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:14.446619 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.447251 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m19:09:14.477984 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:14.480386 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:09:14.480911 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.481318 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:09:14.511897 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:14.518271 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m19:09:14.519677 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:09:14.520224 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m19:09:14.573190 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:14.575430 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 19:09:13.894096 => 19:09:14.575175
[0m19:09:14.575940 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m19:09:14.577463 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a5620d0>]}
[0m19:09:14.578478 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 56717[0m in 0.69s]
[0m19:09:14.579260 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m19:09:14.579827 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m19:09:14.580658 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m19:09:14.581593 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m19:09:14.581987 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m19:09:14.587443 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.588276 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 19:09:14.582221 => 19:09:14.588084
[0m19:09:14.588605 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m19:09:14.592626 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.593240 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.593521 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m19:09:14.593790 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:14.855924 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:14.857673 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.858544 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m19:09:14.893458 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:09:14.901357 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.902061 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m19:09:14.933674 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:14.938865 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:09:14.939710 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.940496 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:09:14.972718 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:14.978291 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m19:09:14.980127 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:09:14.980736 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m19:09:15.012195 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:09:15.015078 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 19:09:14.588802 => 19:09:15.014739
[0m19:09:15.015820 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m19:09:15.017649 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a6535d0>]}
[0m19:09:15.018635 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.44s]
[0m19:09:15.019595 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m19:09:15.020341 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.021388 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m19:09:15.022416 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m19:09:15.022962 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.027972 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.029254 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 19:09:15.023313 => 19:09:15.028941
[0m19:09:15.029761 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.035448 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.036666 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.037123 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m19:09:15.037471 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:09:15.343990 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:09:15.345589 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.346567 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m19:09:15.427110 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m19:09:15.434367 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.435146 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m19:09:15.471802 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:15.476982 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.477642 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m19:09:15.514790 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:09:15.519674 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:09:15.520602 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.521358 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:09:15.559351 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:09:15.567064 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m19:09:15.568896 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:09:15.569733 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m19:09:15.630265 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:09:15.634762 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 19:09:15.030057 => 19:09:15.634336
[0m19:09:15.635608 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m19:09:15.637539 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '143f72ab-9505-480a-8ae9-c5a87e3af9e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a544110>]}
[0m19:09:15.638489 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.62s]
[0m19:09:15.639454 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m19:09:15.641906 [debug] [MainThread]: Using postgres connection "master"
[0m19:09:15.642401 [debug] [MainThread]: On master: BEGIN
[0m19:09:15.642814 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:09:15.902324 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:09:15.904016 [debug] [MainThread]: On master: COMMIT
[0m19:09:15.905115 [debug] [MainThread]: Using postgres connection "master"
[0m19:09:15.905791 [debug] [MainThread]: On master: COMMIT
[0m19:09:15.937100 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:09:15.937997 [debug] [MainThread]: On master: Close
[0m19:09:15.940149 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:09:15.940854 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m19:09:15.941748 [info ] [MainThread]: 
[0m19:09:15.942490 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 1 minutes and 1.37 seconds (61.37s).
[0m19:09:15.946364 [debug] [MainThread]: Command end result
[0m19:09:15.962965 [info ] [MainThread]: 
[0m19:09:15.963517 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:09:15.963887 [info ] [MainThread]: 
[0m19:09:15.964247 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m19:09:15.966803 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 61.576817, "process_user_time": 1.721446, "process_kernel_time": 0.233992, "process_mem_max_rss": "132644864", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:09:15.967352 [debug] [MainThread]: Command `dbt run` succeeded at 19:09:15.967229 after 61.58 seconds
[0m19:09:15.967714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119e06e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10483e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047701d0>]}
[0m19:09:15.968051 [debug] [MainThread]: Flushing usage events
[0m19:11:53.987191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff0dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff2410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108017090>]}


============================== 19:11:53.988731 | 387094f3-a07b-4c6e-a334-0e77e60eda45 ==============================
[0m19:11:53.988731 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:11:53.989047 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'indirect_selection': 'eager', 'partial_parse': 'True', 'log_format': 'default', 'introspect': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'write_json': 'True', 'debug': 'False', 'static_parser': 'True', 'use_colors': 'True', 'printer_width': '80', 'quiet': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'no_print': 'None'}
[0m19:11:54.059448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '387094f3-a07b-4c6e-a334-0e77e60eda45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fb22d0>]}
[0m19:11:54.089151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '387094f3-a07b-4c6e-a334-0e77e60eda45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fb22d0>]}
[0m19:11:54.089570 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:11:54.096323 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:11:54.102040 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:11:54.102356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '387094f3-a07b-4c6e-a334-0e77e60eda45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086e5590>]}
[0m19:11:54.478880 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.records_gap_campaigns' which was not found
[0m19:11:54.481263 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5157985, "process_user_time": 1.187947, "process_kernel_time": 0.098062, "process_mem_max_rss": "124321792", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:11:54.481518 [debug] [MainThread]: Command `dbt run` failed at 19:11:54.481458 after 0.52 seconds
[0m19:11:54.481703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ff2490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078661d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108612c10>]}
[0m19:11:54.481872 [debug] [MainThread]: Flushing usage events
[0m19:13:10.297547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e9410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106656c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106657310>]}


============================== 19:13:10.299176 | 99d3c192-6345-4ed3-9344-b0e17e3f1cc9 ==============================
[0m19:13:10.299176 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:13:10.299545 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'debug': 'False', 'introspect': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'cache_selected_only': 'False', 'static_parser': 'True', 'write_json': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'version_check': 'True', 'log_format': 'default', 'target_path': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'no_print': 'None', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False'}
[0m19:13:10.370986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '99d3c192-6345-4ed3-9344-b0e17e3f1cc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a53a90>]}
[0m19:13:10.400658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '99d3c192-6345-4ed3-9344-b0e17e3f1cc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bea3d0>]}
[0m19:13:10.401526 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:13:10.411971 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:13:10.417727 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:13:10.418008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '99d3c192-6345-4ed3-9344-b0e17e3f1cc9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bac550>]}
[0m19:13:10.780614 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.matomo_visits' which was not found
[0m19:13:10.783088 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.50804085, "process_user_time": 1.172625, "process_kernel_time": 0.110443, "process_mem_max_rss": "124682240", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:13:10.783378 [debug] [MainThread]: Command `dbt run` failed at 19:13:10.783319 after 0.51 seconds
[0m19:13:10.783568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10663a490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100aa67d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d81910>]}
[0m19:13:10.783736 [debug] [MainThread]: Flushing usage events
[0m19:13:25.808452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eebf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11103b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11105f2d0>]}


============================== 19:13:25.809715 | b6f973aa-1e52-45f7-8e40-622b8f07a972 ==============================
[0m19:13:25.809715 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:13:25.810038 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'write_json': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'partial_parse': 'True', 'use_colors': 'True', 'target_path': 'None', 'fail_fast': 'False', 'log_format': 'default', 'log_path': '/Users/danila/github/dbt/logs', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'invocation_command': 'dbt run', 'version_check': 'True', 'debug': 'False', 'cache_selected_only': 'False'}
[0m19:13:25.876555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b6f973aa-1e52-45f7-8e40-622b8f07a972', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111379090>]}
[0m19:13:25.907960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b6f973aa-1e52-45f7-8e40-622b8f07a972', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110598310>]}
[0m19:13:25.908317 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:13:25.915041 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:13:25.920447 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:13:25.920745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b6f973aa-1e52-45f7-8e40-622b8f07a972', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115c9090>]}
[0m19:13:26.284691 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.campaign_names_mapping' which was not found
[0m19:13:26.285709 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.49869424, "process_user_time": 1.194139, "process_kernel_time": 0.087028, "process_mem_max_rss": "123961344", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:13:26.285957 [debug] [MainThread]: Command `dbt run` failed at 19:13:26.285902 after 0.50 seconds
[0m19:13:26.286152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110752e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111605a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111038910>]}
[0m19:13:26.286314 [debug] [MainThread]: Flushing usage events
[0m19:14:02.206893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113177c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131779d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111aa5ad0>]}


============================== 19:14:02.208764 | 340e1672-0899-47d9-b672-15092f4ae495 ==============================
[0m19:14:02.208764 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:14:02.209152 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'quiet': 'False', 'profiles_dir': '/Users/danila/.dbt', 'log_path': '/Users/danila/github/dbt/logs', 'partial_parse': 'True', 'target_path': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'no_print': 'None', 'write_json': 'True', 'warn_error': 'None', 'introspect': 'True', 'printer_width': '80', 'cache_selected_only': 'False', 'use_colors': 'True', 'version_check': 'True', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False'}
[0m19:14:02.281251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '340e1672-0899-47d9-b672-15092f4ae495', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c72090>]}
[0m19:14:02.311099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '340e1672-0899-47d9-b672-15092f4ae495', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113672690>]}
[0m19:14:02.311520 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:14:02.319209 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:14:02.324873 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:14:02.325189 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '340e1672-0899-47d9-b672-15092f4ae495', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1139053d0>]}
[0m19:14:02.687426 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.campaign_names_mapping' which was not found
[0m19:14:02.689518 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.50559705, "process_user_time": 1.174515, "process_kernel_time": 0.106441, "process_mem_max_rss": "124436480", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:14:02.689779 [debug] [MainThread]: Command `dbt run` failed at 19:14:02.689719 after 0.51 seconds
[0m19:14:02.689958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056b6710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131743d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1134e5cd0>]}
[0m19:14:02.690128 [debug] [MainThread]: Flushing usage events
[0m19:16:52.928015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f38fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d83e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f4f890>]}


============================== 19:16:52.929390 | 71e341ba-87b1-4a9d-9603-755684863732 ==============================
[0m19:16:52.929390 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:16:52.929703 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'no_print': 'None', 'quiet': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'debug': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'target_path': 'None', 'partial_parse': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'version_check': 'True', 'warn_error': 'None', 'printer_width': '80', 'log_format': 'default', 'indirect_selection': 'eager'}
[0m19:16:52.997245 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '71e341ba-87b1-4a9d-9603-755684863732', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f83610>]}
[0m19:16:53.028057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '71e341ba-87b1-4a9d-9603-755684863732', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d6c610>]}
[0m19:16:53.028419 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:16:53.034899 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:16:53.040423 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:16:53.040712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '71e341ba-87b1-4a9d-9603-755684863732', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c6e3d0>]}
[0m19:16:53.417164 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.matomo_actions' which was not found
[0m19:16:53.418178 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5110858, "process_user_time": 1.200149, "process_kernel_time": 0.088562, "process_mem_max_rss": "123994112", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:16:53.418437 [debug] [MainThread]: Command `dbt run` failed at 19:16:53.418377 after 0.51 seconds
[0m19:16:53.418620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100f62710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107efda90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f4fc50>]}
[0m19:16:53.418803 [debug] [MainThread]: Flushing usage events
[0m19:17:13.460710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d76910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109dc5390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ddbf10>]}


============================== 19:17:13.461892 | 33eaf512-5717-4d2c-9490-9306761a1db6 ==============================
[0m19:17:13.461892 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:17:13.462210 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs', 'introspect': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'target_path': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'no_print': 'None', 'write_json': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'printer_width': '80', 'debug': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'warn_error': 'None'}
[0m19:17:13.525914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33eaf512-5717-4d2c-9490-9306761a1db6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a219890>]}
[0m19:17:13.555467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33eaf512-5717-4d2c-9490-9306761a1db6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a1dd050>]}
[0m19:17:13.555785 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:17:13.562115 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:17:13.567399 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:17:13.567697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '33eaf512-5717-4d2c-9490-9306761a1db6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a296550>]}
[0m19:17:13.927579 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.records_gap_campaigns' which was not found
[0m19:17:13.928611 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.48801166, "process_user_time": 1.161291, "process_kernel_time": 0.081912, "process_mem_max_rss": "123797504", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:17:13.928873 [debug] [MainThread]: Command `dbt run` failed at 19:17:13.928815 after 0.49 seconds
[0m19:17:13.929052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbe710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a439390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e03b10>]}
[0m19:17:13.929223 [debug] [MainThread]: Flushing usage events
[0m19:17:31.225538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108777ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e2dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e34d0>]}


============================== 19:17:31.226745 | 6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b ==============================
[0m19:17:31.226745 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:17:31.227066 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'quiet': 'False', 'static_parser': 'True', 'target_path': 'None', 'write_json': 'True', 'invocation_command': 'dbt run', 'indirect_selection': 'eager', 'partial_parse': 'True', 'introspect': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'version_check': 'True'}
[0m19:17:31.290724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087756d0>]}
[0m19:17:31.320306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d77150>]}
[0m19:17:31.320625 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:17:31.326956 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:17:31.332261 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:17:31.332549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6b46c6f0-7ae2-4f20-8e89-bccc9f961f2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ebd410>]}
[0m19:17:31.693164 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.campaign_names_mapping' which was not found
[0m19:17:31.694171 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.4886916, "process_user_time": 1.160946, "process_kernel_time": 0.082532, "process_mem_max_rss": "123305984", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:17:31.694426 [debug] [MainThread]: Command `dbt run` failed at 19:17:31.694369 after 0.49 seconds
[0m19:17:31.694607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087e2b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1037be710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087c50d0>]}
[0m19:17:31.694778 [debug] [MainThread]: Flushing usage events
[0m19:18:09.281768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e06910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e55950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e48250>]}


============================== 19:18:09.283017 | d371243f-2b4c-4072-aa3c-d3c5092e1cae ==============================
[0m19:18:09.283017 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:18:09.283341 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'use_colors': 'True', 'warn_error': 'None', 'version_check': 'True', 'target_path': 'None', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'invocation_command': 'dbt run', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'quiet': 'False', 'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'printer_width': '80'}
[0m19:18:09.347417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108316050>]}
[0m19:18:09.376797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c52090>]}
[0m19:18:09.377126 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:18:09.383780 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:18:09.396515 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:18:09.396729 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:18:09.397176 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:18:09.399662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e05390>]}
[0m19:18:09.405222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108441750>]}
[0m19:18:09.405480 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:18:09.405661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085bbe50>]}
[0m19:18:09.406837 [info ] [MainThread]: 
[0m19:18:09.407280 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:18:09.408037 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:18:09.412397 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:18:09.412572 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:18:09.412718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:18:10.325131 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m19:18:10.329309 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:18:10.334537 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:18:10.344245 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:18:10.344879 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:18:10.345278 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:18:11.018498 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m19:18:11.020128 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:18:11.020910 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:18:11.123846 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:18:11.128644 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:18:11.169462 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:18:11.185675 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:11.186400 [debug] [MainThread]: On master: BEGIN
[0m19:18:11.186825 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:18:11.840546 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m19:18:11.842577 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:11.843913 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:18:11.959994 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:18:11.965274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107130910>]}
[0m19:18:11.966603 [debug] [MainThread]: On master: ROLLBACK
[0m19:18:12.062845 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:12.064206 [debug] [MainThread]: On master: BEGIN
[0m19:18:12.198201 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:18:12.199882 [debug] [MainThread]: On master: COMMIT
[0m19:18:12.201122 [debug] [MainThread]: Using postgres connection "master"
[0m19:18:12.202284 [debug] [MainThread]: On master: COMMIT
[0m19:18:12.249078 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:18:12.250692 [debug] [MainThread]: On master: Close
[0m19:18:12.253387 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:18:12.254258 [info ] [MainThread]: 
[0m19:18:12.261250 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m19:18:12.262237 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m19:18:12.263411 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m19:18:12.264010 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m19:18:12.277131 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.278134 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 19:18:12.264415 => 19:18:12.277902
[0m19:18:12.278511 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m19:18:12.303471 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.304252 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.304543 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m19:18:12.304768 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:12.609951 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:12.612104 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:12.614238 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m19:18:43.233642 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 31.0 seconds
[0m19:18:43.241263 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.241709 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m19:18:43.273502 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.278447 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.278838 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m19:18:43.309338 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.326297 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:18:43.326661 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.326950 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m19:18:43.358093 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:43.363524 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup"
[0m19:18:43.367380 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m19:18:43.367706 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m19:18:43.411053 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:43.412587 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 19:18:12.278717 => 19:18:43.412360
[0m19:18:43.413019 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m19:18:43.414013 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082a96d0>]}
[0m19:18:43.414680 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 31.15s]
[0m19:18:43.415324 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m19:18:43.415744 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m19:18:43.416266 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m19:18:43.417001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m19:18:43.417373 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m19:18:43.420201 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m19:18:43.420983 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 19:18:43.417600 => 19:18:43.420788
[0m19:18:43.421341 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m19:18:43.424707 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m19:18:43.425235 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.425516 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m19:18:43.425777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:43.713089 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:43.714417 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.715306 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:18:43.761756 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:18:43.770036 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.770971 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m19:18:43.802967 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.806926 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.807451 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m19:18:43.838155 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:43.843591 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:18:43.844483 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.845421 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m19:18:43.876264 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:43.882909 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."campaign_dim__dbt_backup"
[0m19:18:43.884777 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m19:18:43.885565 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m19:18:43.935117 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:43.938299 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 19:18:43.421541 => 19:18:43.937877
[0m19:18:43.939140 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m19:18:43.941711 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10844b690>]}
[0m19:18:43.942989 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.52s]
[0m19:18:43.944237 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m19:18:43.945215 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m19:18:43.946227 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m19:18:43.947330 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m19:18:43.947915 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m19:18:43.952903 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:43.954133 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 19:18:43.948300 => 19:18:43.953831
[0m19:18:43.954629 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m19:18:43.959834 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:43.960686 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:43.961071 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m19:18:43.961429 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:44.222185 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:44.224348 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.225325 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m19:18:44.274693 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m19:18:44.283800 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.284690 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m19:18:44.316708 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.322613 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.323414 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m19:18:44.355301 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.360416 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:18:44.361253 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.362001 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m19:18:44.393573 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:44.402393 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup"
[0m19:18:44.403602 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m19:18:44.404067 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m19:18:44.456302 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:44.457427 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 19:18:43.954907 => 19:18:44.457290
[0m19:18:44.457691 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m19:18:44.458292 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086b2b50>]}
[0m19:18:44.458661 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.51s]
[0m19:18:44.459031 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m19:18:44.459296 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m19:18:44.459536 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m19:18:44.459908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m19:18:44.460124 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m19:18:44.461979 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m19:18:44.462677 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 19:18:44.460257 => 19:18:44.462489
[0m19:18:44.462936 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m19:18:44.465582 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m19:18:44.466042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.466255 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m19:18:44.466448 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:44.815890 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:44.817961 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.819478 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m19:18:44.871133 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m19:18:44.879668 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.880833 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m19:18:44.924132 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.931503 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.932107 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m19:18:44.974640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:44.979891 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:18:44.980796 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:44.981551 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m19:18:45.024244 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:45.031393 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."deals_dim__dbt_backup"
[0m19:18:45.033247 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m19:18:45.034015 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m19:18:45.094472 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:45.099467 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 19:18:44.463097 => 19:18:45.098630
[0m19:18:45.100912 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m19:18:45.103006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f290>]}
[0m19:18:45.104112 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.64s]
[0m19:18:45.105200 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m19:18:45.105848 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.106881 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m19:18:45.107857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m19:18:45.108327 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.111842 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.112806 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 19:18:45.108615 => 19:18:45.112572
[0m19:18:45.113222 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.117492 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.118194 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.118518 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m19:18:45.118823 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:45.446800 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:45.448938 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.450050 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m19:18:45.493039 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m19:18:45.501937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.502798 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m19:18:45.542952 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:45.548309 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.548852 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m19:18:45.587945 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:45.591877 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:18:45.592631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.593363 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m19:18:45.633313 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:45.639094 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup"
[0m19:18:45.640321 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m19:18:45.641056 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m19:18:45.700051 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:45.705255 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 19:18:45.113453 => 19:18:45.704493
[0m19:18:45.706691 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m19:18:45.708808 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108449b10>]}
[0m19:18:45.709663 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.60s]
[0m19:18:45.710715 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m19:18:45.711273 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:45.711983 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m19:18:45.713068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:18:45.713581 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:45.719226 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:45.721583 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:18:45.713890 => 19:18:45.721342
[0m19:18:45.721964 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:45.727647 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:45.728238 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:45.728529 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:18:45.728800 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:46.030827 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:18:46.032653 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:46.033894 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m19:18:55.767915 [debug] [Thread-1 (]: SQL status: SELECT 153288 in 10.0 seconds
[0m19:18:55.776427 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:55.777447 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:18:55.851976 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:55.856219 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:55.856687 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:18:55.954922 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:18:55.959743 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:18:55.960561 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:55.961165 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:18:56.286352 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:18:56.292508 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup"
[0m19:18:56.293991 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:18:56.294543 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:18:56.372490 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:18:56.374518 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:18:45.722195 => 19:18:56.374244
[0m19:18:56.375046 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:18:56.376231 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086c1bd0>]}
[0m19:18:56.376957 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153288[0m in 10.66s]
[0m19:18:56.377686 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:18:56.378219 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:18:56.378894 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m19:18:56.379736 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:18:56.380172 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:18:56.384619 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.386480 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:18:56.380427 => 19:18:56.386275
[0m19:18:56.386823 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:18:56.390640 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.391187 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.391469 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:18:56.391740 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:18:56.907388 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:18:56.908096 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:18:56.908769 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:19:03.754421 [debug] [Thread-1 (]: SQL status: SELECT 45890 in 7.0 seconds
[0m19:19:03.762496 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.763214 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:19:03.795503 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:03.801018 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.801880 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:19:03.841646 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:03.846346 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:19:03.847171 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.847902 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:19:03.893569 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:03.900281 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:19:03.902026 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:19:03.902797 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:19:03.960780 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:03.965618 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:18:56.387028 => 19:19:03.965316
[0m19:19:03.966236 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:19:03.967789 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10864a550>]}
[0m19:19:03.968668 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45890[0m in 7.59s]
[0m19:19:03.969783 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:19:03.970548 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m19:19:03.971243 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m19:19:03.972145 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m19:19:03.972610 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m19:19:03.976481 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m19:19:03.977433 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 19:19:03.972899 => 19:19:03.977190
[0m19:19:03.977841 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m19:19:03.993411 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m19:19:03.993982 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:03.994235 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m19:19:03.994485 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:04.636149 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:19:04.638109 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.639603 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m19:19:04.700570 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:19:04.709111 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.709728 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m19:19:04.775000 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:04.785143 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.786021 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m19:19:04.837502 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:04.889598 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:19:04.889914 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.890129 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m19:19:04.984689 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:04.987834 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test__dbt_backup"
[0m19:19:04.991310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m19:19:04.991726 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m19:19:05.076225 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:19:05.080156 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 19:19:03.978078 => 19:19:05.079708
[0m19:19:05.080902 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m19:19:05.082810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086bc390>]}
[0m19:19:05.083806 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 1.11s]
[0m19:19:05.084698 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m19:19:05.085320 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m19:19:05.086319 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m19:19:05.087461 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m19:19:05.088000 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m19:19:05.091524 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m19:19:05.092585 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 19:19:05.088305 => 19:19:05.092338
[0m19:19:05.092995 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m19:19:05.097530 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m19:19:05.098218 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:05.098549 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m19:19:05.098843 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:07.595690 [debug] [Thread-1 (]: SQL status: BEGIN in 2.0 seconds
[0m19:19:07.597732 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.599395 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m19:19:07.769142 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:19:07.777649 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.778229 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m19:19:07.832736 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:07.839297 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.839978 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m19:19:07.900943 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:07.906539 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:19:07.907419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:07.908329 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m19:19:07.997965 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:08.005464 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."test_write__dbt_backup"
[0m19:19:08.007390 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m19:19:08.008240 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m19:19:08.151114 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:08.155451 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 19:19:05.093246 => 19:19:08.155024
[0m19:19:08.156323 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m19:19:08.158274 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10869d050>]}
[0m19:19:08.159418 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 3.07s]
[0m19:19:08.160322 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m19:19:08.161039 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m19:19:08.161879 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m19:19:08.162970 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m19:19:08.163519 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m19:19:08.169470 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.170677 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 19:19:08.163966 => 19:19:08.170373
[0m19:19:08.171174 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m19:19:08.176198 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.177038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.177383 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m19:19:08.177692 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:08.912645 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:19:08.916258 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:08.917165 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m19:19:09.188480 [debug] [Thread-1 (]: SQL status: SELECT 56722 in 0.0 seconds
[0m19:19:09.197291 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.198137 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m19:19:09.235089 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:09.241503 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.242199 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m19:19:09.285064 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:09.289989 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:19:09.290817 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.291574 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m19:19:09.426145 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:09.431733 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclicks_fct__dbt_backup"
[0m19:19:09.433033 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m19:19:09.433814 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m19:19:09.540961 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:09.546128 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 19:19:08.171455 => 19:19:09.545381
[0m19:19:09.547386 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m19:19:09.549378 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10863dcd0>]}
[0m19:19:09.550534 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 56722[0m in 1.39s]
[0m19:19:09.551752 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m19:19:09.552611 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m19:19:09.553700 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m19:19:09.554760 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m19:19:09.555307 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m19:19:09.563936 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.565347 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 19:19:09.555631 => 19:19:09.565069
[0m19:19:09.565783 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m19:19:09.570580 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.571240 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.571578 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m19:19:09.571888 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:09.936313 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:19:09.937635 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.939251 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m19:19:09.980481 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m19:19:09.988513 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:09.989520 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m19:19:10.031030 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:10.035070 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:19:10.035860 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:10.036595 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m19:19:10.073796 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:10.079468 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup"
[0m19:19:10.081336 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m19:19:10.082061 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m19:19:10.130279 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m19:19:10.132192 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 19:19:09.566031 => 19:19:10.131927
[0m19:19:10.132689 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m19:19:10.133736 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10844e750>]}
[0m19:19:10.134345 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.58s]
[0m19:19:10.134953 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m19:19:10.135422 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.135922 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m19:19:10.136582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m19:19:10.136967 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.140022 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.140644 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 19:19:10.137205 => 19:19:10.140458
[0m19:19:10.140967 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.144884 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.145733 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.146093 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m19:19:10.146381 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:19:10.456770 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:19:10.458062 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.458753 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m19:19:10.517213 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m19:19:10.525378 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.525972 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m19:19:10.557215 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:10.562720 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.563494 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m19:19:10.595920 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:19:10.601941 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:19:10.602714 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.603424 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m19:19:10.634770 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:19:10.641286 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup"
[0m19:19:10.642554 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m19:19:10.643138 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m19:19:10.695293 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:19:10.699396 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 19:19:10.141162 => 19:19:10.699127
[0m19:19:10.699910 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m19:19:10.701412 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd371243f-2b4c-4072-aa3c-d3c5092e1cae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085136d0>]}
[0m19:19:10.702395 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.56s]
[0m19:19:10.703119 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m19:19:10.704846 [debug] [MainThread]: Using postgres connection "master"
[0m19:19:10.705252 [debug] [MainThread]: On master: BEGIN
[0m19:19:10.705574 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:19:10.959314 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:19:10.961183 [debug] [MainThread]: On master: COMMIT
[0m19:19:10.962135 [debug] [MainThread]: Using postgres connection "master"
[0m19:19:10.962857 [debug] [MainThread]: On master: COMMIT
[0m19:19:10.993416 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:19:10.994931 [debug] [MainThread]: On master: Close
[0m19:19:10.997327 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:19:10.998009 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m19:19:10.998909 [info ] [MainThread]: 
[0m19:19:10.999714 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 1 minutes and 1.59 seconds (61.59s).
[0m19:19:11.003365 [debug] [MainThread]: Command end result
[0m19:19:11.018847 [info ] [MainThread]: 
[0m19:19:11.019361 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:19:11.019678 [info ] [MainThread]: 
[0m19:19:11.020017 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m19:19:11.023095 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 61.762623, "process_user_time": 1.765803, "process_kernel_time": 0.19053, "process_mem_max_rss": "130023424", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:19:11.023657 [debug] [MainThread]: Command `dbt run` succeeded at 19:19:11.023531 after 61.76 seconds
[0m19:19:11.024030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e4e6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108289a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d801d0>]}
[0m19:19:11.024381 [debug] [MainThread]: Flushing usage events
[0m19:19:43.075981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106deb990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104553e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e5f890>]}


============================== 19:19:43.077433 | 4335b8d5-fe91-45f4-bb26-0b2151a9c8e1 ==============================
[0m19:19:43.077433 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:19:43.077756 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'write_json': 'True', 'no_print': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'version_check': 'True', 'target_path': 'None', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'quiet': 'False', 'printer_width': '80', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m19:19:43.146234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4335b8d5-fe91-45f4-bb26-0b2151a9c8e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070c6750>]}
[0m19:19:43.178022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4335b8d5-fe91-45f4-bb26-0b2151a9c8e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071c6e90>]}
[0m19:19:43.179346 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:19:43.186255 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:19:43.191547 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:19:43.191850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4335b8d5-fe91-45f4-bb26-0b2151a9c8e1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073c55d0>]}
[0m19:19:43.568159 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.campaign_perfomance.outclick_cost_int' (models/brand_performance/outclick_cost_int.sql) depends on a source named 'main.matomo_visits' which was not found
[0m19:19:43.569172 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5151364, "process_user_time": 1.186117, "process_kernel_time": 0.097423, "process_mem_max_rss": "123764736", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:19:43.569425 [debug] [MainThread]: Command `dbt run` failed at 19:19:43.569367 after 0.52 seconds
[0m19:19:43.569606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101232710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e7afd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e39cd0>]}
[0m19:19:43.569770 [debug] [MainThread]: Flushing usage events
[0m19:20:18.689997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106153390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061a3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061b7590>]}


============================== 19:20:18.691300 | 537ed143-9187-4149-97a0-5d164a8f1242 ==============================
[0m19:20:18.691300 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:20:18.691610 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'no_print': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'static_parser': 'True', 'log_format': 'default', 'debug': 'False'}
[0m19:20:18.755662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061eb150>]}
[0m19:20:18.785229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066a7b10>]}
[0m19:20:18.785557 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:20:18.791994 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:20:18.805150 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:20:18.805366 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:20:18.805809 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:20:18.808607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106654fd0>]}
[0m19:20:18.813506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065e0550>]}
[0m19:20:18.813744 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:20:18.813924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065c66d0>]}
[0m19:20:18.814616 [info ] [MainThread]: 
[0m19:20:18.814988 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:20:18.815513 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:20:18.819720 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:20:18.819923 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:20:18.820075 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:20:19.285666 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:20:19.290074 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:20:19.295057 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:20:19.304418 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:20:19.305120 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:20:19.305539 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:20:19.668964 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:20:19.670137 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:20:19.670849 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:20:19.719834 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:20:19.723226 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:20:19.782668 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:20:19.796717 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:19.797256 [debug] [MainThread]: On master: BEGIN
[0m19:20:19.797608 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:20:20.218294 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:20:20.219529 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:20.220307 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:20:20.325486 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:20:20.329576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c0250>]}
[0m19:20:20.330439 [debug] [MainThread]: On master: ROLLBACK
[0m19:20:20.380408 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:20.381300 [debug] [MainThread]: On master: BEGIN
[0m19:20:20.461447 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:20:20.463236 [debug] [MainThread]: On master: COMMIT
[0m19:20:20.464142 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:20.464793 [debug] [MainThread]: On master: COMMIT
[0m19:20:20.536784 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:20:20.537279 [debug] [MainThread]: On master: Close
[0m19:20:20.538556 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:20:20.539022 [info ] [MainThread]: 
[0m19:20:20.543036 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:20:20.543700 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:20:20.544604 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:20:20.545017 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:20:20.552500 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:20:20.553217 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:20:20.545303 => 19:20:20.553036
[0m19:20:20.553517 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:20:20.577379 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:20:20.577895 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:20.578115 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:20:20.578312 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:20:21.066744 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:20:21.068667 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:21.069945 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:20:27.621223 [debug] [Thread-1 (]: SQL status: SELECT 45890 in 7.0 seconds
[0m19:20:27.634156 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.634853 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:20:27.734849 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:20:27.742342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.742967 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:20:27.799674 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:20:27.830530 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:20:27.830980 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.831318 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:20:27.927583 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:20:27.941333 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:20:27.948478 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:20:27.949094 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:20:28.030283 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:20:28.035601 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:20:20.553698 => 19:20:28.035041
[0m19:20:28.036573 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:20:28.038975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '537ed143-9187-4149-97a0-5d164a8f1242', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661f090>]}
[0m19:20:28.040485 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45890[0m in 7.49s]
[0m19:20:28.041687 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:20:28.044392 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:28.045123 [debug] [MainThread]: On master: BEGIN
[0m19:20:28.045679 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:20:28.924955 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m19:20:28.926768 [debug] [MainThread]: On master: COMMIT
[0m19:20:28.927582 [debug] [MainThread]: Using postgres connection "master"
[0m19:20:28.928296 [debug] [MainThread]: On master: COMMIT
[0m19:20:28.976572 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:20:28.977552 [debug] [MainThread]: On master: Close
[0m19:20:28.979581 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:20:28.980256 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:20:28.981046 [info ] [MainThread]: 
[0m19:20:28.981840 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 10.17 seconds (10.17s).
[0m19:20:28.983214 [debug] [MainThread]: Command end result
[0m19:20:28.998007 [info ] [MainThread]: 
[0m19:20:28.998803 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:20:28.999159 [info ] [MainThread]: 
[0m19:20:28.999553 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:20:29.002012 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 10.332784, "process_user_time": 1.076476, "process_kernel_time": 0.119128, "process_mem_max_rss": "128073728", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:20:29.002628 [debug] [MainThread]: Command `dbt run` succeeded at 19:20:29.002499 after 10.33 seconds
[0m19:20:29.003064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10119a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10119a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1011116d0>]}
[0m19:20:29.003456 [debug] [MainThread]: Flushing usage events
[0m19:20:59.466501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bfd490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055591d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c6b450>]}


============================== 19:20:59.467784 | ac0ac777-5ae7-4daf-a900-067f25c8440d ==============================
[0m19:20:59.467784 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:20:59.468089 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'write_json': 'True', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'printer_width': '80', 'invocation_command': 'dbt run -m outclick_cost_int', 'debug': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'version_check': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'fail_fast': 'False', 'target_path': 'None', 'send_anonymous_usage_stats': 'True'}
[0m19:20:59.533038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060bf7d0>]}
[0m19:20:59.562436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c41890>]}
[0m19:20:59.562766 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:20:59.569302 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:20:59.582011 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:20:59.582229 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:20:59.582674 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:20:59.585179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ca16d0>]}
[0m19:20:59.590320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060e5a10>]}
[0m19:20:59.590563 [info ] [MainThread]: Found 12 models, 4 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:20:59.590736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063b3e50>]}
[0m19:20:59.591419 [info ] [MainThread]: 
[0m19:20:59.591832 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:20:59.592429 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:20:59.596900 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:20:59.597095 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:20:59.597261 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:21:00.684118 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m19:21:00.688102 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:21:00.692573 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:21:00.702078 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:21:00.702805 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:21:00.703245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:21:01.163543 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:21:01.165839 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:21:01.167379 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:21:01.202129 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:21:01.205809 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:21:01.257530 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:21:01.272621 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.273163 [debug] [MainThread]: On master: BEGIN
[0m19:21:01.273559 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:21:01.645130 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:21:01.646820 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.647685 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:21:01.701350 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:21:01.706333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106062b50>]}
[0m19:21:01.707140 [debug] [MainThread]: On master: ROLLBACK
[0m19:21:01.744622 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.745331 [debug] [MainThread]: On master: BEGIN
[0m19:21:01.816802 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:21:01.817507 [debug] [MainThread]: On master: COMMIT
[0m19:21:01.817952 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:01.818356 [debug] [MainThread]: On master: COMMIT
[0m19:21:01.851594 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:21:01.852520 [debug] [MainThread]: On master: Close
[0m19:21:01.854353 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:21:01.854961 [info ] [MainThread]: 
[0m19:21:01.861040 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:21:01.861768 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:21:01.862727 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:21:01.863217 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:21:01.871891 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:21:01.872673 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:21:01.863516 => 19:21:01.872460
[0m19:21:01.873026 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:21:01.898315 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:21:01.898850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:01.899082 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:21:01.899294 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:21:02.194934 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:21:02.197106 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:02.198796 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
        date(timestamp - interval '2 hours') as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-12-31'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
  );
  
[0m19:21:07.144599 [debug] [Thread-1 (]: SQL status: SELECT 45890 in 5.0 seconds
[0m19:21:07.157115 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.158097 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:21:07.199561 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:21:07.206110 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.207003 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:21:07.240766 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:21:07.267776 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:21:07.268248 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.268597 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:21:07.301887 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:21:07.307759 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:21:07.311575 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:21:07.311895 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:21:07.412833 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:21:07.417470 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:21:01.873228 => 19:21:07.417006
[0m19:21:07.418369 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:21:07.420623 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ac0ac777-5ae7-4daf-a900-067f25c8440d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106413950>]}
[0m19:21:07.421925 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45890[0m in 5.56s]
[0m19:21:07.422941 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:21:07.425585 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:07.426176 [debug] [MainThread]: On master: BEGIN
[0m19:21:07.426631 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:21:07.923783 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:21:07.924135 [debug] [MainThread]: On master: COMMIT
[0m19:21:07.924351 [debug] [MainThread]: Using postgres connection "master"
[0m19:21:07.924552 [debug] [MainThread]: On master: COMMIT
[0m19:21:07.997310 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:21:07.997731 [debug] [MainThread]: On master: Close
[0m19:21:07.998692 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:21:07.999064 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:21:07.999497 [info ] [MainThread]: 
[0m19:21:07.999928 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 8.41 seconds (8.41s).
[0m19:21:08.000716 [debug] [MainThread]: Command end result
[0m19:21:08.009824 [info ] [MainThread]: 
[0m19:21:08.010204 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:21:08.010482 [info ] [MainThread]: 
[0m19:21:08.010794 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:21:08.013422 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.56893, "process_user_time": 1.033299, "process_kernel_time": 0.110566, "process_mem_max_rss": "129433600", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:21:08.014083 [debug] [MainThread]: Command `dbt run` succeeded at 19:21:08.013954 after 8.57 seconds
[0m19:21:08.014474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10620ec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10562ac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c69bd0>]}
[0m19:21:08.014822 [debug] [MainThread]: Flushing usage events
[0m19:33:44.240583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3e9290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a43add0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a45f310>]}


============================== 19:33:44.242513 | 848244b4-5945-4dea-a12a-5dadfe5015ed ==============================
[0m19:33:44.242513 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:33:44.242861 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'quiet': 'False', 'version_check': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'invocation_command': 'dbt run -m outclick_cost_int', 'no_print': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'partial_parse': 'True', 'target_path': 'None', 'use_colors': 'True', 'warn_error': 'None', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'use_experimental_parser': 'False'}
[0m19:33:44.317580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '848244b4-5945-4dea-a12a-5dadfe5015ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7eb150>]}
[0m19:33:44.347313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '848244b4-5945-4dea-a12a-5dadfe5015ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3f3210>]}
[0m19:33:44.347808 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:33:44.355000 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:33:44.368081 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m19:33:44.368406 [debug] [MainThread]: Partial parsing: added file: campaign_perfomance://models/brand_performance/schema.yml
[0m19:33:44.368596 [debug] [MainThread]: Partial parsing: updated file: campaign_perfomance://models/brand_performance/outclick_cost_int.sql
[0m19:33:44.442843 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "brand_performance_deals".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("brand_performance", "deals").
  
  To fix this, change the name of one of these resources:
  - source.campaign_perfomance.brand_performance.deals (models/brand_performance/schema.yml)
  - source.campaign_perfomance.brand_performance.deals (models/brand_performance/source.yml)
[0m19:33:44.445197 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.2280547, "process_user_time": 0.89629, "process_kernel_time": 0.105185, "process_mem_max_rss": "124649472", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:33:44.445561 [debug] [MainThread]: Command `dbt run` failed at 19:33:44.445495 after 0.23 seconds
[0m19:33:44.445759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10490a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048816d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5270d0>]}
[0m19:33:44.445952 [debug] [MainThread]: Flushing usage events
[0m19:34:01.793514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b2610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b1510>]}


============================== 19:34:01.794794 | 0f3c5916-97fb-46de-8c73-1a273418c7da ==============================
[0m19:34:01.794794 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:34:01.795118 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'debug': 'False', 'log_cache_events': 'False', 'use_colors': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'indirect_selection': 'eager', 'version_check': 'True', 'printer_width': '80', 'warn_error': 'None', 'introspect': 'True', 'partial_parse': 'True', 'quiet': 'False', 'write_json': 'True', 'fail_fast': 'False', 'target_path': 'None', 'no_print': 'None', 'log_path': '/Users/danila/github/dbt/logs'}
[0m19:34:01.859380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105994590>]}
[0m19:34:01.888996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f72d10>]}
[0m19:34:01.889339 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:34:01.896205 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:34:01.908962 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:34:01.909176 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:34:01.909623 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:34:01.912169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052bd5d0>]}
[0m19:34:01.918363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059f9150>]}
[0m19:34:01.918634 [info ] [MainThread]: Found 12 models, 6 tests, 14 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m19:34:01.918813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e61410>]}
[0m19:34:01.919548 [info ] [MainThread]: 
[0m19:34:01.919936 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:34:01.920477 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:34:01.925040 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:34:01.925241 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:34:01.925403 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:34:02.341039 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:34:02.345624 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:34:02.350749 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:34:02.360783 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:34:02.361410 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:34:02.361800 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:34:02.688149 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:34:02.690050 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:34:02.691315 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:34:02.735160 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:34:02.740644 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:34:02.780499 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:34:02.798842 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:02.799371 [debug] [MainThread]: On master: BEGIN
[0m19:34:02.799751 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:34:03.060224 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:34:03.062157 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.063839 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:34:03.106022 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:34:03.111829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101d4c8d0>]}
[0m19:34:03.112728 [debug] [MainThread]: On master: ROLLBACK
[0m19:34:03.143397 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.144305 [debug] [MainThread]: On master: BEGIN
[0m19:34:03.206464 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:34:03.208037 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.208937 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.209634 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.241277 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:34:03.242158 [debug] [MainThread]: On master: Close
[0m19:34:03.244231 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:34:03.244953 [info ] [MainThread]: 
[0m19:34:03.251407 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:34:03.252544 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:34:03.253841 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:34:03.254484 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:34:03.267651 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:34:03.254944 => 19:34:03.267249
[0m19:34:03.272747 [debug] [Thread-1 (]: Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m19:34:03.273262 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f3c5916-97fb-46de-8c73-1a273418c7da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fcf210>]}
[0m19:34:03.273816 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model danila.outclick_cost_int ................. [[31mERROR[0m in 0.02s]
[0m19:34:03.274333 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:34:03.275490 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.275744 [debug] [MainThread]: On master: BEGIN
[0m19:34:03.275972 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:34:03.551962 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:34:03.553830 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.555033 [debug] [MainThread]: Using postgres connection "master"
[0m19:34:03.556180 [debug] [MainThread]: On master: COMMIT
[0m19:34:03.590199 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:34:03.592045 [debug] [MainThread]: On master: Close
[0m19:34:03.594141 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:34:03.594758 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:34:03.595473 [info ] [MainThread]: 
[0m19:34:03.596178 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 1.68 seconds (1.68s).
[0m19:34:03.597435 [debug] [MainThread]: Command end result
[0m19:34:03.612923 [info ] [MainThread]: 
[0m19:34:03.613485 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:34:03.613831 [info ] [MainThread]: 
[0m19:34:03.614173 [error] [MainThread]:   Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  'dbt_utils' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m19:34:03.614519 [info ] [MainThread]: 
[0m19:34:03.614889 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m19:34:03.617046 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 1.8445531, "process_user_time": 0.983938, "process_kernel_time": 0.112046, "process_mem_max_rss": "128581632", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:34:03.617676 [debug] [MainThread]: Command `dbt run` failed at 19:34:03.617546 after 1.85 seconds
[0m19:34:03.618138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105222490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059c7390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009aa790>]}
[0m19:34:03.618493 [debug] [MainThread]: Flushing usage events
[0m19:36:15.311760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129e9710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a55c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a56d50>]}


============================== 19:36:15.313070 | 203fa131-ae22-415c-8451-c481be0a34e7 ==============================
[0m19:36:15.313070 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:36:15.313396 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'quiet': 'False', 'log_format': 'default', 'debug': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'static_parser': 'True', 'fail_fast': 'False', 'introspect': 'True', 'write_json': 'True', 'printer_width': '80', 'invocation_command': 'dbt deps', 'version_check': 'True'}
[0m19:36:15.347373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '203fa131-ae22-415c-8451-c481be0a34e7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112aff150>]}
[0m19:36:15.348126 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-k7dvyc_i'
[0m19:36:15.348372 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:36:15.469361 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:36:15.470772 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:36:15.676120 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:36:15.680912 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:36:15.681591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '203fa131-ae22-415c-8451-c481be0a34e7', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b1ba50>]}
[0m19:36:15.687754 [info ] [MainThread]: Updating lock file in file path: /Users/danila/github/dbt/package-lock.yml
[0m19:36:15.689493 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-ccli1z6a'
[0m19:36:15.691803 [info ] [MainThread]: Installing fishtown-analytics/dbt_utils
[0m19:36:16.336391 [info ] [MainThread]: Installed from version 0.7.0
[0m19:36:16.336688 [info ] [MainThread]: Up to date!
[0m19:36:16.336925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '203fa131-ae22-415c-8451-c481be0a34e7', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129f35d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ae7790>]}
[0m19:36:16.338285 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.0485277, "process_user_time": 0.833093, "process_kernel_time": 0.10982, "process_mem_max_rss": "117899264", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:36:16.338614 [debug] [MainThread]: Command `dbt deps` succeeded at 19:36:16.338540 after 1.05 seconds
[0m19:36:16.338838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117e6590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a56d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100102d0>]}
[0m19:36:16.339048 [debug] [MainThread]: Flushing usage events
[0m19:36:22.581509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109925110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109927850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109943490>]}


============================== 19:36:22.582753 | 3728903c-4a0f-46e1-b294-f78b50791534 ==============================
[0m19:36:22.582753 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:36:22.583095 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'fail_fast': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'invocation_command': 'dbt run -m outclick_cost_int', 'use_experimental_parser': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'use_colors': 'True', 'static_parser': 'True', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'debug': 'False', 'version_check': 'True', 'printer_width': '80', 'target_path': 'None', 'write_json': 'True'}
[0m19:36:22.647118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3728903c-4a0f-46e1-b294-f78b50791534', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996c950>]}
[0m19:36:22.676628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3728903c-4a0f-46e1-b294-f78b50791534', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e4950>]}
[0m19:36:22.676979 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:36:22.684138 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =1.7.0
      Required version of dbt for 'dbt_utils': ['>=0.20.0', '<0.21.0']
    Check for a different version of the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils/dbt_project.yml

Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils
[0m19:36:22.685272 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.12385917, "process_user_time": 0.800731, "process_kernel_time": 0.076541, "process_mem_max_rss": "117080064", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:36:22.685589 [debug] [MainThread]: Command `dbt run` failed at 19:36:22.685524 after 0.12 seconds
[0m19:36:22.685812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109943950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10491e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10996c8d0>]}
[0m19:36:22.686046 [debug] [MainThread]: Flushing usage events
[0m19:36:46.542801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10785e910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078d2790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078d2e90>]}


============================== 19:36:46.544338 | 47d772f3-be1b-42c5-b317-59b492db4fbc ==============================
[0m19:36:46.544338 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:36:46.544664 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'invocation_command': 'dbt deps', 'use_colors': 'True', 'version_check': 'True', 'warn_error': 'None', 'write_json': 'True', 'quiet': 'False', 'no_print': 'None', 'profiles_dir': '/Users/danila/.dbt', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'log_format': 'default'}
[0m19:36:46.578202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47d772f3-be1b-42c5-b317-59b492db4fbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10796fa90>]}
[0m19:36:46.579160 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-85t472to'
[0m19:36:46.579401 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:36:46.629731 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:36:46.630674 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:36:46.668290 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:36:46.669362 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:36:46.669573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '47d772f3-be1b-42c5-b317-59b492db4fbc', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078f7690>]}
[0m19:36:46.670523 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package fishtown-analytics/dbt_utils
  Requested range: =0.20.0, =0.20.0
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.5.1', '0.6.0', '0.6.1', '0.6.2', '0.6.3', '0.6.4', '0.6.5', '0.6.6', '0.7.0']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:36:46.672380 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.15191038, "process_user_time": 0.766156, "process_kernel_time": 0.084368, "process_mem_max_rss": "117456896", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:36:46.672682 [debug] [MainThread]: Command `dbt deps` failed at 19:36:46.672615 after 0.15 seconds
[0m19:36:46.672872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078d3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071b9b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1028a66d0>]}
[0m19:36:46.673049 [debug] [MainThread]: Flushing usage events
[0m19:41:36.731717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151e8ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1152339d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11525ed50>]}


============================== 19:41:36.733779 | f58a8b25-d6aa-4f6e-ae68-051433c19f95 ==============================
[0m19:41:36.733779 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:41:36.734200 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'invocation_command': 'dbt deps', 'profiles_dir': '/Users/danila/.dbt', 'log_format': 'default', 'version_check': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'printer_width': '80', 'use_colors': 'True', 'write_json': 'True', 'target_path': 'None', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'no_print': 'None'}
[0m19:41:36.771551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f58a8b25-d6aa-4f6e-ae68-051433c19f95', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11525e510>]}
[0m19:41:36.772522 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-qzfwe3wp'
[0m19:41:36.772784 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:41:36.882235 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:41:36.883510 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:41:37.263776 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:41:37.270405 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:41:37.271417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'f58a8b25-d6aa-4f6e-ae68-051433c19f95', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115317e90>]}
[0m19:41:37.275159 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package fishtown-analytics/dbt_utils
  Requested range: =2.6.2, =2.6.2
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.5.1', '0.6.0', '0.6.1', '0.6.2', '0.6.3', '0.6.4', '0.6.5', '0.6.6', '0.7.0']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:41:37.280176 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.57329375, "process_user_time": 0.782675, "process_kernel_time": 0.103694, "process_mem_max_rss": "119275520", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:41:37.281339 [debug] [MainThread]: Command `dbt deps` failed at 19:41:37.281012 after 0.57 seconds
[0m19:41:37.281988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f014d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11525f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f8a6d0>]}
[0m19:41:37.282497 [debug] [MainThread]: Flushing usage events
[0m19:42:59.304348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106700a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106750250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676f0d0>]}


============================== 19:42:59.306220 | 8145626e-de7b-4b00-bf55-06abcc22bf64 ==============================
[0m19:42:59.306220 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:42:59.306558 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'introspect': 'True', 'no_print': 'None', 'log_format': 'default', 'debug': 'False', 'log_cache_events': 'False', 'target_path': 'None', 'use_colors': 'True', 'printer_width': '80', 'partial_parse': 'True', 'indirect_selection': 'eager', 'quiet': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False'}
[0m19:42:59.345045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8145626e-de7b-4b00-bf55-06abcc22bf64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10453da10>]}
[0m19:42:59.346025 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-_ohnk1pp'
[0m19:42:59.346315 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:42:59.449737 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:42:59.450902 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:42:59.641532 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:42:59.647037 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:42:59.647975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '8145626e-de7b-4b00-bf55-06abcc22bf64', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067f7e10>]}
[0m19:42:59.651423 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package fishtown-analytics/dbt_utils
  Requested range: =2.6.2, =2.6.2
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.5.1', '0.6.0', '0.6.1', '0.6.2', '0.6.3', '0.6.4', '0.6.5', '0.6.6', '0.7.0']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:42:59.656106 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.37705475, "process_user_time": 0.797001, "process_kernel_time": 0.097975, "process_mem_max_rss": "117981184", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:42:59.657086 [debug] [MainThread]: Command `dbt deps` failed at 19:42:59.656881 after 0.38 seconds
[0m19:42:59.657621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10676d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10174a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1016c1510>]}
[0m19:42:59.658111 [debug] [MainThread]: Flushing usage events
[0m19:43:15.150524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a070e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0de1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0de8d0>]}


============================== 19:43:15.151854 | 51a88c38-80c5-4773-b2cc-881c9bf76a67 ==============================
[0m19:43:15.151854 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:43:15.152170 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'no_print': 'None', 'debug': 'False', 'warn_error': 'None', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'quiet': 'False', 'target_path': 'None', 'write_json': 'True', 'profiles_dir': '/Users/danila/.dbt', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'version_check': 'True', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default'}
[0m19:43:15.185065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '51a88c38-80c5-4773-b2cc-881c9bf76a67', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a11c4d0>]}
[0m19:43:15.196670 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-4adp7v20'
[0m19:43:15.196928 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:43:15.240092 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:43:15.241014 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:43:15.277281 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:43:15.278528 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:43:15.278765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '51a88c38-80c5-4773-b2cc-881c9bf76a67', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0c6750>]}
[0m19:43:15.279826 [info ] [MainThread]: Installing fishtown-analytics/dbt_utils
[0m19:43:16.016643 [info ] [MainThread]: Installed from version 0.7.0
[0m19:43:16.016940 [info ] [MainThread]: Up to date!
[0m19:43:16.017192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '51a88c38-80c5-4773-b2cc-881c9bf76a67', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a072350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a15f650>]}
[0m19:43:16.018573 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.8881659, "process_user_time": 0.789453, "process_kernel_time": 0.122442, "process_mem_max_rss": "118980608", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:43:16.018918 [debug] [MainThread]: Command `dbt deps` succeeded at 19:43:16.018839 after 0.89 seconds
[0m19:43:16.019145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0de750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0dee90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0ff490>]}
[0m19:43:16.019354 [debug] [MainThread]: Flushing usage events
[0m19:43:22.059235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e90a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eb3410>]}


============================== 19:43:22.060477 | ed66f062-4a00-433a-9c8c-88ee7ca95fbc ==============================
[0m19:43:22.060477 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:43:22.060796 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'log_format': 'default', 'no_print': 'None', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt', 'warn_error': 'None', 'version_check': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'write_json': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'fail_fast': 'False', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m19:43:22.130549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed66f062-4a00-433a-9c8c-88ee7ca95fbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062eea10>]}
[0m19:43:22.160136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed66f062-4a00-433a-9c8c-88ee7ca95fbc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e90450>]}
[0m19:43:22.160840 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:43:22.169336 [error] [MainThread]: Encountered an error:
Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =1.7.0
      Required version of dbt for 'dbt_utils': ['>=0.20.0', '<0.21.0']
    Check for a different version of the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils/dbt_project.yml

Error encountered in /Users/danila/github/dbt/dbt_packages/dbt_utils
[0m19:43:22.170505 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.13210842, "process_user_time": 0.800864, "process_kernel_time": 0.076938, "process_mem_max_rss": "117407744", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:43:22.170862 [debug] [MainThread]: Command `dbt run` failed at 19:43:22.170790 after 0.13 seconds
[0m19:43:22.171140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057121d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100dc8290>]}
[0m19:43:22.171392 [debug] [MainThread]: Flushing usage events
[0m19:44:36.963557 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a33f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a81e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9f0d0>]}


============================== 19:44:36.965161 | 0fa99d17-7359-4ec8-89bc-1da9f439c740 ==============================
[0m19:44:36.965161 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:44:36.965489 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'printer_width': '80', 'warn_error': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'use_colors': 'True', 'log_format': 'default', 'version_check': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'invocation_command': 'dbt deps', 'cache_selected_only': 'False', 'no_print': 'None', 'target_path': 'None', 'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'write_json': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs'}
[0m19:44:37.000164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0fa99d17-7359-4ec8-89bc-1da9f439c740', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a40250>]}
[0m19:44:37.011289 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-yf_t8p7j'
[0m19:44:37.011551 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:44:37.185068 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:44:37.187014 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
[0m19:44:37.438848 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
[0m19:44:37.444724 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `fishtown-analytics/dbt_utils` package is deprecated in favor of
`dbt-labs/dbt_utils`. Please update your `packages.yml` configuration to use
`dbt-labs/dbt_utils` instead.
[0m19:44:37.445509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '0fa99d17-7359-4ec8-89bc-1da9f439c740', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9e050>]}
[0m19:44:37.448448 [info ] [MainThread]: Installing fishtown-analytics/dbt_utils
[0m19:44:37.942134 [info ] [MainThread]: Installed from version 0.7.0
[0m19:44:37.942433 [info ] [MainThread]: Up to date!
[0m19:44:37.942674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '0fa99d17-7359-4ec8-89bc-1da9f439c740', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b1b690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b5db50>]}
[0m19:44:37.944587 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 1.0035342, "process_user_time": 0.842155, "process_kernel_time": 0.140499, "process_mem_max_rss": "121225216", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:44:37.944962 [debug] [MainThread]: Command `dbt deps` succeeded at 19:44:37.944878 after 1.00 seconds
[0m19:44:37.945200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a7a650>]}
[0m19:44:37.945426 [debug] [MainThread]: Flushing usage events
[0m19:45:35.040648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113cfbad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ce9150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11368ed10>]}


============================== 19:45:35.041983 | ba78e6f3-b477-473e-b608-d3a11723e026 ==============================
[0m19:45:35.041983 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:45:35.042316 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'use_experimental_parser': 'False', 'invocation_command': 'dbt deps', 'version_check': 'True', 'use_colors': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'printer_width': '80', 'target_path': 'None', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'introspect': 'True', 'warn_error': 'None', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt'}
[0m19:45:35.075619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba78e6f3-b477-473e-b608-d3a11723e026', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113381a10>]}
[0m19:45:35.076539 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-q3kk5vmt'
[0m19:45:35.076778 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:45:35.173519 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:45:35.174694 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m19:45:35.263601 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m19:45:35.268217 [error] [MainThread]: Encountered an error:
Could not find a matching compatible version for package dbt-labs/dbt_utils
  Requested range: =0.6.4, =0.6.4
  Compatible versions: ['0.0.1', '0.1.0', '0.1.1', '0.1.2', '0.1.3', '0.1.4', '0.1.5', '0.1.6', '0.1.7', '0.1.8', '0.1.9', '0.1.10', '0.1.11', '0.1.12', '0.1.13', '0.1.14', '0.1.15', '0.1.16', '0.1.17', '0.1.18', '0.1.19', '0.1.20', '0.1.21', '0.1.22', '0.1.23', '0.1.24', '0.1.25', '0.2.0', '0.2.1', '0.2.2', '0.2.3', '0.2.4', '0.2.5', '0.3.0', '0.4.0', '0.4.1', '0.5.0', '0.8.0', '0.8.1', '0.8.2', '0.8.3', '0.8.4', '0.8.5', '0.8.6', '0.9.0', '0.9.1', '0.9.2', '0.9.5', '0.9.6', '1.0.0', '1.1.0', '1.1.1']

  Not shown: package versions incompatible with installed version of dbt-core
  To include them, run 'dbt --no-version-check deps'
[0m19:45:35.269873 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_wall_clock_time": 0.25079504, "process_user_time": 0.764574, "process_kernel_time": 0.089649, "process_mem_max_rss": "118063104", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:45:35.270368 [debug] [MainThread]: Command `dbt deps` failed at 19:45:35.270248 after 0.25 seconds
[0m19:45:35.270693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d57190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10577d4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11324c350>]}
[0m19:45:35.270999 [debug] [MainThread]: Flushing usage events
[0m19:45:51.738302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b6210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661a690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661ad90>]}


============================== 19:45:51.739511 | 6f52328f-965e-4f80-8b7f-45954d048f1d ==============================
[0m19:45:51.739511 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:45:51.739862 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'introspect': 'True', 'quiet': 'False', 'invocation_command': 'dbt deps', 'debug': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'no_print': 'None', 'log_format': 'default', 'warn_error': 'None', 'cache_selected_only': 'False', 'version_check': 'True', 'write_json': 'True', 'fail_fast': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False'}
[0m19:45:51.773865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f52328f-965e-4f80-8b7f-45954d048f1d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10663e610>]}
[0m19:45:51.775508 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-85lf1z07'
[0m19:45:51.775762 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m19:45:51.862151 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m19:45:51.863355 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m19:45:51.947878 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m19:45:51.954070 [info ] [MainThread]: Updating lock file in file path: /Users/danila/github/dbt/package-lock.yml
[0m19:45:51.967195 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-57ohp72r'
[0m19:45:51.969180 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m19:45:52.413076 [info ] [MainThread]: Installed from version 1.1.1
[0m19:45:52.413374 [info ] [MainThread]: Up to date!
[0m19:45:52.413607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6f52328f-965e-4f80-8b7f-45954d048f1d', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10661a1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ab410>]}
[0m19:45:52.414898 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.6973875, "process_user_time": 0.825896, "process_kernel_time": 0.117432, "process_mem_max_rss": "119095296", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:45:52.415212 [debug] [MainThread]: Command `dbt deps` succeeded at 19:45:52.415140 after 0.70 seconds
[0m19:45:52.415424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fd30d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e66550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105222650>]}
[0m19:45:52.415632 [debug] [MainThread]: Flushing usage events
[0m19:45:55.671996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10861c8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f791d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10868b810>]}


============================== 19:45:55.673244 | 55de2acf-c61d-4440-952a-6b3a5e92aef0 ==============================
[0m19:45:55.673244 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:45:55.673564 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'quiet': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'partial_parse': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'introspect': 'True', 'target_path': 'None', 'printer_width': '80', 'version_check': 'True', 'log_cache_events': 'False'}
[0m19:45:55.743630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '55de2acf-c61d-4440-952a-6b3a5e92aef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b5add0>]}
[0m19:45:55.774754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '55de2acf-c61d-4440-952a-6b3a5e92aef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108aac210>]}
[0m19:45:55.775420 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:45:55.785148 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:45:55.790904 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m19:45:55.791178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '55de2acf-c61d-4440-952a-6b3a5e92aef0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d66e10>]}
[0m19:45:56.229394 [error] [MainThread]: Encountered an error:
Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  macro 'dbt_macro__default__surrogate_key' takes not more than 1 argument(s)
  
  > in macro surrogate_key (macros/sql/surrogate_key.sql)
  > called by model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
[0m19:45:56.230779 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.5803096, "process_user_time": 1.231565, "process_kernel_time": 0.091648, "process_mem_max_rss": "123404288", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:45:56.231072 [debug] [MainThread]: Command `dbt run` failed at 19:45:56.231009 after 0.58 seconds
[0m19:45:56.231259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10804f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10868b150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e5f150>]}
[0m19:45:56.231430 [debug] [MainThread]: Flushing usage events
[0m19:47:09.656108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fe8850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11413b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11413a950>]}


============================== 19:47:09.657396 | 47f3e834-670f-4c66-a1a7-c3b3e332c27f ==============================
[0m19:47:09.657396 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:47:09.657715 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'use_colors': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'debug': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'version_check': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'profiles_dir': '/Users/danila/.dbt', 'printer_width': '80', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False'}
[0m19:47:09.724110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47f3e834-670f-4c66-a1a7-c3b3e332c27f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145de910>]}
[0m19:47:09.755939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47f3e834-670f-4c66-a1a7-c3b3e332c27f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145fccd0>]}
[0m19:47:09.756595 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:47:09.765266 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:47:09.770706 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m19:47:09.770974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47f3e834-670f-4c66-a1a7-c3b3e332c27f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11411d1d0>]}
[0m19:47:10.220833 [error] [MainThread]: Encountered an error:
Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  
  Warning: `dbt_utils.surrogate_key` has been replaced by `dbt_utils.generate_surrogate_key`. The new macro treats null values differently to empty strings. To restore the behaviour of the original macro, add a global variable in dbt_project.yml called `surrogate_key_treat_nulls_as_empty_strings` to your dbt_project.yml file with a value of True. The campaign_perfomance.outclick_cost_int model triggered this warning. 
  
  > in macro default__surrogate_key (macros/sql/surrogate_key.sql)
  > called by macro surrogate_key (macros/sql/surrogate_key.sql)
  > called by model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
[0m19:47:10.222688 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.58815664, "process_user_time": 1.289059, "process_kernel_time": 0.09479, "process_mem_max_rss": "124174336", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:47:10.222980 [debug] [MainThread]: Command `dbt run` failed at 19:47:10.222921 after 0.59 seconds
[0m19:47:10.223171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c1550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129e5850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11541fd10>]}
[0m19:47:10.223337 [debug] [MainThread]: Flushing usage events
[0m19:47:58.486731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a747c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7467d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1084f7e90>]}


============================== 19:47:58.487943 | c11cc0a5-4168-473a-82c7-337a4174103c ==============================
[0m19:47:58.487943 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:47:58.488274 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'no_print': 'None', 'fail_fast': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'partial_parse': 'True', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'write_json': 'True', 'version_check': 'True', 'quiet': 'False', 'log_format': 'default', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'invocation_command': 'dbt run -m outclick_cost_int', 'send_anonymous_usage_stats': 'True'}
[0m19:47:58.551682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c11cc0a5-4168-473a-82c7-337a4174103c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab79ad0>]}
[0m19:47:58.581146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c11cc0a5-4168-473a-82c7-337a4174103c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a762750>]}
[0m19:47:58.581466 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:47:58.589755 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:47:58.595145 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m19:47:58.595421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c11cc0a5-4168-473a-82c7-337a4174103c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fba310>]}
[0m19:47:59.022600 [error] [MainThread]: Encountered an error:
Compilation Error in model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
  
  Warning: `dbt_utils.surrogate_key` has been replaced by `dbt_utils.generate_surrogate_key`. The new macro treats null values differently to empty strings. To restore the behaviour of the original macro, add a global variable in dbt_project.yml called `surrogate_key_treat_nulls_as_empty_strings` to your dbt_project.yml file with a value of True. The campaign_perfomance.outclick_cost_int model triggered this warning. 
  
  > in macro default__surrogate_key (macros/sql/surrogate_key.sql)
  > called by macro surrogate_key (macros/sql/surrogate_key.sql)
  > called by model outclick_cost_int (models/brand_performance/outclick_cost_int.sql)
[0m19:47:59.023549 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.55720663, "process_user_time": 1.227179, "process_kernel_time": 0.089247, "process_mem_max_rss": "122568704", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:47:59.023801 [debug] [MainThread]: Command `dbt run` failed at 19:47:59.023743 after 0.56 seconds
[0m19:47:59.023979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a786fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fba1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a7450d0>]}
[0m19:47:59.024146 [debug] [MainThread]: Flushing usage events
[0m19:48:07.459192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d17250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d66410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d67850>]}


============================== 19:48:07.460508 | 62bb71e5-695e-4756-aa97-f6f76fb8eb0d ==============================
[0m19:48:07.460508 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:48:07.460851 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'write_json': 'True', 'no_print': 'None', 'target_path': 'None', 'quiet': 'False', 'partial_parse': 'True', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'warn_error': 'None', 'static_parser': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'use_colors': 'True', 'fail_fast': 'False', 'invocation_command': 'dbt run -m outclick_cost_int'}
[0m19:48:07.526686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10818acd0>]}
[0m19:48:07.556946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108178bd0>]}
[0m19:48:07.557343 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:48:07.565885 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:48:07.581126 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:48:07.581342 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:48:07.581840 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:48:07.584965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10848e550>]}
[0m19:48:07.591181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108178650>]}
[0m19:48:07.591386 [info ] [MainThread]: Found 12 models, 6 tests, 14 sources, 0 exposures, 0 metrics, 515 macros, 0 groups, 0 semantic models
[0m19:48:07.591573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d48450>]}
[0m19:48:07.592203 [info ] [MainThread]: 
[0m19:48:07.592570 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:48:07.593058 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:48:07.597504 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:48:07.597723 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:48:07.597894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:48:08.114536 [debug] [ThreadPool]: SQL status: SELECT 9 in 1.0 seconds
[0m19:48:08.118004 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:48:08.122549 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:48:08.132507 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:48:08.133143 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:48:08.133560 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:48:08.392689 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:48:08.394685 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:48:08.395850 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:48:08.431437 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:48:08.437046 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:48:08.469692 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:48:08.487794 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.488332 [debug] [MainThread]: On master: BEGIN
[0m19:48:08.488694 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:48:08.798849 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:08.800628 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.801627 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:48:08.843557 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:48:08.847610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081cf410>]}
[0m19:48:08.848511 [debug] [MainThread]: On master: ROLLBACK
[0m19:48:08.879646 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.880596 [debug] [MainThread]: On master: BEGIN
[0m19:48:08.942467 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:08.943861 [debug] [MainThread]: On master: COMMIT
[0m19:48:08.945117 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:08.946182 [debug] [MainThread]: On master: COMMIT
[0m19:48:08.976515 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:48:08.978056 [debug] [MainThread]: On master: Close
[0m19:48:08.981072 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:48:08.981885 [info ] [MainThread]: 
[0m19:48:08.987911 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:48:08.988819 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:48:08.990100 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:48:08.990769 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:48:09.014229 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.015397 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:48:08.991204 => 19:48:09.015151
[0m19:48:09.015748 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:48:09.038640 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.039189 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.039413 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:48:09.039616 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:48:09.303889 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:48:09.305852 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:09.307780 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m19:48:16.485559 [debug] [Thread-1 (]: SQL status: SELECT 45891 in 7.0 seconds
[0m19:48:16.499409 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.500292 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:48:16.534658 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:48:16.541681 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.542527 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:48:16.574546 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:48:16.601860 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:48:16.602399 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.602760 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:48:16.633800 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:48:16.641139 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:48:16.646022 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:16.646380 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:48:16.707186 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:48:16.710603 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:48:09.015936 => 19:48:16.710188
[0m19:48:16.711342 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:48:16.713246 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62bb71e5-695e-4756-aa97-f6f76fb8eb0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ab790>]}
[0m19:48:16.714365 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45891[0m in 7.72s]
[0m19:48:16.715422 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:48:16.717353 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:16.717818 [debug] [MainThread]: On master: BEGIN
[0m19:48:16.718195 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:48:17.047111 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:17.048916 [debug] [MainThread]: On master: COMMIT
[0m19:48:17.050074 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:17.051227 [debug] [MainThread]: On master: COMMIT
[0m19:48:17.090815 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:48:17.092348 [debug] [MainThread]: On master: Close
[0m19:48:17.094796 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:48:17.095525 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:48:17.096200 [info ] [MainThread]: 
[0m19:48:17.097190 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 9.50 seconds (9.50s).
[0m19:48:17.098593 [debug] [MainThread]: Command end result
[0m19:48:17.116535 [info ] [MainThread]: 
[0m19:48:17.117100 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:48:17.117446 [info ] [MainThread]: 
[0m19:48:17.117817 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:48:17.120337 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.683342, "process_user_time": 1.113902, "process_kernel_time": 0.11493, "process_mem_max_rss": "128106496", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:48:17.121043 [debug] [MainThread]: Command `dbt run` succeeded at 19:48:17.120912 after 9.68 seconds
[0m19:48:17.121410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d89bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d5e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d5e710>]}
[0m19:48:17.121731 [debug] [MainThread]: Flushing usage events
[0m19:49:42.922107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108677b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108692a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086930d0>]}


============================== 19:49:42.923859 | 76ed4a1d-2c60-4e6d-b75a-b0d024bf064c ==============================
[0m19:49:42.923859 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:49:42.924221 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'static_parser': 'True', 'quiet': 'False', 'partial_parse': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'use_experimental_parser': 'False', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'debug': 'False', 'use_colors': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'write_json': 'True', 'log_cache_events': 'False', 'warn_error': 'None', 'printer_width': '80', 'introspect': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True'}
[0m19:49:42.996964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '76ed4a1d-2c60-4e6d-b75a-b0d024bf064c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108692f10>]}
[0m19:49:43.027188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '76ed4a1d-2c60-4e6d-b75a-b0d024bf064c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089d5b10>]}
[0m19:49:43.027706 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:49:43.036865 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:49:43.054648 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:49:43.055087 [debug] [MainThread]: Partial parsing: updated file: campaign_perfomance://models/brand_performance/source.yml
[0m19:49:43.084243 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "main_deals".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("main", "deals").
  
  To fix this, change the name of one of these resources:
  - source.campaign_perfomance.main.deals (models/brand_performance/source.yml)
  - source.campaign_perfomance.main.deals (models/users/source.yml)
[0m19:49:43.085534 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.18596888, "process_user_time": 0.867111, "process_kernel_time": 0.093774, "process_mem_max_rss": "120602624", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:49:43.085802 [debug] [MainThread]: Command `dbt run` failed at 19:49:43.085742 after 0.19 seconds
[0m19:49:43.085991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108691bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032ee7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e1d1d0>]}
[0m19:49:43.086170 [debug] [MainThread]: Flushing usage events
[0m19:49:58.091865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aa6590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ae5c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b03210>]}


============================== 19:49:58.093072 | aefd3acb-ac63-47a7-8540-8eea18ac9111 ==============================
[0m19:49:58.093072 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:49:58.093428 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'version_check': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'warn_error': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'invocation_command': 'dbt run -m outclick_cost_int', 'log_cache_events': 'False', 'fail_fast': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'log_format': 'default', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'write_json': 'True', 'debug': 'False', 'send_anonymous_usage_stats': 'True'}
[0m19:49:58.159954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aefd3acb-ac63-47a7-8540-8eea18ac9111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aa66d0>]}
[0m19:49:58.190760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aefd3acb-ac63-47a7-8540-8eea18ac9111', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106097150>]}
[0m19:49:58.191131 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:49:58.199511 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:49:58.215581 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:49:58.215990 [debug] [MainThread]: Partial parsing: updated file: campaign_perfomance://models/brand_performance/source.yml
[0m19:49:58.245631 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "main_deals".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("main", "deals").
  
  To fix this, change the name of one of these resources:
  - source.campaign_perfomance.main.deals (models/brand_performance/source.yml)
  - source.campaign_perfomance.main.deals (models/users/source.yml)
[0m19:49:58.246605 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.17539833, "process_user_time": 0.856108, "process_kernel_time": 0.074442, "process_mem_max_rss": "121143296", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:49:58.246871 [debug] [MainThread]: Command `dbt run` failed at 19:49:58.246813 after 0.18 seconds
[0m19:49:58.247065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b01bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ade7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f1910>]}
[0m19:49:58.247246 [debug] [MainThread]: Flushing usage events
[0m19:50:48.577650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d46590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d46350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d63250>]}


============================== 19:50:48.579279 | 2a780604-85a3-485e-b0fd-fe6343d78d0c ==============================
[0m19:50:48.579279 [info ] [MainThread]: Running with dbt=1.7.0
[0m19:50:48.579600 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'log_format': 'default', 'debug': 'False', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'introspect': 'True', 'version_check': 'True', 'fail_fast': 'False', 'static_parser': 'True', 'invocation_command': 'dbt run -m outclick_cost_int', 'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'use_experimental_parser': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'target_path': 'None', 'warn_error': 'None', 'profiles_dir': '/Users/danila/.dbt', 'indirect_selection': 'eager', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m19:50:48.655516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d46910>]}
[0m19:50:48.685251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108230550>]}
[0m19:50:48.685751 [info ] [MainThread]: Registered adapter: postgres=1.7.0
[0m19:50:48.694469 [debug] [MainThread]: checksum: 8434eacd4ffdf0ca3ab22bf0e2d55b45306c9599613e842b959405abc489e606, vars: {}, profile: , target: , version: 1.7.0
[0m19:50:48.715852 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:50:48.716094 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:50:48.716660 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:50:48.719885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082c2810>]}
[0m19:50:48.726496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082077d0>]}
[0m19:50:48.726732 [info ] [MainThread]: Found 12 models, 6 tests, 14 sources, 0 exposures, 0 metrics, 515 macros, 0 groups, 0 semantic models
[0m19:50:48.726914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10826eb10>]}
[0m19:50:48.727561 [info ] [MainThread]: 
[0m19:50:48.727930 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:50:48.728381 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:50:48.732500 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:50:48.732657 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:50:48.732819 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:50:49.106813 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:50:49.111583 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:50:49.116250 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:50:49.125751 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:50:49.126540 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:50:49.126985 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:50:49.424562 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:50:49.426322 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:50:49.428019 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'danila'
  
[0m19:50:49.484120 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m19:50:49.488130 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:50:49.521551 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:50:49.536157 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.536681 [debug] [MainThread]: On master: BEGIN
[0m19:50:49.537029 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:50:49.823683 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:50:49.825755 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.827460 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:50:49.874719 [debug] [MainThread]: SQL status: SELECT 48 in 0.0 seconds
[0m19:50:49.880165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d8c310>]}
[0m19:50:49.881232 [debug] [MainThread]: On master: ROLLBACK
[0m19:50:49.912496 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.913133 [debug] [MainThread]: On master: BEGIN
[0m19:50:49.975571 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:50:49.977125 [debug] [MainThread]: On master: COMMIT
[0m19:50:49.978341 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:49.979449 [debug] [MainThread]: On master: COMMIT
[0m19:50:50.010738 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:50:50.011556 [debug] [MainThread]: On master: Close
[0m19:50:50.013443 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:50:50.014358 [info ] [MainThread]: 
[0m19:50:50.020010 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:50:50.021047 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:50:50.022207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m19:50:50.022808 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:50:50.047028 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.048385 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:50:50.023213 => 19:50:50.048145
[0m19:50:50.048711 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:50:50.070668 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.071237 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.071451 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:50:50.071648 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:50:50.398680 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:50:50.400399 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:50.401874 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m19:50:57.096875 [debug] [Thread-1 (]: SQL status: SELECT 45891 in 7.0 seconds
[0m19:50:57.109651 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.110254 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:50:57.149947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:50:57.156003 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.156615 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:50:57.196830 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:50:57.222237 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:50:57.222686 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.223022 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:50:57.263616 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:50:57.272877 [debug] [Thread-1 (]: Applying DROP to: "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup"
[0m19:50:57.277724 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:50:57.278108 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.7.0", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:50:57.332615 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:50:57.335738 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:50:50.048891 => 19:50:57.335425
[0m19:50:57.336297 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:50:57.337714 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a780604-85a3-485e-b0fd-fe6343d78d0c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108421190>]}
[0m19:50:57.338898 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45891[0m in 7.32s]
[0m19:50:57.339793 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:50:57.341478 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:57.341882 [debug] [MainThread]: On master: BEGIN
[0m19:50:57.342189 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:50:57.769871 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:50:57.771701 [debug] [MainThread]: On master: COMMIT
[0m19:50:57.772891 [debug] [MainThread]: Using postgres connection "master"
[0m19:50:57.774005 [debug] [MainThread]: On master: COMMIT
[0m19:50:57.817826 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:50:57.819224 [debug] [MainThread]: On master: Close
[0m19:50:57.822425 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:50:57.823372 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:50:57.823975 [info ] [MainThread]: 
[0m19:50:57.824544 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 9.10 seconds (9.10s).
[0m19:50:57.825616 [debug] [MainThread]: Command end result
[0m19:50:57.843846 [info ] [MainThread]: 
[0m19:50:57.844244 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:50:57.844529 [info ] [MainThread]: 
[0m19:50:57.844830 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:50:57.847099 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.291962, "process_user_time": 1.086413, "process_kernel_time": 0.129775, "process_mem_max_rss": "130875392", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m19:50:57.847575 [debug] [MainThread]: Command `dbt run` succeeded at 19:50:57.847464 after 9.29 seconds
[0m19:50:57.847901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d3e790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c70290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102cb5590>]}
[0m19:50:57.848199 [debug] [MainThread]: Flushing usage events
[0m23:43:19.624321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065785d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106581d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10658c850>]}


============================== 23:43:19.625958 | 2f8c971d-976d-4778-8c8f-bcfa3264c9a1 ==============================
[0m23:43:19.625958 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:43:19.626308 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'version_check': 'True', 'printer_width': '80', 'log_format': 'default', 'quiet': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'write_json': 'True', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'debug': 'False', 'static_parser': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'introspect': 'True', 'cache_selected_only': 'False', 'fail_fast': 'False'}
[0m23:43:19.636891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f8c971d-976d-4778-8c8f-bcfa3264c9a1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065b8a90>]}
[0m23:43:19.637622 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-z5q4fhqo'
[0m23:43:19.637840 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m23:43:19.750573 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m23:43:19.751834 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m23:43:19.782977 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m23:43:19.788357 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m23:43:20.271602 [info ] [MainThread]: Installed from version 1.1.1
[0m23:43:20.271868 [info ] [MainThread]: Up to date!
[0m23:43:20.272066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '2f8c971d-976d-4778-8c8f-bcfa3264c9a1', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106076cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065bfe10>]}
[0m23:43:20.272606 [debug] [MainThread]: Command `dbt deps` succeeded at 23:43:20.272543 after 0.66 seconds
[0m23:43:20.272771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106584b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100c1ffd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100cb1dd0>]}
[0m23:43:20.272919 [debug] [MainThread]: Flushing usage events
[0m23:43:33.140678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c428d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c49650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c56410>]}


============================== 23:43:33.141860 | 2340448f-a362-4287-85d2-357a2b2cf434 ==============================
[0m23:43:33.141860 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:43:33.142163 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/danila/.dbt', 'log_format': 'default', 'debug': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'target_path': 'None', 'partial_parse': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'printer_width': '80', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'introspect': 'True'}
[0m23:43:33.612590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b08250>]}
[0m23:43:33.619920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10908bc10>]}
[0m23:43:33.620375 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:43:33.634404 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:43:33.655330 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m23:43:33.655610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c65810>]}
[0m23:43:33.967004 [debug] [MainThread]: 1699: static parser successfully parsed example/test.sql
[0m23:43:33.971814 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m23:43:33.973548 [debug] [MainThread]: 1603: static parser failed on example/brand_performance_replacement.sql
[0m23:43:33.976366 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/brand_performance_replacement.sql
[0m23:43:33.976901 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m23:43:33.978033 [debug] [MainThread]: 1699: static parser successfully parsed users/deals_dim.sql
[0m23:43:33.979296 [debug] [MainThread]: 1699: static parser successfully parsed users/campaign_dim.sql
[0m23:43:33.980553 [debug] [MainThread]: 1699: static parser successfully parsed users/brand_comparison_fi.sql
[0m23:43:33.981696 [debug] [MainThread]: 1699: static parser successfully parsed users/daily_campaign_fct.sql
[0m23:43:33.983041 [debug] [MainThread]: 1699: static parser successfully parsed users/test_write.sql
[0m23:43:33.984266 [debug] [MainThread]: 1699: static parser successfully parsed users/outclicks_fct.sql
[0m23:43:33.985370 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m23:43:33.992215 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m23:43:33.993122 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m23:43:33.995295 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m23:43:34.037297 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m23:43:34.039347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c49f10>]}
[0m23:43:34.043586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090e5e90>]}
[0m23:43:34.043767 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:43:34.043931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c48b90>]}
[0m23:43:34.044862 [info ] [MainThread]: 
[0m23:43:34.045171 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:43:34.045762 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:43:34.050139 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:43:34.050369 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:43:34.050492 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:43:34.512343 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m23:43:34.516826 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:43:34.520462 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:43:34.528281 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:43:34.528701 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:43:34.528993 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:43:34.811559 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:43:34.813057 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:43:34.814104 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:43:34.853875 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m23:43:34.859756 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:43:34.892960 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:43:34.905894 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:34.906371 [debug] [MainThread]: On master: BEGIN
[0m23:43:34.906664 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:43:35.311595 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:43:35.313294 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:35.314619 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:43:35.364755 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m23:43:35.367859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4a890>]}
[0m23:43:35.368600 [debug] [MainThread]: On master: ROLLBACK
[0m23:43:35.408169 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:35.408632 [debug] [MainThread]: On master: BEGIN
[0m23:43:35.482284 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:43:35.482623 [debug] [MainThread]: On master: COMMIT
[0m23:43:35.482797 [debug] [MainThread]: Using postgres connection "master"
[0m23:43:35.482951 [debug] [MainThread]: On master: COMMIT
[0m23:43:35.519094 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:43:35.519326 [debug] [MainThread]: On master: Close
[0m23:43:35.519947 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:43:35.520240 [info ] [MainThread]: 
[0m23:43:35.525240 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m23:43:35.525624 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m23:43:35.526143 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m23:43:35.526380 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m23:43:35.533600 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.534466 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 23:43:35.526529 => 23:43:35.534276
[0m23:43:35.534730 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m23:43:35.552233 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.553130 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.553427 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m23:43:35.553594 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:35.850434 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:35.852637 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:35.855175 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m23:43:55.431627 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 20.0 seconds
[0m23:43:55.448849 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.449526 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m23:43:55.488208 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:55.498146 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.499027 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m23:43:55.535745 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:55.570833 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m23:43:55.571605 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.572032 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m23:43:55.608571 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:55.617784 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m23:43:55.618367 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m23:43:55.669188 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:55.675196 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 23:43:35.534879 => 23:43:55.674407
[0m23:43:55.676515 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m23:43:55.679873 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10915a290>]}
[0m23:43:55.681604 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 20.15s]
[0m23:43:55.683274 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m23:43:55.684274 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m23:43:55.685369 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m23:43:55.686716 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m23:43:55.687303 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m23:43:55.693976 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m23:43:55.697111 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 23:43:55.687710 => 23:43:55.696807
[0m23:43:55.697636 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m23:43:55.703631 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m23:43:55.704896 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:55.705371 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m23:43:55.705741 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:56.028744 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:56.030445 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.031654 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m23:43:56.077577 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m23:43:56.089621 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.090913 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m23:43:56.122624 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.137833 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.138758 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m23:43:56.171193 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.178630 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m23:43:56.179758 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.180771 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m23:43:56.211498 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:56.219397 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m23:43:56.220553 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m23:43:56.269736 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:56.274891 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 23:43:55.698003 => 23:43:56.274280
[0m23:43:56.276036 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m23:43:56.278886 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090cb890>]}
[0m23:43:56.280920 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.59s]
[0m23:43:56.282848 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m23:43:56.284043 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.285395 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m23:43:56.287012 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m23:43:56.287701 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.294435 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.295984 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 23:43:56.288259 => 23:43:56.295627
[0m23:43:56.296535 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.302205 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.303258 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.303671 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m23:43:56.303998 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:56.589695 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:56.591250 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.592338 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m23:43:56.641603 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m23:43:56.648563 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.649264 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m23:43:56.681045 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.691479 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.692296 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m23:43:56.723625 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:56.726113 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m23:43:56.726455 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.726753 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m23:43:56.756888 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:56.758412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m23:43:56.758598 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m23:43:56.806670 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:56.807716 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 23:43:56.296813 => 23:43:56.807562
[0m23:43:56.807995 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m23:43:56.808686 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090e0390>]}
[0m23:43:56.809127 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.52s]
[0m23:43:56.809627 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m23:43:56.809949 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m23:43:56.810449 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m23:43:56.811123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m23:43:56.811409 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m23:43:56.813952 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m23:43:56.814578 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 23:43:56.811588 => 23:43:56.814428
[0m23:43:56.814852 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m23:43:56.818185 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m23:43:56.818655 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:56.818869 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m23:43:56.819061 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:57.074508 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:57.076453 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.077767 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m23:43:57.115991 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m23:43:57.127125 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.127997 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m23:43:57.160249 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.169453 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.170393 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m23:43:57.243915 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.251592 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m23:43:57.252724 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.253670 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m23:43:57.286118 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:57.294562 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m23:43:57.295374 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m23:43:57.348253 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:57.352941 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 23:43:56.815016 => 23:43:57.352304
[0m23:43:57.354088 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m23:43:57.357047 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928c2d0>]}
[0m23:43:57.358660 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.55s]
[0m23:43:57.360167 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m23:43:57.361176 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.362515 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m23:43:57.364097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m23:43:57.364886 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.373476 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.374905 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 23:43:57.365459 => 23:43:57.374688
[0m23:43:57.375346 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.380573 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.381873 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.382288 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m23:43:57.382630 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:57.642995 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:57.645105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.646407 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m23:43:57.680841 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m23:43:57.692821 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.694054 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m23:43:57.726992 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.736355 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.737222 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m23:43:57.768562 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:43:57.775907 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m23:43:57.777000 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.777971 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m23:43:57.809441 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:43:57.818340 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m23:43:57.819355 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m23:43:57.868150 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:43:57.871221 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 23:43:57.375631 => 23:43:57.870882
[0m23:43:57.871977 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m23:43:57.873830 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093e0410>]}
[0m23:43:57.874870 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.51s]
[0m23:43:57.875975 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m23:43:57.876691 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:43:57.877557 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m23:43:57.878899 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:43:57.879406 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:43:57.886516 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:57.887841 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:43:57.879741 => 23:43:57.887444
[0m23:43:57.888543 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:43:57.895578 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:57.897052 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:57.897676 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:43:57.898055 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:43:58.154727 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:43:58.156594 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:43:58.158543 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m23:44:06.244779 [debug] [Thread-1 (]: SQL status: SELECT 153700 in 8.0 seconds
[0m23:44:06.250792 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.251389 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:44:06.283528 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:06.288794 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.289441 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:44:06.320378 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:06.323321 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:44:06.323772 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.324153 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:44:06.355842 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:06.359655 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:44:06.360013 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:44:06.407069 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:06.408128 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:43:57.888981 => 23:44:06.407993
[0m23:44:06.408385 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:44:06.408977 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109242750>]}
[0m23:44:06.409359 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153700[0m in 8.53s]
[0m23:44:06.409748 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:44:06.410019 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:44:06.410248 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m23:44:06.410758 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:44:06.411014 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:44:06.415307 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.416922 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:44:06.411164 => 23:44:06.416783
[0m23:44:06.417146 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:44:06.421528 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.421997 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.422190 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:44:06.422367 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:06.750657 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:06.752369 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:06.753601 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m23:44:11.759562 [debug] [Thread-1 (]: SQL status: SELECT 45919 in 5.0 seconds
[0m23:44:11.769077 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.770167 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:44:11.811282 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:11.818060 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.818785 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:44:11.858145 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:11.865051 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:11.865758 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.866284 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:11.906103 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:11.912690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:11.913590 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:44:11.969812 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:11.974286 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:44:06.417276 => 23:44:11.973697
[0m23:44:11.975441 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:44:11.978208 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109351410>]}
[0m23:44:11.979561 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45919[0m in 5.57s]
[0m23:44:11.981080 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:44:11.982030 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m23:44:11.983184 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m23:44:11.984783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m23:44:11.985548 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m23:44:11.991536 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m23:44:11.994080 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 23:44:11.986136 => 23:44:11.993798
[0m23:44:11.994595 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m23:44:12.015622 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m23:44:12.016342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.016615 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m23:44:12.016860 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:12.279957 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:12.281640 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.282940 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m23:44:12.319176 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:44:12.329850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.330777 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m23:44:12.363238 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:12.372381 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.373517 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m23:44:12.405307 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:12.408226 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:44:12.408738 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.409183 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:44:12.439561 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:12.443715 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:44:12.444277 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m23:44:12.475848 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:44:12.477121 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 23:44:11.994918 => 23:44:12.476985
[0m23:44:12.477370 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m23:44:12.477947 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092c8690>]}
[0m23:44:12.478271 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.49s]
[0m23:44:12.478624 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m23:44:12.478851 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m23:44:12.479173 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m23:44:12.479628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m23:44:12.479829 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m23:44:12.481488 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m23:44:12.482644 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 23:44:12.479956 => 23:44:12.482539
[0m23:44:12.482826 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m23:44:12.485154 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m23:44:12.485892 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.486058 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m23:44:12.486202 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:12.835498 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:12.837279 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.838459 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m23:44:12.884048 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:44:12.895391 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.896339 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m23:44:12.939778 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:12.954803 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:12.955924 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m23:44:12.999895 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:13.006932 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m23:44:13.008065 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:13.009236 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m23:44:13.052438 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:13.059755 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m23:44:13.060663 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m23:44:13.133203 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:13.137476 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 23:44:12.482938 => 23:44:13.136890
[0m23:44:13.138579 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m23:44:13.140882 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093b8690>]}
[0m23:44:13.142282 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.66s]
[0m23:44:13.143921 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m23:44:13.144881 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m23:44:13.146039 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m23:44:13.147593 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m23:44:13.148180 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m23:44:13.154016 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.156321 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 23:44:13.148623 => 23:44:13.156089
[0m23:44:13.156799 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m23:44:13.162332 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.163840 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.164320 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m23:44:13.164675 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:13.423998 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:13.425727 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.427129 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m23:44:13.683516 [debug] [Thread-1 (]: SQL status: SELECT 57027 in 0.0 seconds
[0m23:44:13.695486 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.696477 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m23:44:13.728937 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:13.738148 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.739339 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m23:44:13.772861 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:13.779572 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m23:44:13.780682 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.781740 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m23:44:13.814591 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:13.822676 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m23:44:13.823767 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m23:44:13.873719 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:13.877948 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 23:44:13.157122 => 23:44:13.877217
[0m23:44:13.879473 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m23:44:13.882238 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090d7c10>]}
[0m23:44:13.883810 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 57027[0m in 0.73s]
[0m23:44:13.885240 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m23:44:13.886187 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m23:44:13.887519 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m23:44:13.888931 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m23:44:13.889605 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m23:44:13.894646 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:13.896141 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 23:44:13.890026 => 23:44:13.895914
[0m23:44:13.896608 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m23:44:13.902163 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:13.903332 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:13.903711 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m23:44:13.904071 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:14.212092 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:14.213752 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.214949 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m23:44:14.255284 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:44:14.267336 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.268728 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m23:44:14.306474 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:14.312175 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m23:44:14.313318 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.314327 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m23:44:14.352132 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:14.360368 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m23:44:14.361286 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m23:44:14.399618 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:44:14.404824 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 23:44:13.896911 => 23:44:14.404186
[0m23:44:14.406059 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m23:44:14.408914 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10940fd90>]}
[0m23:44:14.410668 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.52s]
[0m23:44:14.412583 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m23:44:14.413621 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m23:44:14.414771 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m23:44:14.416423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m23:44:14.417215 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m23:44:14.424105 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.425663 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 23:44:14.417794 => 23:44:14.425393
[0m23:44:14.426188 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m23:44:14.436370 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.437197 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.437540 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m23:44:14.437815 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:14.727179 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:14.729037 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.730352 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m23:44:14.829861 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m23:44:14.840809 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.841600 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m23:44:14.874388 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:14.884666 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.885591 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m23:44:14.917305 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:14.924730 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m23:44:14.925895 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.926942 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m23:44:14.958110 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:14.967006 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m23:44:14.968195 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m23:44:15.019640 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:15.024063 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 23:44:14.426540 => 23:44:15.023450
[0m23:44:15.025181 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m23:44:15.027918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2340448f-a362-4287-85d2-357a2b2cf434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10943a290>]}
[0m23:44:15.029594 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.61s]
[0m23:44:15.031143 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m23:44:15.034446 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:15.034984 [debug] [MainThread]: On master: BEGIN
[0m23:44:15.035425 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:44:15.296997 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:15.298484 [debug] [MainThread]: On master: COMMIT
[0m23:44:15.299423 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:15.300272 [debug] [MainThread]: On master: COMMIT
[0m23:44:15.331054 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:44:15.332354 [debug] [MainThread]: On master: Close
[0m23:44:15.335144 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:44:15.336116 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m23:44:15.337226 [info ] [MainThread]: 
[0m23:44:15.338402 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 41.29 seconds (41.29s).
[0m23:44:15.345108 [debug] [MainThread]: Command end result
[0m23:44:15.363738 [info ] [MainThread]: 
[0m23:44:15.364593 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:44:15.364831 [info ] [MainThread]: 
[0m23:44:15.365052 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m23:44:15.365499 [debug] [MainThread]: Command `dbt run` succeeded at 23:44:15.365433 after 42.23 seconds
[0m23:44:15.365799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ce3fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cecfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ced210>]}
[0m23:44:15.366008 [debug] [MainThread]: Flushing usage events
[0m23:44:45.980610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112684c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11268aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11268ba90>]}


============================== 23:44:45.982065 | 14011815-505d-47bb-88d8-260bdfa8c389 ==============================
[0m23:44:45.982065 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:44:45.982378 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/danila/.dbt', 'printer_width': '80', 'log_format': 'default', 'write_json': 'True', 'debug': 'False', 'fail_fast': 'False', 'partial_parse': 'True', 'no_print': 'None', 'cache_selected_only': 'False', 'quiet': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'target_path': 'None', 'version_check': 'True'}
[0m23:44:46.011897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126ad290>]}
[0m23:44:46.017998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d9550>]}
[0m23:44:46.018441 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:44:46.028954 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:44:46.064062 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:44:46.064257 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:44:46.064599 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m23:44:46.067022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b0d790>]}
[0m23:44:46.070846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129f9e90>]}
[0m23:44:46.071005 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:44:46.071154 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e4150>]}
[0m23:44:46.071762 [info ] [MainThread]: 
[0m23:44:46.072088 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:44:46.072539 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:44:46.077149 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:44:46.077370 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:44:46.077505 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:44:46.418421 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m23:44:46.420258 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:44:46.422359 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:44:46.427497 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:44:46.427748 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:44:46.427944 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:44:46.681047 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:44:46.682253 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:44:46.682843 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:44:46.717162 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m23:44:46.721669 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:44:46.752713 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:44:46.768378 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:46.768894 [debug] [MainThread]: On master: BEGIN
[0m23:44:46.769252 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:44:47.096009 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:47.096921 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:47.097664 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:44:47.148321 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m23:44:47.155656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129aa910>]}
[0m23:44:47.156331 [debug] [MainThread]: On master: ROLLBACK
[0m23:44:47.195839 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:47.196864 [debug] [MainThread]: On master: BEGIN
[0m23:44:47.275610 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:47.276537 [debug] [MainThread]: On master: COMMIT
[0m23:44:47.276905 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:47.277219 [debug] [MainThread]: On master: COMMIT
[0m23:44:47.317420 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:44:47.318402 [debug] [MainThread]: On master: Close
[0m23:44:47.320489 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:44:47.321263 [info ] [MainThread]: 
[0m23:44:47.330072 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:44:47.330866 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:44:47.332153 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m23:44:47.332632 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:44:47.352592 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.353272 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:44:47.333242 => 23:44:47.353106
[0m23:44:47.353546 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:44:47.373303 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.373764 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.373934 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:44:47.374091 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:44:47.637463 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:44:47.639093 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:47.640500 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m23:44:52.667403 [debug] [Thread-1 (]: SQL status: SELECT 45919 in 5.0 seconds
[0m23:44:52.680321 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.680931 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:44:52.713135 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:52.718520 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.719156 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:44:52.750613 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:44:52.763786 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:52.763996 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.764140 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:44:52.795715 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:44:52.800400 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:44:52.800655 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:44:52.847173 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:44:52.848480 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:44:47.353700 => 23:44:52.848302
[0m23:44:52.848808 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:44:52.849578 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '14011815-505d-47bb-88d8-260bdfa8c389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c59650>]}
[0m23:44:52.850107 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45919[0m in 5.52s]
[0m23:44:52.850684 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:44:52.851925 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:52.852270 [debug] [MainThread]: On master: BEGIN
[0m23:44:52.852522 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:44:53.241372 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:44:53.242961 [debug] [MainThread]: On master: COMMIT
[0m23:44:53.243915 [debug] [MainThread]: Using postgres connection "master"
[0m23:44:53.244809 [debug] [MainThread]: On master: COMMIT
[0m23:44:53.288417 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:44:53.289773 [debug] [MainThread]: On master: Close
[0m23:44:53.292565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:44:53.293030 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m23:44:53.293485 [info ] [MainThread]: 
[0m23:44:53.294025 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 7.22 seconds (7.22s).
[0m23:44:53.294940 [debug] [MainThread]: Command end result
[0m23:44:53.305618 [info ] [MainThread]: 
[0m23:44:53.306156 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:44:53.306462 [info ] [MainThread]: 
[0m23:44:53.306808 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m23:44:53.307403 [debug] [MainThread]: Command `dbt run` succeeded at 23:44:53.307305 after 7.34 seconds
[0m23:44:53.307792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105410410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10540e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10540e750>]}
[0m23:44:53.308134 [debug] [MainThread]: Flushing usage events
[0m23:46:35.326237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067863d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106785650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106790c90>]}


============================== 23:46:35.327903 | c4b63de9-26c5-4c60-885c-dfc8c3678f3e ==============================
[0m23:46:35.327903 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:46:35.328263 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'version_check': 'True', 'partial_parse': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'target_path': 'None', 'log_format': 'default', 'debug': 'False', 'fail_fast': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error': 'None', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m23:46:35.329665 [error] [MainThread]: Encountered an error:
Runtime Error
  The profile 'piter' does not have a target named 'prod'. The valid target names for this profile are:
   - dev
[0m23:46:35.329968 [debug] [MainThread]: Command `dbt ls` failed at 23:46:35.329908 after 0.01 seconds
[0m23:46:35.330119 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106788090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106788110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106784710>]}
[0m23:46:35.330265 [debug] [MainThread]: Flushing usage events
[0m23:58:09.604431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bea350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106be9650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf4c50>]}


============================== 23:58:09.606101 | 83c1c129-8616-493c-93cc-d402a7bd7b86 ==============================
[0m23:58:09.606101 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:58:09.606453 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'introspect': 'True', 'use_colors': 'True', 'printer_width': '80', 'partial_parse': 'True', 'version_check': 'True', 'quiet': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'log_format': 'default'}
[0m23:58:09.639408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c0e9d0>]}
[0m23:58:09.645598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070612d0>]}
[0m23:58:09.646057 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:58:09.657071 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m23:58:09.678460 [info ] [MainThread]: Unable to do partial parsing because of a version mismatch
[0m23:58:09.678751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10594ebd0>]}
[0m23:58:10.005747 [debug] [MainThread]: 1699: static parser successfully parsed example/test.sql
[0m23:58:10.010666 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m23:58:10.012484 [debug] [MainThread]: 1603: static parser failed on example/brand_performance_replacement.sql
[0m23:58:10.015332 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/brand_performance_replacement.sql
[0m23:58:10.015869 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m23:58:10.017033 [debug] [MainThread]: 1699: static parser successfully parsed users/deals_dim.sql
[0m23:58:10.018249 [debug] [MainThread]: 1699: static parser successfully parsed users/campaign_dim.sql
[0m23:58:10.019518 [debug] [MainThread]: 1699: static parser successfully parsed users/brand_comparison_fi.sql
[0m23:58:10.020654 [debug] [MainThread]: 1699: static parser successfully parsed users/daily_campaign_fct.sql
[0m23:58:10.021824 [debug] [MainThread]: 1699: static parser successfully parsed users/test_write.sql
[0m23:58:10.022907 [debug] [MainThread]: 1699: static parser successfully parsed users/outclicks_fct.sql
[0m23:58:10.023999 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m23:58:10.030641 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m23:58:10.031504 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m23:58:10.033681 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m23:58:10.074041 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m23:58:10.076026 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071a9950>]}
[0m23:58:10.081368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10723bbd0>]}
[0m23:58:10.081560 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:58:10.081722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '83c1c129-8616-493c-93cc-d402a7bd7b86', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070cee10>]}
[0m23:58:10.082407 [debug] [MainThread]: Command `dbt ls` succeeded at 23:58:10.082343 after 0.49 seconds
[0m23:58:10.082560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10727ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d18390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102d166d0>]}
[0m23:58:10.082684 [debug] [MainThread]: Flushing usage events
[0m00:00:24.539998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10489bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048b1650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048bb190>]}


============================== 00:00:24.541672 | 737f4946-080e-455a-b452-9b7e0144f265 ==============================
[0m00:00:24.541672 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:00:24.541981 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'quiet': 'False', 'indirect_selection': 'eager', 'write_json': 'True', 'target_path': 'None', 'introspect': 'True', 'fail_fast': 'False', 'warn_error': 'None', 'version_check': 'True', 'partial_parse': 'True', 'no_print': 'None', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'use_colors': 'True'}
[0m00:00:24.574761 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10489b690>]}
[0m00:00:24.580922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d3d290>]}
[0m00:00:24.581370 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:00:24.593051 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:00:24.616141 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m00:00:24.616425 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m00:00:24.616545 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043fc790>]}
[0m00:00:24.935681 [debug] [MainThread]: 1699: static parser successfully parsed example/test.sql
[0m00:00:24.940608 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m00:00:24.942327 [debug] [MainThread]: 1603: static parser failed on example/brand_performance_replacement.sql
[0m00:00:24.945364 [debug] [MainThread]: 1602: parser fallback to jinja rendering on example/brand_performance_replacement.sql
[0m00:00:24.945927 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m00:00:24.947050 [debug] [MainThread]: 1699: static parser successfully parsed users/deals_dim.sql
[0m00:00:24.948308 [debug] [MainThread]: 1699: static parser successfully parsed users/campaign_dim.sql
[0m00:00:24.949712 [debug] [MainThread]: 1699: static parser successfully parsed users/brand_comparison_fi.sql
[0m00:00:24.951106 [debug] [MainThread]: 1699: static parser successfully parsed users/daily_campaign_fct.sql
[0m00:00:24.952262 [debug] [MainThread]: 1699: static parser successfully parsed users/test_write.sql
[0m00:00:24.953364 [debug] [MainThread]: 1699: static parser successfully parsed users/outclicks_fct.sql
[0m00:00:24.954459 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m00:00:24.961178 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m00:00:24.962072 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m00:00:24.964399 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m00:00:25.007124 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m00:00:25.009140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea6d10>]}
[0m00:00:25.013214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048b04d0>]}
[0m00:00:25.013384 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m00:00:25.013540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101d63b90>]}
[0m00:00:25.014497 [info ] [MainThread]: 
[0m00:00:25.014817 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:00:25.015366 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:00:25.019591 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:00:25.019761 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:00:25.019876 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:25.458051 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:00:25.463224 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:00:25.468768 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:00:25.478394 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:00:25.478871 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:00:25.479236 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:00:25.795632 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:00:25.797552 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:00:25.798547 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:00:25.841637 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m00:00:25.843049 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:00:25.881519 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:00:25.890145 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:25.890508 [debug] [MainThread]: On master: BEGIN
[0m00:00:25.890800 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:00:26.198262 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:00:26.198575 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:26.198833 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:00:26.245828 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m00:00:26.247957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d02990>]}
[0m00:00:26.248372 [debug] [MainThread]: On master: ROLLBACK
[0m00:00:26.300997 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:26.301711 [debug] [MainThread]: On master: BEGIN
[0m00:00:26.376536 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:00:26.376886 [debug] [MainThread]: On master: COMMIT
[0m00:00:26.377061 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:26.377211 [debug] [MainThread]: On master: COMMIT
[0m00:00:26.413241 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:00:26.413476 [debug] [MainThread]: On master: Close
[0m00:00:26.414126 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:00:26.414418 [info ] [MainThread]: 
[0m00:00:26.419050 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m00:00:26.419441 [info ] [Thread-1 (]: 1 of 12 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m00:00:26.419984 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m00:00:26.420243 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m00:00:26.427386 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.428304 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 00:00:26.420396 => 00:00:26.428153
[0m00:00:26.428531 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m00:00:26.450089 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.451115 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.451299 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m00:00:26.451447 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:26.707423 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:26.707893 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:26.708634 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m00:00:48.622716 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 22.0 seconds
[0m00:00:48.636814 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.637612 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m00:00:48.669924 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:48.676974 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.677509 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m00:00:48.708977 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:48.736398 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:00:48.736931 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.737214 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:00:48.767929 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:48.773626 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:00:48.773963 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m00:00:48.818354 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:48.821722 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 00:00:26.428653 => 00:00:48.821330
[0m00:00:48.822405 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m00:00:48.824261 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e05410>]}
[0m00:00:48.825457 [info ] [Thread-1 (]: 1 of 12 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 22.40s]
[0m00:00:48.826536 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m00:00:48.827165 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m00:00:48.828029 [info ] [Thread-1 (]: 2 of 12 START sql table model danila.campaign_dim .............................. [RUN]
[0m00:00:48.828905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m00:00:48.829279 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m00:00:48.832537 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m00:00:48.834325 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 00:00:48.829510 => 00:00:48.834111
[0m00:00:48.834659 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m00:00:48.838750 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m00:00:48.839402 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:48.839653 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m00:00:48.839887 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:49.256343 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:49.257460 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.258044 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:00:49.328619 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:00:49.337925 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.338302 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m00:00:49.382661 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.385413 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.385721 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m00:00:49.430340 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.434557 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:00:49.435154 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.435644 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:00:49.480035 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:49.485509 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:00:49.486157 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m00:00:49.550997 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:49.555585 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 00:00:48.834853 => 00:00:49.554970
[0m00:00:49.556749 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m00:00:49.559590 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e06790>]}
[0m00:00:49.560917 [info ] [Thread-1 (]: 2 of 12 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.73s]
[0m00:00:49.561976 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m00:00:49.562623 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m00:00:49.563357 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m00:00:49.564282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m00:00:49.564723 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m00:00:49.571969 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.573058 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 00:00:49.564998 => 00:00:49.572838
[0m00:00:49.573397 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m00:00:49.577725 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.578418 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.578682 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m00:00:49.578927 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:49.860969 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:49.861264 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.861467 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:00:49.914161 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:00:49.916322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.916544 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m00:00:49.950734 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.953195 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.953497 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m00:00:49.986926 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:49.989088 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:00:49.989432 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:49.989746 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:00:50.023735 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:50.028790 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:00:50.029377 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m00:00:50.085354 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:50.090144 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 00:00:49.573599 => 00:00:50.089510
[0m00:00:50.091083 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m00:00:50.092580 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd7990>]}
[0m00:00:50.093386 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.53s]
[0m00:00:50.094158 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m00:00:50.094681 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m00:00:50.095495 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.deals_dim ................................. [RUN]
[0m00:00:50.096483 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m00:00:50.096874 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m00:00:50.100534 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m00:00:50.101404 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 00:00:50.097127 => 00:00:50.101216
[0m00:00:50.101709 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m00:00:50.105717 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m00:00:50.106370 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.106630 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m00:00:50.106878 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:50.364495 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:50.366142 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.367196 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m00:00:50.405690 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m00:00:50.413175 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.413845 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m00:00:50.445539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:50.450377 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.450793 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m00:00:50.482332 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:50.485434 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:00:50.485919 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.486193 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:00:50.516746 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:50.522031 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:00:50.522787 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m00:00:50.571675 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:50.575557 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 00:00:50.101902 => 00:00:50.575166
[0m00:00:50.576264 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m00:00:50.577989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fb8410>]}
[0m00:00:50.579002 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.48s]
[0m00:00:50.580042 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m00:00:50.580719 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m00:00:50.581667 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m00:00:50.582642 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m00:00:50.583050 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m00:00:50.587666 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.588923 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 00:00:50.583318 => 00:00:50.588606
[0m00:00:50.589360 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m00:00:50.594571 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.595522 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.595853 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m00:00:50.596140 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:50.925121 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:50.927238 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.928754 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m00:00:50.971147 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m00:00:50.981598 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:50.982162 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m00:00:51.023441 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:51.029940 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:51.030452 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m00:00:51.070551 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:51.074976 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:00:51.075478 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:51.075914 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:00:51.116668 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:51.122861 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:00:51.123372 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m00:00:51.179370 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:51.183358 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 00:00:50.589595 => 00:00:51.183007
[0m00:00:51.184036 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m00:00:51.185803 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f1c4d0>]}
[0m00:00:51.186800 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.60s]
[0m00:00:51.187879 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m00:00:51.188598 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:51.189693 [info ] [Thread-1 (]: 6 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m00:00:51.190863 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:00:51.191345 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:51.198418 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.199669 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:00:51.191671 => 00:00:51.199415
[0m00:00:51.200084 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:51.204579 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.205157 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.205446 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:00:51.205724 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:51.482446 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:51.484303 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:51.486262 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:00:59.252308 [debug] [Thread-1 (]: SQL status: SELECT 153711 in 8.0 seconds
[0m00:00:59.260208 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.260590 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:00:59.294663 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:59.299591 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.300078 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:00:59.333778 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:00:59.341196 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:00:59.342552 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.344059 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:00:59.377290 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:00:59.382446 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:00:59.383324 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:00:59.434223 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:00:59.438890 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:00:51.200333 => 00:00:59.438153
[0m00:00:59.440393 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:00:59.443172 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fc2290>]}
[0m00:00:59.444535 [info ] [Thread-1 (]: 6 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153711[0m in 8.25s]
[0m00:00:59.446013 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:00:59.446974 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:00:59.448162 [info ] [Thread-1 (]: 7 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m00:00:59.450013 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:00:59.450702 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:00:59.461113 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.463481 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:00:59.451152 => 00:00:59.463226
[0m00:00:59.463928 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:00:59.469857 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.470746 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.471133 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:00:59.471467 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:00:59.822546 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:00:59.824525 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:00:59.826262 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m00:01:04.392964 [debug] [Thread-1 (]: SQL status: SELECT 45930 in 5.0 seconds
[0m00:01:04.404485 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.405854 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:01:04.443720 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:04.450774 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.452107 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:01:04.490836 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:04.501833 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:01:04.502632 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.503042 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:01:04.540110 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:04.548435 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:01:04.549797 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:01:04.602857 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:04.607585 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:00:59.464250 => 00:01:04.607013
[0m00:01:04.608846 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:01:04.611492 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e2e410>]}
[0m00:01:04.613231 [info ] [Thread-1 (]: 7 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45930[0m in 5.16s]
[0m00:01:04.615206 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:01:04.616466 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m00:01:04.617501 [info ] [Thread-1 (]: 8 of 12 START sql view model danila.test ....................................... [RUN]
[0m00:01:04.619334 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m00:01:04.620035 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m00:01:04.626646 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m00:01:04.628264 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 00:01:04.620512 => 00:01:04.627781
[0m00:01:04.628917 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m00:01:04.651319 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m00:01:04.653284 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.653636 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m00:01:04.653926 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:04.910598 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:04.911798 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.912446 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m00:01:04.948608 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:01:04.956113 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.956625 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m00:01:04.987799 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:04.995210 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:04.995643 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m00:01:05.026333 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:05.030333 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:01:05.030878 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:05.031415 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:01:05.062513 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:05.067358 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:01:05.067945 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m00:01:05.100004 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:01:05.104897 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 00:01:04.629264 => 00:01:05.104310
[0m00:01:05.106202 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m00:01:05.109071 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050400d0>]}
[0m00:01:05.110834 [info ] [Thread-1 (]: 8 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.49s]
[0m00:01:05.112676 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m00:01:05.113834 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m00:01:05.114821 [info ] [Thread-1 (]: 9 of 12 START sql table model danila.test_write ................................ [RUN]
[0m00:01:05.116245 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m00:01:05.117039 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m00:01:05.122169 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m00:01:05.123866 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 00:01:05.117560 => 00:01:05.123436
[0m00:01:05.124408 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m00:01:05.131051 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m00:01:05.132192 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.132676 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m00:01:05.133014 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:05.415052 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:05.416315 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.416798 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m00:01:05.451023 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:01:05.459597 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.460264 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m00:01:05.492042 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:05.494030 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.494250 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m00:01:05.525045 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:05.526667 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:01:05.526915 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.527107 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:01:05.558226 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:05.560585 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:01:05.560881 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m00:01:05.610356 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:05.613561 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 00:01:05.124743 => 00:01:05.613140
[0m00:01:05.614315 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m00:01:05.616242 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d7c9d0>]}
[0m00:01:05.617413 [info ] [Thread-1 (]: 9 of 12 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.50s]
[0m00:01:05.618574 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m00:01:05.619151 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m00:01:05.619838 [info ] [Thread-1 (]: 10 of 12 START sql table model danila.outclicks_fct ............................ [RUN]
[0m00:01:05.620896 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m00:01:05.621385 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m00:01:05.628243 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.629720 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 00:01:05.621700 => 00:01:05.629453
[0m00:01:05.630150 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m00:01:05.635254 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.635970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.636198 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m00:01:05.636388 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:05.894384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:05.895038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:05.895349 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m00:01:06.137705 [debug] [Thread-1 (]: SQL status: SELECT 57045 in 0.0 seconds
[0m00:01:06.147136 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.147955 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m00:01:06.179958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:06.188408 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.189277 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m00:01:06.220947 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:06.224772 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:01:06.225288 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.225549 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:01:06.256425 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:06.263244 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:01:06.264283 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m00:01:06.315870 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:06.320665 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 00:01:05.630416 => 00:01:06.320072
[0m00:01:06.321777 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m00:01:06.324327 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050299d0>]}
[0m00:01:06.326005 [info ] [Thread-1 (]: 10 of 12 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 57045[0m in 0.70s]
[0m00:01:06.327797 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m00:01:06.328794 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.330050 [info ] [Thread-1 (]: 11 of 12 START sql view model danila.my_second_dbt_model ....................... [RUN]
[0m00:01:06.331160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now model.campaign_perfomance.my_second_dbt_model)
[0m00:01:06.331551 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.338055 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.339428 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (compile): 00:01:06.332029 => 00:01:06.339114
[0m00:01:06.340009 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.346872 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.348006 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.348481 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: BEGIN
[0m00:01:06.348807 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:06.720876 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:06.722644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.724062 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */

  create view "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp"
    
    
  as (
    -- Use the `ref` function to select from other models

select *
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id = 1
  );
[0m00:01:06.760556 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:01:06.771617 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.772565 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
[0m00:01:06.804711 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:06.807836 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m00:01:06.808516 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.809087 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: COMMIT
[0m00:01:06.840667 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:06.849069 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_second_dbt_model"
[0m00:01:06.850197 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_second_dbt_model"} */
drop view if exists "deep-analysis-console"."danila"."my_second_dbt_model__dbt_backup" cascade
[0m00:01:06.881650 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:01:06.885074 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_second_dbt_model (execute): 00:01:06.340348 => 00:01:06.884749
[0m00:01:06.885734 [debug] [Thread-1 (]: On model.campaign_perfomance.my_second_dbt_model: Close
[0m00:01:06.887878 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e23a50>]}
[0m00:01:06.889567 [info ] [Thread-1 (]: 11 of 12 OK created sql view model danila.my_second_dbt_model .................. [[32mCREATE VIEW[0m in 0.56s]
[0m00:01:06.891187 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m00:01:06.892135 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m00:01:06.893201 [info ] [Thread-1 (]: 12 of 12 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m00:01:06.894721 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_second_dbt_model, now model.campaign_perfomance.brand_comparison_fi)
[0m00:01:06.895484 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m00:01:06.900800 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:06.902148 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 00:01:06.895937 => 00:01:06.901924
[0m00:01:06.902610 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m00:01:06.909635 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:06.911498 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:06.912128 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m00:01:06.912512 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:07.174128 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:01:07.175162 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.175773 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m00:01:07.237409 [debug] [Thread-1 (]: SQL status: SELECT 66 in 0.0 seconds
[0m00:01:07.248037 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.249436 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m00:01:07.281454 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:07.297030 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.297926 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m00:01:07.329028 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:01:07.336623 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:01:07.337461 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.338198 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:01:07.368962 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:01:07.376121 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:01:07.377232 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m00:01:07.426413 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:01:07.430656 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 00:01:06.902953 => 00:01:07.430078
[0m00:01:07.431789 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m00:01:07.433769 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '737f4946-080e-455a-b452-9b7e0144f265', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104230d50>]}
[0m00:01:07.434742 [info ] [Thread-1 (]: 12 of 12 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 66[0m in 0.54s]
[0m00:01:07.436318 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m00:01:07.439619 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:07.440177 [debug] [MainThread]: On master: BEGIN
[0m00:01:07.440635 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:01:07.793563 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:01:07.795160 [debug] [MainThread]: On master: COMMIT
[0m00:01:07.796117 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:07.796970 [debug] [MainThread]: On master: COMMIT
[0m00:01:07.839882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:01:07.840995 [debug] [MainThread]: On master: Close
[0m00:01:07.842936 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:01:07.843840 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m00:01:07.844601 [info ] [MainThread]: 
[0m00:01:07.845464 [info ] [MainThread]: Finished running 10 table models, 2 view models in 0 hours 0 minutes and 42.83 seconds (42.83s).
[0m00:01:07.851498 [debug] [MainThread]: Command end result
[0m00:01:07.870779 [info ] [MainThread]: 
[0m00:01:07.871748 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:01:07.872557 [info ] [MainThread]: 
[0m00:01:07.873160 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m00:01:07.873854 [debug] [MainThread]: Command `dbt run` succeeded at 00:01:07.873727 after 43.34 seconds
[0m00:01:07.874191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009e02d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ece510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1009de5d0>]}
[0m00:01:07.874490 [debug] [MainThread]: Flushing usage events
[0m00:04:56.774465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c5550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075d5650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075dfa10>]}


============================== 00:04:56.776182 | 83b3cb88-fbe7-4fe8-981e-5d1922bed09f ==============================
[0m00:04:56.776182 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:04:56.776495 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'fail_fast': 'False', 'log_format': 'default', 'use_experimental_parser': 'False', 'version_check': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'static_parser': 'True', 'use_colors': 'True', 'write_json': 'True', 'quiet': 'False'}
[0m00:04:56.787075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '83b3cb88-fbe7-4fe8-981e-5d1922bed09f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075e74d0>]}
[0m00:04:56.787765 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-kdq9lt81'
[0m00:04:56.787972 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m00:04:56.874332 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m00:04:56.875320 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m00:04:56.921357 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m00:04:56.925950 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m00:04:57.503125 [info ] [MainThread]: Installed from version 1.1.1
[0m00:04:57.503394 [info ] [MainThread]: Up to date!
[0m00:04:57.503612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '83b3cb88-fbe7-4fe8-981e-5d1922bed09f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c5d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c7210>]}
[0m00:04:57.504133 [debug] [MainThread]: Command `dbt deps` succeeded at 00:04:57.504065 after 0.74 seconds
[0m00:04:57.504296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064d7490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10370c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10370a5d0>]}
[0m00:04:57.504444 [debug] [MainThread]: Flushing usage events
[0m00:22:03.312346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062846d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107395650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107397990>]}


============================== 00:22:03.314067 | 13bab066-a2b1-4068-8ba7-7f4e0b831aa4 ==============================
[0m00:22:03.314067 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:22:03.314371 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'target_path': 'None', 'write_json': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'warn_error': 'None', 'fail_fast': 'False', 'no_print': 'None', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'printer_width': '80', 'introspect': 'True', 'indirect_selection': 'eager', 'quiet': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'debug': 'False'}
[0m00:22:03.348551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107803150>]}
[0m00:22:03.354713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073ac750>]}
[0m00:22:03.355161 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:22:03.367017 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:22:03.409632 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:22:03.409827 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:22:03.410164 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m00:22:03.412599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10739d250>]}
[0m00:22:03.417552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10782d2d0>]}
[0m00:22:03.417787 [info ] [MainThread]: Found 12 models, 6 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m00:22:03.418878 [info ] [MainThread]: 
[0m00:22:03.419260 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:22:03.419937 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:22:03.424623 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:22:03.424777 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:22:03.424883 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:22:03.840710 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:22:03.844544 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:22:03.848973 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:22:03.857849 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:22:03.858326 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:22:03.858638 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:22:04.126514 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:22:04.128154 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:22:04.129345 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:22:04.166324 [debug] [ThreadPool]: SQL status: SELECT 20 in 0.0 seconds
[0m00:22:04.171139 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:22:04.202385 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:22:04.218081 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.218543 [debug] [MainThread]: On master: BEGIN
[0m00:22:04.218902 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:22:04.480637 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:22:04.481451 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.482081 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:22:04.523985 [debug] [MainThread]: SQL status: SELECT 42 in 0.0 seconds
[0m00:22:04.529649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079d5d10>]}
[0m00:22:04.530654 [debug] [MainThread]: On master: ROLLBACK
[0m00:22:04.561757 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.563174 [debug] [MainThread]: On master: BEGIN
[0m00:22:04.625318 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:22:04.625635 [debug] [MainThread]: On master: COMMIT
[0m00:22:04.625810 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:04.625959 [debug] [MainThread]: On master: COMMIT
[0m00:22:04.656968 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:22:04.657198 [debug] [MainThread]: On master: Close
[0m00:22:04.657756 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:22:04.658018 [info ] [MainThread]: 
[0m00:22:04.661280 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_performance_replacement
[0m00:22:04.661620 [info ] [Thread-1 (]: 1 of 18 START sql table model danila.brand_performance_replacement ............. [RUN]
[0m00:22:04.662083 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.brand_performance_replacement)
[0m00:22:04.662299 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_performance_replacement
[0m00:22:04.669045 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:04.669522 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (compile): 00:22:04.662436 => 00:22:04.669401
[0m00:22:04.669717 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_performance_replacement
[0m00:22:04.690272 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:04.691222 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:04.691401 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: BEGIN
[0m00:22:04.691570 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:05.013784 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:05.014392 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:05.015257 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH outclick_cost AS ( 
select 
sum(d.cost)/sum(d.unique_outclicks) as unique_outclick_cost
from (
/*outclicks aggregated data from matomo tables*/
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND date(timestamp - interval '2 hours')>'2024-02-16'
    group by campaign_name, campaignname, date, brand_name, country_code
    union all
    select 
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        campaign as ga_campaign_name, 
        NULL as brand_name, NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where 
        campaign_names_mapping.campaign_vertical='casino'
        and day >'2024-02-16'
    group by day, country_code, campaign_name, ga_campaign_name
) d
)

select 
    d.country_code,
    d.brand_name, 
    'https://clickstorm.cashstormcreative.ee/dashboard/53-brand-performance-daily-details?date=past20days&country_code=' || d.country_code || '&brand=' || d.brand_name || '' as Details,
    coalesce(sum(d.outclicks),0) as outclicks, 
    sum(d.unique_outclicks) as unique_outclicks, 
    sum(d.signups) as signups, 
    sum(d.cpa_count) as FTDs, 
    sum(d.gtee_commissions) as gtee_commissions, 
    avg(d.avg_deposit_amount) as avg_deposit_amount, 
    avg(d.avg_list_position) as avg_position,
    (sum(d.signups)/NULLIF(sum(d.unique_outclicks),0)*100)  as signup_rate,
    (sum(d.cpa_count)/NULLIF(sum(d.unique_outclicks),0)*100) as conversion_rate,
    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks) 
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))
    END as EPC,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 
            THEN (((sum(d.cpa_commissions)+sum(d.gtee_commissions)+sum(d.revshare_commissions))/sum(d.unique_outclicks))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
        ELSE ((sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0))*100/NULLIF((select unique_outclick_cost from outclick_cost),0))-100
    END as ROI,

    CASE 
        WHEN sum(d.gtee_count)<>0 or sum(d.revshare_commissions)<>0 THEN (sum(d.cpa_commissions)/NULLIF(sum(unique_outclicks),0)) 
        ELSE NULL
    END as EPC_excl_gtee_rs,
    (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0)) as avg_commission,
    CASE 
        WHEN sum(d.gtee_commissions)>0 THEN ((sum(d.cpa_commissions)+sum(d.gtee_commissions))/NULLIF(sum(d.cpa_count),0))   
        ELSE (sum(d.cpa_commissions)/NULLIF(sum(d.cpa_count),0))
    END as avg_commission_incl_gtee,
    nullif(sum(d.revshare_commissions),0) as revshare_commissions
from (
/*outclicks aggregated data from matomo tables*/
    select date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2024-02-16'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, NULL as unique_outclicks, NULL as avg_list_position, NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where right(brand_name,6)<>'sports'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, brand_name
) d
group by d.country_code, d.brand_name
having sum(d.outclicks)>0 or sum(d.signups)>0  or sum(d.cpa_count)>0 or sum(d.gtee_count)>0 or sum(d.revshare_commissions)<>0
order by EPC desc NULLS last, FTDs desc NULLS last, unique_outclicks desc NULLS last, d.country_code
  );
  
[0m00:22:30.031321 [debug] [Thread-1 (]: SQL status: SELECT 2112 in 25.0 seconds
[0m00:22:30.045425 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.046024 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement" rename to "brand_performance_replacement__dbt_backup"
[0m00:22:30.086183 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.093045 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.093644 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
alter table "deep-analysis-console"."danila"."brand_performance_replacement__dbt_tmp" rename to "brand_performance_replacement"
[0m00:22:30.134014 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.161455 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:22:30.161900 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.162181 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: COMMIT
[0m00:22:30.201453 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:30.210792 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_performance_replacement"
[0m00:22:30.211175 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_performance_replacement"} */
drop table if exists "deep-analysis-console"."danila"."brand_performance_replacement__dbt_backup" cascade
[0m00:22:30.263357 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:30.266881 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_performance_replacement (execute): 00:22:04.669839 => 00:22:30.266496
[0m00:22:30.267448 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_performance_replacement: Close
[0m00:22:30.268989 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078f0c90>]}
[0m00:22:30.269894 [info ] [Thread-1 (]: 1 of 18 OK created sql table model danila.brand_performance_replacement ........ [[32mSELECT 2112[0m in 25.61s]
[0m00:22:30.270708 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_performance_replacement
[0m00:22:30.271216 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.campaign_dim
[0m00:22:30.271864 [info ] [Thread-1 (]: 2 of 18 START sql table model danila.campaign_dim .............................. [RUN]
[0m00:22:30.272654 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.brand_performance_replacement, now model.campaign_perfomance.campaign_dim)
[0m00:22:30.273007 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.campaign_dim
[0m00:22:30.277109 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.campaign_dim"
[0m00:22:30.278259 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (compile): 00:22:30.273214 => 00:22:30.278023
[0m00:22:30.278675 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.campaign_dim
[0m00:22:30.283559 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.campaign_dim"
[0m00:22:30.284470 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.284782 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: BEGIN
[0m00:22:30.285034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:30.640694 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:30.642315 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.643537 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    id as id
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:22:30.689330 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:22:30.698276 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.698840 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim" rename to "campaign_dim__dbt_backup"
[0m00:22:30.731282 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.736265 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.736819 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
alter table "deep-analysis-console"."danila"."campaign_dim__dbt_tmp" rename to "campaign_dim"
[0m00:22:30.768240 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:30.773070 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:22:30.773690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.774222 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: COMMIT
[0m00:22:30.805703 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:30.814487 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.campaign_dim"
[0m00:22:30.815513 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.campaign_dim"} */
drop table if exists "deep-analysis-console"."danila"."campaign_dim__dbt_backup" cascade
[0m00:22:30.863187 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:30.865614 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.campaign_dim (execute): 00:22:30.278876 => 00:22:30.865357
[0m00:22:30.866127 [debug] [Thread-1 (]: On model.campaign_perfomance.campaign_dim: Close
[0m00:22:30.867429 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e9c90>]}
[0m00:22:30.868320 [info ] [Thread-1 (]: 2 of 18 OK created sql table model danila.campaign_dim ......................... [[32mSELECT 1562[0m in 0.59s]
[0m00:22:30.869220 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.campaign_dim
[0m00:22:30.869717 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.daily_campaign_fct
[0m00:22:30.870311 [info ] [Thread-1 (]: 3 of 18 START sql table model danila.daily_campaign_fct ........................ [RUN]
[0m00:22:30.871207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.campaign_dim, now model.campaign_perfomance.daily_campaign_fct)
[0m00:22:30.871591 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.daily_campaign_fct
[0m00:22:30.874480 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:30.876317 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (compile): 00:22:30.871839 => 00:22:30.876115
[0m00:22:30.876656 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.daily_campaign_fct
[0m00:22:30.880670 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:30.881401 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:30.881686 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: BEGIN
[0m00:22:30.881937 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:31.140149 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:31.141913 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.143107 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH records_gap_campaigns AS (
    SELECT * FROM "deep-analysis-console"."console"."records_gap_campaigns"
)

select 
    campaign as ga_campaign_id,
    day as date, 
    clicks as clicks, 
    cost as ad_costs, 
    budget as budget
from records_gap_campaigns
where day>'2024-04-01'
  );
  
[0m00:22:31.193267 [debug] [Thread-1 (]: SQL status: SELECT 1562 in 0.0 seconds
[0m00:22:31.200691 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.201374 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct" rename to "daily_campaign_fct__dbt_backup"
[0m00:22:31.233169 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.242084 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.242629 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
alter table "deep-analysis-console"."danila"."daily_campaign_fct__dbt_tmp" rename to "daily_campaign_fct"
[0m00:22:31.274032 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.276897 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:22:31.277276 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.277608 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: COMMIT
[0m00:22:31.308229 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:31.309804 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.daily_campaign_fct"
[0m00:22:31.309991 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.daily_campaign_fct"} */
drop table if exists "deep-analysis-console"."danila"."daily_campaign_fct__dbt_backup" cascade
[0m00:22:31.361451 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:31.362518 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.daily_campaign_fct (execute): 00:22:30.876861 => 00:22:31.362377
[0m00:22:31.362758 [debug] [Thread-1 (]: On model.campaign_perfomance.daily_campaign_fct: Close
[0m00:22:31.363331 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a7a4d0>]}
[0m00:22:31.363695 [info ] [Thread-1 (]: 3 of 18 OK created sql table model danila.daily_campaign_fct ................... [[32mSELECT 1562[0m in 0.49s]
[0m00:22:31.364111 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.daily_campaign_fct
[0m00:22:31.364377 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dim
[0m00:22:31.364642 [info ] [Thread-1 (]: 4 of 18 START sql table model danila.deals_dim ................................. [RUN]
[0m00:22:31.365212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.daily_campaign_fct, now model.campaign_perfomance.deals_dim)
[0m00:22:31.365475 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dim
[0m00:22:31.367551 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dim"
[0m00:22:31.368138 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (compile): 00:22:31.365634 => 00:22:31.368006
[0m00:22:31.368374 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dim
[0m00:22:31.372101 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dim"
[0m00:22:31.372514 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.372704 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: BEGIN
[0m00:22:31.372887 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:31.678822 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:31.680361 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.681043 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */

  
    

  create  table "deep-analysis-console"."danila"."deals_dim__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


WITH deals AS (
    SELECT * FROM "deep-analysis-console"."console"."deals"
)

select 
    id as id,
    geo as geo_id,
    created_at as created_at_cet, 
    deal_start_date as started_at, 
    deal_end_date as ended_at,
    deal_cpa as cpa, 
    deal_gtee as deal_guarantee, 
    deal_revshare as deal_revenue_share,
    --deal_guarantee_started_at, 
    --deal_guarantee_ended_at, 
    --campaign_group,
    gap_campaign_name as ga_campaign_id 
    --vertical, 
    --traffic_source
from deals
where created_at>'2024-04-01'
  );
  
[0m00:22:31.724324 [debug] [Thread-1 (]: SQL status: SELECT 168 in 0.0 seconds
[0m00:22:31.731943 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.732535 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim" rename to "deals_dim__dbt_backup"
[0m00:22:31.769997 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.776587 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.777093 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
alter table "deep-analysis-console"."danila"."deals_dim__dbt_tmp" rename to "deals_dim"
[0m00:22:31.814135 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:31.818819 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:22:31.819412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.819932 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: COMMIT
[0m00:22:31.857283 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:31.864954 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dim"
[0m00:22:31.865587 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dim"} */
drop table if exists "deep-analysis-console"."danila"."deals_dim__dbt_backup" cascade
[0m00:22:31.920279 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:31.923382 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dim (execute): 00:22:31.368517 => 00:22:31.922996
[0m00:22:31.924013 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dim: Close
[0m00:22:31.925711 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107868fd0>]}
[0m00:22:31.926747 [info ] [Thread-1 (]: 4 of 18 OK created sql table model danila.deals_dim ............................ [[32mSELECT 168[0m in 0.56s]
[0m00:22:31.927787 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dim
[0m00:22:31.928764 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_first_dbt_model
[0m00:22:31.929778 [info ] [Thread-1 (]: 5 of 18 START sql table model danila.my_first_dbt_model ........................ [RUN]
[0m00:22:31.930664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dim, now model.campaign_perfomance.my_first_dbt_model)
[0m00:22:31.931083 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.my_first_dbt_model
[0m00:22:31.935736 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:31.936796 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (compile): 00:22:31.931355 => 00:22:31.936550
[0m00:22:31.937200 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.my_first_dbt_model
[0m00:22:31.942649 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:31.943535 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:31.943845 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: BEGIN
[0m00:22:31.944134 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:32.204335 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:32.206446 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.207520 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */

  
    

  create  table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp"
  
  
    as
  
  (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
[0m00:22:32.242777 [debug] [Thread-1 (]: SQL status: SELECT 2 in 0.0 seconds
[0m00:22:32.251038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.251559 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
[0m00:22:32.283335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:32.288669 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.289228 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
alter table "deep-analysis-console"."danila"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
[0m00:22:32.321087 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:32.326314 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:22:32.327153 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.327756 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: COMMIT
[0m00:22:32.360316 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:32.369038 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.my_first_dbt_model"
[0m00:22:32.369765 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.my_first_dbt_model"} */
drop table if exists "deep-analysis-console"."danila"."my_first_dbt_model__dbt_backup" cascade
[0m00:22:32.419132 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:32.424020 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.my_first_dbt_model (execute): 00:22:31.937435 => 00:22:32.423371
[0m00:22:32.425146 [debug] [Thread-1 (]: On model.campaign_perfomance.my_first_dbt_model: Close
[0m00:22:32.426810 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5f590>]}
[0m00:22:32.427435 [info ] [Thread-1 (]: 5 of 18 OK created sql table model danila.my_first_dbt_model ................... [[32mSELECT 2[0m in 0.50s]
[0m00:22:32.427991 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_first_dbt_model
[0m00:22:32.428336 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:32.428869 [info ] [Thread-1 (]: 6 of 18 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m00:22:32.429435 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.my_first_dbt_model, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:22:32.429703 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:32.433357 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.434143 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:22:32.429871 => 00:22:32.433987
[0m00:22:32.434394 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:32.437677 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.438139 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.438333 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:22:32.438525 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:32.718834 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:32.720591 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:32.722493 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:22:40.671595 [debug] [Thread-1 (]: SQL status: SELECT 153723 in 8.0 seconds
[0m00:22:40.679958 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.680692 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:22:40.711627 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:40.715598 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.716029 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:22:40.747088 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:40.755262 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:22:40.755933 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.756490 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:22:40.788336 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:40.794065 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:22:40.794701 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:22:40.845993 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:40.850608 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:22:32.434550 => 00:22:40.850001
[0m00:22:40.851715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:22:40.853516 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10787bad0>]}
[0m00:22:40.854339 [info ] [Thread-1 (]: 6 of 18 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 153723[0m in 8.42s]
[0m00:22:40.855115 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:22:40.855643 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:22:40.856489 [info ] [Thread-1 (]: 7 of 18 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m00:22:40.857376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:22:40.857738 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:22:40.874953 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:22:40.876432 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:22:40.857964 => 00:22:40.876265
[0m00:22:40.876705 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:22:40.879768 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:22:40.880205 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:40.880434 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:22:40.880645 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:41.197173 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:41.199047 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:41.200039 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m00:22:46.201746 [debug] [Thread-1 (]: SQL status: SELECT 45942 in 5.0 seconds
[0m00:22:46.210049 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.210771 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:22:46.249536 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.259642 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.260297 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:22:46.298931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.303151 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:22:46.303678 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.304107 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:22:46.342963 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:46.350756 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:22:46.351466 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:22:46.405599 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:46.409752 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:22:40.876864 => 00:22:46.409520
[0m00:22:46.410209 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:22:46.411644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5c0d0>]}
[0m00:22:46.412521 [info ] [Thread-1 (]: 7 of 18 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 45942[0m in 5.55s]
[0m00:22:46.413297 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:22:46.413764 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m00:22:46.414390 [info ] [Thread-1 (]: 8 of 18 START sql view model danila.test ....................................... [RUN]
[0m00:22:46.415311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m00:22:46.415650 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m00:22:46.418742 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m00:22:46.419549 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 00:22:46.415871 => 00:22:46.419368
[0m00:22:46.419856 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m00:22:46.434772 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m00:22:46.435371 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.435582 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m00:22:46.435770 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:46.719899 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:46.721571 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.722741 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    select 
    date_parsed as date, 
    geo as country_code, 
    registrations as signups
from "deep-analysis-console"."console"."records" records
where right(brand_name,6)<>'sports'
    and date > '2023-12-31'
    and geo='vn'
    and brand_name='20bet'
    and registrations>0
order by date_parsed desc


-- select * from "deep-analysis-console"."console"."campaign_names_mapping" where geo='vn'
  );
[0m00:22:46.758518 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m00:22:46.766412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.766996 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m00:22:46.798508 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.804338 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.804985 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m00:22:46.836153 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:46.841268 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:22:46.841957 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.842380 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m00:22:46.872833 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:46.877341 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m00:22:46.877670 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m00:22:46.908899 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m00:22:46.909746 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 00:22:46.420058 => 00:22:46.909648
[0m00:22:46.909920 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m00:22:46.910369 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107af1c90>]}
[0m00:22:46.910636 [info ] [Thread-1 (]: 8 of 18 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.50s]
[0m00:22:46.910941 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m00:22:46.911133 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test_write
[0m00:22:46.911401 [info ] [Thread-1 (]: 9 of 18 START sql table model danila.test_write ................................ [RUN]
[0m00:22:46.911795 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.test_write)
[0m00:22:46.911966 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test_write
[0m00:22:46.913358 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test_write"
[0m00:22:46.914618 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (compile): 00:22:46.912077 => 00:22:46.914521
[0m00:22:46.914777 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test_write
[0m00:22:46.916758 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test_write"
[0m00:22:46.917044 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:46.917189 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: BEGIN
[0m00:22:46.917330 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:47.189000 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:47.190676 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.191788 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */

  
    

  create  table "deep-analysis-console"."danila"."test_write__dbt_tmp"
  
  
    as
  
  (
    -- models/test_write.sql


select 1 as danila
  );
  
[0m00:22:47.227907 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:47.236409 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.236848 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write" rename to "test_write__dbt_backup"
[0m00:22:47.270273 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:47.275240 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.275716 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
alter table "deep-analysis-console"."danila"."test_write__dbt_tmp" rename to "test_write"
[0m00:22:47.310521 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:47.314949 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:22:47.315577 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.316103 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: COMMIT
[0m00:22:47.349858 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:47.356078 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test_write"
[0m00:22:47.356738 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test_write"} */
drop table if exists "deep-analysis-console"."danila"."test_write__dbt_backup" cascade
[0m00:22:47.407771 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:47.411167 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test_write (execute): 00:22:46.914878 => 00:22:47.410894
[0m00:22:47.411739 [debug] [Thread-1 (]: On model.campaign_perfomance.test_write: Close
[0m00:22:47.413296 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b04f90>]}
[0m00:22:47.414392 [info ] [Thread-1 (]: 9 of 18 OK created sql table model danila.test_write ........................... [[32mSELECT 1[0m in 0.50s]
[0m00:22:47.415539 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test_write
[0m00:22:47.416297 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclicks_fct
[0m00:22:47.417278 [info ] [Thread-1 (]: 10 of 18 START sql table model danila.outclicks_fct ............................ [RUN]
[0m00:22:47.418580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test_write, now model.campaign_perfomance.outclicks_fct)
[0m00:22:47.419116 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclicks_fct
[0m00:22:47.424677 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.426898 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (compile): 00:22:47.419417 => 00:22:47.426602
[0m00:22:47.427316 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclicks_fct
[0m00:22:47.432269 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.433091 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.433388 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: BEGIN
[0m00:22:47.433682 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:47.795822 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:47.797648 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:47.799092 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp"
  
  
    as
  
  (
    -- -- models/test_write.sql


WITH outclicks AS (
    SELECT * FROM "deep-analysis-console"."console"."postbacks_outgoing"
),
deals AS (
    SELECT * FROM "deep-analysis-console"."danila"."deals_dim"
)

select 
    outclicks.id as outclick_id,
    outclicks.timestamp as created_at_cet, 
    outclicks.user_id, 
    outclicks.deal_id,
    outclicks.adclickid as ad_click_id,
    outclicks.money_page_name as moneypage_template_id, 
    outclicks.provider_id as affiliated_account_id,
    --site_id ??
    outclicks.geo as geo_id,
    deals.ga_campaign_id as ga_campaign_id
from outclicks
left join deals
on outclicks.deal_id = deals.id



where timestamp>'2024-04-01'
  );
  
[0m00:22:48.069696 [debug] [Thread-1 (]: SQL status: SELECT 57065 in 0.0 seconds
[0m00:22:48.076322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.076928 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct" rename to "outclicks_fct__dbt_backup"
[0m00:22:48.121582 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:48.128501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.129021 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
alter table "deep-analysis-console"."danila"."outclicks_fct__dbt_tmp" rename to "outclicks_fct"
[0m00:22:48.173124 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:48.180850 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:22:48.181378 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.181767 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: COMMIT
[0m00:22:48.225971 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:48.232480 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclicks_fct"
[0m00:22:48.232940 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclicks_fct"} */
drop table if exists "deep-analysis-console"."danila"."outclicks_fct__dbt_backup" cascade
[0m00:22:48.297282 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:48.302056 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclicks_fct (execute): 00:22:47.427564 => 00:22:48.301690
[0m00:22:48.302637 [debug] [Thread-1 (]: On model.campaign_perfomance.outclicks_fct: Close
[0m00:22:48.303913 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aba010>]}
[0m00:22:48.304620 [info ] [Thread-1 (]: 10 of 18 OK created sql table model danila.outclicks_fct ....................... [[32mSELECT 57065[0m in 0.89s]
[0m00:22:48.305361 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclicks_fct
[0m00:22:48.305808 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.306353 [info ] [Thread-1 (]: 11 of 18 START test not_null_my_first_dbt_model_id ............................. [RUN]
[0m00:22:48.307039 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclicks_fct, now test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710)
[0m00:22:48.307570 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.322162 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.323854 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710 (compile): 00:22:48.308058 => 00:22:48.323692
[0m00:22:48.324113 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.331520 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.332028 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.332236 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
[0m00:22:48.332432 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:48.593876 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:48.595621 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"
[0m00:22:48.596842 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
[0m00:22:48.629982 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:48.636770 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710 (execute): 00:22:48.324260 => 00:22:48.636434
[0m00:22:48.637336 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
[0m00:22:48.668786 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710: Close
[0m00:22:48.670676 [error] [Thread-1 (]: 11 of 18 FAIL 1 not_null_my_first_dbt_model_id ................................. [[31mFAIL 1[0m in 0.36s]
[0m00:22:48.671901 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710
[0m00:22:48.672674 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:48.673526 [info ] [Thread-1 (]: 12 of 18 START test unique_my_first_dbt_model_id ............................... [RUN]
[0m00:22:48.674667 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_my_first_dbt_model_id.5fb22c2710, now test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321)
[0m00:22:48.675509 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:48.686024 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.687055 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321 (compile): 00:22:48.675916 => 00:22:48.686825
[0m00:22:48.687485 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:48.690486 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.691422 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.691729 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: BEGIN
[0m00:22:48.692013 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:48.953027 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:48.954923 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"
[0m00:22:48.955696 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:22:48.989122 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:48.992491 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321 (execute): 00:22:48.687730 => 00:22:48.992145
[0m00:22:48.993127 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
[0m00:22:49.025047 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321: Close
[0m00:22:49.028601 [info ] [Thread-1 (]: 12 of 18 PASS unique_my_first_dbt_model_id ..................................... [[32mPASS[0m in 0.35s]
[0m00:22:49.030096 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321
[0m00:22:49.030820 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.031733 [info ] [Thread-1 (]: 13 of 18 START test not_null_outclick_cost_int_id .............................. [RUN]
[0m00:22:49.032889 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_my_first_dbt_model_id.16e066b321, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m00:22:49.033382 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.040389 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.042084 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 00:22:49.033680 => 00:22:49.041728
[0m00:22:49.042588 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.045614 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.046518 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.046855 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m00:22:49.047150 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:49.324613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:49.326160 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:22:49.327060 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m00:22:49.374966 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:49.379766 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 00:22:49.042838 => 00:22:49.379311
[0m00:22:49.380504 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m00:22:49.413994 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m00:22:49.416596 [info ] [Thread-1 (]: 13 of 18 PASS not_null_outclick_cost_int_id .................................... [[32mPASS[0m in 0.38s]
[0m00:22:49.417826 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:22:49.418588 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.419385 [info ] [Thread-1 (]: 14 of 18 START test unique_outclick_cost_int_id ................................ [RUN]
[0m00:22:49.420639 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m00:22:49.421241 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.428966 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.430456 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 00:22:49.421942 => 00:22:49.430238
[0m00:22:49.431082 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.434344 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.435201 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.435552 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m00:22:49.435895 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:49.740150 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:49.741919 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:22:49.742707 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:22:49.797399 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:22:49.802645 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 00:22:49.431447 => 00:22:49.801899
[0m00:22:49.803850 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m00:22:49.840704 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m00:22:49.843376 [error] [Thread-1 (]: 14 of 18 FAIL 6892 unique_outclick_cost_int_id ................................. [[31mFAIL 6892[0m in 0.42s]
[0m00:22:49.844625 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:22:49.845347 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.brand_comparison_fi
[0m00:22:49.846284 [info ] [Thread-1 (]: 15 of 18 START sql table model danila.brand_comparison_fi ...................... [RUN]
[0m00:22:49.847471 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f, now model.campaign_perfomance.brand_comparison_fi)
[0m00:22:49.848021 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.brand_comparison_fi
[0m00:22:49.854312 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:49.855718 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (compile): 00:22:49.848653 => 00:22:49.855495
[0m00:22:49.856149 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.brand_comparison_fi
[0m00:22:49.861519 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:49.862667 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:49.862982 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: BEGIN
[0m00:22:49.863270 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:22:50.140428 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:22:50.142406 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.143867 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */

  
    

  create  table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


WITH agg_outclicks AS (
    -- Assuming `outclicks_fct` needs to join with `deals_dim` to get `ga_campaign_id`
    SELECT
        date(created_at_cet) as date,
        ga_campaign_id,
        count(*) as total_outclicks
    FROM "deep-analysis-console"."danila"."outclicks_fct"
    GROUP BY 1, 2
),

combined_campaign_data AS (
    -- Then, merge this data with the daily_campaign_fct
    SELECT
        co.date,
        co.ga_campaign_id,
        co.total_outclicks,
        dc.clicks,
        dc.ad_costs,
        dc.budget
    FROM agg_outclicks co
    LEFT JOIN "deep-analysis-console"."danila"."daily_campaign_fct" dc 
    ON co.ga_campaign_id = dc.ga_campaign_id 
        AND co.date = dc.date
)

SELECT
    date,
    ga_campaign_id,
    total_outclicks,
    clicks,
    ad_costs,
    budget
FROM combined_campaign_data
ORDER BY date, ga_campaign_id
  );
  
[0m00:22:50.206274 [debug] [Thread-1 (]: SQL status: SELECT 68 in 0.0 seconds
[0m00:22:50.215595 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.216321 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi" rename to "brand_comparison_fi__dbt_backup"
[0m00:22:50.250549 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:50.257817 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.258255 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
alter table "deep-analysis-console"."danila"."brand_comparison_fi__dbt_tmp" rename to "brand_comparison_fi"
[0m00:22:50.291484 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:22:50.295499 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:22:50.296213 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.296879 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: COMMIT
[0m00:22:50.330390 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:22:50.341060 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.brand_comparison_fi"
[0m00:22:50.341520 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.brand_comparison_fi"} */
drop table if exists "deep-analysis-console"."danila"."brand_comparison_fi__dbt_backup" cascade
[0m00:22:50.392554 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:22:50.394888 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.brand_comparison_fi (execute): 00:22:49.856427 => 00:22:50.394665
[0m00:22:50.395328 [debug] [Thread-1 (]: On model.campaign_perfomance.brand_comparison_fi: Close
[0m00:22:50.396539 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '13bab066-a2b1-4068-8ba7-7f4e0b831aa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b8c2d0>]}
[0m00:22:50.397252 [info ] [Thread-1 (]: 15 of 18 OK created sql table model danila.brand_comparison_fi ................. [[32mSELECT 68[0m in 0.55s]
[0m00:22:50.398155 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.brand_comparison_fi
[0m00:22:50.398761 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.my_second_dbt_model
[0m00:22:50.399295 [info ] [Thread-1 (]: 16 of 18 SKIP relation danila.my_second_dbt_model .............................. [[33mSKIP[0m]
[0m00:22:50.399827 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.my_second_dbt_model
[0m00:22:50.400588 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_my_second_dbt_model_id.151b76d778
[0m00:22:50.401023 [info ] [Thread-1 (]: 17 of 18 SKIP test not_null_my_second_dbt_model_id ............................. [[33mSKIP[0m]
[0m00:22:50.401623 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_my_second_dbt_model_id.151b76d778
[0m00:22:50.401966 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_my_second_dbt_model_id.57a0f8c493
[0m00:22:50.402319 [info ] [Thread-1 (]: 18 of 18 SKIP test unique_my_second_dbt_model_id ............................... [[33mSKIP[0m]
[0m00:22:50.402723 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_my_second_dbt_model_id.57a0f8c493
[0m00:22:50.404024 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:50.404282 [debug] [MainThread]: On master: BEGIN
[0m00:22:50.404497 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:22:50.765967 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:22:50.767551 [debug] [MainThread]: On master: COMMIT
[0m00:22:50.768433 [debug] [MainThread]: Using postgres connection "master"
[0m00:22:50.769233 [debug] [MainThread]: On master: COMMIT
[0m00:22:50.812876 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:22:50.813940 [debug] [MainThread]: On master: Close
[0m00:22:50.816297 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:22:50.817095 [debug] [MainThread]: Connection 'model.campaign_perfomance.brand_comparison_fi' was properly closed.
[0m00:22:50.817789 [info ] [MainThread]: 
[0m00:22:50.818400 [info ] [MainThread]: Finished running 10 table models, 2 view models, 6 tests in 0 hours 0 minutes and 47.40 seconds (47.40s).
[0m00:22:50.822511 [debug] [MainThread]: Command end result
[0m00:22:50.835531 [info ] [MainThread]: 
[0m00:22:50.836083 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
[0m00:22:50.836391 [info ] [MainThread]: 
[0m00:22:50.836708 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m00:22:50.836998 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m00:22:50.837146 [info ] [MainThread]: 
[0m00:22:50.837276 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m00:22:50.837418 [info ] [MainThread]: 
[0m00:22:50.837543 [error] [MainThread]: [31mFailure in test unique_outclick_cost_int_id (models/brand_performance/schema.yml)[0m
[0m00:22:50.837663 [error] [MainThread]:   Got 6892 results, configured to fail if != 0
[0m00:22:50.837779 [info ] [MainThread]: 
[0m00:22:50.837894 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_cost_int_id.sql
[0m00:22:50.838029 [info ] [MainThread]: 
[0m00:22:50.838188 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=2 SKIP=3 TOTAL=18
[0m00:22:50.838526 [debug] [MainThread]: Command `dbt build` failed at 00:22:50.838473 after 47.54 seconds
[0m00:22:50.838713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e84310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034c25d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107989290>]}
[0m00:22:50.838895 [debug] [MainThread]: Flushing usage events
[0m00:42:33.470759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e39dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e53bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e53f90>]}


============================== 00:42:33.472301 | e445f906-6e85-4069-8379-269a0f62fd9c ==============================
[0m00:42:33.472301 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:42:33.472598 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'log_path': '/Users/danila/github/dbt/logs', 'debug': 'False', 'target_path': 'None', 'fail_fast': 'False', 'cache_selected_only': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'version_check': 'True', 'introspect': 'True', 'static_parser': 'True', 'quiet': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'partial_parse': 'True', 'use_colors': 'True'}
[0m00:42:33.504938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e695d0>]}
[0m00:42:33.511225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e63590>]}
[0m00:42:33.511741 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:42:33.523288 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:42:33.564642 [debug] [MainThread]: Partial parsing enabled: 12 files deleted, 0 files added, 0 files changed.
[0m00:42:33.564966 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/test.sql
[0m00:42:33.565079 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/deals_dim.sql
[0m00:42:33.565173 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/my_first_dbt_model.sql
[0m00:42:33.565259 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/brand_comparison_fi.sql
[0m00:42:33.565341 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/brand_performance_replacement.sql
[0m00:42:33.565425 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/daily_campaign_fct.sql
[0m00:42:33.565505 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/campaign_dim.sql
[0m00:42:33.565585 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/example/my_second_dbt_model.sql
[0m00:42:33.565666 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/outclicks_fct.sql
[0m00:42:33.565743 [debug] [MainThread]: Partial parsing: deleted file: campaign_perfomance://models/users/test_write.sql
[0m00:42:33.567752 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m00:42:33.570014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e53390>]}
[0m00:42:33.574979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107449fd0>]}
[0m00:42:33.575179 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m00:42:33.575936 [info ] [MainThread]: 
[0m00:42:33.576294 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:42:33.576789 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:42:33.581097 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:42:33.581293 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:42:33.581411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:42:33.931486 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:42:33.936697 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:42:33.940881 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:42:33.950427 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:33.950913 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:42:33.951237 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:42:34.233093 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:42:34.235122 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:34.236347 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:42:34.274251 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m00:42:34.275951 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:42:34.308895 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:42:34.313285 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.313501 [debug] [MainThread]: On master: BEGIN
[0m00:42:34.313649 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:42:34.571756 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:34.573572 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.574554 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:42:34.615841 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m00:42:34.622269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10744aa50>]}
[0m00:42:34.623378 [debug] [MainThread]: On master: ROLLBACK
[0m00:42:34.655374 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.656605 [debug] [MainThread]: On master: BEGIN
[0m00:42:34.719085 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:34.720524 [debug] [MainThread]: On master: COMMIT
[0m00:42:34.721223 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:34.721770 [debug] [MainThread]: On master: COMMIT
[0m00:42:34.753951 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:42:34.755362 [debug] [MainThread]: On master: Close
[0m00:42:34.757843 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:42:34.758598 [info ] [MainThread]: 
[0m00:42:34.766043 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:34.766754 [info ] [Thread-1 (]: 1 of 4 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m00:42:34.767633 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:42:34.768033 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:34.777166 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:34.778401 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:42:34.768281 => 00:42:34.778188
[0m00:42:34.778732 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:34.803713 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:34.804262 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:34.804442 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:42:34.804608 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:35.066648 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:35.067985 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:35.069736 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:42:42.963080 [debug] [Thread-1 (]: SQL status: SELECT 153732 in 8.0 seconds
[0m00:42:42.977937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:42.978787 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:42:43.010667 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:43.017697 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:43.018299 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:42:43.050694 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:43.078058 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:42:43.078574 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:43.078848 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:42:43.109793 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:42:43.117042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:42:43.117385 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:42:43.165085 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:42:43.168141 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:42:34.778913 => 00:42:43.167852
[0m00:42:43.168731 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:42:43.170186 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074fcd50>]}
[0m00:42:43.170986 [info ] [Thread-1 (]: 1 of 4 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 153732[0m in 8.40s]
[0m00:42:43.171729 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:42:43.172202 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:42:43.172754 [info ] [Thread-1 (]: 2 of 4 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m00:42:43.173501 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:42:43.173851 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:42:43.188828 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.190496 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:42:43.174082 => 00:42:43.190347
[0m00:42:43.190732 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:42:43.193579 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.194130 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.194327 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:42:43.194507 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:43.515254 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:43.516810 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:43.517888 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)

select 
    md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
    *
from main
  );
  
[0m00:42:48.387822 [debug] [Thread-1 (]: SQL status: SELECT 45951 in 5.0 seconds
[0m00:42:48.396987 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.397914 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:42:48.428993 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:48.436349 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.437028 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:42:48.468862 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:42:48.473918 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:42:48.474761 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.475416 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:42:48.527819 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:42:48.533986 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:42:48.534736 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:42:48.581861 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:42:48.585542 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:42:43.190875 => 00:42:48.585149
[0m00:42:48.586295 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:42:48.588188 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e445f906-6e85-4069-8379-269a0f62fd9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107518310>]}
[0m00:42:48.589367 [info ] [Thread-1 (]: 2 of 4 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45951[0m in 5.41s]
[0m00:42:48.590508 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:42:48.592245 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.592819 [info ] [Thread-1 (]: 3 of 4 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m00:42:48.593919 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m00:42:48.594399 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.608373 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.610063 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 00:42:48.594694 => 00:42:48.609867
[0m00:42:48.610373 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.620169 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.621330 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.621646 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m00:42:48.621871 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:48.899133 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:48.901127 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:42:48.902195 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m00:42:48.946756 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:42:48.952239 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 00:42:48.610574 => 00:42:48.951758
[0m00:42:48.953059 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m00:42:48.987139 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m00:42:48.990702 [info ] [Thread-1 (]: 3 of 4 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.40s]
[0m00:42:48.992212 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:42:48.993095 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:48.994023 [info ] [Thread-1 (]: 4 of 4 START test unique_outclick_cost_int_id .................................. [RUN]
[0m00:42:48.995437 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m00:42:48.996136 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:49.007322 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.009494 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 00:42:48.996846 => 00:42:49.009282
[0m00:42:49.009834 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:49.012207 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.013098 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.013396 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m00:42:49.013669 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:42:49.364644 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:42:49.365755 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:42:49.366351 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:42:49.425780 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:42:49.430018 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 00:42:49.010040 => 00:42:49.429544
[0m00:42:49.430812 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m00:42:49.473930 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m00:42:49.477136 [error] [Thread-1 (]: 4 of 4 FAIL 6895 unique_outclick_cost_int_id ................................... [[31mFAIL 6895[0m in 0.48s]
[0m00:42:49.478675 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:42:49.481870 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:49.482489 [debug] [MainThread]: On master: BEGIN
[0m00:42:49.483034 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:42:49.740767 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:49.742531 [debug] [MainThread]: On master: COMMIT
[0m00:42:49.743638 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:49.744345 [debug] [MainThread]: On master: COMMIT
[0m00:42:49.774839 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:42:49.776390 [debug] [MainThread]: On master: Close
[0m00:42:49.778428 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:42:49.778872 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m00:42:49.779413 [info ] [MainThread]: 
[0m00:42:49.780026 [info ] [MainThread]: Finished running 2 table models, 2 tests in 0 hours 0 minutes and 16.20 seconds (16.20s).
[0m00:42:49.781489 [debug] [MainThread]: Command end result
[0m00:42:49.794803 [info ] [MainThread]: 
[0m00:42:49.795327 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m00:42:49.795604 [info ] [MainThread]: 
[0m00:42:49.795882 [error] [MainThread]: [31mFailure in test unique_outclick_cost_int_id (models/brand_performance/schema.yml)[0m
[0m00:42:49.796141 [error] [MainThread]:   Got 6895 results, configured to fail if != 0
[0m00:42:49.796374 [info ] [MainThread]: 
[0m00:42:49.796615 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_cost_int_id.sql
[0m00:42:49.796866 [info ] [MainThread]: 
[0m00:42:49.797185 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m00:42:49.797684 [debug] [MainThread]: Command `dbt build` failed at 00:42:49.797604 after 16.34 seconds
[0m00:42:49.797958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102f7e5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102f7e650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e44090>]}
[0m00:42:49.798218 [debug] [MainThread]: Flushing usage events
[0m00:42:58.851966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e6fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e85650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8c4d0>]}


============================== 00:42:58.853826 | e4933fce-325e-470f-ad04-4095ab54e33c ==============================
[0m00:42:58.853826 [info ] [MainThread]: Running with dbt=1.5.4
[0m00:42:58.854151 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'introspect': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'partial_parse': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False', 'static_parser': 'True', 'debug': 'False', 'write_json': 'True', 'warn_error': 'None', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None'}
[0m00:42:58.885049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eaa7d0>]}
[0m00:42:58.891386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8d1d0>]}
[0m00:42:58.891845 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m00:42:58.902487 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m00:42:58.931947 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:42:58.932136 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:42:58.932347 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m00:42:58.934673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c07c90>]}
[0m00:42:58.937847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea9a10>]}
[0m00:42:58.938003 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m00:42:58.938730 [info ] [MainThread]: 
[0m00:42:58.939054 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:42:58.939516 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m00:42:58.943747 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m00:42:58.943916 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m00:42:58.944042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:42:59.247059 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m00:42:59.251334 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m00:42:59.255425 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m00:42:59.264390 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:59.264940 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m00:42:59.265259 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:42:59.549892 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m00:42:59.551134 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m00:42:59.552008 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m00:42:59.587101 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m00:42:59.592339 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m00:42:59.624348 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m00:42:59.640037 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:59.640734 [debug] [MainThread]: On master: BEGIN
[0m00:42:59.641149 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:42:59.904419 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:42:59.905695 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:59.906790 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:42:59.950654 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m00:42:59.956036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e9e910>]}
[0m00:42:59.957140 [debug] [MainThread]: On master: ROLLBACK
[0m00:42:59.988480 [debug] [MainThread]: Using postgres connection "master"
[0m00:42:59.989583 [debug] [MainThread]: On master: BEGIN
[0m00:43:00.051595 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:43:00.052785 [debug] [MainThread]: On master: COMMIT
[0m00:43:00.053706 [debug] [MainThread]: Using postgres connection "master"
[0m00:43:00.054426 [debug] [MainThread]: On master: COMMIT
[0m00:43:00.085800 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:43:00.086664 [debug] [MainThread]: On master: Close
[0m00:43:00.088783 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:43:00.089793 [info ] [MainThread]: 
[0m00:43:00.099754 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:00.100727 [info ] [Thread-1 (]: 1 of 4 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m00:43:00.101957 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m00:43:00.102467 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:00.114560 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.115969 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 00:43:00.102800 => 00:43:00.115722
[0m00:43:00.116299 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:00.141640 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.142232 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.142421 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m00:43:00.142597 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:00.401345 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:00.402970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:00.404152 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql


select 
    date(timestamp - interval '2 hours') as date, 
    "left"(matomo_actions.eventname::text, 2) as country_code, 
    lower(sitename) as campaign_name, 
    campaignname as ga_campaign_name,
    CASE 
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
        when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical, 
    "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
    count(matomo_actions.id) as outclicks,
    count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
    round(avg(eventvalue), 2) AS avg_list_position,
    string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
    NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
    NULL as gtee_commissions, NULL as avg_deposit_amount
from "deep-analysis-console"."console"."matomo_actions" matomo_actions
left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
on matomo_actions.matomo_visit_id=matomo_visits.id
where 
    matomo_actions.type = 'event' 
    AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
    --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    and date(timestamp - interval '2 hours') >'2023-12-31'
--[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
-- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
-- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
/*affiliate records aggregated data from records table*/
union all
select 
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
    coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-12-31'
    -- right(brand_name,6)<>'sports'
    -- and date_parsed > '2023-12-31'
--[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
-- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
-- [[ and  ]]
group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
  );
  
[0m00:43:07.984866 [debug] [Thread-1 (]: SQL status: SELECT 153732 in 8.0 seconds
[0m00:43:07.998636 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:07.999381 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m00:43:08.030952 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:08.038456 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:08.039193 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m00:43:08.071185 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:08.096099 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:43:08.096640 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:08.096933 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m00:43:08.127984 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:43:08.133003 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m00:43:08.133331 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m00:43:08.181247 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:43:08.184389 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 00:43:00.116487 => 00:43:08.184050
[0m00:43:08.185056 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m00:43:08.186965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055e2150>]}
[0m00:43:08.187836 [info ] [Thread-1 (]: 1 of 4 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 153732[0m in 8.09s]
[0m00:43:08.188615 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m00:43:08.189101 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m00:43:08.189774 [info ] [Thread-1 (]: 2 of 4 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m00:43:08.190611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m00:43:08.190970 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m00:43:08.207467 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.209146 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 00:43:08.191182 => 00:43:08.208993
[0m00:43:08.209393 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m00:43:08.212241 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.212692 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.212899 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m00:43:08.213082 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:08.545006 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:08.546518 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:08.547815 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m00:43:13.286385 [debug] [Thread-1 (]: SQL status: SELECT 45951 in 5.0 seconds
[0m00:43:13.290532 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.291002 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m00:43:13.330987 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:13.334469 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.334850 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m00:43:13.375148 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m00:43:13.380907 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:43:13.381448 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.381823 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m00:43:13.422147 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m00:43:13.427418 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m00:43:13.427971 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m00:43:13.483615 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m00:43:13.487989 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 00:43:08.209546 => 00:43:13.487542
[0m00:43:13.488939 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m00:43:13.491258 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4933fce-325e-470f-ad04-4095ab54e33c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057a8390>]}
[0m00:43:13.492540 [info ] [Thread-1 (]: 2 of 4 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 45951[0m in 5.30s]
[0m00:43:13.493803 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m00:43:13.495420 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.496159 [info ] [Thread-1 (]: 3 of 4 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m00:43:13.497298 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m00:43:13.497954 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.512109 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.514148 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 00:43:13.498349 => 00:43:13.513910
[0m00:43:13.514488 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.524397 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.525191 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.525423 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m00:43:13.525614 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:13.854482 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:13.856763 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m00:43:13.857940 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m00:43:13.909216 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:43:13.915404 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 00:43:13.514670 => 00:43:13.914939
[0m00:43:13.916148 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m00:43:13.956647 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m00:43:13.959895 [info ] [Thread-1 (]: 3 of 4 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.46s]
[0m00:43:13.961317 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m00:43:13.962231 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:13.963235 [info ] [Thread-1 (]: 4 of 4 START test unique_outclick_cost_int_id .................................. [RUN]
[0m00:43:13.964804 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m00:43:13.965532 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:13.976032 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:13.977134 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 00:43:13.965988 => 00:43:13.976916
[0m00:43:13.977517 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:13.980191 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:13.980932 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:13.981227 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m00:43:13.981506 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:43:14.243205 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m00:43:14.244962 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m00:43:14.246127 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m00:43:14.306567 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m00:43:14.310802 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 00:43:13.977752 => 00:43:14.310214
[0m00:43:14.311570 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m00:43:14.342711 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m00:43:14.345772 [info ] [Thread-1 (]: 4 of 4 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.38s]
[0m00:43:14.347234 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m00:43:14.350386 [debug] [MainThread]: Using postgres connection "master"
[0m00:43:14.351131 [debug] [MainThread]: On master: BEGIN
[0m00:43:14.351766 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:43:14.638298 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m00:43:14.639683 [debug] [MainThread]: On master: COMMIT
[0m00:43:14.640434 [debug] [MainThread]: Using postgres connection "master"
[0m00:43:14.641026 [debug] [MainThread]: On master: COMMIT
[0m00:43:14.675385 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m00:43:14.676905 [debug] [MainThread]: On master: Close
[0m00:43:14.679503 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:43:14.680182 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m00:43:14.680944 [info ] [MainThread]: 
[0m00:43:14.681708 [info ] [MainThread]: Finished running 2 table models, 2 tests in 0 hours 0 minutes and 15.74 seconds (15.74s).
[0m00:43:14.684027 [debug] [MainThread]: Command end result
[0m00:43:14.695392 [info ] [MainThread]: 
[0m00:43:14.696059 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:43:14.696460 [info ] [MainThread]: 
[0m00:43:14.696870 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m00:43:14.697582 [debug] [MainThread]: Command `dbt build` succeeded at 00:43:14.697456 after 15.86 seconds
[0m00:43:14.697993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104894d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8cc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e74290>]}
[0m00:43:14.698340 [debug] [MainThread]: Flushing usage events
[0m12:28:37.874713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ce7b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cfd650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cffd10>]}


============================== 12:28:37.876587 | faf1709a-8a57-4fd4-ad36-de6b0486eeef ==============================
[0m12:28:37.876587 [info ] [MainThread]: Running with dbt=1.5.4
[0m12:28:37.876902 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'no_print': 'None', 'partial_parse': 'True', 'introspect': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'target_path': 'None', 'static_parser': 'True', 'use_experimental_parser': 'False', 'quiet': 'False', 'debug': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_format': 'default'}
[0m12:28:37.907433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ce4e10>]}
[0m12:28:37.913955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d04850>]}
[0m12:28:37.914467 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m12:28:37.924644 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m12:28:37.952262 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:28:37.952461 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:28:37.952694 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m12:28:37.955062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072b29d0>]}
[0m12:28:37.961501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10716bb90>]}
[0m12:28:37.961737 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 421 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m12:28:37.962484 [info ] [MainThread]: 
[0m12:28:37.962867 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:28:37.963326 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m12:28:37.967547 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m12:28:37.967701 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m12:28:37.967821 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:28:38.250548 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m12:28:38.253450 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m12:28:38.256353 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m12:28:38.264914 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m12:28:38.265535 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m12:28:38.265857 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:28:38.523925 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m12:28:38.524746 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m12:28:38.525403 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m12:28:38.560586 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m12:28:38.563732 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m12:28:38.593990 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m12:28:38.606697 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:38.607109 [debug] [MainThread]: On master: BEGIN
[0m12:28:38.607414 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:28:38.874234 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:38.875797 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:38.876772 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:28:38.923250 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m12:28:38.928626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10667cdd0>]}
[0m12:28:38.929656 [debug] [MainThread]: On master: ROLLBACK
[0m12:28:38.962391 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:38.963538 [debug] [MainThread]: On master: BEGIN
[0m12:28:39.029100 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:39.030708 [debug] [MainThread]: On master: COMMIT
[0m12:28:39.031733 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:39.032309 [debug] [MainThread]: On master: COMMIT
[0m12:28:39.063648 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:28:39.064598 [debug] [MainThread]: On master: Close
[0m12:28:39.066912 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:28:39.067635 [info ] [MainThread]: 
[0m12:28:39.076031 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:39.076821 [info ] [Thread-1 (]: 1 of 4 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m12:28:39.077660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m12:28:39.078047 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:39.097725 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.099173 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 12:28:39.078290 => 12:28:39.098953
[0m12:28:39.099437 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:39.122505 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.123095 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.123278 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m12:28:39.123433 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:39.415412 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:39.417022 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:39.418908 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m12:28:47.055209 [debug] [Thread-1 (]: SQL status: SELECT 156347 in 8.0 seconds
[0m12:28:47.068465 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.069181 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m12:28:47.103724 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:47.110419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.111150 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m12:28:47.142826 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:47.172062 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m12:28:47.172580 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.172863 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m12:28:47.203047 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:47.208433 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m12:28:47.208755 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m12:28:47.257848 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:47.261374 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 12:28:39.099551 => 12:28:47.261046
[0m12:28:47.261996 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m12:28:47.263710 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071ea7d0>]}
[0m12:28:47.264658 [info ] [Thread-1 (]: 1 of 4 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156347[0m in 8.19s]
[0m12:28:47.265754 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m12:28:47.266472 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m12:28:47.267167 [info ] [Thread-1 (]: 2 of 4 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m12:28:47.268081 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m12:28:47.268479 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m12:28:47.278259 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.279610 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 12:28:47.268723 => 12:28:47.279444
[0m12:28:47.279875 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m12:28:47.283217 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.283631 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.283841 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m12:28:47.284041 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:47.645061 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:47.647178 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:47.648431 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m12:28:52.441799 [debug] [Thread-1 (]: SQL status: SELECT 46501 in 5.0 seconds
[0m12:28:52.451249 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.451933 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m12:28:52.494922 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:52.505219 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.505870 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m12:28:52.545776 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m12:28:52.551701 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m12:28:52.552445 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.552948 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m12:28:52.593015 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m12:28:52.599936 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m12:28:52.600722 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m12:28:52.656954 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m12:28:52.661155 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 12:28:47.280039 => 12:28:52.660759
[0m12:28:52.662047 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m12:28:52.664543 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'faf1709a-8a57-4fd4-ad36-de6b0486eeef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1073cbd90>]}
[0m12:28:52.665625 [info ] [Thread-1 (]: 2 of 4 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46501[0m in 5.40s]
[0m12:28:52.666822 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m12:28:52.668303 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:52.668960 [info ] [Thread-1 (]: 3 of 4 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m12:28:52.669947 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m12:28:52.670415 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:52.684126 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.686605 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 12:28:52.670707 => 12:28:52.686416
[0m12:28:52.686901 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:52.696129 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.696853 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.697085 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m12:28:52.697271 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:52.976716 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:52.978450 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m12:28:52.979607 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m12:28:53.027406 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m12:28:53.032690 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 12:28:52.687076 => 12:28:53.032258
[0m12:28:53.033518 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m12:28:53.067298 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m12:28:53.070302 [info ] [Thread-1 (]: 3 of 4 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.40s]
[0m12:28:53.071702 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m12:28:53.072605 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.073362 [info ] [Thread-1 (]: 4 of 4 START test unique_outclick_cost_int_id .................................. [RUN]
[0m12:28:53.074324 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m12:28:53.074806 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.084705 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.087205 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 12:28:53.075130 => 12:28:53.086929
[0m12:28:53.087593 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.090308 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.091013 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.091269 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m12:28:53.091505 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:28:53.351229 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m12:28:53.351537 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m12:28:53.351763 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m12:28:53.423489 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m12:28:53.426122 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 12:28:53.087815 => 12:28:53.425801
[0m12:28:53.426795 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m12:28:53.458452 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m12:28:53.460974 [info ] [Thread-1 (]: 4 of 4 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.39s]
[0m12:28:53.462060 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m12:28:53.464444 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:53.464899 [debug] [MainThread]: On master: BEGIN
[0m12:28:53.465201 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:28:53.819180 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m12:28:53.821113 [debug] [MainThread]: On master: COMMIT
[0m12:28:53.821806 [debug] [MainThread]: Using postgres connection "master"
[0m12:28:53.822393 [debug] [MainThread]: On master: COMMIT
[0m12:28:53.866324 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m12:28:53.867712 [debug] [MainThread]: On master: Close
[0m12:28:53.869637 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:28:53.870208 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m12:28:53.870933 [info ] [MainThread]: 
[0m12:28:53.871660 [info ] [MainThread]: Finished running 2 table models, 2 tests in 0 hours 0 minutes and 15.91 seconds (15.91s).
[0m12:28:53.873700 [debug] [MainThread]: Command end result
[0m12:28:53.887950 [info ] [MainThread]: 
[0m12:28:53.888737 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:28:53.889066 [info ] [MainThread]: 
[0m12:28:53.889411 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m12:28:53.890027 [debug] [MainThread]: Command `dbt build` succeeded at 12:28:53.889924 after 16.03 seconds
[0m12:28:53.890366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e2c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e2a650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e2a5d0>]}
[0m12:28:53.890692 [debug] [MainThread]: Flushing usage events
[0m15:22:13.367993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d0d690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d19650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d1f550>]}


============================== 15:22:13.369512 | a4ffdef9-be9d-48f1-9028-54d892cc37fd ==============================
[0m15:22:13.369512 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:22:13.369838 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'log_format': 'default', 'printer_width': '80', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'static_parser': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': '/Users/danila/.dbt'}
[0m15:22:13.397736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051a6050>]}
[0m15:22:13.404244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051a5090>]}
[0m15:22:13.404767 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:22:13.414988 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:22:13.442351 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:22:13.442531 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:22:13.442743 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m15:22:13.445305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104be93d0>]}
[0m15:22:13.449554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051aa750>]}
[0m15:22:13.449797 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m15:22:13.449970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1021cbb90>]}
[0m15:22:13.450595 [info ] [MainThread]: 
[0m15:22:13.450917 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:22:13.451368 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:22:13.455307 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:22:13.455435 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:22:13.455538 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:22:13.770500 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m15:22:13.771757 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:22:13.773029 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:22:13.777168 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:22:13.777393 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:22:13.777576 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:22:14.062693 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:22:14.064326 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:22:14.065599 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:22:14.102846 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m15:22:14.108729 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:22:14.141288 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:22:14.154658 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:14.155057 [debug] [MainThread]: On master: BEGIN
[0m15:22:14.155335 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:22:14.415069 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:14.416289 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:14.417287 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:22:14.460735 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m15:22:14.465593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105177910>]}
[0m15:22:14.466561 [debug] [MainThread]: On master: ROLLBACK
[0m15:22:14.498180 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:14.499462 [debug] [MainThread]: On master: BEGIN
[0m15:22:14.563886 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:14.565223 [debug] [MainThread]: On master: COMMIT
[0m15:22:14.566173 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:14.567479 [debug] [MainThread]: On master: COMMIT
[0m15:22:14.599949 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:14.601150 [debug] [MainThread]: On master: Close
[0m15:22:14.603947 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:22:14.604706 [info ] [MainThread]: 
[0m15:22:14.615924 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m15:22:14.616900 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m15:22:14.618104 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m15:22:14.618649 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m15:22:14.640543 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:22:14.642104 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 15:22:14.618932 => 15:22:14.641938
[0m15:22:14.642353 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m15:22:14.662787 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:22:14.663505 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:22:14.663706 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m15:22:14.663870 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:14.922550 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:14.924428 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:22:14.926496 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        --CAST(
    CASE
        WHEN DATE( - INTERVAL '2 hour') > '2023-10-28' THEN DATE( - INTERVAL '2 hour')
        ELSE DATE( - INTERVAL '3 hour')
    END
 AS DATE) as parsed_timestamp,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:22:14.961469 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "as"
LINE 22:  AS DATE) as parsed_timestamp,
                   ^

[0m15:22:14.962942 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: ROLLBACK
[0m15:22:14.995625 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 15:22:14.642493 => 15:22:14.994605
[0m15:22:14.997045 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m15:22:15.010322 [debug] [Thread-1 (]: Database Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)
  syntax error at or near "as"
  LINE 22:  AS DATE) as parsed_timestamp,
                     ^
  compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m15:22:15.011063 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105176ed0>]}
[0m15:22:15.011730 [error] [Thread-1 (]: 1 of 2 ERROR creating sql table model danila.outclick_by_brand_int ............. [[31mERROR[0m in 0.39s]
[0m15:22:15.012336 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m15:22:15.012782 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m15:22:15.013334 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m15:22:15.014066 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m15:22:15.014412 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m15:22:15.022042 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m15:22:15.023376 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 15:22:15.014635 => 15:22:15.023157
[0m15:22:15.023687 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m15:22:15.026848 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m15:22:15.027369 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:22:15.027588 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m15:22:15.027794 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:22:15.306434 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:22:15.308313 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:22:15.310173 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:22:22.133034 [debug] [Thread-1 (]: SQL status: SELECT 46515 in 7.0 seconds
[0m15:22:22.145126 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:22:22.145725 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:22:22.177931 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:22.184212 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:22:22.184981 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:22:22.217358 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:22:22.244855 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:22:22.245461 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:22:22.245755 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:22:22.277096 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:22:22.282637 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:22:22.283047 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:22:22.329508 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:22:22.332410 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 15:22:15.023863 => 15:22:22.332050
[0m15:22:22.333113 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m15:22:22.334845 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4ffdef9-be9d-48f1-9028-54d892cc37fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053a42d0>]}
[0m15:22:22.335806 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46515[0m in 7.32s]
[0m15:22:22.336625 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m15:22:22.338497 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:22.338888 [debug] [MainThread]: On master: BEGIN
[0m15:22:22.339138 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:22:22.596207 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:22:22.597816 [debug] [MainThread]: On master: COMMIT
[0m15:22:22.598780 [debug] [MainThread]: Using postgres connection "master"
[0m15:22:22.599689 [debug] [MainThread]: On master: COMMIT
[0m15:22:22.631187 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:22:22.632414 [debug] [MainThread]: On master: Close
[0m15:22:22.634591 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:22:22.635144 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m15:22:22.635688 [info ] [MainThread]: 
[0m15:22:22.636226 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 9.18 seconds (9.18s).
[0m15:22:22.637265 [debug] [MainThread]: Command end result
[0m15:22:22.653070 [info ] [MainThread]: 
[0m15:22:22.653561 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:22:22.653850 [info ] [MainThread]: 
[0m15:22:22.654112 [error] [MainThread]: [33mDatabase Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)[0m
[0m15:22:22.654364 [error] [MainThread]:   syntax error at or near "as"
[0m15:22:22.654605 [error] [MainThread]:   LINE 22:  AS DATE) as parsed_timestamp,
[0m15:22:22.654832 [error] [MainThread]:                      ^
[0m15:22:22.655066 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m15:22:22.655298 [info ] [MainThread]: 
[0m15:22:22.655569 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m15:22:22.656037 [debug] [MainThread]: Command `dbt run` failed at 15:22:22.655954 after 9.29 seconds
[0m15:22:22.656344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e465d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e46510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105177850>]}
[0m15:22:22.656628 [debug] [MainThread]: Flushing usage events
[0m17:00:35.348472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047cc910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047dfa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047dff90>]}


============================== 17:00:35.350266 | 34053eed-5041-4108-8574-a4e93b55b0f1 ==============================
[0m17:00:35.350266 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:00:35.350651 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'printer_width': '80', 'write_json': 'True', 'static_parser': 'True', 'no_print': 'None', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'fail_fast': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'target_path': 'None'}
[0m17:00:35.383080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '34053eed-5041-4108-8574-a4e93b55b0f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046a9590>]}
[0m17:00:35.389303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '34053eed-5041-4108-8574-a4e93b55b0f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104320e90>]}
[0m17:00:35.389766 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:00:35.401296 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:00:35.442057 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:00:35.442257 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:00:35.442476 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:00:35.444998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '34053eed-5041-4108-8574-a4e93b55b0f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d5e090>]}
[0m17:00:35.449889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '34053eed-5041-4108-8574-a4e93b55b0f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c6b5d0>]}
[0m17:00:35.450131 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:00:35.450294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '34053eed-5041-4108-8574-a4e93b55b0f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101c9c150>]}
[0m17:00:35.450848 [info ] [MainThread]: 
[0m17:00:35.451189 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:00:35.451619 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:00:35.456014 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:00:35.456182 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:00:35.456301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:00:35.825164 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:00:35.829220 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:00:35.833476 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:00:35.841934 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:00:35.842429 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:00:35.842736 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:00:36.103877 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:00:36.105523 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:00:36.106654 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:00:36.142644 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:00:36.147743 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:00:36.178952 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:00:36.192256 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:36.192671 [debug] [MainThread]: On master: BEGIN
[0m17:00:36.193100 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:00:36.453838 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:00:36.455514 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:36.456488 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:00:36.501571 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:00:36.507444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '34053eed-5041-4108-8574-a4e93b55b0f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ccbcd0>]}
[0m17:00:36.508382 [debug] [MainThread]: On master: ROLLBACK
[0m17:00:36.540209 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:36.541047 [debug] [MainThread]: On master: BEGIN
[0m17:00:36.602598 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:00:36.603094 [debug] [MainThread]: On master: COMMIT
[0m17:00:36.603377 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:36.603626 [debug] [MainThread]: On master: COMMIT
[0m17:00:36.634611 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:00:36.634914 [debug] [MainThread]: On master: Close
[0m17:00:36.635457 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:00:36.635698 [info ] [MainThread]: 
[0m17:00:36.639526 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:00:36.639900 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:00:36.640384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:00:36.640588 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:00:36.654036 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:36.655377 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:00:36.640714 => 17:00:36.655243
[0m17:00:36.655575 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:00:36.673549 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:36.674213 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:36.674393 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:00:36.674534 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:00:36.929575 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:00:36.930105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:36.930700 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:00:45.103434 [debug] [Thread-1 (]: SQL status: SELECT 156466 in 8.0 seconds
[0m17:00:45.118313 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:45.119122 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:00:45.150958 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:00:45.157314 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:45.158197 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:00:45.189992 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:00:45.220536 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:00:45.221452 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:45.221973 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:00:45.253375 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:00:45.261717 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:00:45.262353 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:00:45.310288 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:00:45.313860 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:00:36.655682 => 17:00:45.313450
[0m17:00:45.314695 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:00:45.316777 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '34053eed-5041-4108-8574-a4e93b55b0f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047eb410>]}
[0m17:00:45.318053 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156466[0m in 8.68s]
[0m17:00:45.319209 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:00:45.321882 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:45.322391 [debug] [MainThread]: On master: BEGIN
[0m17:00:45.322880 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:00:45.673872 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:00:45.675124 [debug] [MainThread]: On master: COMMIT
[0m17:00:45.676072 [debug] [MainThread]: Using postgres connection "master"
[0m17:00:45.676665 [debug] [MainThread]: On master: COMMIT
[0m17:00:45.719215 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:00:45.720593 [debug] [MainThread]: On master: Close
[0m17:00:45.722714 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:00:45.723527 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m17:00:45.724483 [info ] [MainThread]: 
[0m17:00:45.725392 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 10.27 seconds (10.27s).
[0m17:00:45.726816 [debug] [MainThread]: Command end result
[0m17:00:45.746931 [info ] [MainThread]: 
[0m17:00:45.747867 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:00:45.748322 [info ] [MainThread]: 
[0m17:00:45.748880 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:00:45.749928 [debug] [MainThread]: Command `dbt run` succeeded at 17:00:45.749765 after 10.41 seconds
[0m17:00:45.750618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047dc090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100909190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100906690>]}
[0m17:00:45.751328 [debug] [MainThread]: Flushing usage events
[0m17:01:31.443834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e780d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e6ebd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e8bfd0>]}


============================== 17:01:31.445456 | 47b847f9-1957-4ac8-bc21-bba6a5a3bde2 ==============================
[0m17:01:31.445456 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:01:31.445754 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'static_parser': 'True', 'quiet': 'False', 'version_check': 'True', 'log_format': 'default', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'no_print': 'None', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'use_experimental_parser': 'False', 'introspect': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m17:01:31.475130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '47b847f9-1957-4ac8-bc21-bba6a5a3bde2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e94d10>]}
[0m17:01:31.481244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '47b847f9-1957-4ac8-bc21-bba6a5a3bde2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f60fd0>]}
[0m17:01:31.481673 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:01:31.491752 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m17:01:31.512885 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:01:31.513197 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m17:01:31.513324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47b847f9-1957-4ac8-bc21-bba6a5a3bde2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a8bf50>]}
[0m17:01:31.823898 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:01:31.834982 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:01:31.836017 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:01:31.839239 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:01:31.873863 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:01:31.875960 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47b847f9-1957-4ac8-bc21-bba6a5a3bde2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b28e10>]}
[0m17:01:31.879924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47b847f9-1957-4ac8-bc21-bba6a5a3bde2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ba00d0>]}
[0m17:01:31.880111 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:01:31.880273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47b847f9-1957-4ac8-bc21-bba6a5a3bde2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e848d0>]}
[0m17:01:31.880862 [debug] [MainThread]: Command `dbt ls` succeeded at 17:01:31.880804 after 0.45 seconds
[0m17:01:31.881018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101528390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101526610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1015266d0>]}
[0m17:01:31.881144 [debug] [MainThread]: Flushing usage events
[0m17:02:10.942613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f84c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f8bd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f8bf90>]}


============================== 17:02:10.944308 | ed2ce5e2-7c39-4506-aef2-8e02ae9677f0 ==============================
[0m17:02:10.944308 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:02:10.944617 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'partial_parse': 'True', 'static_parser': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'use_experimental_parser': 'False', 'debug': 'False', 'log_cache_events': 'False', 'version_check': 'True', 'log_format': 'default', 'no_print': 'None', 'printer_width': '80', 'quiet': 'False', 'indirect_selection': 'eager', 'warn_error': 'None'}
[0m17:02:10.974511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f94950>]}
[0m17:02:10.980661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110361010>]}
[0m17:02:10.981118 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:02:10.991679 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:02:11.012485 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:02:11.012761 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m17:02:11.012876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110487f90>]}
[0m17:02:11.318518 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:02:11.329554 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:02:11.330579 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:02:11.333794 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:02:11.367557 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:02:11.369528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110352f50>]}
[0m17:02:11.372478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106a5990>]}
[0m17:02:11.372643 [info ] [MainThread]: Found 2 models, 2 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:02:11.372791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042e4150>]}
[0m17:02:11.373331 [info ] [MainThread]: 
[0m17:02:11.373645 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:02:11.374103 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:02:11.378339 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:02:11.378540 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:02:11.378671 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:02:11.753624 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:02:11.758337 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:02:11.761711 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:02:11.769959 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:02:11.770611 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:02:11.771152 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:02:12.049811 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:02:12.051517 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:02:12.052952 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:02:12.091721 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:02:12.096085 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:02:12.131149 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:02:12.144613 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:12.145197 [debug] [MainThread]: On master: BEGIN
[0m17:02:12.145598 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:02:12.466007 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:02:12.467964 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:12.469157 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:02:12.517369 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:02:12.521888 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110467ed0>]}
[0m17:02:12.523428 [debug] [MainThread]: On master: ROLLBACK
[0m17:02:12.559530 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:12.559843 [debug] [MainThread]: On master: BEGIN
[0m17:02:12.647121 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:02:12.648110 [debug] [MainThread]: On master: COMMIT
[0m17:02:12.648697 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:12.649126 [debug] [MainThread]: On master: COMMIT
[0m17:02:12.686412 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:02:12.687644 [debug] [MainThread]: On master: Close
[0m17:02:12.689642 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:02:12.690441 [info ] [MainThread]: 
[0m17:02:12.699005 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:02:12.699983 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:02:12.700893 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:02:12.701276 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:02:12.713718 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:12.714763 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:02:12.701518 => 17:02:12.714522
[0m17:02:12.715109 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:02:12.739029 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:12.739876 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:12.740124 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:02:12.740306 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:02:13.015313 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:02:13.016680 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:13.017993 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:02:23.896202 [debug] [Thread-1 (]: SQL status: SELECT 156470 in 11.0 seconds
[0m17:02:23.909846 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:23.910557 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:02:23.944498 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:02:23.952180 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:23.953122 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:02:23.986975 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:02:24.014939 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:02:24.015477 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:24.015757 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:02:24.049313 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:02:24.054789 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:02:24.055132 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:02:24.107638 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:02:24.110637 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:02:12.715301 => 17:02:24.110306
[0m17:02:24.111307 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:02:24.113010 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed2ce5e2-7c39-4506-aef2-8e02ae9677f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110455810>]}
[0m17:02:24.113940 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156470[0m in 11.41s]
[0m17:02:24.115000 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:02:24.116670 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:24.117105 [debug] [MainThread]: On master: BEGIN
[0m17:02:24.117416 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:02:24.375378 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:02:24.376348 [debug] [MainThread]: On master: COMMIT
[0m17:02:24.376823 [debug] [MainThread]: Using postgres connection "master"
[0m17:02:24.377109 [debug] [MainThread]: On master: COMMIT
[0m17:02:24.408490 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:02:24.409921 [debug] [MainThread]: On master: Close
[0m17:02:24.412723 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:02:24.413277 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m17:02:24.413875 [info ] [MainThread]: 
[0m17:02:24.414589 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 13.04 seconds (13.04s).
[0m17:02:24.416034 [debug] [MainThread]: Command end result
[0m17:02:24.429625 [info ] [MainThread]: 
[0m17:02:24.430208 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:02:24.430585 [info ] [MainThread]: 
[0m17:02:24.430972 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:02:24.431613 [debug] [MainThread]: Command `dbt run` succeeded at 17:02:24.431503 after 13.50 seconds
[0m17:02:24.431978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f97c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f1a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e38410>]}
[0m17:02:24.432299 [debug] [MainThread]: Flushing usage events
[0m17:04:28.615723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922bcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109247a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109247f90>]}


============================== 17:04:28.617520 | a168f323-72cc-44f9-b347-eebce21f4c5c ==============================
[0m17:04:28.617520 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:04:28.617812 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'no_print': 'None', 'target_path': 'None', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'version_check': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'warn_error': 'None', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'cache_selected_only': 'False', 'write_json': 'True', 'quiet': 'False'}
[0m17:04:28.646416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a168f323-72cc-44f9-b347-eebce21f4c5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096cddd0>]}
[0m17:04:28.652520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a168f323-72cc-44f9-b347-eebce21f4c5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bdd650>]}
[0m17:04:28.652920 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:04:28.662876 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:04:28.689577 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:04:28.689777 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:04:28.689991 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:04:28.692292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a168f323-72cc-44f9-b347-eebce21f4c5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109776dd0>]}
[0m17:04:28.696561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a168f323-72cc-44f9-b347-eebce21f4c5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109247910>]}
[0m17:04:28.696756 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:04:28.696913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a168f323-72cc-44f9-b347-eebce21f4c5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106704150>]}
[0m17:04:28.697468 [info ] [MainThread]: 
[0m17:04:28.697800 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:04:28.698224 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:04:28.702656 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:04:28.702880 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:04:28.703005 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:04:28.969437 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:04:28.971241 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:04:28.972833 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:04:28.978168 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:04:28.978456 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:04:28.978665 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:04:29.234277 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:04:29.235959 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:04:29.236609 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:04:29.291137 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:04:29.295282 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:04:29.326513 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:04:29.340133 [debug] [MainThread]: Using postgres connection "master"
[0m17:04:29.340566 [debug] [MainThread]: On master: BEGIN
[0m17:04:29.341018 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:04:29.619233 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:04:29.620318 [debug] [MainThread]: Using postgres connection "master"
[0m17:04:29.621100 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:04:29.662979 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:04:29.667983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a168f323-72cc-44f9-b347-eebce21f4c5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b5c90>]}
[0m17:04:29.668954 [debug] [MainThread]: On master: ROLLBACK
[0m17:04:29.700259 [debug] [MainThread]: Using postgres connection "master"
[0m17:04:29.701239 [debug] [MainThread]: On master: BEGIN
[0m17:04:29.784699 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:04:29.785568 [debug] [MainThread]: On master: COMMIT
[0m17:04:29.786338 [debug] [MainThread]: Using postgres connection "master"
[0m17:04:29.787042 [debug] [MainThread]: On master: COMMIT
[0m17:04:29.817948 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:04:29.819056 [debug] [MainThread]: On master: Close
[0m17:04:29.822130 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:04:29.822913 [info ] [MainThread]: 
[0m17:04:29.832755 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:04:29.833556 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:04:29.834583 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:04:29.835154 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:04:29.857594 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:29.858836 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:04:29.835614 => 17:04:29.858675
[0m17:04:29.859106 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:04:29.881034 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:29.881603 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:29.881790 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:04:29.881958 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:04:30.157940 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:04:30.159221 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:30.160173 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:04:38.971541 [debug] [Thread-1 (]: SQL status: SELECT 156470 in 9.0 seconds
[0m17:04:38.985689 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:38.986275 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:04:39.020095 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:04:39.024867 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:39.025505 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:04:39.059614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:04:39.084772 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:04:39.085235 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:39.085512 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:04:39.118421 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:04:39.123858 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:04:39.124191 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:04:39.174458 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:04:39.178259 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:04:29.859253 => 17:04:39.177817
[0m17:04:39.179058 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:04:39.180857 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a168f323-72cc-44f9-b347-eebce21f4c5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10987a1d0>]}
[0m17:04:39.181873 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156470[0m in 9.35s]
[0m17:04:39.182807 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:04:39.185127 [debug] [MainThread]: Using postgres connection "master"
[0m17:04:39.185533 [debug] [MainThread]: On master: BEGIN
[0m17:04:39.185825 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:04:39.463796 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:04:39.465559 [debug] [MainThread]: On master: COMMIT
[0m17:04:39.466538 [debug] [MainThread]: Using postgres connection "master"
[0m17:04:39.467424 [debug] [MainThread]: On master: COMMIT
[0m17:04:39.498087 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:04:39.498729 [debug] [MainThread]: On master: Close
[0m17:04:39.500385 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:04:39.500856 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m17:04:39.501438 [info ] [MainThread]: 
[0m17:04:39.502122 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 10.80 seconds (10.80s).
[0m17:04:39.503368 [debug] [MainThread]: Command end result
[0m17:04:39.518053 [info ] [MainThread]: 
[0m17:04:39.518797 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:04:39.519204 [info ] [MainThread]: 
[0m17:04:39.519599 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:04:39.520291 [debug] [MainThread]: Command `dbt run` succeeded at 17:04:39.520183 after 10.92 seconds
[0m17:04:39.520687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d30310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10536e690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105371190>]}
[0m17:04:39.521144 [debug] [MainThread]: Flushing usage events
[0m17:04:52.868305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10666d790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fd52d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106694e10>]}


============================== 17:04:52.869731 | 513ae3bd-b758-4676-8778-2b877a6e9342 ==============================
[0m17:04:52.869731 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:04:52.870029 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'fail_fast': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'version_check': 'True', 'quiet': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'no_print': 'None', 'write_json': 'True', 'introspect': 'True', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'cache_selected_only': 'False', 'log_format': 'default'}
[0m17:04:52.898723 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '513ae3bd-b758-4676-8778-2b877a6e9342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066782d0>]}
[0m17:04:52.904891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '513ae3bd-b758-4676-8778-2b877a6e9342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106921490>]}
[0m17:04:52.905304 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:04:52.916397 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m17:04:52.934319 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:04:52.934603 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m17:04:52.934730 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '513ae3bd-b758-4676-8778-2b877a6e9342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b83e90>]}
[0m17:04:53.248806 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:04:53.260015 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:04:53.261101 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:04:53.264442 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:04:53.302978 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:04:53.304916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '513ae3bd-b758-4676-8778-2b877a6e9342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b87ed0>]}
[0m17:04:53.308376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '513ae3bd-b758-4676-8778-2b877a6e9342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106db0fd0>]}
[0m17:04:53.308547 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:04:53.308695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '513ae3bd-b758-4676-8778-2b877a6e9342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106db3fd0>]}
[0m17:04:53.309245 [debug] [MainThread]: Command `dbt ls` succeeded at 17:04:53.309189 after 0.45 seconds
[0m17:04:53.309397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101534390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101532610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1015326d0>]}
[0m17:04:53.309530 [debug] [MainThread]: Flushing usage events
[0m17:05:04.695964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070f63d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fbe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fbfd0>]}


============================== 17:05:04.697155 | 333d9236-dfee-4781-97d7-08f9b1478889 ==============================
[0m17:05:04.697155 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:05:04.697444 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'target_path': 'None', 'no_print': 'None', 'cache_selected_only': 'False', 'printer_width': '80', 'fail_fast': 'False', 'quiet': 'False', 'debug': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'use_colors': 'True', 'warn_error': 'None', 'introspect': 'True', 'log_format': 'default', 'version_check': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m17:05:04.724593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107553150>]}
[0m17:05:04.730695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107580c50>]}
[0m17:05:04.730978 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:05:04.740315 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:05:04.759440 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:05:04.759706 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m17:05:04.759822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076a7e10>]}
[0m17:05:05.066054 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:05:05.077200 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:05:05.078234 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:05:05.081569 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:05:05.119073 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:05:05.121048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760bad0>]}
[0m17:05:05.124890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077ca410>]}
[0m17:05:05.125077 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:05:05.125241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045b83d0>]}
[0m17:05:05.125828 [info ] [MainThread]: 
[0m17:05:05.126158 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:05:05.126565 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:05:05.130823 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:05:05.131047 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:05:05.131177 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:05:05.473062 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:05:05.476460 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:05:05.479607 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:05:05.488046 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:05:05.488541 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:05:05.488806 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:05:05.844720 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:05:05.846020 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:05:05.847014 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:05:05.893989 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:05:05.898392 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:05:05.941303 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:05:05.955971 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:05.956508 [debug] [MainThread]: On master: BEGIN
[0m17:05:05.956804 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:05:06.235424 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:05:06.235805 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:06.236150 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:05:06.279398 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:05:06.281039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107689950>]}
[0m17:05:06.281395 [debug] [MainThread]: On master: ROLLBACK
[0m17:05:06.314683 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:06.314968 [debug] [MainThread]: On master: BEGIN
[0m17:05:06.399166 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:05:06.400446 [debug] [MainThread]: On master: COMMIT
[0m17:05:06.401176 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:06.401755 [debug] [MainThread]: On master: COMMIT
[0m17:05:06.435997 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:05:06.438096 [debug] [MainThread]: On master: Close
[0m17:05:06.440906 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:05:06.441766 [info ] [MainThread]: 
[0m17:05:06.450934 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:06.451741 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:05:06.452686 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:05:06.453120 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:06.466218 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:06.467126 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:05:06.453428 => 17:05:06.466944
[0m17:05:06.467446 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:06.490457 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:06.490982 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:06.491162 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:05:06.491330 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:05:06.794021 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:05:06.795538 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:06.796702 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:05:17.807482 [debug] [Thread-1 (]: SQL status: SELECT 156470 in 11.0 seconds
[0m17:05:17.820196 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:17.820778 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:05:17.858307 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:05:17.864576 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:17.865337 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:05:17.903053 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:05:17.930631 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:05:17.931100 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:17.931378 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:05:17.969072 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:05:17.976231 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:17.976640 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:05:18.032570 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:05:18.035903 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:05:06.467623 => 17:05:18.035534
[0m17:05:18.036689 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:05:18.038674 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '333d9236-dfee-4781-97d7-08f9b1478889', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b4e10>]}
[0m17:05:18.039679 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156470[0m in 11.59s]
[0m17:05:18.040633 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:18.043072 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:18.043516 [debug] [MainThread]: On master: BEGIN
[0m17:05:18.043910 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:05:18.384049 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:05:18.385153 [debug] [MainThread]: On master: COMMIT
[0m17:05:18.386188 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:18.386875 [debug] [MainThread]: On master: COMMIT
[0m17:05:18.426088 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:05:18.426550 [debug] [MainThread]: On master: Close
[0m17:05:18.428259 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:05:18.428690 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m17:05:18.429146 [info ] [MainThread]: 
[0m17:05:18.429591 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 13.30 seconds (13.30s).
[0m17:05:18.430403 [debug] [MainThread]: Command end result
[0m17:05:18.443993 [info ] [MainThread]: 
[0m17:05:18.444327 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:05:18.444580 [info ] [MainThread]: 
[0m17:05:18.444861 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:05:18.445238 [debug] [MainThread]: Command `dbt run` succeeded at 17:05:18.445183 after 13.76 seconds
[0m17:05:18.445585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1031541d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032227d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103222750>]}
[0m17:05:18.445971 [debug] [MainThread]: Flushing usage events
[0m17:05:21.873551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105878fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105885650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10588bfd0>]}


============================== 17:05:21.875008 | f47a4fa5-cb5c-4ec5-900f-d462505a25f8 ==============================
[0m17:05:21.875008 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:05:21.875326 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'printer_width': '80', 'no_print': 'None', 'profiles_dir': '/Users/danila/.dbt', 'indirect_selection': 'eager', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'use_colors': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'introspect': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True'}
[0m17:05:21.902758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f47a4fa5-cb5c-4ec5-900f-d462505a25f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10586ec90>]}
[0m17:05:21.908928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f47a4fa5-cb5c-4ec5-900f-d462505a25f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c21190>]}
[0m17:05:21.909209 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:05:21.918760 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:05:21.948242 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:05:21.948433 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:05:21.948643 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:05:21.950896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f47a4fa5-cb5c-4ec5-900f-d462505a25f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10589d910>]}
[0m17:05:21.954092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f47a4fa5-cb5c-4ec5-900f-d462505a25f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105884590>]}
[0m17:05:21.954250 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:05:21.954394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f47a4fa5-cb5c-4ec5-900f-d462505a25f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1025d8150>]}
[0m17:05:21.954935 [info ] [MainThread]: 
[0m17:05:21.955242 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:05:21.955656 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:05:21.959509 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:05:21.959636 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:05:21.959735 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:05:22.363719 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:05:22.366196 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:05:22.368754 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:05:22.374720 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:05:22.375033 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:05:22.375270 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:05:22.654493 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:05:22.655456 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:05:22.655852 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:05:22.690081 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:05:22.694231 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:05:22.725397 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:05:22.739154 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:22.739618 [debug] [MainThread]: On master: BEGIN
[0m17:05:22.739952 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:05:23.022410 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:05:23.023966 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:23.025346 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:05:23.071513 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:05:23.076982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f47a4fa5-cb5c-4ec5-900f-d462505a25f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bdbe90>]}
[0m17:05:23.077982 [debug] [MainThread]: On master: ROLLBACK
[0m17:05:23.108930 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:23.109791 [debug] [MainThread]: On master: BEGIN
[0m17:05:23.170495 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:05:23.171035 [debug] [MainThread]: On master: COMMIT
[0m17:05:23.171236 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:23.171409 [debug] [MainThread]: On master: COMMIT
[0m17:05:23.202041 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:05:23.202281 [debug] [MainThread]: On master: Close
[0m17:05:23.203149 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:05:23.203449 [info ] [MainThread]: 
[0m17:05:23.206418 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:23.206834 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:05:23.207355 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:05:23.207593 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:23.223655 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:23.225082 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:05:23.207743 => 17:05:23.224946
[0m17:05:23.225302 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:23.244328 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:23.244730 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:23.244907 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:05:23.245051 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:05:23.567404 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:05:23.569242 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:23.570743 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:05:33.933073 [debug] [Thread-1 (]: SQL status: SELECT 156470 in 10.0 seconds
[0m17:05:33.946546 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:33.947155 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:05:33.986896 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:05:33.992932 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:33.993593 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:05:34.033923 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:05:34.058364 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:05:34.058872 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:34.059167 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:05:34.099256 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:05:34.104632 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:05:34.105017 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:05:34.162421 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:05:34.165809 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:05:23.225421 => 17:05:34.165384
[0m17:05:34.166572 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:05:34.168753 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f47a4fa5-cb5c-4ec5-900f-d462505a25f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c91fd0>]}
[0m17:05:34.170023 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156470[0m in 10.96s]
[0m17:05:34.171179 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:05:34.173807 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:34.174223 [debug] [MainThread]: On master: BEGIN
[0m17:05:34.174566 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:05:34.532092 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:05:34.533711 [debug] [MainThread]: On master: COMMIT
[0m17:05:34.534573 [debug] [MainThread]: Using postgres connection "master"
[0m17:05:34.535361 [debug] [MainThread]: On master: COMMIT
[0m17:05:34.626631 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:05:34.627992 [debug] [MainThread]: On master: Close
[0m17:05:34.629973 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:05:34.630477 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m17:05:34.631100 [info ] [MainThread]: 
[0m17:05:34.631802 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 12.68 seconds (12.68s).
[0m17:05:34.632863 [debug] [MainThread]: Command end result
[0m17:05:34.645387 [info ] [MainThread]: 
[0m17:05:34.646056 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:05:34.646431 [info ] [MainThread]: 
[0m17:05:34.646860 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:05:34.647640 [debug] [MainThread]: Command `dbt run` succeeded at 17:05:34.647518 after 12.78 seconds
[0m17:05:34.648087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c5ae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101244410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101242750>]}
[0m17:05:34.648493 [debug] [MainThread]: Flushing usage events
[0m17:13:01.068711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b51f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b69650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b6ffd0>]}


============================== 17:13:01.070541 | daea319d-b6a9-4e05-865f-ad237d47bacd ==============================
[0m17:13:01.070541 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:13:01.070846 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'use_colors': 'True', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'fail_fast': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'target_path': 'None', 'debug': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False'}
[0m17:13:01.099803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'daea319d-b6a9-4e05-865f-ad237d47bacd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b6f850>]}
[0m17:13:01.105898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'daea319d-b6a9-4e05-865f-ad237d47bacd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ff4210>]}
[0m17:13:01.106349 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:13:01.117288 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:13:01.155645 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:13:01.155823 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:13:01.156037 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:13:01.158295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'daea319d-b6a9-4e05-865f-ad237d47bacd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10710a8d0>]}
[0m17:13:01.162337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'daea319d-b6a9-4e05-865f-ad237d47bacd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b69e90>]}
[0m17:13:01.162492 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:13:01.162648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'daea319d-b6a9-4e05-865f-ad237d47bacd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10402c150>]}
[0m17:13:01.163193 [info ] [MainThread]: 
[0m17:13:01.163516 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:13:01.163948 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:13:01.168207 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:13:01.168406 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:13:01.168533 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:13:01.466856 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:13:01.471609 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:13:01.475268 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:13:01.484150 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:13:01.484688 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:13:01.485014 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:13:01.794536 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:13:01.794962 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:13:01.795202 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:13:01.834863 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:13:01.836579 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:13:01.873846 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:13:01.887401 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:01.887807 [debug] [MainThread]: On master: BEGIN
[0m17:13:01.888137 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:13:02.262972 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:13:02.264645 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:02.265979 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:13:02.315816 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:13:02.321318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'daea319d-b6a9-4e05-865f-ad237d47bacd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b52a50>]}
[0m17:13:02.322036 [debug] [MainThread]: On master: ROLLBACK
[0m17:13:02.360933 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:02.361764 [debug] [MainThread]: On master: BEGIN
[0m17:13:02.440688 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:13:02.442089 [debug] [MainThread]: On master: COMMIT
[0m17:13:02.443181 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:02.444061 [debug] [MainThread]: On master: COMMIT
[0m17:13:02.483400 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:13:02.484617 [debug] [MainThread]: On master: Close
[0m17:13:02.486316 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:13:02.486949 [info ] [MainThread]: 
[0m17:13:02.496814 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:13:02.497584 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:13:02.498539 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:13:02.499103 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:13:02.520973 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:02.521851 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:13:02.499486 => 17:13:02.521723
[0m17:13:02.521992 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:13:02.542306 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:02.542739 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:02.542913 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:13:02.543069 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:13:02.798941 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:13:02.800179 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:02.801366 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:13:11.776900 [debug] [Thread-1 (]: SQL status: SELECT 156504 in 9.0 seconds
[0m17:13:11.791391 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:11.792047 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:13:11.822503 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:13:11.827654 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:11.828505 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:13:11.859559 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:13:11.885842 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:13:11.886325 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:11.886616 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:13:11.917678 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:13:11.923001 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:13:11.923343 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:13:11.971674 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:13:11.974609 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:13:02.522074 => 17:13:11.974251
[0m17:13:11.975242 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:13:11.977031 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'daea319d-b6a9-4e05-865f-ad237d47bacd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107116c50>]}
[0m17:13:11.978189 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156504[0m in 9.48s]
[0m17:13:11.979046 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:13:11.981015 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:11.981486 [debug] [MainThread]: On master: BEGIN
[0m17:13:11.981797 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:13:12.244354 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:13:12.246042 [debug] [MainThread]: On master: COMMIT
[0m17:13:12.246993 [debug] [MainThread]: Using postgres connection "master"
[0m17:13:12.247856 [debug] [MainThread]: On master: COMMIT
[0m17:13:12.279631 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:13:12.280316 [debug] [MainThread]: On master: Close
[0m17:13:12.281998 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:13:12.282496 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m17:13:12.283049 [info ] [MainThread]: 
[0m17:13:12.283707 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 11.12 seconds (11.12s).
[0m17:13:12.284926 [debug] [MainThread]: Command end result
[0m17:13:12.298682 [info ] [MainThread]: 
[0m17:13:12.299361 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:13:12.299746 [info ] [MainThread]: 
[0m17:13:12.300120 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:13:12.300810 [debug] [MainThread]: Command `dbt run` succeeded at 17:13:12.300705 after 11.24 seconds
[0m17:13:12.301199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046aee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c98450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071f4190>]}
[0m17:13:12.301555 [debug] [MainThread]: Flushing usage events
[0m17:14:14.574101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052f6e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106959650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695ffd0>]}


============================== 17:14:14.575670 | f2838a8e-3d29-47c9-905b-01a82ce88ddc ==============================
[0m17:14:14.575670 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:14:14.575979 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'write_json': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'introspect': 'True', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'log_format': 'default', 'debug': 'False', 'log_cache_events': 'False', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'target_path': 'None', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m17:14:14.604523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f2838a8e-3d29-47c9-905b-01a82ce88ddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10694d890>]}
[0m17:14:14.610668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f2838a8e-3d29-47c9-905b-01a82ce88ddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ddfd50>]}
[0m17:14:14.611073 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:14:14.620858 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:14:14.646783 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:14:14.646972 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:14:14.647182 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:14:14.649439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f2838a8e-3d29-47c9-905b-01a82ce88ddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106efa750>]}
[0m17:14:14.653686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f2838a8e-3d29-47c9-905b-01a82ce88ddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dd2550>]}
[0m17:14:14.653878 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:14:14.654047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f2838a8e-3d29-47c9-905b-01a82ce88ddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103e1c150>]}
[0m17:14:14.654552 [info ] [MainThread]: 
[0m17:14:14.654876 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:14:14.655328 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:14:14.659568 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:14:14.659750 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:14:14.659885 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:14:14.941129 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:14:14.944117 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:14:14.946508 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:14:14.953024 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:14:14.953385 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:14:14.953638 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:14:15.285672 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:14:15.287314 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:14:15.288166 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:14:15.330913 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:14:15.334977 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:14:15.372281 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:14:15.385569 [debug] [MainThread]: Using postgres connection "master"
[0m17:14:15.385971 [debug] [MainThread]: On master: BEGIN
[0m17:14:15.386288 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:14:15.693686 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:14:15.695227 [debug] [MainThread]: Using postgres connection "master"
[0m17:14:15.696157 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:14:15.761868 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:14:15.765258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f2838a8e-3d29-47c9-905b-01a82ce88ddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069738d0>]}
[0m17:14:15.766069 [debug] [MainThread]: On master: ROLLBACK
[0m17:14:15.796201 [debug] [MainThread]: Using postgres connection "master"
[0m17:14:15.796492 [debug] [MainThread]: On master: BEGIN
[0m17:14:15.858318 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:14:15.859443 [debug] [MainThread]: On master: COMMIT
[0m17:14:15.859837 [debug] [MainThread]: Using postgres connection "master"
[0m17:14:15.860162 [debug] [MainThread]: On master: COMMIT
[0m17:14:15.891097 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:14:15.891758 [debug] [MainThread]: On master: Close
[0m17:14:15.893927 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:14:15.894653 [info ] [MainThread]: 
[0m17:14:15.902983 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:14:15.903793 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:14:15.904651 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:14:15.905065 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:14:15.925468 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:15.926136 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:14:15.905327 => 17:14:15.925984
[0m17:14:15.926372 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:14:15.946804 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:15.947260 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:15.947433 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:14:15.947594 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:14:16.258057 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:14:16.259572 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:16.261244 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:14:35.522287 [debug] [Thread-1 (]: SQL status: SELECT 156530 in 19.0 seconds
[0m17:14:35.542887 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:35.543703 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:14:35.581571 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:14:35.590859 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:35.591568 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:14:35.628994 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:14:35.665279 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:14:35.665952 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:35.666348 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:14:35.702987 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:14:35.713150 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:14:35.713833 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:14:35.768370 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:14:35.771800 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:14:15.926502 => 17:14:35.771456
[0m17:14:35.772346 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:14:35.774283 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f2838a8e-3d29-47c9-905b-01a82ce88ddc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106df6c50>]}
[0m17:14:35.776920 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156530[0m in 19.87s]
[0m17:14:35.779269 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:14:35.782953 [debug] [MainThread]: Using postgres connection "master"
[0m17:14:35.783797 [debug] [MainThread]: On master: BEGIN
[0m17:14:35.784669 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:14:36.189571 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:14:36.191272 [debug] [MainThread]: On master: COMMIT
[0m17:14:36.192240 [debug] [MainThread]: Using postgres connection "master"
[0m17:14:36.193100 [debug] [MainThread]: On master: COMMIT
[0m17:14:36.236377 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:14:36.237598 [debug] [MainThread]: On master: Close
[0m17:14:36.239852 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:14:36.240445 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m17:14:36.241502 [info ] [MainThread]: 
[0m17:14:36.242964 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 21.59 seconds (21.59s).
[0m17:14:36.244908 [debug] [MainThread]: Command end result
[0m17:14:36.264248 [info ] [MainThread]: 
[0m17:14:36.265351 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:14:36.265951 [info ] [MainThread]: 
[0m17:14:36.266691 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m17:14:36.267994 [debug] [MainThread]: Command `dbt run` succeeded at 17:14:36.267865 after 21.70 seconds
[0m17:14:36.268818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10696bad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10696bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a88410>]}
[0m17:14:36.269605 [debug] [MainThread]: Flushing usage events
[0m17:15:49.065483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12226f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122289650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12228bfd0>]}


============================== 17:15:49.067076 | 9717ed38-333c-4508-a80a-516847df725b ==============================
[0m17:15:49.067076 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:15:49.067396 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'static_parser': 'True', 'indirect_selection': 'eager', 'printer_width': '80', 'use_experimental_parser': 'False', 'version_check': 'True', 'target_path': 'None', 'no_print': 'None', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'debug': 'False', 'cache_selected_only': 'False', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'log_format': 'default', 'introspect': 'True'}
[0m17:15:49.096459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9717ed38-333c-4508-a80a-516847df725b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10605d910>]}
[0m17:15:49.102635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9717ed38-333c-4508-a80a-516847df725b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122761810>]}
[0m17:15:49.103040 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:15:49.113515 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m17:15:49.131394 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:15:49.131661 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m17:15:49.131793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9717ed38-333c-4508-a80a-516847df725b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122883f90>]}
[0m17:15:49.437375 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:15:49.448342 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:15:49.449325 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:15:49.452553 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:15:49.486935 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:15:49.488856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9717ed38-333c-4508-a80a-516847df725b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222aaf90>]}
[0m17:15:49.491827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9717ed38-333c-4508-a80a-516847df725b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122bad010>]}
[0m17:15:49.491979 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:15:49.492128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9717ed38-333c-4508-a80a-516847df725b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122287210>]}
[0m17:15:49.492699 [debug] [MainThread]: Command `dbt ls` succeeded at 17:15:49.492640 after 0.44 seconds
[0m17:15:49.492850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e88390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e86610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102e866d0>]}
[0m17:15:49.492987 [debug] [MainThread]: Flushing usage events
[0m17:16:39.633473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e78210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e85650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e90850>]}


============================== 17:16:39.635090 | 1208c5dd-c863-4580-96e0-0ba62f6b290c ==============================
[0m17:16:39.635090 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:16:39.635381 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'static_parser': 'True', 'no_print': 'None', 'target_path': 'None', 'use_experimental_parser': 'False', 'debug': 'False', 'warn_error': 'None', 'partial_parse': 'True', 'printer_width': '80', 'quiet': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'cache_selected_only': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'version_check': 'True', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m17:16:39.664714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e79d50>]}
[0m17:16:39.670845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e79d50>]}
[0m17:16:39.671235 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:16:39.681354 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:16:39.700158 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:16:39.700429 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m17:16:39.700560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111487e10>]}
[0m17:16:40.017718 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:16:40.028914 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:16:40.029938 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:16:40.033291 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:16:40.069447 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:16:40.071399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113ac110>]}
[0m17:16:40.074552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116aa990>]}
[0m17:16:40.074727 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:16:40.074881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113339d0>]}
[0m17:16:40.075532 [info ] [MainThread]: 
[0m17:16:40.075839 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:16:40.076266 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:16:40.080445 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:16:40.080638 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:16:40.080751 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:16:40.448127 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:16:40.452568 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:16:40.455692 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:16:40.463333 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:16:40.463821 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:16:40.464082 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:16:40.725456 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:16:40.726791 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:16:40.727577 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:16:40.762611 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:16:40.766466 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:16:40.797835 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:16:40.811668 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:40.812071 [debug] [MainThread]: On master: BEGIN
[0m17:16:40.812344 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:16:41.086577 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:16:41.086877 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:41.087074 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:16:41.130127 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:16:41.131396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e6ff90>]}
[0m17:16:41.131692 [debug] [MainThread]: On master: ROLLBACK
[0m17:16:41.164379 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:41.164625 [debug] [MainThread]: On master: BEGIN
[0m17:16:41.261674 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:16:41.262896 [debug] [MainThread]: On master: COMMIT
[0m17:16:41.263630 [debug] [MainThread]: Using postgres connection "master"
[0m17:16:41.264271 [debug] [MainThread]: On master: COMMIT
[0m17:16:41.310537 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:16:41.311592 [debug] [MainThread]: On master: Close
[0m17:16:41.313382 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:16:41.314017 [info ] [MainThread]: 
[0m17:16:41.320666 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:16:41.321189 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:16:41.321923 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:16:41.322247 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:16:41.332625 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:41.333248 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:16:41.322449 => 17:16:41.333101
[0m17:16:41.333484 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:16:41.356502 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:41.357003 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:41.357178 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:16:41.357334 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:41.963215 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m17:16:41.965019 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:41.966597 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:16:50.188189 [debug] [Thread-1 (]: SQL status: SELECT 156537 in 8.0 seconds
[0m17:16:50.201801 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:50.202483 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:16:50.240004 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:16:50.245888 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:50.246650 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:16:50.284351 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:16:50.312873 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:16:50.313399 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:50.313689 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:16:50.349965 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:16:50.355322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:16:50.355723 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:16:50.416486 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:16:50.420938 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:16:41.333628 => 17:16:50.420533
[0m17:16:50.421776 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:16:50.423888 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111474850>]}
[0m17:16:50.425056 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156537[0m in 9.10s]
[0m17:16:50.426311 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:16:50.427129 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m17:16:50.428139 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m17:16:50.429318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m17:16:50.429789 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m17:16:50.440581 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m17:16:50.443017 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 17:16:50.430136 => 17:16:50.442731
[0m17:16:50.443430 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m17:16:50.448436 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m17:16:50.449026 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:16:50.449290 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m17:16:50.449524 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:16:50.706219 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:16:50.707548 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:16:50.708625 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m17:17:02.331712 [debug] [Thread-1 (]: SQL status: SELECT 46533 in 12.0 seconds
[0m17:17:02.343737 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:17:02.344551 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m17:17:02.375378 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:17:02.381358 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:17:02.382020 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m17:17:02.413540 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:17:02.418033 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m17:17:02.418655 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:17:02.419188 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m17:17:02.450819 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:17:02.458441 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:17:02.459870 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m17:17:02.506039 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:17:02.510402 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 17:16:50.443671 => 17:17:02.509697
[0m17:17:02.511604 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m17:17:02.515250 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1208c5dd-c863-4580-96e0-0ba62f6b290c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116e4d90>]}
[0m17:17:02.516909 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46533[0m in 12.09s]
[0m17:17:02.518417 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m17:17:02.521719 [debug] [MainThread]: Using postgres connection "master"
[0m17:17:02.522650 [debug] [MainThread]: On master: BEGIN
[0m17:17:02.523464 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:17:02.916423 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:17:02.917795 [debug] [MainThread]: On master: COMMIT
[0m17:17:02.918349 [debug] [MainThread]: Using postgres connection "master"
[0m17:17:02.918779 [debug] [MainThread]: On master: COMMIT
[0m17:17:02.961090 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:17:02.961928 [debug] [MainThread]: On master: Close
[0m17:17:02.963611 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:17:02.964166 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m17:17:02.964787 [info ] [MainThread]: 
[0m17:17:02.965859 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 22.89 seconds (22.89s).
[0m17:17:02.968464 [debug] [MainThread]: Command end result
[0m17:17:02.985133 [info ] [MainThread]: 
[0m17:17:02.985967 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:17:02.986398 [info ] [MainThread]: 
[0m17:17:02.986897 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:17:02.987760 [debug] [MainThread]: Command `dbt run` succeeded at 17:17:02.987663 after 23.37 seconds
[0m17:17:02.988267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f2a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a94290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a925d0>]}
[0m17:17:02.988705 [debug] [MainThread]: Flushing usage events
[0m17:19:27.161399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10576e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105785650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105790c90>]}


============================== 17:19:27.163065 | 14bcb80f-a1ad-4963-92d4-aadec0ffcd66 ==============================
[0m17:19:27.163065 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:19:27.163402 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'no_print': 'None', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False', 'quiet': 'False', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'log_format': 'default', 'partial_parse': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'fail_fast': 'False', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None'}
[0m17:19:27.192483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '14bcb80f-a1ad-4963-92d4-aadec0ffcd66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057aa9d0>]}
[0m17:19:27.198687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '14bcb80f-a1ad-4963-92d4-aadec0ffcd66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057909d0>]}
[0m17:19:27.199120 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:19:27.208922 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m17:19:27.227093 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:19:27.227370 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m17:19:27.227503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '14bcb80f-a1ad-4963-92d4-aadec0ffcd66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c47e10>]}
[0m17:19:27.521487 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:19:27.532374 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:19:27.533364 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:19:27.536596 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:19:27.571073 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:19:27.573003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '14bcb80f-a1ad-4963-92d4-aadec0ffcd66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c52f50>]}
[0m17:19:27.576007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '14bcb80f-a1ad-4963-92d4-aadec0ffcd66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eaa350>]}
[0m17:19:27.576161 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:19:27.576311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '14bcb80f-a1ad-4963-92d4-aadec0ffcd66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b0ef50>]}
[0m17:19:27.576864 [debug] [MainThread]: Command `dbt ls` succeeded at 17:19:27.576812 after 0.42 seconds
[0m17:19:27.577013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1014d4390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1014d2610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1014d26d0>]}
[0m17:19:27.577137 [debug] [MainThread]: Flushing usage events
[0m17:19:42.186860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fcd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107109650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107113090>]}


============================== 17:19:42.188192 | 07da88bb-1bc8-469b-8842-14d1d4bf942d ==============================
[0m17:19:42.188192 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:19:42.188506 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'warn_error': 'None', 'introspect': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'target_path': 'None', 'log_cache_events': 'False', 'quiet': 'False', 'printer_width': '80', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'version_check': 'True', 'fail_fast': 'False', 'debug': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'partial_parse': 'True'}
[0m17:19:42.215652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070fdad0>]}
[0m17:19:42.221780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075941d0>]}
[0m17:19:42.222029 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:19:42.231391 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:19:42.249650 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:19:42.249920 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m17:19:42.250038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076bbf90>]}
[0m17:19:42.546116 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:19:42.557016 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:19:42.558008 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:19:42.561238 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:19:42.595825 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:19:42.597752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107750950>]}
[0m17:19:42.600738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107717090>]}
[0m17:19:42.600893 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:19:42.601043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045bbd10>]}
[0m17:19:42.601696 [info ] [MainThread]: 
[0m17:19:42.602004 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:19:42.602483 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:19:42.606500 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:19:42.606648 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:19:42.606746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:19:43.012142 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:19:43.016215 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:19:43.019547 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:19:43.028262 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:19:43.028759 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:19:43.029067 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:19:43.289744 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:19:43.291306 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:19:43.292331 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:19:43.328493 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:19:43.331278 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:19:43.361968 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:19:43.376824 [debug] [MainThread]: Using postgres connection "master"
[0m17:19:43.377260 [debug] [MainThread]: On master: BEGIN
[0m17:19:43.377598 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:19:43.730376 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:19:43.730917 [debug] [MainThread]: Using postgres connection "master"
[0m17:19:43.731204 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:19:43.787625 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:19:43.790083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d2150>]}
[0m17:19:43.790575 [debug] [MainThread]: On master: ROLLBACK
[0m17:19:43.834026 [debug] [MainThread]: Using postgres connection "master"
[0m17:19:43.834803 [debug] [MainThread]: On master: BEGIN
[0m17:19:43.919916 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:19:43.921136 [debug] [MainThread]: On master: COMMIT
[0m17:19:43.922074 [debug] [MainThread]: Using postgres connection "master"
[0m17:19:43.922924 [debug] [MainThread]: On master: COMMIT
[0m17:19:43.965346 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:19:43.966526 [debug] [MainThread]: On master: Close
[0m17:19:43.969027 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:19:43.969791 [info ] [MainThread]: 
[0m17:19:43.979771 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:19:43.980413 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:19:43.981289 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:19:43.981659 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:19:43.993412 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:43.994212 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:19:43.981920 => 17:19:43.994040
[0m17:19:43.994495 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:19:44.017155 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:44.017670 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:44.017851 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:19:44.018015 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:19:44.277208 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:19:44.278298 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:44.279301 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m17:19:55.364355 [debug] [Thread-1 (]: SQL status: SELECT 156553 in 11.0 seconds
[0m17:19:55.380597 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:55.381199 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:19:55.412143 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:19:55.420142 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:55.420875 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:19:55.452639 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:19:55.485769 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:19:55.486359 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:55.486745 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:19:55.517198 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:19:55.525024 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:19:55.525801 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:19:55.763266 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:19:55.765723 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:19:43.994661 => 17:19:55.765518
[0m17:19:55.766655 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:19:55.767972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075b3b90>]}
[0m17:19:55.768803 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156553[0m in 11.79s]
[0m17:19:55.769559 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:19:55.770047 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m17:19:55.770618 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m17:19:55.771460 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m17:19:55.771915 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m17:19:55.782443 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m17:19:55.783968 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 17:19:55.772227 => 17:19:55.783648
[0m17:19:55.784415 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m17:19:55.794586 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m17:19:55.796121 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:19:55.796555 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m17:19:55.796831 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:19:56.126100 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:19:56.127295 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:19:56.127932 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m17:20:03.161369 [debug] [Thread-1 (]: SQL status: SELECT 46533 in 7.0 seconds
[0m17:20:03.168800 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:20:03.169746 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m17:20:03.207471 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:20:03.213710 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:20:03.214968 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m17:20:03.252343 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:20:03.255980 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m17:20:03.256710 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:20:03.257269 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m17:20:03.294402 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:20:03.302481 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:20:03.303195 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m17:20:03.355198 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:20:03.358762 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 17:19:55.784643 => 17:20:03.358587
[0m17:20:03.359114 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m17:20:03.359923 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '07da88bb-1bc8-469b-8842-14d1d4bf942d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075f7890>]}
[0m17:20:03.360435 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46533[0m in 7.59s]
[0m17:20:03.362674 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m17:20:03.366122 [debug] [MainThread]: Using postgres connection "master"
[0m17:20:03.366464 [debug] [MainThread]: On master: BEGIN
[0m17:20:03.366707 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:20:03.678984 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:20:03.680522 [debug] [MainThread]: On master: COMMIT
[0m17:20:03.681461 [debug] [MainThread]: Using postgres connection "master"
[0m17:20:03.682812 [debug] [MainThread]: On master: COMMIT
[0m17:20:03.716965 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:20:03.717984 [debug] [MainThread]: On master: Close
[0m17:20:03.720433 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:20:03.721263 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m17:20:03.721803 [info ] [MainThread]: 
[0m17:20:03.722189 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 21.12 seconds (21.12s).
[0m17:20:03.724172 [debug] [MainThread]: Command end result
[0m17:20:03.739347 [info ] [MainThread]: 
[0m17:20:03.740129 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:20:03.740702 [info ] [MainThread]: 
[0m17:20:03.741208 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:20:03.742119 [debug] [MainThread]: Command `dbt run` succeeded at 17:20:03.741980 after 21.57 seconds
[0m17:20:03.742601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10710b7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b91690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032365d0>]}
[0m17:20:03.743000 [debug] [MainThread]: Flushing usage events
[0m17:31:09.170225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111275b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111285650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111292750>]}


============================== 17:31:09.171883 | b475f46d-92e0-4e32-9cec-51b245f7def2 ==============================
[0m17:31:09.171883 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:31:09.172206 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'printer_width': '80', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'partial_parse': 'True', 'use_colors': 'True', 'introspect': 'True', 'warn_error': 'None', 'version_check': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/danila/.dbt'}
[0m17:31:09.172444 [info ] [MainThread]: dbt version: 1.5.4
[0m17:31:09.172606 [info ] [MainThread]: python version: 3.11.9
[0m17:31:09.172755 [info ] [MainThread]: python path: /opt/anaconda3/envs/dbt_env2/bin/python3.11
[0m17:31:09.172886 [info ] [MainThread]: os info: macOS-14.4.1-arm64-arm-64bit
[0m17:31:09.173013 [info ] [MainThread]: Using profiles.yml file at /Users/danila/.dbt/profiles.yml
[0m17:31:09.173146 [info ] [MainThread]: Using dbt_project.yml file at /Users/danila/github/dbt/dbt_project.yml
[0m17:31:09.173266 [info ] [MainThread]: Configuration:
[0m17:31:09.194208 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:31:09.204024 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:31:09.204285 [info ] [MainThread]: Required dependencies:
[0m17:31:09.204480 [debug] [MainThread]: Executing "git --help"
[0m17:31:09.221502 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:31:09.221900 [debug] [MainThread]: STDERR: "b''"
[0m17:31:09.222018 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:31:09.222167 [info ] [MainThread]: Connection:
[0m17:31:09.222329 [info ] [MainThread]:   host: pg10-deepanalysis-db-do-user-3167072-0.b.db.ondigitalocean.com
[0m17:31:09.222455 [info ] [MainThread]:   port: 25060
[0m17:31:09.222569 [info ] [MainThread]:   user: doadmin
[0m17:31:09.222684 [info ] [MainThread]:   database: deep-analysis-console
[0m17:31:09.222799 [info ] [MainThread]:   schema: danila
[0m17:31:09.222915 [info ] [MainThread]:   search_path: None
[0m17:31:09.223028 [info ] [MainThread]:   keepalives_idle: 0
[0m17:31:09.223142 [info ] [MainThread]:   sslmode: require
[0m17:31:09.223595 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:31:09.226130 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m17:31:09.226512 [debug] [MainThread]: Using postgres connection "debug"
[0m17:31:09.226633 [debug] [MainThread]: On debug: select 1 as id
[0m17:31:09.226761 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:31:09.569573 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m17:31:09.574531 [debug] [MainThread]: On debug: Close
[0m17:31:09.576170 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m17:31:09.577042 [info ] [MainThread]: [32mAll checks passed![0m
[0m17:31:09.578576 [debug] [MainThread]: Command `dbt debug` succeeded at 17:31:09.578300 after 0.42 seconds
[0m17:31:09.579378 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:31:09.580056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c125d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c12650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11115d6d0>]}
[0m17:31:09.580922 [debug] [MainThread]: Flushing usage events
[0m17:31:59.313456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b7d8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b81650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b87910>]}


============================== 17:31:59.315281 | ce5a9141-b2e8-49a9-95f8-ce48711d9a16 ==============================
[0m17:31:59.315281 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:31:59.315586 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'fail_fast': 'False', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'log_format': 'default', 'cache_selected_only': 'False', 'debug': 'False', 'no_print': 'None', 'version_check': 'True', 'target_path': 'None', 'printer_width': '80', 'static_parser': 'True'}
[0m17:31:59.315812 [info ] [MainThread]: dbt version: 1.5.4
[0m17:31:59.315965 [info ] [MainThread]: python version: 3.11.9
[0m17:31:59.316115 [info ] [MainThread]: python path: /opt/anaconda3/envs/dbt_env2/bin/python3.11
[0m17:31:59.316245 [info ] [MainThread]: os info: macOS-14.4.1-arm64-arm-64bit
[0m17:31:59.316375 [info ] [MainThread]: Using profiles.yml file at /Users/danila/.dbt/profiles.yml
[0m17:31:59.316513 [info ] [MainThread]: Using dbt_project.yml file at /Users/danila/github/dbt/dbt_project.yml
[0m17:31:59.316630 [info ] [MainThread]: Configuration:
[0m17:31:59.338558 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:31:59.348859 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:31:59.349105 [info ] [MainThread]: Required dependencies:
[0m17:31:59.349284 [debug] [MainThread]: Executing "git --help"
[0m17:31:59.357630 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:31:59.358029 [debug] [MainThread]: STDERR: "b''"
[0m17:31:59.358159 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:31:59.358310 [info ] [MainThread]: Connection:
[0m17:31:59.358469 [info ] [MainThread]:   host: pg10-deepanalysis-db-do-user-3167072-0.b.db.ondigitalocean.com
[0m17:31:59.358592 [info ] [MainThread]:   port: 25060
[0m17:31:59.358706 [info ] [MainThread]:   user: doadmin
[0m17:31:59.358831 [info ] [MainThread]:   database: deep-analysis-console
[0m17:31:59.358945 [info ] [MainThread]:   schema: console
[0m17:31:59.359058 [info ] [MainThread]:   search_path: None
[0m17:31:59.359174 [info ] [MainThread]:   keepalives_idle: 0
[0m17:31:59.359287 [info ] [MainThread]:   sslmode: require
[0m17:31:59.359769 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:31:59.362820 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m17:31:59.363283 [debug] [MainThread]: Using postgres connection "debug"
[0m17:31:59.363416 [debug] [MainThread]: On debug: select 1 as id
[0m17:31:59.363538 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:31:59.818280 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m17:31:59.820218 [debug] [MainThread]: On debug: Close
[0m17:31:59.820850 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m17:31:59.821239 [info ] [MainThread]: [32mAll checks passed![0m
[0m17:31:59.821980 [debug] [MainThread]: Command `dbt debug` succeeded at 17:31:59.821847 after 0.52 seconds
[0m17:31:59.822322 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:31:59.822664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bc6710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130646d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103828390>]}
[0m17:31:59.823108 [debug] [MainThread]: Flushing usage events
[0m17:35:54.710710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a377c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a38d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a39d490>]}


============================== 17:35:54.712465 | b1bdcb5f-6a8f-4013-b3c9-0a5b266e9411 ==============================
[0m17:35:54.712465 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:35:54.712789 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'use_colors': 'True', 'quiet': 'False', 'static_parser': 'True', 'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'warn_error': 'None', 'target_path': 'None', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'debug': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'indirect_selection': 'eager', 'log_format': 'default', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'no_print': 'None', 'printer_width': '80', 'send_anonymous_usage_stats': 'True'}
[0m17:35:54.743178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1bdcb5f-6a8f-4013-b3c9-0a5b266e9411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa3b150>]}
[0m17:35:54.749585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1bdcb5f-6a8f-4013-b3c9-0a5b266e9411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a25d810>]}
[0m17:35:54.750172 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:35:54.760484 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m17:35:54.779427 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:35:54.779700 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m17:35:54.779829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b1bdcb5f-6a8f-4013-b3c9-0a5b266e9411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab87f90>]}
[0m17:35:55.074985 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:35:55.086685 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:35:55.087715 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:35:55.090929 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:35:55.126132 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:35:55.128073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1bdcb5f-6a8f-4013-b3c9-0a5b266e9411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aae3b50>]}
[0m17:35:55.132065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1bdcb5f-6a8f-4013-b3c9-0a5b266e9411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acaa510>]}
[0m17:35:55.132233 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:35:55.132378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1bdcb5f-6a8f-4013-b3c9-0a5b266e9411', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa802d0>]}
[0m17:35:55.132913 [debug] [MainThread]: Command `dbt ls` succeeded at 17:35:55.132857 after 0.43 seconds
[0m17:35:55.133069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052cc390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052ca610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052ca6d0>]}
[0m17:35:55.133205 [debug] [MainThread]: Flushing usage events
[0m17:36:11.356152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c6fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c8ba90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c8bf90>]}


============================== 17:36:11.357764 | 82f6026b-c223-4647-969a-8904ab3d801a ==============================
[0m17:36:11.357764 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:36:11.358079 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'use_colors': 'True', 'version_check': 'True', 'quiet': 'False', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'warn_error': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'introspect': 'True', 'fail_fast': 'False', 'target_path': 'None', 'indirect_selection': 'eager', 'static_parser': 'True', 'debug': 'False', 'no_print': 'None', 'write_json': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'send_anonymous_usage_stats': 'True'}
[0m17:36:11.387603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104310e90>]}
[0m17:36:11.393718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c87250>]}
[0m17:36:11.394144 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:36:11.404437 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m17:36:11.423918 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:36:11.424203 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m17:36:11.424320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106267e90>]}
[0m17:36:11.726674 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:36:11.737587 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:36:11.738599 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:36:11.741795 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:36:11.776529 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m17:36:11.778464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10625db90>]}
[0m17:36:11.781522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10638e410>]}
[0m17:36:11.781676 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:36:11.781823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062720d0>]}
[0m17:36:11.782498 [info ] [MainThread]: 
[0m17:36:11.782828 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:36:11.783289 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m17:36:11.787442 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m17:36:11.787611 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m17:36:11.787733 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:36:12.162952 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m17:36:12.168020 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m17:36:12.170640 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m17:36:12.176966 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:36:12.177264 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m17:36:12.177505 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:36:12.433946 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m17:36:12.435366 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m17:36:12.436036 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m17:36:12.471282 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m17:36:12.475271 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m17:36:12.506669 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m17:36:12.522233 [debug] [MainThread]: Using postgres connection "master"
[0m17:36:12.522692 [debug] [MainThread]: On master: BEGIN
[0m17:36:12.523058 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:36:12.785256 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:36:12.786562 [debug] [MainThread]: Using postgres connection "master"
[0m17:36:12.787645 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:36:12.828992 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m17:36:12.833923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10623f050>]}
[0m17:36:12.834920 [debug] [MainThread]: On master: ROLLBACK
[0m17:36:12.865969 [debug] [MainThread]: Using postgres connection "master"
[0m17:36:12.866987 [debug] [MainThread]: On master: BEGIN
[0m17:36:12.929417 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:36:12.930311 [debug] [MainThread]: On master: COMMIT
[0m17:36:12.931062 [debug] [MainThread]: Using postgres connection "master"
[0m17:36:12.931677 [debug] [MainThread]: On master: COMMIT
[0m17:36:12.962398 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:36:12.963078 [debug] [MainThread]: On master: Close
[0m17:36:12.965470 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:36:12.966221 [info ] [MainThread]: 
[0m17:36:12.974966 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m17:36:12.975723 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m17:36:12.976734 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m17:36:12.977229 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m17:36:12.990643 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:12.991911 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 17:36:12.977585 => 17:36:12.991721
[0m17:36:12.992210 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m17:36:13.015349 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:13.015824 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:13.016006 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m17:36:13.016172 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:36:13.272843 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:36:13.274205 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:13.275676 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m17:36:21.648752 [debug] [Thread-1 (]: SQL status: SELECT 156579 in 8.0 seconds
[0m17:36:21.661178 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:21.661834 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m17:36:21.693516 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:36:21.699768 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:21.700408 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m17:36:21.731649 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:36:21.756593 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:36:21.757020 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:21.757306 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m17:36:21.788111 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:36:21.793265 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m17:36:21.793602 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m17:36:21.841614 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:36:21.844383 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 17:36:12.992393 => 17:36:21.844092
[0m17:36:21.845069 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m17:36:21.846607 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b55550>]}
[0m17:36:21.847494 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156579[0m in 8.87s]
[0m17:36:21.848276 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m17:36:21.848835 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m17:36:21.849608 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m17:36:21.850431 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m17:36:21.850818 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m17:36:21.859565 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m17:36:21.861540 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 17:36:21.851105 => 17:36:21.861272
[0m17:36:21.861907 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m17:36:21.866606 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m17:36:21.867176 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:36:21.867423 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m17:36:21.867628 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:36:22.170036 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m17:36:22.171972 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:36:22.173400 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m17:36:27.198862 [debug] [Thread-1 (]: SQL status: SELECT 46536 in 5.0 seconds
[0m17:36:27.206545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:36:27.207296 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m17:36:27.245279 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:36:27.252769 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:36:27.253366 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m17:36:27.290932 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m17:36:27.295996 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m17:36:27.296691 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:36:27.297241 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m17:36:27.335641 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m17:36:27.341247 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m17:36:27.341944 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m17:36:27.394835 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m17:36:27.398641 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 17:36:21.862102 => 17:36:27.398310
[0m17:36:27.399322 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m17:36:27.400992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82f6026b-c223-4647-969a-8904ab3d801a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ca8f10>]}
[0m17:36:27.402126 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46536[0m in 5.55s]
[0m17:36:27.403406 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m17:36:27.406082 [debug] [MainThread]: Using postgres connection "master"
[0m17:36:27.406514 [debug] [MainThread]: On master: BEGIN
[0m17:36:27.406850 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:36:27.886845 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m17:36:27.888393 [debug] [MainThread]: On master: COMMIT
[0m17:36:27.889172 [debug] [MainThread]: Using postgres connection "master"
[0m17:36:27.889844 [debug] [MainThread]: On master: COMMIT
[0m17:36:27.921744 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m17:36:27.922818 [debug] [MainThread]: On master: Close
[0m17:36:27.925563 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:36:27.926123 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m17:36:27.926749 [info ] [MainThread]: 
[0m17:36:27.927485 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 16.14 seconds (16.14s).
[0m17:36:27.928973 [debug] [MainThread]: Command end result
[0m17:36:27.943375 [info ] [MainThread]: 
[0m17:36:27.943993 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:36:27.944391 [info ] [MainThread]: 
[0m17:36:27.944819 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m17:36:27.945438 [debug] [MainThread]: Command `dbt run` succeeded at 17:36:27.945326 after 16.60 seconds
[0m17:36:27.945817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b55490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1008f0290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1008ee5d0>]}
[0m17:36:27.946155 [debug] [MainThread]: Flushing usage events
[0m17:40:18.388791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10564e8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10564d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10565cd10>]}


============================== 17:40:18.391053 | e0eec944-fb33-44e0-97d2-6054544255f2 ==============================
[0m17:40:18.391053 [info ] [MainThread]: Running with dbt=1.5.4
[0m17:40:18.391366 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'log_cache_events': 'False', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'write_json': 'True', 'no_print': 'None', 'version_check': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'quiet': 'False', 'use_experimental_parser': 'False'}
[0m17:40:18.421712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e0eec944-fb33-44e0-97d2-6054544255f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ab3150>]}
[0m17:40:18.428589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e0eec944-fb33-44e0-97d2-6054544255f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a92fd0>]}
[0m17:40:18.429085 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m17:40:18.441313 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m17:40:18.463263 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:40:18.463576 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m17:40:18.463720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e0eec944-fb33-44e0-97d2-6054544255f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bfff90>]}
[0m17:40:18.815422 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m17:40:18.828027 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m17:40:18.829187 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m17:40:18.832828 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m17:40:18.871912 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m17:40:18.874211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0eec944-fb33-44e0-97d2-6054544255f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ac6750>]}
[0m17:40:18.877819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0eec944-fb33-44e0-97d2-6054544255f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101ad090>]}
[0m17:40:18.878001 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m17:40:18.878153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0eec944-fb33-44e0-97d2-6054544255f2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105baded0>]}
[0m17:40:18.878731 [debug] [MainThread]: Command `dbt ls` succeeded at 17:40:18.878662 after 0.50 seconds
[0m17:40:18.878883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10551d350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10177c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10177a810>]}
[0m17:40:18.879021 [debug] [MainThread]: Flushing usage events
[0m18:35:11.979652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107278650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107289650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10728bfd0>]}


============================== 18:35:11.981411 | 4db41698-e77b-4860-8359-548d64022d0d ==============================
[0m18:35:11.981411 [info ] [MainThread]: Running with dbt=1.5.4
[0m18:35:11.981719 [debug] [MainThread]: running dbt with arguments {'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'version_check': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'debug': 'False', 'log_format': 'default', 'quiet': 'False', 'fail_fast': 'False', 'warn_error': 'None', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'no_print': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'target_path': 'None'}
[0m18:35:12.013037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4db41698-e77b-4860-8359-548d64022d0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10726e350>]}
[0m18:35:12.019171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4db41698-e77b-4860-8359-548d64022d0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075c7150>]}
[0m18:35:12.019632 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m18:35:12.041109 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m18:35:12.081836 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:35:12.082024 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:35:12.082243 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m18:35:12.084556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4db41698-e77b-4860-8359-548d64022d0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c6ad0>]}
[0m18:35:12.088512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4db41698-e77b-4860-8359-548d64022d0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075d7610>]}
[0m18:35:12.088679 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m18:35:12.088830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4db41698-e77b-4860-8359-548d64022d0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072887d0>]}
[0m18:35:12.089368 [debug] [MainThread]: Command `dbt ls` succeeded at 18:35:12.089315 after 0.12 seconds
[0m18:35:12.089512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107290ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107291090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1029a84d0>]}
[0m18:35:12.089638 [debug] [MainThread]: Flushing usage events
[0m18:35:41.345852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11427a190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114285650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142909d0>]}


============================== 18:35:41.347567 | 94953820-d730-40d3-8a60-909363caa563 ==============================
[0m18:35:41.347567 [info ] [MainThread]: Running with dbt=1.5.4
[0m18:35:41.347884 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'static_parser': 'True', 'quiet': 'False', 'introspect': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'write_json': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'target_path': 'None', 'debug': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'use_colors': 'True', 'version_check': 'True'}
[0m18:35:41.377967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11427bed0>]}
[0m18:35:41.384469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1145d5350>]}
[0m18:35:41.384912 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m18:35:41.395789 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m18:35:41.416258 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:35:41.416536 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m18:35:41.416655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1146fbfd0>]}
[0m18:35:41.730548 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m18:35:41.742477 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m18:35:41.743524 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m18:35:41.746770 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m18:35:41.786171 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m18:35:41.788265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114705f10>]}
[0m18:35:41.791845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1151aaad0>]}
[0m18:35:41.792008 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m18:35:41.792159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110520250>]}
[0m18:35:41.792816 [info ] [MainThread]: 
[0m18:35:41.793120 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:35:41.793530 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m18:35:41.797366 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m18:35:41.797498 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m18:35:41.797594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:35:42.225269 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m18:35:42.229312 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m18:35:42.233378 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m18:35:42.242193 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:35:42.242714 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m18:35:42.243028 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:35:42.512371 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m18:35:42.513607 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:35:42.514220 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m18:35:42.550588 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m18:35:42.553715 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m18:35:42.585603 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m18:35:42.599991 [debug] [MainThread]: Using postgres connection "master"
[0m18:35:42.600451 [debug] [MainThread]: On master: BEGIN
[0m18:35:42.600782 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:35:42.864434 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:35:42.865836 [debug] [MainThread]: Using postgres connection "master"
[0m18:35:42.867099 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:35:42.908844 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m18:35:42.910787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11464a750>]}
[0m18:35:42.911224 [debug] [MainThread]: On master: ROLLBACK
[0m18:35:42.942304 [debug] [MainThread]: Using postgres connection "master"
[0m18:35:42.942621 [debug] [MainThread]: On master: BEGIN
[0m18:35:43.003778 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:35:43.004726 [debug] [MainThread]: On master: COMMIT
[0m18:35:43.005337 [debug] [MainThread]: Using postgres connection "master"
[0m18:35:43.005700 [debug] [MainThread]: On master: COMMIT
[0m18:35:43.037055 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:35:43.038069 [debug] [MainThread]: On master: Close
[0m18:35:43.039792 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:35:43.040617 [info ] [MainThread]: 
[0m18:35:43.048188 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m18:35:43.048845 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m18:35:43.049687 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m18:35:43.050076 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m18:35:43.060883 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:43.062401 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 18:35:43.050329 => 18:35:43.062195
[0m18:35:43.062673 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m18:35:43.088130 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:43.088765 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:43.088954 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m18:35:43.089118 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:35:43.391715 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m18:35:43.392249 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:43.392789 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m18:35:51.638072 [debug] [Thread-1 (]: SQL status: SELECT 156819 in 8.0 seconds
[0m18:35:51.654628 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:51.655519 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m18:35:51.693315 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:35:51.700439 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:51.701417 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m18:35:51.739105 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:35:51.770367 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:35:51.771016 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:51.771410 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:35:51.808230 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m18:35:51.818870 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:35:51.819569 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m18:35:51.874961 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m18:35:51.878575 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 18:35:43.062835 => 18:35:51.878174
[0m18:35:51.879654 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m18:35:51.882461 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x115184190>]}
[0m18:35:51.884450 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156819[0m in 8.83s]
[0m18:35:51.886293 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m18:35:51.887386 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m18:35:51.888709 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m18:35:51.890490 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m18:35:51.891343 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m18:35:51.905152 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m18:35:51.909045 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 18:35:51.891937 => 18:35:51.908679
[0m18:35:51.909574 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m18:35:51.916349 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m18:35:51.917110 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:35:51.917421 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m18:35:51.917706 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:35:52.205408 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m18:35:52.206766 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:35:52.207966 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m18:35:57.457609 [debug] [Thread-1 (]: SQL status: SELECT 46543 in 5.0 seconds
[0m18:35:57.467246 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:35:57.468078 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m18:35:57.499598 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:35:57.508125 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:35:57.508920 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m18:35:57.540950 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:35:57.545196 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m18:35:57.545907 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:35:57.546483 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m18:35:57.577749 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m18:35:57.583629 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:35:57.584673 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m18:35:57.632029 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m18:35:57.637454 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 18:35:51.909851 => 18:35:57.636978
[0m18:35:57.638624 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m18:35:57.641079 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '94953820-d730-40d3-8a60-909363caa563', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1146af290>]}
[0m18:35:57.642217 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46543[0m in 5.75s]
[0m18:35:57.643400 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m18:35:57.646273 [debug] [MainThread]: Using postgres connection "master"
[0m18:35:57.646831 [debug] [MainThread]: On master: BEGIN
[0m18:35:57.647286 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:35:57.903026 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:35:57.904164 [debug] [MainThread]: On master: COMMIT
[0m18:35:57.904836 [debug] [MainThread]: Using postgres connection "master"
[0m18:35:57.905398 [debug] [MainThread]: On master: COMMIT
[0m18:35:57.935887 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:35:57.936420 [debug] [MainThread]: On master: Close
[0m18:35:57.937186 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:35:57.937400 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m18:35:57.937647 [info ] [MainThread]: 
[0m18:35:57.937941 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 16.14 seconds (16.14s).
[0m18:35:57.938605 [debug] [MainThread]: Command end result
[0m18:35:57.946737 [info ] [MainThread]: 
[0m18:35:57.947130 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:35:57.947375 [info ] [MainThread]: 
[0m18:35:57.947641 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:35:57.948062 [debug] [MainThread]: Command `dbt run` succeeded at 18:35:57.947990 after 16.62 seconds
[0m18:35:57.948315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10618c290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10618a510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106101910>]}
[0m18:35:57.948567 [debug] [MainThread]: Flushing usage events
[0m18:37:31.100865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049c8bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d5650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049db2d0>]}


============================== 18:37:31.102552 | 032929f4-4286-4b45-bfed-1dce857b0442 ==============================
[0m18:37:31.102552 [info ] [MainThread]: Running with dbt=1.5.4
[0m18:37:31.102873 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'introspect': 'True', 'write_json': 'True', 'warn_error': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'use_experimental_parser': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/danila/.dbt', 'version_check': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'debug': 'False', 'use_colors': 'True', 'static_parser': 'True', 'quiet': 'False', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False'}
[0m18:37:31.133275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '032929f4-4286-4b45-bfed-1dce857b0442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104234050>]}
[0m18:37:31.139335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '032929f4-4286-4b45-bfed-1dce857b0442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e53150>]}
[0m18:37:31.139750 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m18:37:31.150652 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m18:37:31.189607 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:37:31.189787 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:37:31.190000 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m18:37:31.192352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '032929f4-4286-4b45-bfed-1dce857b0442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f3b250>]}
[0m18:37:31.196520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '032929f4-4286-4b45-bfed-1dce857b0442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d5450>]}
[0m18:37:31.196694 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m18:37:31.196847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '032929f4-4286-4b45-bfed-1dce857b0442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101e87b90>]}
[0m18:37:31.197354 [info ] [MainThread]: 
[0m18:37:31.197665 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:37:31.198085 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m18:37:31.201983 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m18:37:31.202114 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m18:37:31.202221 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:37:31.561028 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m18:37:31.566639 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m18:37:31.571137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m18:37:31.580227 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:37:31.580811 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m18:37:31.581129 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:37:31.892377 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m18:37:31.894063 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:37:31.895701 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m18:37:31.942186 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m18:37:31.946280 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m18:37:31.981016 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m18:37:31.993869 [debug] [MainThread]: Using postgres connection "master"
[0m18:37:31.994375 [debug] [MainThread]: On master: BEGIN
[0m18:37:31.994673 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:37:32.255801 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:37:32.257672 [debug] [MainThread]: Using postgres connection "master"
[0m18:37:32.258544 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:37:32.300818 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m18:37:32.305621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '032929f4-4286-4b45-bfed-1dce857b0442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f152d0>]}
[0m18:37:32.306816 [debug] [MainThread]: On master: ROLLBACK
[0m18:37:32.337849 [debug] [MainThread]: Using postgres connection "master"
[0m18:37:32.338771 [debug] [MainThread]: On master: BEGIN
[0m18:37:32.400159 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:37:32.400496 [debug] [MainThread]: On master: COMMIT
[0m18:37:32.400692 [debug] [MainThread]: Using postgres connection "master"
[0m18:37:32.400855 [debug] [MainThread]: On master: COMMIT
[0m18:37:32.431271 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:37:32.431508 [debug] [MainThread]: On master: Close
[0m18:37:32.432138 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:37:32.432438 [info ] [MainThread]: 
[0m18:37:32.435984 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m18:37:32.436398 [info ] [Thread-1 (]: 1 of 1 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m18:37:32.436971 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m18:37:32.437246 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m18:37:32.452823 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:32.453431 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 18:37:32.437424 => 18:37:32.453296
[0m18:37:32.453651 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m18:37:32.472651 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:32.473245 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:32.473412 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m18:37:32.473553 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:37:32.801940 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m18:37:32.803446 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:32.804620 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m18:37:40.990127 [debug] [Thread-1 (]: SQL status: SELECT 156837 in 8.0 seconds
[0m18:37:41.003292 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:41.003980 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m18:37:41.043331 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:37:41.048324 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:41.048920 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m18:37:41.088528 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:37:41.113901 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:37:41.114350 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:41.114644 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:37:41.153704 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m18:37:41.159526 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:37:41.160362 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m18:37:41.217315 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m18:37:41.221249 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 18:37:32.453773 => 18:37:41.220590
[0m18:37:41.222109 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m18:37:41.223353 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '032929f4-4286-4b45-bfed-1dce857b0442', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e61d10>]}
[0m18:37:41.224361 [info ] [Thread-1 (]: 1 of 1 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156837[0m in 8.79s]
[0m18:37:41.225404 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m18:37:41.227558 [debug] [MainThread]: Using postgres connection "master"
[0m18:37:41.227926 [debug] [MainThread]: On master: BEGIN
[0m18:37:41.228292 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:37:41.578832 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:37:41.580243 [debug] [MainThread]: On master: COMMIT
[0m18:37:41.580988 [debug] [MainThread]: Using postgres connection "master"
[0m18:37:41.581396 [debug] [MainThread]: On master: COMMIT
[0m18:37:41.623822 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:37:41.625203 [debug] [MainThread]: On master: Close
[0m18:37:41.627021 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:37:41.627469 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_by_brand_int' was properly closed.
[0m18:37:41.627975 [info ] [MainThread]: 
[0m18:37:41.628546 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 10.43 seconds (10.43s).
[0m18:37:41.629542 [debug] [MainThread]: Command end result
[0m18:37:41.642820 [info ] [MainThread]: 
[0m18:37:41.643594 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:37:41.644140 [info ] [MainThread]: 
[0m18:37:41.644478 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m18:37:41.644830 [debug] [MainThread]: Command `dbt run` succeeded at 18:37:41.644772 after 10.56 seconds
[0m18:37:41.645018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049eb510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103453510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100b04250>]}
[0m18:37:41.645196 [debug] [MainThread]: Flushing usage events
[0m18:49:00.812488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10767b2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10769e550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10769ec10>]}


============================== 18:49:00.814203 | 17c95a05-0942-4ef7-8340-a3dc2de501e0 ==============================
[0m18:49:00.814203 [info ] [MainThread]: Running with dbt=1.5.4
[0m18:49:00.814523 [debug] [MainThread]: running dbt with arguments {'static_parser': 'True', 'use_colors': 'True', 'debug': 'False', 'fail_fast': 'False', 'cache_selected_only': 'False', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'warn_error': 'None', 'profiles_dir': '/Users/danila/.dbt', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'partial_parse': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'target_path': 'None', 'version_check': 'True'}
[0m18:49:01.275141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10767a310>]}
[0m18:49:01.282120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a1c150>]}
[0m18:49:01.282806 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m18:49:01.300338 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m18:49:01.348814 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:49:01.349064 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:49:01.349328 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m18:49:01.351993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b47710>]}
[0m18:49:01.357893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a2cc50>]}
[0m18:49:01.358258 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m18:49:01.358462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a979d0>]}
[0m18:49:01.359394 [info ] [MainThread]: 
[0m18:49:01.359860 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:49:01.360373 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m18:49:01.365033 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m18:49:01.365257 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m18:49:01.365378 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:49:01.756872 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m18:49:01.759903 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m18:49:01.761948 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m18:49:01.769039 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:49:01.769500 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m18:49:01.769780 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:49:02.023169 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m18:49:02.024382 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:49:02.025240 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m18:49:02.059744 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m18:49:02.062181 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m18:49:02.092572 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m18:49:02.104381 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:02.104804 [debug] [MainThread]: On master: BEGIN
[0m18:49:02.105090 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:49:02.408105 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:49:02.409612 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:02.410640 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:49:02.458781 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m18:49:02.462087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079f5d90>]}
[0m18:49:02.462878 [debug] [MainThread]: On master: ROLLBACK
[0m18:49:02.498181 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:02.498658 [debug] [MainThread]: On master: BEGIN
[0m18:49:02.564984 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:49:02.566353 [debug] [MainThread]: On master: COMMIT
[0m18:49:02.567337 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:02.568054 [debug] [MainThread]: On master: COMMIT
[0m18:49:02.623527 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:49:02.624743 [debug] [MainThread]: On master: Close
[0m18:49:02.626865 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:49:02.627494 [info ] [MainThread]: 
[0m18:49:02.635122 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:02.635853 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m18:49:02.636863 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m18:49:02.637342 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:02.660501 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:02.662004 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 18:49:02.637655 => 18:49:02.661833
[0m18:49:02.662271 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:02.684528 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:02.685584 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:02.685817 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m18:49:02.685996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:49:02.975832 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m18:49:02.977806 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:02.979309 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m18:49:13.328530 [debug] [Thread-1 (]: SQL status: SELECT 156838 in 10.0 seconds
[0m18:49:13.342292 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:13.342921 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m18:49:13.374031 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:49:13.379976 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:13.380722 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m18:49:13.412380 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:49:13.439793 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:49:13.440380 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:13.440716 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:49:13.471140 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m18:49:13.476578 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:13.476909 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m18:49:13.523754 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m18:49:13.527207 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 18:49:02.662423 => 18:49:13.526871
[0m18:49:13.527885 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m18:49:13.529707 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107692190>]}
[0m18:49:13.530669 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156838[0m in 10.89s]
[0m18:49:13.531534 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:13.532160 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m18:49:13.532855 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m18:49:13.533674 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m18:49:13.534089 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m18:49:13.543331 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m18:49:13.545163 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 18:49:13.534662 => 18:49:13.544921
[0m18:49:13.545547 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m18:49:13.548902 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m18:49:13.549460 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:13.549724 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m18:49:13.549967 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:49:13.828368 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m18:49:13.829567 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:13.830947 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m18:49:20.815974 [debug] [Thread-1 (]: SQL status: SELECT 46544 in 7.0 seconds
[0m18:49:20.823139 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:20.823806 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m18:49:20.855305 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:49:20.862997 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:20.863556 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m18:49:20.895448 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:49:20.899798 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m18:49:20.900237 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:20.900603 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m18:49:20.931869 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m18:49:20.936191 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:20.936746 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m18:49:20.981752 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m18:49:20.985321 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 18:49:13.545744 => 18:49:20.985007
[0m18:49:20.985983 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m18:49:20.988009 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17c95a05-0942-4ef7-8340-a3dc2de501e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ba8cd0>]}
[0m18:49:20.989039 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46544[0m in 7.45s]
[0m18:49:20.990159 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m18:49:20.992743 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:20.993164 [debug] [MainThread]: On master: BEGIN
[0m18:49:20.993520 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:49:21.252428 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:49:21.253589 [debug] [MainThread]: On master: COMMIT
[0m18:49:21.254806 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:21.255446 [debug] [MainThread]: On master: COMMIT
[0m18:49:21.286326 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:49:21.287421 [debug] [MainThread]: On master: Close
[0m18:49:21.289191 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:49:21.289599 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m18:49:21.290064 [info ] [MainThread]: 
[0m18:49:21.290612 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 19.93 seconds (19.93s).
[0m18:49:21.291820 [debug] [MainThread]: Command end result
[0m18:49:21.303918 [info ] [MainThread]: 
[0m18:49:21.304670 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:49:21.305239 [info ] [MainThread]: 
[0m18:49:21.305665 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:49:21.306332 [debug] [MainThread]: Command `dbt run` succeeded at 18:49:21.306217 after 20.51 seconds
[0m18:49:21.306663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101614250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101612610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101612590>]}
[0m18:49:21.306990 [debug] [MainThread]: Flushing usage events
[0m18:49:33.501298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074dc6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c930d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c93790>]}


============================== 18:49:33.502967 | a0c57208-65c4-4cbb-a7ba-5b43f1933c1b ==============================
[0m18:49:33.502967 [info ] [MainThread]: Running with dbt=1.5.4
[0m18:49:33.503278 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'use_colors': 'True', 'no_print': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager', 'quiet': 'False', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'log_format': 'default', 'printer_width': '80', 'warn_error': 'None', 'cache_selected_only': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'static_parser': 'True', 'use_experimental_parser': 'False', 'debug': 'False', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m18:49:33.535645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a0c57208-65c4-4cbb-a7ba-5b43f1933c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074dcad0>]}
[0m18:49:33.542148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a0c57208-65c4-4cbb-a7ba-5b43f1933c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120050f10>]}
[0m18:49:33.542595 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m18:49:33.554157 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m18:49:33.574838 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:49:33.575117 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m18:49:33.575241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a0c57208-65c4-4cbb-a7ba-5b43f1933c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c07ad0>]}
[0m18:49:33.895275 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m18:49:33.906446 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m18:49:33.907478 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m18:49:33.910792 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m18:49:33.948812 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m18:49:33.950800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a0c57208-65c4-4cbb-a7ba-5b43f1933c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12008e350>]}
[0m18:49:33.954883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a0c57208-65c4-4cbb-a7ba-5b43f1933c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1202ae8d0>]}
[0m18:49:33.955084 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m18:49:33.955241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0c57208-65c4-4cbb-a7ba-5b43f1933c1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120085490>]}
[0m18:49:33.955865 [debug] [MainThread]: Command `dbt ls` succeeded at 18:49:33.955803 after 0.47 seconds
[0m18:49:33.956029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107419790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1033943d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103392710>]}
[0m18:49:33.956172 [debug] [MainThread]: Flushing usage events
[0m18:49:45.061208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e73b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e89650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e93950>]}


============================== 18:49:45.062863 | 7fee52e1-48c2-4ed3-baec-67866d2ca159 ==============================
[0m18:49:45.062863 [info ] [MainThread]: Running with dbt=1.5.4
[0m18:49:45.063170 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'version_check': 'True', 'introspect': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'write_json': 'True', 'profiles_dir': '/Users/danila/.dbt', 'cache_selected_only': 'False', 'use_experimental_parser': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'partial_parse': 'True', 'printer_width': '80', 'quiet': 'False', 'debug': 'False', 'indirect_selection': 'eager'}
[0m18:49:45.095202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053fa2d0>]}
[0m18:49:45.101750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076dce10>]}
[0m18:49:45.102220 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m18:49:45.112970 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m18:49:45.132494 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m18:49:45.132799 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m18:49:45.132920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082ffe10>]}
[0m18:49:45.449866 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m18:49:45.461771 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m18:49:45.462879 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m18:49:45.466171 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m18:49:45.504932 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m18:49:45.506929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081f6850>]}
[0m18:49:45.510485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108182410>]}
[0m18:49:45.510666 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m18:49:45.510824 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a23ad0>]}
[0m18:49:45.511584 [info ] [MainThread]: 
[0m18:49:45.511904 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:49:45.512329 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m18:49:45.516336 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m18:49:45.516525 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m18:49:45.516639 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:49:45.999863 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m18:49:46.004760 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m18:49:46.007767 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m18:49:46.015318 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:49:46.015801 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m18:49:46.016066 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:49:46.280168 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m18:49:46.281944 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m18:49:46.282786 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m18:49:46.318022 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m18:49:46.322839 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m18:49:46.354467 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m18:49:46.369306 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:46.369730 [debug] [MainThread]: On master: BEGIN
[0m18:49:46.370079 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:49:46.678237 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:49:46.678655 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:46.678991 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:49:46.726935 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m18:49:46.730053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082afd90>]}
[0m18:49:46.730941 [debug] [MainThread]: On master: ROLLBACK
[0m18:49:46.766948 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:46.768037 [debug] [MainThread]: On master: BEGIN
[0m18:49:46.841465 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:49:46.842592 [debug] [MainThread]: On master: COMMIT
[0m18:49:46.843588 [debug] [MainThread]: Using postgres connection "master"
[0m18:49:46.844351 [debug] [MainThread]: On master: COMMIT
[0m18:49:46.881221 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:49:46.882274 [debug] [MainThread]: On master: Close
[0m18:49:46.884791 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m18:49:46.885589 [info ] [MainThread]: 
[0m18:49:46.895030 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:46.895808 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m18:49:46.896842 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m18:49:46.897316 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:46.910368 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:46.911657 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 18:49:46.897622 => 18:49:46.911454
[0m18:49:46.911988 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:46.936173 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:46.937425 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:46.937628 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m18:49:46.937799 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:49:47.240743 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m18:49:47.241912 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:47.242990 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m18:49:55.565538 [debug] [Thread-1 (]: SQL status: SELECT 156838 in 8.0 seconds
[0m18:49:55.577871 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:55.578661 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m18:49:55.616624 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:49:55.623191 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:55.623919 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m18:49:55.661745 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:49:55.688942 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:49:55.689381 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:55.689671 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m18:49:55.726372 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m18:49:55.731866 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m18:49:55.732277 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m18:49:55.791309 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m18:49:55.796329 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 18:49:46.912166 => 18:49:55.796015
[0m18:49:55.796994 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m18:49:55.798690 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10821a150>]}
[0m18:49:55.799654 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156838[0m in 8.90s]
[0m18:49:55.800523 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m18:49:55.801119 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m18:49:55.802175 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m18:49:55.803029 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m18:49:55.803415 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m18:49:55.812155 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m18:49:55.814336 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 18:49:55.803657 => 18:49:55.814106
[0m18:49:55.814669 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m18:49:55.819271 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m18:49:55.820045 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:55.820297 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m18:49:55.820526 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:49:56.125719 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m18:49:56.127438 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:49:56.128500 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m18:50:03.096231 [debug] [Thread-1 (]: SQL status: SELECT 46544 in 7.0 seconds
[0m18:50:03.104574 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:50:03.105376 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m18:50:03.142934 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:50:03.149502 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:50:03.150168 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m18:50:03.187747 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m18:50:03.193146 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m18:50:03.193788 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:50:03.194347 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m18:50:03.231302 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m18:50:03.237037 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m18:50:03.237644 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m18:50:03.289465 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m18:50:03.293693 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 18:49:55.814861 => 18:50:03.293353
[0m18:50:03.294387 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m18:50:03.296065 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7fee52e1-48c2-4ed3-baec-67866d2ca159', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108435510>]}
[0m18:50:03.297070 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46544[0m in 7.49s]
[0m18:50:03.298174 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m18:50:03.300430 [debug] [MainThread]: Using postgres connection "master"
[0m18:50:03.300866 [debug] [MainThread]: On master: BEGIN
[0m18:50:03.301235 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:50:03.606365 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m18:50:03.607896 [debug] [MainThread]: On master: COMMIT
[0m18:50:03.608913 [debug] [MainThread]: Using postgres connection "master"
[0m18:50:03.609612 [debug] [MainThread]: On master: COMMIT
[0m18:50:03.645834 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m18:50:03.647035 [debug] [MainThread]: On master: Close
[0m18:50:03.649734 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:50:03.650247 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m18:50:03.650885 [info ] [MainThread]: 
[0m18:50:03.651583 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 18.14 seconds (18.14s).
[0m18:50:03.653070 [debug] [MainThread]: Command end result
[0m18:50:03.664754 [info ] [MainThread]: 
[0m18:50:03.665430 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:50:03.665829 [info ] [MainThread]: 
[0m18:50:03.666262 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m18:50:03.666984 [debug] [MainThread]: Command `dbt run` succeeded at 18:50:03.666854 after 18.62 seconds
[0m18:50:03.667388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10369e590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1036a0fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d55150>]}
[0m18:50:03.667733 [debug] [MainThread]: Flushing usage events
[0m19:28:14.666463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108735110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087572d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108757990>]}


============================== 19:28:14.667999 | cce6f6ac-6407-4f91-a374-610f34177457 ==============================
[0m19:28:14.667999 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:28:14.668302 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'printer_width': '80', 'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'indirect_selection': 'eager', 'log_format': 'default', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'partial_parse': 'True', 'no_print': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'static_parser': 'True'}
[0m19:28:14.697347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cce6f6ac-6407-4f91-a374-610f34177457', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108735d10>]}
[0m19:28:14.703453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cce6f6ac-6407-4f91-a374-610f34177457', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108bc76d0>]}
[0m19:28:14.703943 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:28:14.714912 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m19:28:14.733789 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m19:28:14.734094 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m19:28:14.734230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'cce6f6ac-6407-4f91-a374-610f34177457', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cfbfd0>]}
[0m19:28:15.043848 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m19:28:15.054786 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m19:28:15.055805 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m19:28:15.059070 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m19:28:15.093522 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:28:15.095462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cce6f6ac-6407-4f91-a374-610f34177457', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cf99d0>]}
[0m19:28:15.098706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cce6f6ac-6407-4f91-a374-610f34177457', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e26950>]}
[0m19:28:15.098887 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:28:15.099039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cce6f6ac-6407-4f91-a374-610f34177457', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c13690>]}
[0m19:28:15.099580 [debug] [MainThread]: Command `dbt ls` succeeded at 19:28:15.099526 after 0.45 seconds
[0m19:28:15.099734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10875af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047a82d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104876650>]}
[0m19:28:15.099872 [debug] [MainThread]: Flushing usage events
[0m19:28:33.270441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110071710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110089650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110093dd0>]}


============================== 19:28:33.271681 | d0a41909-2235-40cd-af28-563651d2a14e ==============================
[0m19:28:33.271681 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:28:33.271975 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'use_colors': 'True', 'quiet': 'False', 'target_path': 'None', 'write_json': 'True', 'log_format': 'default', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'static_parser': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'fail_fast': 'False', 'cache_selected_only': 'False'}
[0m19:28:33.299401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110097e10>]}
[0m19:28:33.305870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110413690>]}
[0m19:28:33.306190 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:28:33.315278 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:28:33.336387 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m19:28:33.336684 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m19:28:33.336807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11054bf50>]}
[0m19:28:33.631590 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m19:28:33.642710 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m19:28:33.643707 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m19:28:33.646995 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m19:28:33.681590 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:28:33.683512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11073e150>]}
[0m19:28:33.686593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b0c90>]}
[0m19:28:33.686749 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:28:33.686899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045dc090>]}
[0m19:28:33.687562 [info ] [MainThread]: 
[0m19:28:33.687871 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:28:33.688337 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:28:33.692304 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:28:33.692468 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:28:33.692573 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:28:34.025725 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:28:34.028881 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:28:34.032778 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:28:34.040566 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:28:34.041224 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:28:34.041583 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:28:34.370000 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:28:34.371138 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:28:34.371713 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:28:34.415596 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:28:34.418816 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:28:34.458432 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:28:34.470630 [debug] [MainThread]: Using postgres connection "master"
[0m19:28:34.471188 [debug] [MainThread]: On master: BEGIN
[0m19:28:34.471509 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:28:34.732685 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:28:34.734063 [debug] [MainThread]: Using postgres connection "master"
[0m19:28:34.734850 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:28:34.775962 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:28:34.780595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110736bd0>]}
[0m19:28:34.781644 [debug] [MainThread]: On master: ROLLBACK
[0m19:28:34.812559 [debug] [MainThread]: Using postgres connection "master"
[0m19:28:34.812964 [debug] [MainThread]: On master: BEGIN
[0m19:28:34.874615 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:28:34.875028 [debug] [MainThread]: On master: COMMIT
[0m19:28:34.875326 [debug] [MainThread]: Using postgres connection "master"
[0m19:28:34.875600 [debug] [MainThread]: On master: COMMIT
[0m19:28:34.906377 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:28:34.907384 [debug] [MainThread]: On master: Close
[0m19:28:34.909159 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:28:34.909837 [info ] [MainThread]: 
[0m19:28:34.918223 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:28:34.918849 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:28:34.919657 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:28:34.920043 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:28:34.931448 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:34.932569 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:28:34.920294 => 19:28:34.932324
[0m19:28:34.932910 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:28:34.956608 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:34.957134 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:34.957311 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:28:34.957470 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:28:35.506303 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:28:35.508022 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:35.508857 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:28:44.121571 [debug] [Thread-1 (]: SQL status: SELECT 156840 in 9.0 seconds
[0m19:28:44.134753 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:44.135350 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:28:44.172086 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:28:44.177731 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:44.178246 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:28:44.215461 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:28:44.237802 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:28:44.238170 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:44.238412 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:28:44.274772 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:28:44.279379 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:28:44.279715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:28:44.336242 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:28:44.339162 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:28:34.933095 => 19:28:44.338645
[0m19:28:44.340259 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:28:44.342089 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104eb6d0>]}
[0m19:28:44.343053 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156840[0m in 9.42s]
[0m19:28:44.344098 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:28:44.344892 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:28:44.345846 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:28:44.346931 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:28:44.347410 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:28:44.357941 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:28:44.359011 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:28:44.347713 => 19:28:44.358783
[0m19:28:44.359315 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:28:44.364070 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:28:44.364668 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:28:44.364927 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:28:44.365166 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:28:44.660134 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:28:44.661949 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:28:44.663337 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:28:49.859105 [debug] [Thread-1 (]: SQL status: SELECT 46546 in 5.0 seconds
[0m19:28:49.866658 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:28:49.867444 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:28:49.902421 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:28:49.908503 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:28:49.909034 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:28:49.946051 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:28:49.949401 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:28:49.950162 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:28:49.950846 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:28:49.985462 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:28:49.994117 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:28:49.995307 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:28:50.045438 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:28:50.049330 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:28:44.359492 => 19:28:50.049035
[0m19:28:50.050001 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:28:50.051998 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd0a41909-2235-40cd-af28-563651d2a14e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107fcbd0>]}
[0m19:28:50.053053 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46546[0m in 5.71s]
[0m19:28:50.054070 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:28:50.056678 [debug] [MainThread]: Using postgres connection "master"
[0m19:28:50.057021 [debug] [MainThread]: On master: BEGIN
[0m19:28:50.057433 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:28:50.442243 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:28:50.442755 [debug] [MainThread]: On master: COMMIT
[0m19:28:50.443038 [debug] [MainThread]: Using postgres connection "master"
[0m19:28:50.443288 [debug] [MainThread]: On master: COMMIT
[0m19:28:50.473437 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:28:50.474211 [debug] [MainThread]: On master: Close
[0m19:28:50.475353 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:28:50.475660 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m19:28:50.476094 [info ] [MainThread]: 
[0m19:28:50.476554 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 16.79 seconds (16.79s).
[0m19:28:50.477770 [debug] [MainThread]: Command end result
[0m19:28:50.488108 [info ] [MainThread]: 
[0m19:28:50.488751 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:28:50.489154 [info ] [MainThread]: 
[0m19:28:50.489572 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m19:28:50.490305 [debug] [MainThread]: Command `dbt run` succeeded at 19:28:50.490206 after 17.23 seconds
[0m19:28:50.490646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11008af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102f50250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102f4e590>]}
[0m19:28:50.490979 [debug] [MainThread]: Flushing usage events
[0m19:32:27.366900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107215b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722ed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722f410>]}


============================== 19:32:27.368460 | 114235b2-5b77-4bdd-9f39-f53c88f76993 ==============================
[0m19:32:27.368460 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:32:27.368777 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'profiles_dir': '/Users/danila/.dbt', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'printer_width': '80', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'target_path': 'None', 'partial_parse': 'True', 'write_json': 'True', 'static_parser': 'True', 'introspect': 'True'}
[0m19:32:27.398097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '114235b2-5b77-4bdd-9f39-f53c88f76993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107250210>]}
[0m19:32:27.404277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '114235b2-5b77-4bdd-9f39-f53c88f76993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076b8410>]}
[0m19:32:27.404702 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:32:27.414685 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:32:27.441144 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:32:27.441330 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:32:27.441543 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:32:27.443817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '114235b2-5b77-4bdd-9f39-f53c88f76993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077877d0>]}
[0m19:32:27.447162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '114235b2-5b77-4bdd-9f39-f53c88f76993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076cc290>]}
[0m19:32:27.447326 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:32:27.448052 [info ] [MainThread]: 
[0m19:32:27.448392 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:32:27.448851 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:32:27.453120 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:32:27.453325 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:32:27.453445 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:32:27.771507 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:32:27.775294 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:32:27.778834 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:32:27.787865 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:32:27.788491 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:32:27.788809 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:32:28.049514 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:32:28.050637 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:32:28.051411 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:32:28.086341 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:32:28.091514 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:32:28.123033 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:32:28.136975 [debug] [MainThread]: Using postgres connection "master"
[0m19:32:28.137408 [debug] [MainThread]: On master: BEGIN
[0m19:32:28.137747 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:32:28.449342 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:32:28.450871 [debug] [MainThread]: Using postgres connection "master"
[0m19:32:28.451871 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:32:28.499465 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:32:28.503435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '114235b2-5b77-4bdd-9f39-f53c88f76993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722e610>]}
[0m19:32:28.504172 [debug] [MainThread]: On master: ROLLBACK
[0m19:32:28.535013 [debug] [MainThread]: Using postgres connection "master"
[0m19:32:28.535623 [debug] [MainThread]: On master: BEGIN
[0m19:32:28.597463 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:32:28.597802 [debug] [MainThread]: On master: COMMIT
[0m19:32:28.598008 [debug] [MainThread]: Using postgres connection "master"
[0m19:32:28.598189 [debug] [MainThread]: On master: COMMIT
[0m19:32:28.628196 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:32:28.628549 [debug] [MainThread]: On master: Close
[0m19:32:28.629342 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:32:28.629696 [info ] [MainThread]: 
[0m19:32:28.634959 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:32:28.635407 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:32:28.636010 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:32:28.636291 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:32:28.652230 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:32:28.652825 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:32:28.636468 => 19:32:28.652697
[0m19:32:28.653045 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:32:28.672894 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:32:28.673395 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:32:28.673559 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:32:28.673710 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:32:28.976696 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:32:28.977938 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:32:28.978844 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    --    and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
--    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:33:11.021352 [debug] [Thread-1 (]: SQL status: SELECT 932605 in 42.0 seconds
[0m19:33:11.038774 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:33:11.039426 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:33:11.077537 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:33:11.086920 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:33:11.088436 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:33:11.126545 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:33:11.161585 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:33:11.162219 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:33:11.162616 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:33:11.199287 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:33:11.208820 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:33:11.209425 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:33:11.261862 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:33:11.266723 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:32:28.653173 => 19:33:11.266065
[0m19:33:11.267855 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:33:11.270667 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '114235b2-5b77-4bdd-9f39-f53c88f76993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077effd0>]}
[0m19:33:11.272346 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 932605[0m in 42.63s]
[0m19:33:11.274236 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:33:11.275210 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:33:11.276063 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:33:11.276959 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:33:11.277715 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:33:11.292064 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:33:11.293319 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:33:11.278232 => 19:33:11.293069
[0m19:33:11.293690 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:33:11.298693 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:33:11.299632 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:33:11.300017 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:33:11.300253 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:33:11.626072 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:33:11.627783 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:33:11.629618 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:33:18.547069 [debug] [Thread-1 (]: SQL status: SELECT 46550 in 7.0 seconds
[0m19:33:18.558174 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:33:18.558830 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:33:18.589818 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:33:18.598344 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:33:18.599481 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:33:18.630579 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:33:18.633143 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:33:18.633512 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:33:18.633782 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:33:18.664142 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:33:18.668349 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:33:18.668995 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:33:18.716798 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:33:18.720734 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:33:11.293898 => 19:33:18.720059
[0m19:33:18.721294 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:33:18.723387 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '114235b2-5b77-4bdd-9f39-f53c88f76993', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078fac10>]}
[0m19:33:18.724169 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46550[0m in 7.45s]
[0m19:33:18.724954 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:33:18.726215 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:33:18.727572 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m19:33:18.729187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m19:33:18.729512 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:33:18.746901 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:33:18.749419 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 19:33:18.729708 => 19:33:18.749087
[0m19:33:18.749831 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:33:18.764763 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:33:18.765700 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:33:18.766048 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m19:33:18.766349 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:33:19.027316 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:33:19.029051 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:33:19.029891 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m19:33:19.225172 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:33:19.230618 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 19:33:18.750039 => 19:33:19.230327
[0m19:33:19.231134 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m19:33:19.262405 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m19:33:19.264893 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 0.54s]
[0m19:33:19.265866 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:33:19.267099 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:33:19.268424 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m19:33:19.269524 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m19:33:19.269863 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:33:19.279835 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:33:19.281360 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 19:33:19.270064 => 19:33:19.281039
[0m19:33:19.281851 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:33:19.285249 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:33:19.286122 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:33:19.286470 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m19:33:19.286798 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:33:19.547673 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:33:19.548902 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:33:19.549563 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:33:21.169616 [debug] [Thread-1 (]: SQL status: SELECT 1 in 2.0 seconds
[0m19:33:21.173992 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 19:33:19.282107 => 19:33:21.173536
[0m19:33:21.174549 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m19:33:21.297563 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m19:33:21.299663 [error] [Thread-1 (]: 4 of 6 FAIL 188281 unique_outclick_by_brand_int_id ............................. [[31mFAIL 188281[0m in 2.03s]
[0m19:33:21.301882 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:33:21.303064 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:33:21.303613 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:33:21.305317 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:33:21.306098 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:33:21.315201 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:33:21.317753 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:33:21.306738 => 19:33:21.317273
[0m19:33:21.318497 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:33:21.321936 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:33:21.323073 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:33:21.323460 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:33:21.323744 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:33:21.679611 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:33:21.680876 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:33:21.681357 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:33:21.725520 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:33:21.728830 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:33:21.318863 => 19:33:21.728254
[0m19:33:21.729652 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:33:21.763198 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:33:21.765038 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.46s]
[0m19:33:21.766717 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:33:21.767977 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:33:21.769246 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:33:21.771189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:33:21.771879 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:33:21.778407 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:33:21.780760 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:33:21.772347 => 19:33:21.780218
[0m19:33:21.781365 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:33:21.785419 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:33:21.786933 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:33:21.787482 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:33:21.787878 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:33:22.108767 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:33:22.110086 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:33:22.111005 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:33:22.178274 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:33:22.183615 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:33:21.782055 => 19:33:22.182768
[0m19:33:22.184910 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:33:22.216107 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:33:22.219565 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.45s]
[0m19:33:22.221170 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:33:22.223477 [debug] [MainThread]: Using postgres connection "master"
[0m19:33:22.224697 [debug] [MainThread]: On master: BEGIN
[0m19:33:22.225498 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:33:22.530245 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:33:22.531713 [debug] [MainThread]: On master: COMMIT
[0m19:33:22.532292 [debug] [MainThread]: Using postgres connection "master"
[0m19:33:22.532676 [debug] [MainThread]: On master: COMMIT
[0m19:33:22.569698 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:33:22.570668 [debug] [MainThread]: On master: Close
[0m19:33:22.572302 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:33:22.572904 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:33:22.573510 [info ] [MainThread]: 
[0m19:33:22.574106 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 55.13 seconds (55.13s).
[0m19:33:22.575822 [debug] [MainThread]: Command end result
[0m19:33:22.595779 [info ] [MainThread]: 
[0m19:33:22.596780 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:33:22.597615 [info ] [MainThread]: 
[0m19:33:22.598367 [error] [MainThread]: [31mFailure in test unique_outclick_by_brand_int_id (models/brand_performance/schema.yml)[0m
[0m19:33:22.598885 [error] [MainThread]:   Got 188281 results, configured to fail if != 0
[0m19:33:22.599294 [info ] [MainThread]: 
[0m19:33:22.599700 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_by_brand_int_id.sql
[0m19:33:22.600120 [info ] [MainThread]: 
[0m19:33:22.600621 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m19:33:22.602059 [debug] [MainThread]: Command `dbt build` failed at 19:33:22.601787 after 55.24 seconds
[0m19:33:22.602722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10335a4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10335a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046f0090>]}
[0m19:33:22.603206 [debug] [MainThread]: Flushing usage events
[0m19:37:36.329348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f6f510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f81650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f8bcd0>]}


============================== 19:37:36.330721 | 96dce8d1-7e41-4321-825e-e413cc7639a9 ==============================
[0m19:37:36.330721 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:37:36.331021 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'cache_selected_only': 'False', 'printer_width': '80', 'version_check': 'True', 'static_parser': 'True', 'quiet': 'False', 'use_colors': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'write_json': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'debug': 'False', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'partial_parse': 'True', 'log_cache_events': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt'}
[0m19:37:36.358589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96dce8d1-7e41-4321-825e-e413cc7639a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fa96d0>]}
[0m19:37:36.364702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96dce8d1-7e41-4321-825e-e413cc7639a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a44fd10>]}
[0m19:37:36.365169 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:37:36.375513 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:37:36.411065 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:37:36.411249 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:37:36.411468 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:37:36.413738 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96dce8d1-7e41-4321-825e-e413cc7639a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a533690>]}
[0m19:37:36.417124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96dce8d1-7e41-4321-825e-e413cc7639a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a471c50>]}
[0m19:37:36.417301 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:37:36.418045 [info ] [MainThread]: 
[0m19:37:36.418367 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:37:36.418811 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:37:36.422817 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:37:36.422959 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:37:36.423067 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:37:36.734403 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:37:36.735674 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:37:36.736931 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:37:36.741160 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:37:36.741421 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:37:36.741605 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:37:37.022445 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:37:37.024232 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:37:37.025301 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:37:37.072877 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:37:37.078115 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:37:37.112232 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:37:37.124417 [debug] [MainThread]: Using postgres connection "master"
[0m19:37:37.124814 [debug] [MainThread]: On master: BEGIN
[0m19:37:37.125122 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:37:37.454833 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:37:37.455785 [debug] [MainThread]: Using postgres connection "master"
[0m19:37:37.456371 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:37:37.506799 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:37:37.509008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96dce8d1-7e41-4321-825e-e413cc7639a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4e0a50>]}
[0m19:37:37.509588 [debug] [MainThread]: On master: ROLLBACK
[0m19:37:37.550046 [debug] [MainThread]: Using postgres connection "master"
[0m19:37:37.550311 [debug] [MainThread]: On master: BEGIN
[0m19:37:37.629615 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:37:37.629950 [debug] [MainThread]: On master: COMMIT
[0m19:37:37.630164 [debug] [MainThread]: Using postgres connection "master"
[0m19:37:37.630369 [debug] [MainThread]: On master: COMMIT
[0m19:37:37.670325 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:37:37.670640 [debug] [MainThread]: On master: Close
[0m19:37:37.671481 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:37:37.671885 [info ] [MainThread]: 
[0m19:37:37.678152 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:37:37.678688 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:37:37.679407 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:37:37.679734 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:37:37.697304 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:37:37.697914 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:37:37.679946 => 19:37:37.697776
[0m19:37:37.698140 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:37:37.718697 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:37:37.719147 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:37:37.719307 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:37:37.719457 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:37:37.972811 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:37:37.973258 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:37:37.973749 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
    --    and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
--    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:38:10.446623 [debug] [Thread-1 (]: SQL status: SELECT 932605 in 32.0 seconds
[0m19:38:10.464006 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:38:10.464743 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:38:10.496195 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:38:10.504346 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:38:10.505308 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:38:10.537451 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:38:10.573766 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:38:10.574265 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:38:10.574641 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:38:10.606838 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:38:10.614902 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:38:10.615431 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:38:10.687836 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:38:10.692563 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:37:37.698273 => 19:38:10.691893
[0m19:38:10.693725 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:38:10.695612 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96dce8d1-7e41-4321-825e-e413cc7639a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5a4310>]}
[0m19:38:10.697665 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 932605[0m in 33.02s]
[0m19:38:10.699790 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:38:10.701106 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:38:10.703085 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:38:10.704904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:38:10.705695 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:38:10.719620 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:38:10.721127 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:38:10.706303 => 19:38:10.720894
[0m19:38:10.721622 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:38:10.726812 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:38:10.727719 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:38:10.728095 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:38:10.728438 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:38:11.126430 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:38:11.128104 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:38:11.129929 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:38:16.305391 [debug] [Thread-1 (]: SQL status: SELECT 46550 in 5.0 seconds
[0m19:38:16.314852 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:38:16.315340 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:38:16.346602 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:38:16.356768 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:38:16.357978 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:38:16.389592 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:38:16.395367 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:38:16.396401 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:38:16.397336 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:38:16.428725 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:38:16.436401 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:38:16.436790 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:38:16.484320 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:38:16.489440 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:38:10.721940 => 19:38:16.488831
[0m19:38:16.490577 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:38:16.493129 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96dce8d1-7e41-4321-825e-e413cc7639a9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6b70d0>]}
[0m19:38:16.494894 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46550[0m in 5.79s]
[0m19:38:16.496725 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:38:16.497938 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:38:16.499624 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m19:38:16.501450 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m19:38:16.502355 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:38:16.519377 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:38:16.520716 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 19:38:16.502929 => 19:38:16.520336
[0m19:38:16.521227 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:38:16.535093 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:38:16.536224 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:38:16.536571 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m19:38:16.536868 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:38:16.794968 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:38:16.795464 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:38:16.795765 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m19:38:16.923097 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:38:16.927609 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 19:38:16.521496 => 19:38:16.927204
[0m19:38:16.928254 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m19:38:16.959306 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m19:38:16.962489 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 0.46s]
[0m19:38:16.964609 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:38:16.965795 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:38:16.967157 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m19:38:16.969158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m19:38:16.970172 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:38:16.983438 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:38:16.985383 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 19:38:16.970805 => 19:38:16.984973
[0m19:38:16.985881 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:38:16.989266 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:38:16.990542 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:38:16.990929 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m19:38:16.991161 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:38:17.249146 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:38:17.251215 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:38:17.251842 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:38:18.517815 [debug] [Thread-1 (]: SQL status: SELECT 1 in 1.0 seconds
[0m19:38:18.521319 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 19:38:16.986137 => 19:38:18.520953
[0m19:38:18.521955 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m19:38:18.553266 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m19:38:18.555945 [error] [Thread-1 (]: 4 of 6 FAIL 188281 unique_outclick_by_brand_int_id ............................. [[31mFAIL 188281[0m in 1.59s]
[0m19:38:18.556976 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:38:18.558013 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:38:18.558849 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:38:18.559754 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:38:18.560208 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:38:18.567179 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:38:18.568883 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:38:18.560501 => 19:38:18.568594
[0m19:38:18.569377 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:38:18.572753 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:38:18.574195 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:38:18.574639 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:38:18.575047 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:38:18.836954 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:38:18.838684 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:38:18.839855 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:38:18.882930 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:38:18.885493 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:38:18.569681 => 19:38:18.885204
[0m19:38:18.886049 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:38:18.917623 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:38:18.919509 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.36s]
[0m19:38:18.920846 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:38:18.921507 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:38:18.922039 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:38:18.923044 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:38:18.923693 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:38:18.930707 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:38:18.932416 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:38:18.924112 => 19:38:18.932109
[0m19:38:18.932927 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:38:18.935702 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:38:18.937052 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:38:18.937518 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:38:18.937990 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:38:19.196581 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:38:19.198547 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:38:19.200370 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:38:19.264166 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:38:19.267551 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:38:18.933267 => 19:38:19.267117
[0m19:38:19.268306 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:38:19.299606 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:38:19.303284 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.38s]
[0m19:38:19.305588 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:38:19.308931 [debug] [MainThread]: Using postgres connection "master"
[0m19:38:19.309513 [debug] [MainThread]: On master: BEGIN
[0m19:38:19.310057 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:38:19.567216 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:38:19.568773 [debug] [MainThread]: On master: COMMIT
[0m19:38:19.569732 [debug] [MainThread]: Using postgres connection "master"
[0m19:38:19.570729 [debug] [MainThread]: On master: COMMIT
[0m19:38:19.602071 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:38:19.603241 [debug] [MainThread]: On master: Close
[0m19:38:19.605458 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:38:19.605918 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:38:19.606526 [info ] [MainThread]: 
[0m19:38:19.607264 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 43.19 seconds (43.19s).
[0m19:38:19.609659 [debug] [MainThread]: Command end result
[0m19:38:19.628406 [info ] [MainThread]: 
[0m19:38:19.629274 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:38:19.629754 [info ] [MainThread]: 
[0m19:38:19.630209 [error] [MainThread]: [31mFailure in test unique_outclick_by_brand_int_id (models/brand_performance/schema.yml)[0m
[0m19:38:19.630708 [error] [MainThread]:   Got 188281 results, configured to fail if != 0
[0m19:38:19.631456 [info ] [MainThread]: 
[0m19:38:19.631995 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_by_brand_int_id.sql
[0m19:38:19.632428 [info ] [MainThread]: 
[0m19:38:19.632835 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m19:38:19.633593 [debug] [MainThread]: Command `dbt build` failed at 19:38:19.633472 after 43.31 seconds
[0m19:38:19.634016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e764d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e76410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a46b610>]}
[0m19:38:19.634412 [debug] [MainThread]: Flushing usage events
[0m19:43:38.635487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c6da10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c8c710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c8ce10>]}


============================== 19:43:38.637217 | af995481-d9ae-4af3-961a-97b96e152937 ==============================
[0m19:43:38.637217 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:43:38.637551 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'debug': 'False', 'version_check': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'static_parser': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'log_format': 'default', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'quiet': 'False', 'partial_parse': 'True', 'no_print': 'None'}
[0m19:43:38.667266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'af995481-d9ae-4af3-961a-97b96e152937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094dca90>]}
[0m19:43:38.673565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'af995481-d9ae-4af3-961a-97b96e152937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa20650>]}
[0m19:43:38.674016 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:43:38.684456 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:43:38.719547 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:43:38.719751 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:43:38.719974 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:43:38.722290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'af995481-d9ae-4af3-961a-97b96e152937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab16b90>]}
[0m19:43:38.725560 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'af995481-d9ae-4af3-961a-97b96e152937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c9dbd0>]}
[0m19:43:38.725736 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:43:38.726512 [info ] [MainThread]: 
[0m19:43:38.726885 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:43:38.727343 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:43:38.731257 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:43:38.731385 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:43:38.731491 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:43:39.122673 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:43:39.124062 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:43:39.125492 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:43:39.130165 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:43:39.130387 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:43:39.130561 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:43:39.386677 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:43:39.388483 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:43:39.389755 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:43:39.424593 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:43:39.429144 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:43:39.474975 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:43:39.487694 [debug] [MainThread]: Using postgres connection "master"
[0m19:43:39.488349 [debug] [MainThread]: On master: BEGIN
[0m19:43:39.488759 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:43:39.851860 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:43:39.853504 [debug] [MainThread]: Using postgres connection "master"
[0m19:43:39.854439 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:43:39.913039 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:43:39.917256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'af995481-d9ae-4af3-961a-97b96e152937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108fa4d90>]}
[0m19:43:39.918246 [debug] [MainThread]: On master: ROLLBACK
[0m19:43:39.951430 [debug] [MainThread]: Using postgres connection "master"
[0m19:43:39.952587 [debug] [MainThread]: On master: BEGIN
[0m19:43:40.104021 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:43:40.104474 [debug] [MainThread]: On master: COMMIT
[0m19:43:40.104693 [debug] [MainThread]: Using postgres connection "master"
[0m19:43:40.104882 [debug] [MainThread]: On master: COMMIT
[0m19:43:40.138145 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:43:40.138408 [debug] [MainThread]: On master: Close
[0m19:43:40.138950 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:43:40.139208 [info ] [MainThread]: 
[0m19:43:40.142945 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:43:40.143316 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:43:40.143830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:43:40.144068 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:43:40.158775 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:40.159333 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:43:40.144226 => 19:43:40.159215
[0m19:43:40.159528 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:43:40.178565 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:40.179066 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:40.179222 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:43:40.179382 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:43:40.457218 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:43:40.458827 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:40.460205 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
       
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
       --and date(timestamp - interval '2 hours') >'2023-12-31'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:43:48.155242 [debug] [Thread-1 (]: SQL status: SELECT 156844 in 8.0 seconds
[0m19:43:48.168723 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:48.169483 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:43:48.202989 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:43:48.207843 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:48.208468 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:43:48.242308 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:43:48.275062 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:43:48.275543 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:48.275934 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:43:48.309797 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:43:48.317030 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:43:48.317501 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:43:48.392222 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:43:48.397764 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:43:40.159643 => 19:43:48.397091
[0m19:43:48.399025 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:43:48.401866 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af995481-d9ae-4af3-961a-97b96e152937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa82c10>]}
[0m19:43:48.403092 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156844[0m in 8.26s]
[0m19:43:48.403628 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:43:48.403962 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:43:48.404997 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:43:48.406589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:43:48.407234 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:43:48.419260 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:43:48.420754 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:43:48.407598 => 19:43:48.420451
[0m19:43:48.421179 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:43:48.425902 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:43:48.426850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:43:48.427239 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:43:48.427594 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:43:48.969122 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:43:48.970105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:43:48.971374 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:43:53.687986 [debug] [Thread-1 (]: SQL status: SELECT 46550 in 5.0 seconds
[0m19:43:53.700063 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:43:53.700897 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:43:53.743773 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:43:53.749560 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:43:53.750157 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:43:53.794079 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:43:53.798174 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:43:53.798658 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:43:53.798971 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:43:53.841916 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:43:53.847096 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:43:53.847472 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:43:53.904848 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:43:53.906672 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:43:48.421429 => 19:43:53.906504
[0m19:43:53.906991 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:43:53.908750 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af995481-d9ae-4af3-961a-97b96e152937', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac4c210>]}
[0m19:43:53.910318 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46550[0m in 5.50s]
[0m19:43:53.912076 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:43:53.913356 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:43:53.914959 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m19:43:53.917122 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m19:43:53.918150 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:43:53.935838 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:43:53.936990 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 19:43:53.918667 => 19:43:53.936774
[0m19:43:53.937389 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:43:53.948855 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:43:53.949647 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:43:53.949983 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m19:43:53.950291 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:43:54.348976 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:43:54.349936 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:43:54.350653 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m19:43:54.434181 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:43:54.436234 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 19:43:53.937596 => 19:43:54.436044
[0m19:43:54.436554 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m19:43:54.479525 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m19:43:54.480896 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 0.56s]
[0m19:43:54.481752 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:43:54.482376 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:43:54.482937 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m19:43:54.483696 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m19:43:54.484043 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:43:54.492598 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:43:54.493632 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 19:43:54.484295 => 19:43:54.493383
[0m19:43:54.494053 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:43:54.496180 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:43:54.496766 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:43:54.497062 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m19:43:54.497336 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:43:54.777384 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:43:54.778426 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:43:54.778969 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:43:54.936286 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:43:54.941187 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 19:43:54.494297 => 19:43:54.940605
[0m19:43:54.942116 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m19:43:54.986720 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m19:43:54.988937 [error] [Thread-1 (]: 4 of 6 FAIL 28067 unique_outclick_by_brand_int_id .............................. [[31mFAIL 28067[0m in 0.51s]
[0m19:43:54.990532 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:43:54.991100 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:43:54.992178 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:43:54.992953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:43:54.993331 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:43:55.000801 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:43:55.001963 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:43:54.993531 => 19:43:55.001747
[0m19:43:55.002577 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:43:55.006485 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:43:55.007920 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:43:55.008398 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:43:55.008777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:43:55.349193 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:43:55.349940 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:43:55.350374 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:43:55.393186 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:43:55.398776 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:43:55.003004 => 19:43:55.398073
[0m19:43:55.399961 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:43:55.431069 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:43:55.434179 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.44s]
[0m19:43:55.435339 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:43:55.436110 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:43:55.436911 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:43:55.438427 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:43:55.439593 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:43:55.449880 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:43:55.451572 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:43:55.440418 => 19:43:55.451268
[0m19:43:55.452205 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:43:55.455760 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:43:55.456831 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:43:55.457309 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:43:55.457710 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:43:55.713024 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:43:55.714160 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:43:55.715608 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:43:55.777401 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:43:55.781018 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:43:55.452584 => 19:43:55.780693
[0m19:43:55.782050 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:43:55.813290 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:43:55.815872 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.38s]
[0m19:43:55.817235 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:43:55.819552 [debug] [MainThread]: Using postgres connection "master"
[0m19:43:55.820368 [debug] [MainThread]: On master: BEGIN
[0m19:43:55.821213 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:43:56.080211 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:43:56.081829 [debug] [MainThread]: On master: COMMIT
[0m19:43:56.082874 [debug] [MainThread]: Using postgres connection "master"
[0m19:43:56.083818 [debug] [MainThread]: On master: COMMIT
[0m19:43:56.117019 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:43:56.117966 [debug] [MainThread]: On master: Close
[0m19:43:56.119936 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:43:56.120649 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:43:56.121503 [info ] [MainThread]: 
[0m19:43:56.122327 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 17.39 seconds (17.39s).
[0m19:43:56.124643 [debug] [MainThread]: Command end result
[0m19:43:56.142300 [info ] [MainThread]: 
[0m19:43:56.143225 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:43:56.143736 [info ] [MainThread]: 
[0m19:43:56.144357 [error] [MainThread]: [31mFailure in test unique_outclick_by_brand_int_id (models/brand_performance/schema.yml)[0m
[0m19:43:56.145011 [error] [MainThread]:   Got 28067 results, configured to fail if != 0
[0m19:43:56.145581 [info ] [MainThread]: 
[0m19:43:56.146209 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_by_brand_int_id.sql
[0m19:43:56.146651 [info ] [MainThread]: 
[0m19:43:56.147083 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m19:43:56.147830 [debug] [MainThread]: Command `dbt build` failed at 19:43:56.147702 after 17.59 seconds
[0m19:43:56.148263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a55650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a54850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ab57c90>]}
[0m19:43:56.148657 [debug] [MainThread]: Flushing usage events
[0m19:48:26.087124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10666cc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066869d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106687610>]}


============================== 19:48:26.088782 | d330c2e5-ea61-4aa0-88e9-ebc39613af07 ==============================
[0m19:48:26.088782 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:48:26.089091 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'cache_selected_only': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'log_format': 'default', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'static_parser': 'True', 'use_colors': 'True', 'no_print': 'None', 'use_experimental_parser': 'False', 'version_check': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'debug': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'printer_width': '80', 'fail_fast': 'False'}
[0m19:48:26.119659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd330c2e5-ea61-4aa0-88e9-ebc39613af07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066789d0>]}
[0m19:48:26.126064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd330c2e5-ea61-4aa0-88e9-ebc39613af07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10635d350>]}
[0m19:48:26.126584 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:48:26.136610 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:48:26.165846 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:48:26.166072 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:48:26.166309 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:48:26.168614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd330c2e5-ea61-4aa0-88e9-ebc39613af07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c14210>]}
[0m19:48:26.171995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd330c2e5-ea61-4aa0-88e9-ebc39613af07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069eed10>]}
[0m19:48:26.172159 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:48:26.172846 [info ] [MainThread]: 
[0m19:48:26.173158 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:48:26.173608 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:48:26.177673 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:48:26.177820 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:48:26.177933 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:48:26.517853 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:48:26.521324 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:48:26.524651 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:48:26.532511 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:48:26.533229 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:48:26.533561 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:48:26.812762 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:48:26.814459 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:48:26.815538 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:48:26.854088 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:48:26.859310 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:48:26.892564 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:48:26.906945 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:26.907693 [debug] [MainThread]: On master: BEGIN
[0m19:48:26.908199 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:48:27.189866 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:27.191689 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:27.192714 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:48:27.237613 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:48:27.242444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd330c2e5-ea61-4aa0-88e9-ebc39613af07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069ab1d0>]}
[0m19:48:27.243507 [debug] [MainThread]: On master: ROLLBACK
[0m19:48:27.276983 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:27.277821 [debug] [MainThread]: On master: BEGIN
[0m19:48:27.343844 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:27.344375 [debug] [MainThread]: On master: COMMIT
[0m19:48:27.344616 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:27.344828 [debug] [MainThread]: On master: COMMIT
[0m19:48:27.377967 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:48:27.378407 [debug] [MainThread]: On master: Close
[0m19:48:27.379244 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:48:27.379577 [info ] [MainThread]: 
[0m19:48:27.384742 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:48:27.385211 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:48:27.385865 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:48:27.386128 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:48:27.402002 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:48:27.402977 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:48:27.386289 => 19:48:27.402825
[0m19:48:27.403210 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:48:27.423476 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:48:27.424136 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:48:27.424293 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:48:27.424439 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:48:27.701501 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:48:27.703079 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:48:27.704734 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        --
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
        --and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:48:27.742237 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "CASE"
LINE 47:     CASE
             ^

[0m19:48:27.744073 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: ROLLBACK
[0m19:48:27.778823 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:48:27.403333 => 19:48:27.777674
[0m19:48:27.780379 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:48:27.794552 [debug] [Thread-1 (]: Database Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)
  syntax error at or near "CASE"
  LINE 47:     CASE
               ^
  compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:48:27.795722 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd330c2e5-ea61-4aa0-88e9-ebc39613af07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106cac150>]}
[0m19:48:27.797106 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model danila.outclick_by_brand_int ............. [[31mERROR[0m in 0.41s]
[0m19:48:27.797895 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:48:27.798352 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:48:27.798980 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:48:27.800068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:48:27.800488 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:48:27.808860 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:48:27.809812 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:48:27.800723 => 19:48:27.809635
[0m19:48:27.810103 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:48:27.813459 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:48:27.814186 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:27.814409 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:48:27.814620 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:48:28.119934 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:48:28.121629 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:28.123133 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:48:32.937802 [debug] [Thread-1 (]: SQL status: SELECT 46551 in 5.0 seconds
[0m19:48:32.947866 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:32.948309 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:48:32.984810 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:48:32.987357 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:32.987816 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:48:33.025281 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:48:33.042079 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:48:33.042488 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:33.042623 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:48:33.080111 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:48:33.085854 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:48:33.086244 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:48:33.138904 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:48:33.143044 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:48:27.810286 => 19:48:33.142667
[0m19:48:33.143787 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:48:33.145643 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd330c2e5-ea61-4aa0-88e9-ebc39613af07', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c04290>]}
[0m19:48:33.146861 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46551[0m in 5.35s]
[0m19:48:33.147781 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:48:33.148382 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:48:33.149216 [info ] [Thread-1 (]: 3 of 6 SKIP test not_null_outclick_by_brand_int_id ............................. [[33mSKIP[0m]
[0m19:48:33.149709 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:48:33.150078 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:48:33.150552 [info ] [Thread-1 (]: 4 of 6 SKIP test unique_outclick_by_brand_int_id ............................... [[33mSKIP[0m]
[0m19:48:33.151198 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:48:33.151659 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:48:33.152131 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:48:33.153235 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:48:33.153806 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:48:33.162733 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:48:33.163626 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:48:33.154093 => 19:48:33.163513
[0m19:48:33.163806 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:48:33.171364 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:48:33.172026 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:48:33.172257 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:48:33.172468 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:48:33.498920 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:48:33.500544 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:48:33.501282 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:48:33.553468 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:48:33.559542 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:48:33.163911 => 19:48:33.558788
[0m19:48:33.560635 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:48:33.601496 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:48:33.604142 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.45s]
[0m19:48:33.605366 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:48:33.606030 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:48:33.606780 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:48:33.608202 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:48:33.608842 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:48:33.618650 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:48:33.620697 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:48:33.609186 => 19:48:33.620213
[0m19:48:33.621336 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:48:33.623113 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:48:33.623684 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:48:33.623821 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:48:33.623941 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:48:33.880118 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:48:33.881815 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:48:33.882360 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:48:33.944336 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:48:33.948847 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:48:33.621645 => 19:48:33.948288
[0m19:48:33.949628 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:48:33.980460 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:48:33.983480 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.38s]
[0m19:48:33.984866 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:48:33.987406 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:33.987773 [debug] [MainThread]: On master: BEGIN
[0m19:48:33.988078 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:48:34.315919 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:48:34.317330 [debug] [MainThread]: On master: COMMIT
[0m19:48:34.318023 [debug] [MainThread]: Using postgres connection "master"
[0m19:48:34.318836 [debug] [MainThread]: On master: COMMIT
[0m19:48:34.358551 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:48:34.359920 [debug] [MainThread]: On master: Close
[0m19:48:34.361941 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:48:34.362563 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:48:34.363159 [info ] [MainThread]: 
[0m19:48:34.363718 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 8.19 seconds (8.19s).
[0m19:48:34.365220 [debug] [MainThread]: Command end result
[0m19:48:34.376741 [info ] [MainThread]: 
[0m19:48:34.377516 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:48:34.377946 [info ] [MainThread]: 
[0m19:48:34.378333 [error] [MainThread]: [33mDatabase Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)[0m
[0m19:48:34.378684 [error] [MainThread]:   syntax error at or near "CASE"
[0m19:48:34.379027 [error] [MainThread]:   LINE 47:     CASE
[0m19:48:34.379339 [error] [MainThread]:                ^
[0m19:48:34.379646 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:48:34.379956 [info ] [MainThread]: 
[0m19:48:34.380185 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=2 TOTAL=6
[0m19:48:34.380584 [debug] [MainThread]: Command `dbt build` failed at 19:48:34.380520 after 8.30 seconds
[0m19:48:34.380815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100b9e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100b9e410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106687450>]}
[0m19:48:34.381026 [debug] [MainThread]: Flushing usage events
[0m19:49:23.021668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10616fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106186f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106187690>]}


============================== 19:49:23.022902 | f73d61ca-2de1-4ab2-958f-4d918361db6d ==============================
[0m19:49:23.022902 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:49:23.023212 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'log_cache_events': 'False', 'debug': 'False', 'partial_parse': 'True', 'static_parser': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'version_check': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'use_colors': 'True', 'write_json': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None'}
[0m19:49:23.051173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f73d61ca-2de1-4ab2-958f-4d918361db6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106179450>]}
[0m19:49:23.057562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f73d61ca-2de1-4ab2-958f-4d918361db6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106760810>]}
[0m19:49:23.057881 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:49:23.067603 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:49:23.097918 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:49:23.098107 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:49:23.098321 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:49:23.100598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f73d61ca-2de1-4ab2-958f-4d918361db6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10707a0d0>]}
[0m19:49:23.103879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f73d61ca-2de1-4ab2-958f-4d918361db6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106770590>]}
[0m19:49:23.104038 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:49:23.104751 [info ] [MainThread]: 
[0m19:49:23.105077 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:49:23.105548 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:49:23.109867 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:49:23.110073 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:49:23.110194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:49:23.442769 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:49:23.444838 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:49:23.446458 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:49:23.450652 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:49:23.450799 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:49:23.450932 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:49:23.707392 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:49:23.708926 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:49:23.709847 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:49:23.748377 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:49:23.753229 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:49:23.787156 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:49:23.803436 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:23.804144 [debug] [MainThread]: On master: BEGIN
[0m19:49:23.804415 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:49:24.102504 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:49:24.104113 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:24.105577 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:49:24.149843 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:49:24.154626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f73d61ca-2de1-4ab2-958f-4d918361db6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c3550>]}
[0m19:49:24.155775 [debug] [MainThread]: On master: ROLLBACK
[0m19:49:24.190560 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:24.192143 [debug] [MainThread]: On master: BEGIN
[0m19:49:24.259144 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:49:24.260109 [debug] [MainThread]: On master: COMMIT
[0m19:49:24.260483 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:24.260794 [debug] [MainThread]: On master: COMMIT
[0m19:49:24.294108 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:49:24.294933 [debug] [MainThread]: On master: Close
[0m19:49:24.296017 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:49:24.296446 [info ] [MainThread]: 
[0m19:49:24.305812 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:24.306759 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:49:24.308062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:49:24.308948 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:24.331551 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:24.332571 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:49:24.309318 => 19:49:24.332393
[0m19:49:24.332857 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:24.355384 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:24.356145 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:24.356326 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:49:24.356497 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:24.613972 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:49:24.615651 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:24.616928 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        --
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
        --and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:49:24.652581 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "CASE"
LINE 47:     CASE
             ^

[0m19:49:24.654323 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: ROLLBACK
[0m19:49:24.686461 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:49:24.333016 => 19:49:24.685633
[0m19:49:24.688036 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:49:24.698852 [debug] [Thread-1 (]: Database Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)
  syntax error at or near "CASE"
  LINE 47:     CASE
               ^
  compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:49:24.699658 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f73d61ca-2de1-4ab2-958f-4d918361db6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107095950>]}
[0m19:49:24.700468 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model danila.outclick_by_brand_int ............. [[31mERROR[0m in 0.39s]
[0m19:49:24.701040 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:24.701481 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:49:24.702322 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:49:24.703228 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:49:24.703550 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:49:24.712199 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:49:24.713505 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:49:24.703742 => 19:49:24.713282
[0m19:49:24.713860 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:49:24.717270 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:49:24.717869 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:24.718124 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:49:24.718370 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:25.351862 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m19:49:25.353482 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:25.355006 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:49:30.161856 [debug] [Thread-1 (]: SQL status: SELECT 46551 in 5.0 seconds
[0m19:49:30.173634 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:30.174437 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:49:30.211575 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:49:30.216535 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:30.217715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:49:30.255793 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:49:30.277339 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:49:30.277849 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:30.278096 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:49:30.314850 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:49:30.320280 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:30.320759 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:49:30.372881 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:49:30.375997 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:49:24.714039 => 19:49:30.375696
[0m19:49:30.376568 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:49:30.377661 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f73d61ca-2de1-4ab2-958f-4d918361db6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107094dd0>]}
[0m19:49:30.378306 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46551[0m in 5.67s]
[0m19:49:30.378904 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:49:30.379301 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:49:30.379833 [info ] [Thread-1 (]: 3 of 6 SKIP test not_null_outclick_by_brand_int_id ............................. [[33mSKIP[0m]
[0m19:49:30.380682 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:49:30.381173 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:49:30.381647 [info ] [Thread-1 (]: 4 of 6 SKIP test unique_outclick_by_brand_int_id ............................... [[33mSKIP[0m]
[0m19:49:30.382152 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:49:30.382546 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:30.382940 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:49:30.383626 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:49:30.383948 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:30.394189 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:30.394945 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:49:30.384124 => 19:49:30.394804
[0m19:49:30.395182 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:30.404346 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:30.404942 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:30.405127 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:49:30.405301 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:30.691888 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:49:30.694254 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:30.695074 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:49:30.739785 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:49:30.745607 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:49:30.395328 => 19:49:30.745102
[0m19:49:30.746710 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:49:30.781527 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:49:30.785276 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.40s]
[0m19:49:30.786441 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:30.787419 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:30.788132 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:49:30.789532 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:49:30.790106 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:30.798206 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:30.799269 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:49:30.790485 => 19:49:30.799060
[0m19:49:30.799608 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:30.801932 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:30.802606 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:30.802882 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:49:30.803156 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:31.061143 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:49:31.062893 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:31.064104 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:49:31.123163 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:49:31.126717 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:49:30.799814 => 19:49:31.126279
[0m19:49:31.127514 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:49:31.163726 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:49:31.166009 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.38s]
[0m19:49:31.167298 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:31.169822 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:31.170516 [debug] [MainThread]: On master: BEGIN
[0m19:49:31.170822 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:49:31.505859 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:49:31.507247 [debug] [MainThread]: On master: COMMIT
[0m19:49:31.508174 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:31.508925 [debug] [MainThread]: On master: COMMIT
[0m19:49:31.549078 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:49:31.550711 [debug] [MainThread]: On master: Close
[0m19:49:31.552689 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:49:31.553294 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:49:31.553941 [info ] [MainThread]: 
[0m19:49:31.554650 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 8.45 seconds (8.45s).
[0m19:49:31.556679 [debug] [MainThread]: Command end result
[0m19:49:31.567787 [info ] [MainThread]: 
[0m19:49:31.568614 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:49:31.569011 [info ] [MainThread]: 
[0m19:49:31.569393 [error] [MainThread]: [33mDatabase Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)[0m
[0m19:49:31.569665 [error] [MainThread]:   syntax error at or near "CASE"
[0m19:49:31.569815 [error] [MainThread]:   LINE 47:     CASE
[0m19:49:31.569944 [error] [MainThread]:                ^
[0m19:49:31.570058 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:49:31.570192 [info ] [MainThread]: 
[0m19:49:31.570386 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=2 TOTAL=6
[0m19:49:31.570730 [debug] [MainThread]: Command `dbt build` failed at 19:49:31.570682 after 8.56 seconds
[0m19:49:31.570908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101280890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101281650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101de9790>]}
[0m19:49:31.571098 [debug] [MainThread]: Flushing usage events
[0m19:49:43.590895 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11006e1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110086d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110087410>]}


============================== 19:49:43.592331 | 0e71e107-615a-4e0f-84a4-bf4e58638166 ==============================
[0m19:49:43.592331 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:49:43.592746 [debug] [MainThread]: running dbt with arguments {'fail_fast': 'False', 'debug': 'False', 'quiet': 'False', 'introspect': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'use_experimental_parser': 'False', 'use_colors': 'True', 'printer_width': '80', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'partial_parse': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'warn_error': 'None', 'indirect_selection': 'eager'}
[0m19:49:43.621131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0e71e107-615a-4e0f-84a4-bf4e58638166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110079390>]}
[0m19:49:43.628150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0e71e107-615a-4e0f-84a4-bf4e58638166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104c4750>]}
[0m19:49:43.628729 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:49:43.638942 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:49:43.667484 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:49:43.667661 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:49:43.667879 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:49:43.670123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0e71e107-615a-4e0f-84a4-bf4e58638166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079d5010>]}
[0m19:49:43.673666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0e71e107-615a-4e0f-84a4-bf4e58638166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104e5c90>]}
[0m19:49:43.673895 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:49:43.674691 [info ] [MainThread]: 
[0m19:49:43.675032 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:49:43.675530 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:49:43.680011 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:49:43.680297 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:49:43.680441 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:49:44.031420 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:49:44.033055 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:49:44.034753 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:49:44.039613 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:49:44.039930 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:49:44.040158 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:49:44.629275 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m19:49:44.630482 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:49:44.631092 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:49:44.672234 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:49:44.675610 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:49:44.712624 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:49:44.724420 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:44.725000 [debug] [MainThread]: On master: BEGIN
[0m19:49:44.725348 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:49:45.068096 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:49:45.070292 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:45.071205 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:49:45.137860 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:49:45.142849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0e71e107-615a-4e0f-84a4-bf4e58638166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11051ba90>]}
[0m19:49:45.143701 [debug] [MainThread]: On master: ROLLBACK
[0m19:49:45.174512 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:45.176044 [debug] [MainThread]: On master: BEGIN
[0m19:49:45.237619 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:49:45.238622 [debug] [MainThread]: On master: COMMIT
[0m19:49:45.239052 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:45.239410 [debug] [MainThread]: On master: COMMIT
[0m19:49:45.269941 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:49:45.271266 [debug] [MainThread]: On master: Close
[0m19:49:45.273452 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:49:45.274151 [info ] [MainThread]: 
[0m19:49:45.284965 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:45.285894 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:49:45.287051 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:49:45.287424 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:45.307706 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:45.308833 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:49:45.287590 => 19:49:45.308606
[0m19:49:45.309138 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:45.332459 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:45.333281 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:45.333473 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:49:45.333643 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:45.588668 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:49:45.589972 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:49:45.591287 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        --#
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --#and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
        --and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:49:45.629047 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "CASE"
LINE 47:     CASE
             ^

[0m19:49:45.630821 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: ROLLBACK
[0m19:49:45.664054 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:49:45.309303 => 19:49:45.663209
[0m19:49:45.665086 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:49:45.677561 [debug] [Thread-1 (]: Database Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)
  syntax error at or near "CASE"
  LINE 47:     CASE
               ^
  compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:49:45.678792 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e71e107-615a-4e0f-84a4-bf4e58638166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ff650>]}
[0m19:49:45.679910 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model danila.outclick_by_brand_int ............. [[31mERROR[0m in 0.39s]
[0m19:49:45.680584 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:49:45.681061 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:49:45.681870 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:49:45.682601 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:49:45.682912 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:49:45.690714 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:49:45.691531 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:49:45.683116 => 19:49:45.691368
[0m19:49:45.691802 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:49:45.694866 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:49:45.695430 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:45.695653 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:49:45.695872 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:45.953706 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:49:45.955065 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:45.956350 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:49:50.900430 [debug] [Thread-1 (]: SQL status: SELECT 46551 in 5.0 seconds
[0m19:49:50.913882 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:50.914818 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:49:50.946419 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:49:50.952807 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:50.953519 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:49:50.986341 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:49:51.009201 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:49:51.009662 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:51.009937 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:49:51.040382 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:49:51.045133 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:49:51.045484 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:49:51.090835 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:49:51.093872 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:49:45.691979 => 19:49:51.093524
[0m19:49:51.094524 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:49:51.096160 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0e71e107-615a-4e0f-84a4-bf4e58638166', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110546590>]}
[0m19:49:51.097197 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46551[0m in 5.41s]
[0m19:49:51.098318 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:49:51.099032 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:49:51.099896 [info ] [Thread-1 (]: 3 of 6 SKIP test not_null_outclick_by_brand_int_id ............................. [[33mSKIP[0m]
[0m19:49:51.100559 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:49:51.101006 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:49:51.101498 [info ] [Thread-1 (]: 4 of 6 SKIP test unique_outclick_by_brand_int_id ............................... [[33mSKIP[0m]
[0m19:49:51.102014 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:49:51.102359 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:51.102748 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:49:51.103482 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:49:51.103812 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:51.115463 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:51.116386 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:49:51.104016 => 19:49:51.116232
[0m19:49:51.116631 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:51.125857 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:51.126585 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:51.126781 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:49:51.126959 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:51.408697 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:49:51.409554 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:49:51.410024 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:49:51.467129 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:49:51.471972 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:49:51.116786 => 19:49:51.471522
[0m19:49:51.472782 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:49:51.504423 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:49:51.507919 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.40s]
[0m19:49:51.509089 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:49:51.509847 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:51.510656 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:49:51.511923 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:49:51.512376 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:51.522328 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:51.523445 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:49:51.512769 => 19:49:51.523193
[0m19:49:51.523828 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:51.526015 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:51.526633 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:51.526948 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:49:51.527240 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:49:51.887173 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:49:51.888102 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:49:51.888736 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:49:51.962537 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:49:51.965233 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:49:51.524040 => 19:49:51.964869
[0m19:49:51.965974 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:49:52.008711 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:49:52.011288 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.50s]
[0m19:49:52.012562 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:49:52.015039 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:52.015629 [debug] [MainThread]: On master: BEGIN
[0m19:49:52.016035 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:49:52.279092 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:49:52.280223 [debug] [MainThread]: On master: COMMIT
[0m19:49:52.280801 [debug] [MainThread]: Using postgres connection "master"
[0m19:49:52.281323 [debug] [MainThread]: On master: COMMIT
[0m19:49:52.312645 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:49:52.314727 [debug] [MainThread]: On master: Close
[0m19:49:52.317074 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:49:52.317935 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:49:52.318958 [info ] [MainThread]: 
[0m19:49:52.319984 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 8.64 seconds (8.64s).
[0m19:49:52.321985 [debug] [MainThread]: Command end result
[0m19:49:52.331854 [info ] [MainThread]: 
[0m19:49:52.332451 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:49:52.332842 [info ] [MainThread]: 
[0m19:49:52.333203 [error] [MainThread]: [33mDatabase Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)[0m
[0m19:49:52.333505 [error] [MainThread]:   syntax error at or near "CASE"
[0m19:49:52.333807 [error] [MainThread]:   LINE 47:     CASE
[0m19:49:52.334121 [error] [MainThread]:                ^
[0m19:49:52.334440 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:49:52.334771 [info ] [MainThread]: 
[0m19:49:52.335120 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=2 TOTAL=6
[0m19:49:52.335777 [debug] [MainThread]: Command `dbt build` failed at 19:49:52.335673 after 8.75 seconds
[0m19:49:52.336148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107d5d350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102fc5810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102fc4890>]}
[0m19:49:52.336495 [debug] [MainThread]: Flushing usage events
[0m19:55:16.623336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d75a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d89650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d9d110>]}


============================== 19:55:16.625099 | ba5b3a6a-677b-45e5-a812-549ce866eea8 ==============================
[0m19:55:16.625099 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:55:16.625403 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'log_path': '/Users/danila/github/dbt/logs', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'printer_width': '80', 'warn_error': 'None', 'use_colors': 'True', 'static_parser': 'True', 'debug': 'False', 'quiet': 'False', 'target_path': 'None', 'partial_parse': 'True', 'log_format': 'default', 'no_print': 'None', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True'}
[0m19:55:16.656004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba5b3a6a-677b-45e5-a812-549ce866eea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d80f10>]}
[0m19:55:16.662169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ba5b3a6a-677b-45e5-a812-549ce866eea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106218490>]}
[0m19:55:16.662653 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:55:16.673191 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:55:16.708426 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:55:16.708607 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:55:16.708827 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m19:55:16.711138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ba5b3a6a-677b-45e5-a812-549ce866eea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056156d0>]}
[0m19:55:16.714783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba5b3a6a-677b-45e5-a812-549ce866eea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061e4590>]}
[0m19:55:16.714984 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:55:16.715753 [info ] [MainThread]: 
[0m19:55:16.716081 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:55:16.716522 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:55:16.720432 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:55:16.720567 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:55:16.720670 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:55:17.038953 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:55:17.040594 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:55:17.042076 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:55:17.046949 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:55:17.047304 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:55:17.047545 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:55:17.310341 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:55:17.311694 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:55:17.312376 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:55:17.346981 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:55:17.351025 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:55:17.382465 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:55:17.397431 [debug] [MainThread]: Using postgres connection "master"
[0m19:55:17.398145 [debug] [MainThread]: On master: BEGIN
[0m19:55:17.398472 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:55:17.660104 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:55:17.660490 [debug] [MainThread]: Using postgres connection "master"
[0m19:55:17.660700 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:55:17.702345 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:55:17.705051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba5b3a6a-677b-45e5-a812-549ce866eea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051a0b90>]}
[0m19:55:17.705867 [debug] [MainThread]: On master: ROLLBACK
[0m19:55:17.737145 [debug] [MainThread]: Using postgres connection "master"
[0m19:55:17.737720 [debug] [MainThread]: On master: BEGIN
[0m19:55:17.800184 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:55:17.801600 [debug] [MainThread]: On master: COMMIT
[0m19:55:17.802572 [debug] [MainThread]: Using postgres connection "master"
[0m19:55:17.803359 [debug] [MainThread]: On master: COMMIT
[0m19:55:17.836167 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:55:17.837740 [debug] [MainThread]: On master: Close
[0m19:55:17.840572 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:55:17.841834 [info ] [MainThread]: 
[0m19:55:17.853142 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:55:17.854333 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:55:17.855490 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:55:17.856068 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:55:17.881824 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:55:17.882758 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:55:17.856328 => 19:55:17.882567
[0m19:55:17.883075 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:55:17.908320 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:55:17.909147 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:55:17.909346 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:55:17.909535 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:55:18.169505 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:55:18.171318 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:55:18.172974 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        --#
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --#and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
        --and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:55:18.207404 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "CASE"
LINE 47:     CASE
             ^

[0m19:55:18.208272 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: ROLLBACK
[0m19:55:18.239426 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:55:17.883258 => 19:55:18.238810
[0m19:55:18.240127 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:55:18.250760 [debug] [Thread-1 (]: Database Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)
  syntax error at or near "CASE"
  LINE 47:     CASE
               ^
  compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:55:18.252142 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba5b3a6a-677b-45e5-a812-549ce866eea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062fd510>]}
[0m19:55:18.253190 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model danila.outclick_by_brand_int ............. [[31mERROR[0m in 0.40s]
[0m19:55:18.254045 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:55:18.254722 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:55:18.255919 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:55:18.257084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:55:18.257473 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:55:18.268811 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:55:18.270074 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:55:18.257721 => 19:55:18.269777
[0m19:55:18.270588 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:55:18.274674 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:55:18.275459 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:55:18.275761 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:55:18.276175 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:55:18.537571 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:55:18.539319 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:55:18.541072 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:55:23.355435 [debug] [Thread-1 (]: SQL status: SELECT 46551 in 5.0 seconds
[0m19:55:23.363170 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:55:23.363579 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:55:23.395234 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:55:23.400785 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:55:23.401349 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:55:23.433386 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:55:23.459782 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:55:23.460169 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:55:23.460466 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:55:23.491465 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:55:23.499920 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:55:23.500475 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:55:23.549290 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:55:23.553238 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:55:18.270854 => 19:55:23.552835
[0m19:55:23.554043 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:55:23.555882 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ba5b3a6a-677b-45e5-a812-549ce866eea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106278a50>]}
[0m19:55:23.557074 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46551[0m in 5.30s]
[0m19:55:23.558211 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:55:23.558811 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:55:23.559554 [info ] [Thread-1 (]: 3 of 6 SKIP test not_null_outclick_by_brand_int_id ............................. [[33mSKIP[0m]
[0m19:55:23.560010 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:55:23.560371 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:55:23.560844 [info ] [Thread-1 (]: 4 of 6 SKIP test unique_outclick_by_brand_int_id ............................... [[33mSKIP[0m]
[0m19:55:23.561410 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:55:23.561829 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:55:23.562278 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:55:23.563148 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:55:23.563653 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:55:23.579773 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:55:23.580740 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:55:23.563949 => 19:55:23.580532
[0m19:55:23.581086 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:55:23.591548 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:55:23.592171 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:55:23.592409 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:55:23.592624 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:55:23.851450 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:55:23.853349 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:55:23.854441 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:55:23.896701 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:55:23.903701 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:55:23.581298 => 19:55:23.902989
[0m19:55:23.904782 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:55:23.936243 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:55:23.940051 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.38s]
[0m19:55:23.942257 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:55:23.943649 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:55:23.945094 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:55:23.947058 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:55:23.947939 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:55:23.959987 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:55:23.962145 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:55:23.948470 => 19:55:23.961717
[0m19:55:23.962797 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:55:23.966908 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:55:23.968009 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:55:23.968393 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:55:23.968747 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:55:24.293991 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:55:24.295581 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:55:24.296410 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:55:24.364432 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:55:24.369732 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:55:23.963149 => 19:55:24.369062
[0m19:55:24.370882 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:55:24.411036 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:55:24.413885 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.47s]
[0m19:55:24.415684 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:55:24.418819 [debug] [MainThread]: Using postgres connection "master"
[0m19:55:24.419572 [debug] [MainThread]: On master: BEGIN
[0m19:55:24.420335 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:55:24.780645 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:55:24.781694 [debug] [MainThread]: On master: COMMIT
[0m19:55:24.782376 [debug] [MainThread]: Using postgres connection "master"
[0m19:55:24.783122 [debug] [MainThread]: On master: COMMIT
[0m19:55:24.826401 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:55:24.827920 [debug] [MainThread]: On master: Close
[0m19:55:24.829820 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:55:24.830419 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:55:24.831520 [info ] [MainThread]: 
[0m19:55:24.832455 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 8.12 seconds (8.12s).
[0m19:55:24.834119 [debug] [MainThread]: Command end result
[0m19:55:24.849931 [info ] [MainThread]: 
[0m19:55:24.850805 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:55:24.851473 [info ] [MainThread]: 
[0m19:55:24.852185 [error] [MainThread]: [33mDatabase Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)[0m
[0m19:55:24.852725 [error] [MainThread]:   syntax error at or near "CASE"
[0m19:55:24.853207 [error] [MainThread]:   LINE 47:     CASE
[0m19:55:24.853660 [error] [MainThread]:                ^
[0m19:55:24.854113 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m19:55:24.854539 [info ] [MainThread]: 
[0m19:55:24.855049 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=2 TOTAL=6
[0m19:55:24.855970 [debug] [MainThread]: Command `dbt build` failed at 19:55:24.855849 after 8.25 seconds
[0m19:55:24.856511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100d8e4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c5d350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106218c90>]}
[0m19:55:24.856984 [debug] [MainThread]: Flushing usage events
[0m19:56:19.781836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b6fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b85650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b8c610>]}


============================== 19:56:19.783128 | ca22ee02-fed8-46a0-a22a-73a577d45402 ==============================
[0m19:56:19.783128 [info ] [MainThread]: Running with dbt=1.5.4
[0m19:56:19.783456 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'debug': 'False', 'no_print': 'None', 'target_path': 'None', 'static_parser': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'use_experimental_parser': 'False', 'introspect': 'True', 'write_json': 'True', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_format': 'default', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'version_check': 'True', 'partial_parse': 'True'}
[0m19:56:19.811096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca22ee02-fed8-46a0-a22a-73a577d45402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b79450>]}
[0m19:56:19.817775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca22ee02-fed8-46a0-a22a-73a577d45402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a053150>]}
[0m19:56:19.818133 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m19:56:19.827622 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m19:56:19.854987 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:56:19.855180 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:56:19.855392 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m19:56:19.857734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca22ee02-fed8-46a0-a22a-73a577d45402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a071250>]}
[0m19:56:19.861092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca22ee02-fed8-46a0-a22a-73a577d45402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a040e90>]}
[0m19:56:19.861243 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m19:56:19.862034 [info ] [MainThread]: 
[0m19:56:19.862412 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:56:19.862903 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m19:56:19.867223 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m19:56:19.867387 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m19:56:19.867495 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:56:20.273323 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m19:56:20.275590 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m19:56:20.277718 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m19:56:20.283799 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:56:20.284159 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m19:56:20.284408 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:56:20.613043 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m19:56:20.614192 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m19:56:20.614851 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m19:56:20.658720 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m19:56:20.663174 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m19:56:20.702880 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m19:56:20.718722 [debug] [MainThread]: Using postgres connection "master"
[0m19:56:20.723256 [debug] [MainThread]: On master: BEGIN
[0m19:56:20.724328 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:56:21.031241 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:56:21.032674 [debug] [MainThread]: Using postgres connection "master"
[0m19:56:21.033770 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:56:21.081024 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m19:56:21.085063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca22ee02-fed8-46a0-a22a-73a577d45402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109baacd0>]}
[0m19:56:21.086110 [debug] [MainThread]: On master: ROLLBACK
[0m19:56:21.123700 [debug] [MainThread]: Using postgres connection "master"
[0m19:56:21.124595 [debug] [MainThread]: On master: BEGIN
[0m19:56:21.256301 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:56:21.256880 [debug] [MainThread]: On master: COMMIT
[0m19:56:21.257146 [debug] [MainThread]: Using postgres connection "master"
[0m19:56:21.257359 [debug] [MainThread]: On master: COMMIT
[0m19:56:21.294178 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:56:21.294651 [debug] [MainThread]: On master: Close
[0m19:56:21.295620 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:56:21.296037 [info ] [MainThread]: 
[0m19:56:21.302317 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m19:56:21.302904 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m19:56:21.303643 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m19:56:21.303978 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m19:56:21.321061 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:21.321859 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 19:56:21.304179 => 19:56:21.321709
[0m19:56:21.322083 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m19:56:21.342536 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:21.343013 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:21.343177 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m19:56:21.343327 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:56:21.598573 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:56:21.600166 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:21.601425 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 AS date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --#and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-12-31'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main

-- select * from console.outclick_by_brand_int
-- limit 10
  );
  
[0m19:56:29.493954 [debug] [Thread-1 (]: SQL status: SELECT 156845 in 8.0 seconds
[0m19:56:29.508087 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:29.508869 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m19:56:29.541218 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:56:29.548082 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:29.548954 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m19:56:29.580906 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:56:29.605972 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:56:29.606515 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:29.606791 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m19:56:29.638928 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:56:29.644064 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m19:56:29.644407 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m19:56:29.691533 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:56:29.694668 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 19:56:21.322214 => 19:56:29.694274
[0m19:56:29.695385 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m19:56:29.696581 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca22ee02-fed8-46a0-a22a-73a577d45402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a068d90>]}
[0m19:56:29.697303 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156845[0m in 8.39s]
[0m19:56:29.698042 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m19:56:29.698499 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m19:56:29.699093 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m19:56:29.700015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m19:56:29.700426 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m19:56:29.707972 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m19:56:29.708620 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 19:56:29.700662 => 19:56:29.708458
[0m19:56:29.708892 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m19:56:29.711735 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m19:56:29.712155 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:56:29.712367 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m19:56:29.712577 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:56:30.023879 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:56:30.025746 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:56:30.026996 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m19:56:34.891302 [debug] [Thread-1 (]: SQL status: SELECT 46551 in 5.0 seconds
[0m19:56:34.902477 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:56:34.903184 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m19:56:34.935442 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:56:34.942211 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:56:34.943108 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m19:56:34.976041 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m19:56:34.981259 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:56:34.982035 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:56:34.982697 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m19:56:35.016054 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m19:56:35.023940 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m19:56:35.024814 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m19:56:35.071371 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m19:56:35.076514 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 19:56:29.709063 => 19:56:35.075886
[0m19:56:35.077289 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m19:56:35.078859 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca22ee02-fed8-46a0-a22a-73a577d45402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2a1d90>]}
[0m19:56:35.079742 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46551[0m in 5.38s]
[0m19:56:35.080570 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m19:56:35.081140 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:56:35.081962 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m19:56:35.083166 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m19:56:35.083983 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:56:35.096047 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:56:35.096862 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 19:56:35.084288 => 19:56:35.096690
[0m19:56:35.097156 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:56:35.106517 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:56:35.107012 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:56:35.107233 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m19:56:35.107424 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:56:35.371834 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:56:35.373154 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m19:56:35.374067 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m19:56:35.436170 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:56:35.442129 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 19:56:35.097326 => 19:56:35.441587
[0m19:56:35.443235 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m19:56:35.474311 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m19:56:35.478190 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 0.40s]
[0m19:56:35.479847 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m19:56:35.480910 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:56:35.481904 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m19:56:35.483338 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m19:56:35.483984 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:56:35.495065 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:56:35.496372 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 19:56:35.484422 => 19:56:35.496112
[0m19:56:35.496785 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:56:35.498995 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:56:35.499630 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:56:35.499935 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m19:56:35.500226 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:56:35.829284 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:56:35.829828 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m19:56:35.830240 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:56:36.004095 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:56:36.007895 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 19:56:35.496997 => 19:56:36.007344
[0m19:56:36.008973 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m19:56:36.048427 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m19:56:36.052081 [error] [Thread-1 (]: 4 of 6 FAIL 28067 unique_outclick_by_brand_int_id .............................. [[31mFAIL 28067[0m in 0.57s]
[0m19:56:36.053477 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m19:56:36.054318 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:56:36.055348 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m19:56:36.056658 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m19:56:36.057364 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:56:36.064182 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:56:36.065412 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 19:56:36.057783 => 19:56:36.065170
[0m19:56:36.065838 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:56:36.068152 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:56:36.068762 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:56:36.069063 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m19:56:36.069349 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:56:36.403581 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:56:36.404489 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m19:56:36.404815 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m19:56:36.457611 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:56:36.461405 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 19:56:36.066079 => 19:56:36.460958
[0m19:56:36.462523 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m19:56:36.500031 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m19:56:36.503420 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.45s]
[0m19:56:36.504768 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m19:56:36.505420 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:56:36.506091 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m19:56:36.507089 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m19:56:36.507559 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:56:36.513450 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:56:36.514392 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 19:56:36.507860 => 19:56:36.514148
[0m19:56:36.514768 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:56:36.516776 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:56:36.517304 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:56:36.517605 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m19:56:36.517883 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:56:36.782598 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m19:56:36.784090 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m19:56:36.785835 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:56:36.847197 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m19:56:36.850941 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 19:56:36.515006 => 19:56:36.850523
[0m19:56:36.851699 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m19:56:36.883168 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m19:56:36.886215 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.38s]
[0m19:56:36.887491 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m19:56:36.890599 [debug] [MainThread]: Using postgres connection "master"
[0m19:56:36.891206 [debug] [MainThread]: On master: BEGIN
[0m19:56:36.891694 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:56:37.146357 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m19:56:37.147789 [debug] [MainThread]: On master: COMMIT
[0m19:56:37.148351 [debug] [MainThread]: Using postgres connection "master"
[0m19:56:37.148837 [debug] [MainThread]: On master: COMMIT
[0m19:56:37.179332 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m19:56:37.180080 [debug] [MainThread]: On master: Close
[0m19:56:37.182125 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:56:37.182742 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m19:56:37.183408 [info ] [MainThread]: 
[0m19:56:37.184113 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 17.32 seconds (17.32s).
[0m19:56:37.186584 [debug] [MainThread]: Command end result
[0m19:56:37.201669 [info ] [MainThread]: 
[0m19:56:37.202364 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m19:56:37.202688 [info ] [MainThread]: 
[0m19:56:37.203014 [error] [MainThread]: [31mFailure in test unique_outclick_by_brand_int_id (models/brand_performance/schema.yml)[0m
[0m19:56:37.203317 [error] [MainThread]:   Got 28067 results, configured to fail if != 0
[0m19:56:37.203603 [info ] [MainThread]: 
[0m19:56:37.203880 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_by_brand_int_id.sql
[0m19:56:37.204191 [info ] [MainThread]: 
[0m19:56:37.204530 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m19:56:37.205183 [debug] [MainThread]: Command `dbt build` failed at 19:56:37.205079 after 17.43 seconds
[0m19:56:37.205556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049f8890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049f9650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c77610>]}
[0m19:56:37.205889 [debug] [MainThread]: Flushing usage events
[0m20:09:01.734198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104781610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d9c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d9d150>]}


============================== 20:09:01.735826 | 0771d9d9-b249-41d5-ad25-223b67589d4f ==============================
[0m20:09:01.735826 [info ] [MainThread]: Running with dbt=1.5.4
[0m20:09:01.736126 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'version_check': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'introspect': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'quiet': 'False', 'use_colors': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'target_path': 'None', 'debug': 'False', 'printer_width': '80', 'log_cache_events': 'False', 'cache_selected_only': 'False'}
[0m20:09:01.766725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c5d850>]}
[0m20:09:01.773253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10628ee10>]}
[0m20:09:01.773778 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m20:09:01.784223 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m20:09:01.820108 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:09:01.820320 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:09:01.820552 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m20:09:01.822881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653b050>]}
[0m20:09:01.826402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062b2350>]}
[0m20:09:01.826579 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m20:09:01.826729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102240090>]}
[0m20:09:01.827409 [info ] [MainThread]: 
[0m20:09:01.827748 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:09:01.828214 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m20:09:01.832687 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m20:09:01.832912 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m20:09:01.833034 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:09:02.240187 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m20:09:02.245052 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m20:09:02.248522 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m20:09:02.257169 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:09:02.257715 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m20:09:02.258016 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:09:02.566946 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:09:02.568411 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:09:02.569512 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m20:09:02.610659 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m20:09:02.615929 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m20:09:02.653030 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m20:09:02.663936 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:02.664448 [debug] [MainThread]: On master: BEGIN
[0m20:09:02.664753 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:09:02.923319 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:09:02.925102 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:02.926366 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:09:02.968286 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m20:09:02.969814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051a0fd0>]}
[0m20:09:02.970097 [debug] [MainThread]: On master: ROLLBACK
[0m20:09:03.000589 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:03.000808 [debug] [MainThread]: On master: BEGIN
[0m20:09:03.063565 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:09:03.064610 [debug] [MainThread]: On master: COMMIT
[0m20:09:03.065287 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:03.065792 [debug] [MainThread]: On master: COMMIT
[0m20:09:03.096318 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:09:03.097341 [debug] [MainThread]: On master: Close
[0m20:09:03.098829 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:09:03.099425 [info ] [MainThread]: 
[0m20:09:03.107109 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m20:09:03.107771 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m20:09:03.108770 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m20:09:03.109188 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m20:09:03.131899 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:03.132620 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 20:09:03.109459 => 20:09:03.132466
[0m20:09:03.132885 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m20:09:03.155564 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:03.156067 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:03.156241 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m20:09:03.156405 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:09:03.415700 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:09:03.416940 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:03.417883 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m20:09:11.233507 [debug] [Thread-1 (]: SQL status: SELECT 156848 in 8.0 seconds
[0m20:09:11.245975 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:11.246555 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m20:09:11.279359 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:09:11.284322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:11.284995 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m20:09:11.316081 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:09:11.340473 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:09:11.340920 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:11.341205 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:09:11.371799 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:09:11.376785 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:09:11.377118 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m20:09:11.425127 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:09:11.427976 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 20:09:03.133037 => 20:09:11.427695
[0m20:09:11.428556 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m20:09:11.430058 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065182d0>]}
[0m20:09:11.430980 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156848[0m in 8.32s]
[0m20:09:11.431746 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m20:09:11.432272 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m20:09:11.433051 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m20:09:11.434013 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m20:09:11.434415 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m20:09:11.442788 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m20:09:11.443634 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 20:09:11.434677 => 20:09:11.443440
[0m20:09:11.443916 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m20:09:11.446984 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m20:09:11.447520 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:09:11.447773 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m20:09:11.448009 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:09:11.781820 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:09:11.783696 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:09:11.784679 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m20:09:18.356213 [debug] [Thread-1 (]: SQL status: SELECT 46554 in 7.0 seconds
[0m20:09:18.363175 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:09:18.363775 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m20:09:18.403807 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:09:18.410866 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:09:18.411342 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m20:09:18.478205 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:09:18.481739 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:09:18.482404 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:09:18.482917 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:09:18.522699 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:09:18.530494 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:09:18.531095 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m20:09:18.584397 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:09:18.587462 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 20:09:11.444091 => 20:09:18.587106
[0m20:09:18.588160 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m20:09:18.589746 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0771d9d9-b249-41d5-ad25-223b67589d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10668d610>]}
[0m20:09:18.590656 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46554[0m in 7.16s]
[0m20:09:18.591571 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m20:09:18.593828 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:18.594262 [debug] [MainThread]: On master: BEGIN
[0m20:09:18.594595 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:09:18.968606 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:09:18.970248 [debug] [MainThread]: On master: COMMIT
[0m20:09:18.971255 [debug] [MainThread]: Using postgres connection "master"
[0m20:09:18.971775 [debug] [MainThread]: On master: COMMIT
[0m20:09:19.008412 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:09:19.009578 [debug] [MainThread]: On master: Close
[0m20:09:19.011538 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:09:19.012138 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m20:09:19.012762 [info ] [MainThread]: 
[0m20:09:19.013464 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 17.19 seconds (17.19s).
[0m20:09:19.014957 [debug] [MainThread]: Command end result
[0m20:09:19.026841 [info ] [MainThread]: 
[0m20:09:19.027454 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:09:19.027842 [info ] [MainThread]: 
[0m20:09:19.028254 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:09:19.029041 [debug] [MainThread]: Command `dbt run` succeeded at 20:09:19.028909 after 17.31 seconds
[0m20:09:19.029501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104983a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105944310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100eac190>]}
[0m20:09:19.029891 [debug] [MainThread]: Flushing usage events
[0m20:11:48.248102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049efb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a05650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a0b710>]}


============================== 20:11:48.249731 | 9918b6e5-ab14-4450-9b46-e91de3d65ec9 ==============================
[0m20:11:48.249731 [info ] [MainThread]: Running with dbt=1.5.4
[0m20:11:48.250047 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'version_check': 'True', 'static_parser': 'True', 'write_json': 'True', 'quiet': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_format': 'default', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'debug': 'False'}
[0m20:11:48.278700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1038f0c10>]}
[0m20:11:48.284966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044ef990>]}
[0m20:11:48.285427 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m20:11:48.295086 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m20:11:48.322950 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:11:48.323137 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:11:48.323348 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m20:11:48.325651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f44b10>]}
[0m20:11:48.329002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e8a9d0>]}
[0m20:11:48.329173 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m20:11:48.329336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101ec8290>]}
[0m20:11:48.330023 [info ] [MainThread]: 
[0m20:11:48.330344 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:11:48.330835 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m20:11:48.335255 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m20:11:48.335489 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m20:11:48.335623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:11:48.682560 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m20:11:48.684061 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m20:11:48.685618 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m20:11:48.690382 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:11:48.690690 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m20:11:48.690913 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:11:48.954275 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:11:48.955985 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:11:48.957062 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m20:11:48.993147 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m20:11:48.998154 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m20:11:49.030562 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m20:11:49.044927 [debug] [MainThread]: Using postgres connection "master"
[0m20:11:49.045368 [debug] [MainThread]: On master: BEGIN
[0m20:11:49.045727 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:11:49.403968 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:11:49.405281 [debug] [MainThread]: Using postgres connection "master"
[0m20:11:49.406128 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:11:49.459919 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m20:11:49.465509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a429d0>]}
[0m20:11:49.466667 [debug] [MainThread]: On master: ROLLBACK
[0m20:11:49.509134 [debug] [MainThread]: Using postgres connection "master"
[0m20:11:49.509497 [debug] [MainThread]: On master: BEGIN
[0m20:11:49.594400 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:11:49.594731 [debug] [MainThread]: On master: COMMIT
[0m20:11:49.594904 [debug] [MainThread]: Using postgres connection "master"
[0m20:11:49.595055 [debug] [MainThread]: On master: COMMIT
[0m20:11:49.637084 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:11:49.637345 [debug] [MainThread]: On master: Close
[0m20:11:49.637980 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:11:49.638280 [info ] [MainThread]: 
[0m20:11:49.640953 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m20:11:49.641395 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m20:11:49.641979 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m20:11:49.642227 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m20:11:49.657503 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:49.658808 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 20:11:49.642377 => 20:11:49.658672
[0m20:11:49.659026 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m20:11:49.678362 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:49.678790 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:49.678944 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m20:11:49.679085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:11:49.937156 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:11:49.938600 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:49.939792 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m20:11:57.879343 [debug] [Thread-1 (]: SQL status: SELECT 156848 in 8.0 seconds
[0m20:11:57.892406 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:57.893216 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m20:11:57.925432 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:11:57.931307 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:57.932084 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m20:11:57.963374 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:11:57.988406 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:11:57.988852 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:57.989132 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:11:58.019488 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:11:58.024787 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:11:58.025143 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m20:11:58.074668 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:11:58.077892 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 20:11:49.659151 => 20:11:58.077550
[0m20:11:58.078541 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m20:11:58.080359 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa5b90>]}
[0m20:11:58.081266 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156848[0m in 8.44s]
[0m20:11:58.082033 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m20:11:58.082500 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m20:11:58.083047 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m20:11:58.083840 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m20:11:58.084199 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m20:11:58.092204 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m20:11:58.093061 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 20:11:58.084440 => 20:11:58.092897
[0m20:11:58.093344 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m20:11:58.096464 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m20:11:58.097028 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:11:58.097270 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m20:11:58.097499 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:11:58.374688 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:11:58.375261 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:11:58.375587 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m20:12:03.201654 [debug] [Thread-1 (]: SQL status: SELECT 46554 in 5.0 seconds
[0m20:12:03.208794 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:12:03.209500 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m20:12:03.244123 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:12:03.253968 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:12:03.254571 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m20:12:03.417329 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:12:03.422822 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:12:03.423705 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:12:03.424403 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:12:03.459409 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:12:03.465514 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:12:03.466245 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m20:12:03.515133 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:12:03.519590 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 20:11:58.093513 => 20:12:03.519318
[0m20:12:03.520179 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m20:12:03.521942 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9918b6e5-ab14-4450-9b46-e91de3d65ec9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050d91d0>]}
[0m20:12:03.522843 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46554[0m in 5.44s]
[0m20:12:03.523690 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m20:12:03.525734 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:03.526167 [debug] [MainThread]: On master: BEGIN
[0m20:12:03.526533 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:12:03.815868 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:12:03.817395 [debug] [MainThread]: On master: COMMIT
[0m20:12:03.818201 [debug] [MainThread]: Using postgres connection "master"
[0m20:12:03.818784 [debug] [MainThread]: On master: COMMIT
[0m20:12:03.850290 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:12:03.851371 [debug] [MainThread]: On master: Close
[0m20:12:03.854235 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:12:03.854879 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m20:12:03.855519 [info ] [MainThread]: 
[0m20:12:03.856243 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 15.53 seconds (15.53s).
[0m20:12:03.857737 [debug] [MainThread]: Command end result
[0m20:12:03.870059 [info ] [MainThread]: 
[0m20:12:03.870758 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:12:03.871135 [info ] [MainThread]: 
[0m20:12:03.871544 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:12:03.872260 [debug] [MainThread]: Command `dbt run` succeeded at 20:12:03.872128 after 15.64 seconds
[0m20:12:03.872674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a13b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100b32410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100aa9650>]}
[0m20:12:03.873051 [debug] [MainThread]: Flushing usage events
[0m20:22:33.811419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f6f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f8bc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f8bf90>]}


============================== 20:22:33.812811 | ed6a6c43-d538-4987-ad10-152e6b413191 ==============================
[0m20:22:33.812811 [info ] [MainThread]: Running with dbt=1.5.4
[0m20:22:33.813107 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False', 'use_colors': 'True', 'fail_fast': 'False', 'printer_width': '80', 'partial_parse': 'True', 'indirect_selection': 'eager', 'log_format': 'default', 'debug': 'False', 'version_check': 'True', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None'}
[0m20:22:33.840506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106266c50>]}
[0m20:22:33.846725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e54e10>]}
[0m20:22:33.847196 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m20:22:33.858563 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m20:22:33.898905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:22:33.899079 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:22:33.899296 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m20:22:33.901593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d84d0>]}
[0m20:22:33.905876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082190d0>]}
[0m20:22:33.906096 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m20:22:33.906266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ad4290>]}
[0m20:22:33.906949 [info ] [MainThread]: 
[0m20:22:33.907289 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:22:33.907731 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m20:22:33.911975 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m20:22:33.912147 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m20:22:33.912261 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:22:34.234097 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m20:22:34.235391 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m20:22:34.236737 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m20:22:34.241329 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:22:34.241586 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m20:22:34.241776 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:22:34.500738 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:22:34.501974 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:22:34.502530 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m20:22:34.537873 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m20:22:34.541091 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m20:22:34.572446 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m20:22:34.584841 [debug] [MainThread]: Using postgres connection "master"
[0m20:22:34.585277 [debug] [MainThread]: On master: BEGIN
[0m20:22:34.585556 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:22:34.942510 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:22:34.943989 [debug] [MainThread]: Using postgres connection "master"
[0m20:22:34.945238 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:22:34.999266 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m20:22:35.004296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072a0710>]}
[0m20:22:35.005253 [debug] [MainThread]: On master: ROLLBACK
[0m20:22:35.068279 [debug] [MainThread]: Using postgres connection "master"
[0m20:22:35.068638 [debug] [MainThread]: On master: BEGIN
[0m20:22:35.155750 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:22:35.156892 [debug] [MainThread]: On master: COMMIT
[0m20:22:35.157278 [debug] [MainThread]: Using postgres connection "master"
[0m20:22:35.157617 [debug] [MainThread]: On master: COMMIT
[0m20:22:35.199975 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:22:35.201233 [debug] [MainThread]: On master: Close
[0m20:22:35.204212 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:22:35.204889 [info ] [MainThread]: 
[0m20:22:35.212815 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m20:22:35.213496 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m20:22:35.214664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m20:22:35.215230 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m20:22:35.235244 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:35.236452 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 20:22:35.215520 => 20:22:35.236269
[0m20:22:35.236713 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m20:22:35.258188 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:35.259000 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:35.259215 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m20:22:35.259395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:22:35.541692 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:22:35.543372 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:35.544257 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        date(timestamp - interval '2 hours') as date, 
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        and date(timestamp - interval '2 hours') >'2023-12-31'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-12-31'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m20:22:43.366484 [debug] [Thread-1 (]: SQL status: SELECT 156848 in 8.0 seconds
[0m20:22:43.377985 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:43.378518 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m20:22:43.409323 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:22:43.412532 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:43.412910 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m20:22:43.443647 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:22:43.466312 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:22:43.466689 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:43.466968 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:22:43.497660 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:22:43.502335 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:22:43.502672 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m20:22:43.550956 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:22:43.553195 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 20:22:35.236855 => 20:22:43.552914
[0m20:22:43.553782 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m20:22:43.555175 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fc02d0>]}
[0m20:22:43.555844 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 156848[0m in 8.34s]
[0m20:22:43.556585 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m20:22:43.557105 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m20:22:43.557826 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m20:22:43.558587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m20:22:43.558911 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m20:22:43.567718 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m20:22:43.569276 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 20:22:43.559292 => 20:22:43.569090
[0m20:22:43.569595 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m20:22:43.572768 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m20:22:43.573316 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:22:43.573574 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m20:22:43.573818 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:22:43.917824 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:22:43.918876 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:22:43.919619 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            date(timestamp - interval '2 hours') as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND date(timestamp - interval '2 hours')>'2023-12-31' --matomo
        group by campaign_name, campaignname, campaign_vertical, date, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-12-31'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m20:22:48.734280 [debug] [Thread-1 (]: SQL status: SELECT 46554 in 5.0 seconds
[0m20:22:48.740134 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:22:48.740668 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m20:22:48.780014 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:22:48.787174 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:22:48.787841 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m20:22:48.828195 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:22:48.831987 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:22:48.832644 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:22:48.833246 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:22:48.872781 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:22:48.878579 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:22:48.879218 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m20:22:48.934542 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:22:48.937298 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 20:22:43.569776 => 20:22:48.936971
[0m20:22:48.937977 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m20:22:48.939774 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ed6a6c43-d538-4987-ad10-152e6b413191', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108455150>]}
[0m20:22:48.940783 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 46554[0m in 5.38s]
[0m20:22:48.941897 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m20:22:48.944681 [debug] [MainThread]: Using postgres connection "master"
[0m20:22:48.945219 [debug] [MainThread]: On master: BEGIN
[0m20:22:48.945598 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:22:49.271206 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:22:49.272793 [debug] [MainThread]: On master: COMMIT
[0m20:22:49.273782 [debug] [MainThread]: Using postgres connection "master"
[0m20:22:49.274819 [debug] [MainThread]: On master: COMMIT
[0m20:22:49.311669 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:22:49.312523 [debug] [MainThread]: On master: Close
[0m20:22:49.314306 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:22:49.314859 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m20:22:49.315519 [info ] [MainThread]: 
[0m20:22:49.316244 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 15.41 seconds (15.41s).
[0m20:22:49.317745 [debug] [MainThread]: Command end result
[0m20:22:49.330932 [info ] [MainThread]: 
[0m20:22:49.331687 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:22:49.332104 [info ] [MainThread]: 
[0m20:22:49.332566 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:22:49.333427 [debug] [MainThread]: Command `dbt run` succeeded at 20:22:49.333258 after 15.53 seconds
[0m20:22:49.333949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103740190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10373e410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10373e4d0>]}
[0m20:22:49.334334 [debug] [MainThread]: Flushing usage events
[0m20:24:28.358078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eacbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ec5650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ecf2d0>]}


============================== 20:24:28.359407 | 2429058f-9979-455d-8dad-9cc9711bc66b ==============================
[0m20:24:28.359407 [info ] [MainThread]: Running with dbt=1.5.4
[0m20:24:28.359722 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'write_json': 'True', 'printer_width': '80', 'no_print': 'None', 'introspect': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'quiet': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'fail_fast': 'False', 'static_parser': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'version_check': 'True', 'warn_error': 'None'}
[0m20:24:28.386983 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eb9050>]}
[0m20:24:28.393040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053506d0>]}
[0m20:24:28.393323 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m20:24:28.406554 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m20:24:28.435344 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:24:28.435554 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:24:28.435778 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m20:24:28.438123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054420d0>]}
[0m20:24:28.441457 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105364190>]}
[0m20:24:28.441620 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m20:24:28.441776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102388290>]}
[0m20:24:28.442457 [info ] [MainThread]: 
[0m20:24:28.442769 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:24:28.443203 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m20:24:28.447098 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m20:24:28.447227 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m20:24:28.447332 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:24:28.764794 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.0 seconds
[0m20:24:28.766220 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m20:24:28.767574 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m20:24:28.771506 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:24:28.771714 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m20:24:28.771874 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:24:29.030141 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m20:24:29.031617 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m20:24:29.032274 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m20:24:29.068046 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m20:24:29.071146 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m20:24:29.101906 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m20:24:29.113534 [debug] [MainThread]: Using postgres connection "master"
[0m20:24:29.114070 [debug] [MainThread]: On master: BEGIN
[0m20:24:29.114361 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:24:29.439257 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:24:29.440515 [debug] [MainThread]: Using postgres connection "master"
[0m20:24:29.441935 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:24:29.491304 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m20:24:29.496729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048453d0>]}
[0m20:24:29.497772 [debug] [MainThread]: On master: ROLLBACK
[0m20:24:29.536718 [debug] [MainThread]: Using postgres connection "master"
[0m20:24:29.537346 [debug] [MainThread]: On master: BEGIN
[0m20:24:29.615742 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m20:24:29.617209 [debug] [MainThread]: On master: COMMIT
[0m20:24:29.618321 [debug] [MainThread]: Using postgres connection "master"
[0m20:24:29.619142 [debug] [MainThread]: On master: COMMIT
[0m20:24:29.658168 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:24:29.659105 [debug] [MainThread]: On master: Close
[0m20:24:29.661566 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:24:29.662315 [info ] [MainThread]: 
[0m20:24:29.669170 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m20:24:29.669997 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m20:24:29.671187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m20:24:29.671722 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m20:24:29.696603 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:29.697414 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 20:24:29.672072 => 20:24:29.697239
[0m20:24:29.697699 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m20:24:29.719645 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:29.720199 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:29.720375 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m20:24:29.720540 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:24:29.977741 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:24:29.979729 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:29.981015 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-01-01'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m20:24:46.085056 [debug] [Thread-1 (]: SQL status: SELECT 498166 in 16.0 seconds
[0m20:24:46.098410 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:46.099140 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m20:24:46.131687 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:24:46.138050 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:46.138777 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m20:24:46.169617 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:24:46.193487 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:24:46.193973 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:46.194300 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m20:24:46.226995 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:24:46.234280 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m20:24:46.234819 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m20:24:46.283776 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:24:46.287044 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 20:24:29.697845 => 20:24:46.286668
[0m20:24:46.287800 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m20:24:46.289791 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f5c10>]}
[0m20:24:46.291100 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 498166[0m in 16.62s]
[0m20:24:46.292363 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m20:24:46.293092 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m20:24:46.293969 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m20:24:46.295054 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m20:24:46.295603 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m20:24:46.306550 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m20:24:46.307419 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 20:24:46.295886 => 20:24:46.307214
[0m20:24:46.307758 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m20:24:46.311261 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m20:24:46.311770 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:24:46.312017 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m20:24:46.312253 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:24:46.598830 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m20:24:46.600572 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:24:46.602432 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
        group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-01-01'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m20:24:56.404018 [debug] [Thread-1 (]: SQL status: SELECT 141987 in 10.0 seconds
[0m20:24:56.410565 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:24:56.411212 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m20:24:56.441981 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:24:56.449677 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:24:56.450192 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m20:24:56.481675 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m20:24:56.484489 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:24:56.485124 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:24:56.485715 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m20:24:56.519067 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m20:24:56.523249 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m20:24:56.523816 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m20:24:56.569198 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m20:24:56.571351 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 20:24:46.307950 => 20:24:56.571097
[0m20:24:56.572556 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m20:24:56.574190 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2429058f-9979-455d-8dad-9cc9711bc66b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10559abd0>]}
[0m20:24:56.575157 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 141987[0m in 10.28s]
[0m20:24:56.576334 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m20:24:56.578692 [debug] [MainThread]: Using postgres connection "master"
[0m20:24:56.579201 [debug] [MainThread]: On master: BEGIN
[0m20:24:56.579557 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:24:57.250792 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m20:24:57.252314 [debug] [MainThread]: On master: COMMIT
[0m20:24:57.253163 [debug] [MainThread]: Using postgres connection "master"
[0m20:24:57.253679 [debug] [MainThread]: On master: COMMIT
[0m20:24:57.328359 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m20:24:57.330136 [debug] [MainThread]: On master: Close
[0m20:24:57.332467 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:24:57.332989 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m20:24:57.333588 [info ] [MainThread]: 
[0m20:24:57.334277 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 28.89 seconds (28.89s).
[0m20:24:57.335719 [debug] [MainThread]: Command end result
[0m20:24:57.347569 [info ] [MainThread]: 
[0m20:24:57.348202 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:24:57.348586 [info ] [MainThread]: 
[0m20:24:57.348988 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:24:57.349668 [debug] [MainThread]: Command `dbt run` succeeded at 20:24:57.349553 after 29.00 seconds
[0m20:24:57.350061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a7c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ff4190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ff24d0>]}
[0m20:24:57.350418 [debug] [MainThread]: Flushing usage events
[0m22:00:04.632970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa868d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a75d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa8bfd0>]}


============================== 22:00:04.634706 | 7cbd6b72-26a6-407d-8053-2411402b6ee0 ==============================
[0m22:00:04.634706 [info ] [MainThread]: Running with dbt=1.5.4
[0m22:00:04.635027 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'quiet': 'False', 'indirect_selection': 'eager', 'warn_error': 'None', 'static_parser': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/danila/.dbt', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'use_experimental_parser': 'False', 'debug': 'False', 'write_json': 'True', 'no_print': 'None', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True'}
[0m22:00:04.665475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa97e50>]}
[0m22:00:04.671591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa89550>]}
[0m22:00:04.672033 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m22:00:04.683283 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m22:00:04.724195 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:00:04.724393 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:00:04.724615 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m22:00:04.726959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b085590>]}
[0m22:00:04.732105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af79750>]}
[0m22:00:04.732305 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m22:00:04.732469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106360290>]}
[0m22:00:04.733095 [info ] [MainThread]: 
[0m22:00:04.733406 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:00:04.733813 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:00:04.737621 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:00:04.737757 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:00:04.737871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:00:05.321772 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.0 seconds
[0m22:00:05.325843 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:00:05.329580 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:00:05.338078 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:00:05.338585 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:00:05.338902 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:00:05.855808 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m22:00:05.857487 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:00:05.858668 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m22:00:05.901445 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m22:00:05.905241 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:00:05.946785 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:00:05.951558 [debug] [MainThread]: Using postgres connection "master"
[0m22:00:05.951769 [debug] [MainThread]: On master: BEGIN
[0m22:00:05.951920 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:00:06.917244 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:00:06.918946 [debug] [MainThread]: Using postgres connection "master"
[0m22:00:06.920260 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:00:07.166653 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m22:00:07.171363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa97fd0>]}
[0m22:00:07.172401 [debug] [MainThread]: On master: ROLLBACK
[0m22:00:07.515580 [debug] [MainThread]: Using postgres connection "master"
[0m22:00:07.517351 [debug] [MainThread]: On master: BEGIN
[0m22:00:07.674975 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:00:07.676322 [debug] [MainThread]: On master: COMMIT
[0m22:00:07.676926 [debug] [MainThread]: Using postgres connection "master"
[0m22:00:07.677558 [debug] [MainThread]: On master: COMMIT
[0m22:00:07.756279 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:00:07.757907 [debug] [MainThread]: On master: Close
[0m22:00:07.760312 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:00:07.761153 [info ] [MainThread]: 
[0m22:00:07.770320 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:00:07.771108 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m22:00:07.772207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:00:07.772692 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:00:07.790692 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:07.791833 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:00:07.773149 => 22:00:07.791693
[0m22:00:07.792025 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:00:07.815032 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:07.815736 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:07.815956 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:00:07.816125 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:00:08.360270 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:00:08.361916 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:08.363151 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-01-01'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m22:00:24.842520 [debug] [Thread-1 (]: SQL status: SELECT 498182 in 16.0 seconds
[0m22:00:24.855457 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:24.856094 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:00:24.927554 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:00:24.934263 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:24.934951 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:00:25.009492 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:00:25.035537 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:00:25.036041 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:25.036336 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:00:25.140598 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:00:25.152151 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:00:25.152886 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:00:25.231675 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:00:25.236345 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:00:07.792112 => 22:00:25.235939
[0m22:00:25.237050 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:00:25.238657 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af734d0>]}
[0m22:00:25.239598 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 498182[0m in 17.47s]
[0m22:00:25.240526 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:00:25.241156 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:00:25.241948 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m22:00:25.242867 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:00:25.243296 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:00:25.253663 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:00:25.255224 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:00:25.243590 => 22:00:25.254997
[0m22:00:25.255559 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:00:25.258901 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:00:25.259434 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:00:25.259696 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:00:25.259933 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:00:25.785548 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:00:25.787419 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:00:25.788892 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
        group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-01-01'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m22:00:35.322018 [debug] [Thread-1 (]: SQL status: SELECT 141992 in 10.0 seconds
[0m22:00:35.329436 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:00:35.330173 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m22:00:35.394381 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:00:35.404651 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:00:35.405237 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:00:35.474194 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:00:35.478724 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:00:35.479416 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:00:35.480018 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:00:35.564075 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:00:35.569181 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:00:35.569859 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:00:35.655619 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:00:35.659033 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:00:25.255753 => 22:00:35.658693
[0m22:00:35.659750 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:00:35.661542 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7cbd6b72-26a6-407d-8053-2411402b6ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b194fd0>]}
[0m22:00:35.662530 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 141992[0m in 10.42s]
[0m22:00:35.663668 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:00:35.666071 [debug] [MainThread]: Using postgres connection "master"
[0m22:00:35.666515 [debug] [MainThread]: On master: BEGIN
[0m22:00:35.666880 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:00:36.194441 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:00:36.196090 [debug] [MainThread]: On master: COMMIT
[0m22:00:36.197152 [debug] [MainThread]: Using postgres connection "master"
[0m22:00:36.198061 [debug] [MainThread]: On master: COMMIT
[0m22:00:36.259248 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:00:36.260630 [debug] [MainThread]: On master: Close
[0m22:00:36.262818 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:00:36.263370 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m22:00:36.263990 [info ] [MainThread]: 
[0m22:00:36.264950 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 31.53 seconds (31.53s).
[0m22:00:36.266539 [debug] [MainThread]: Command end result
[0m22:00:36.279512 [info ] [MainThread]: 
[0m22:00:36.280295 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:00:36.280721 [info ] [MainThread]: 
[0m22:00:36.281169 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m22:00:36.281920 [debug] [MainThread]: Command `dbt run` succeeded at 22:00:36.281793 after 31.66 seconds
[0m22:00:36.282294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104eca410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e40850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e40890>]}
[0m22:00:36.282646 [debug] [MainThread]: Flushing usage events
[0m22:02:52.489086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dfa6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e1c510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e1cc10>]}


============================== 22:02:52.490727 | e6f1b9b0-c20d-4a98-8180-58fb9b006a4f ==============================
[0m22:02:52.490727 [info ] [MainThread]: Running with dbt=1.5.4
[0m22:02:52.491046 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'static_parser': 'True', 'warn_error': 'None', 'log_cache_events': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'debug': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'write_json': 'True', 'printer_width': '80', 'no_print': 'None', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'partial_parse': 'True', 'indirect_selection': 'eager', 'quiet': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False'}
[0m22:02:52.520273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109297150>]}
[0m22:02:52.526718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e341d0>]}
[0m22:02:52.527132 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m22:02:52.537556 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m22:02:52.572297 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:02:52.572486 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:02:52.572700 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m22:02:52.574975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093b2950>]}
[0m22:02:52.578294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e34110>]}
[0m22:02:52.578454 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m22:02:52.578605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062d4290>]}
[0m22:02:52.579275 [info ] [MainThread]: 
[0m22:02:52.579603 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:02:52.580068 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:02:52.584132 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:02:52.584263 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:02:52.584369 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:02:52.960729 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m22:02:52.964684 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:02:52.968274 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:02:52.977058 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:02:52.977627 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:02:52.977933 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:02:53.238966 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m22:02:53.240572 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:02:53.241693 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m22:02:53.279036 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m22:02:53.285547 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:02:53.318316 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:02:53.330493 [debug] [MainThread]: Using postgres connection "master"
[0m22:02:53.330988 [debug] [MainThread]: On master: BEGIN
[0m22:02:53.331293 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:02:54.234908 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:02:54.236519 [debug] [MainThread]: Using postgres connection "master"
[0m22:02:54.237865 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:02:54.329679 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m22:02:54.334013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109302b90>]}
[0m22:02:54.335071 [debug] [MainThread]: On master: ROLLBACK
[0m22:02:54.672218 [debug] [MainThread]: Using postgres connection "master"
[0m22:02:54.673626 [debug] [MainThread]: On master: BEGIN
[0m22:02:54.833849 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:02:54.835425 [debug] [MainThread]: On master: COMMIT
[0m22:02:54.836533 [debug] [MainThread]: Using postgres connection "master"
[0m22:02:54.837611 [debug] [MainThread]: On master: COMMIT
[0m22:02:54.918690 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:02:54.919729 [debug] [MainThread]: On master: Close
[0m22:02:54.922317 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:02:54.923160 [info ] [MainThread]: 
[0m22:02:54.932036 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:02:54.932902 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m22:02:54.933943 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:02:54.934385 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:02:54.957563 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:02:54.958284 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:02:54.934697 => 22:02:54.958126
[0m22:02:54.958554 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:02:54.980276 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:02:54.980718 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:02:54.980894 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:02:54.981054 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:02:55.275411 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:02:55.277260 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:02:55.279468 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-01-01'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m22:03:14.810532 [debug] [Thread-1 (]: SQL status: SELECT 498182 in 20.0 seconds
[0m22:03:14.825545 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:03:14.826518 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:03:14.859343 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:03:14.865680 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:03:14.866891 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:03:14.898582 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:03:14.923247 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:03:14.923981 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:03:14.924283 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:03:14.955358 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:03:14.962998 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:03:14.963806 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:03:15.019091 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:03:15.021476 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:02:54.958710 => 22:03:15.021188
[0m22:03:15.022044 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:03:15.023603 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092806d0>]}
[0m22:03:15.024571 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 498182[0m in 20.09s]
[0m22:03:15.025576 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:03:15.026151 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:03:15.026914 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m22:03:15.028157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:03:15.028563 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:03:15.045041 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:03:15.046498 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:03:15.028870 => 22:03:15.046171
[0m22:03:15.047181 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:03:15.053627 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:03:15.054705 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:03:15.055112 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:03:15.055465 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:03:15.703116 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:03:15.704282 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:03:15.705615 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
        group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-01-01'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m22:03:28.688286 [debug] [Thread-1 (]: SQL status: SELECT 141993 in 13.0 seconds
[0m22:03:28.699067 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:03:28.700334 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m22:03:28.768289 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:03:28.781487 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:03:28.782394 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:03:28.859999 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:03:28.867090 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:03:28.868050 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:03:28.868851 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:03:28.948713 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:03:28.954472 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:03:28.954961 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:03:29.054956 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:03:29.058331 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:03:15.047601 => 22:03:29.058088
[0m22:03:29.058854 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:03:29.061212 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e6f1b9b0-c20d-4a98-8180-58fb9b006a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109693e50>]}
[0m22:03:29.062011 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 141993[0m in 14.03s]
[0m22:03:29.063955 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:03:29.067846 [debug] [MainThread]: Using postgres connection "master"
[0m22:03:29.068549 [debug] [MainThread]: On master: BEGIN
[0m22:03:29.069152 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:03:29.767116 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:03:29.768706 [debug] [MainThread]: On master: COMMIT
[0m22:03:29.769691 [debug] [MainThread]: Using postgres connection "master"
[0m22:03:29.770851 [debug] [MainThread]: On master: COMMIT
[0m22:03:29.854777 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:03:29.856374 [debug] [MainThread]: On master: Close
[0m22:03:29.859171 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:03:29.860049 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m22:03:29.861097 [info ] [MainThread]: 
[0m22:03:29.862264 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 37.28 seconds (37.28s).
[0m22:03:29.864883 [debug] [MainThread]: Command end result
[0m22:03:29.882232 [info ] [MainThread]: 
[0m22:03:29.883126 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:03:29.883650 [info ] [MainThread]: 
[0m22:03:29.884316 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m22:03:29.885325 [debug] [MainThread]: Command `dbt run` succeeded at 22:03:29.885202 after 37.41 seconds
[0m22:03:29.885830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c8310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f40190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f3e4d0>]}
[0m22:03:29.886261 [debug] [MainThread]: Flushing usage events
[0m22:17:50.903444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10557fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10559c4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10559cdd0>]}


============================== 22:17:50.905122 | 35705079-4061-43a8-80d0-2d130f970220 ==============================
[0m22:17:50.905122 [info ] [MainThread]: Running with dbt=1.5.4
[0m22:17:50.905433 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'use_colors': 'True', 'log_format': 'default', 'target_path': 'None', 'printer_width': '80', 'no_print': 'None', 'fail_fast': 'False', 'version_check': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'quiet': 'False', 'warn_error': 'None', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'profiles_dir': '/Users/danila/.dbt', 'log_path': '/Users/danila/github/dbt/logs'}
[0m22:17:50.935934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35705079-4061-43a8-80d0-2d130f970220', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105465310>]}
[0m22:17:50.942112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35705079-4061-43a8-80d0-2d130f970220', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a20a10>]}
[0m22:17:50.942550 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m22:17:50.953452 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m22:17:50.988384 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:17:50.988713 [debug] [MainThread]: Partial parsing: updated file: campaign_perfomance://macros/matomo_timestamp_to_date.sql
[0m22:17:50.989401 [error] [MainThread]: Encountered an error:
Compilation Error
  expected token 'end of statement block', got '('
    line 1
      {% macro matomo_timestamp_to_date(timestamp)(ts) %}
[0m22:17:50.989720 [debug] [MainThread]: Command `dbt build` failed at 22:17:50.989664 after 0.10 seconds
[0m22:17:50.989878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1016c24d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1016c2550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105af0f50>]}
[0m22:17:50.990041 [debug] [MainThread]: Flushing usage events
[0m22:18:26.878407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a6ca50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a81650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a87fd0>]}


============================== 22:18:26.880262 | 7b26c4da-0771-477d-adcd-7bf57a522d87 ==============================
[0m22:18:26.880262 [info ] [MainThread]: Running with dbt=1.5.4
[0m22:18:26.880564 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'cache_selected_only': 'False', 'no_print': 'None', 'indirect_selection': 'eager', 'version_check': 'True', 'write_json': 'True', 'quiet': 'False', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'log_cache_events': 'False', 'target_path': 'None', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None'}
[0m22:18:26.909775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b26c4da-0771-477d-adcd-7bf57a522d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d1f150>]}
[0m22:18:26.916463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b26c4da-0771-477d-adcd-7bf57a522d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d0e650>]}
[0m22:18:26.917064 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m22:18:26.927993 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m22:18:26.955024 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:18:26.955212 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:18:26.955433 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m22:18:26.957685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b26c4da-0771-477d-adcd-7bf57a522d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066caf10>]}
[0m22:18:26.961481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b26c4da-0771-477d-adcd-7bf57a522d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a9d710>]}
[0m22:18:26.961695 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m22:18:26.962466 [info ] [MainThread]: 
[0m22:18:26.962792 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:18:26.963218 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:18:26.967381 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:18:26.967535 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:18:26.967648 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:18:27.890170 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.0 seconds
[0m22:18:27.894111 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:18:27.897592 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:18:27.906138 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:18:27.906753 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:18:27.907074 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:18:29.278410 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m22:18:29.280410 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:18:29.281595 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m22:18:29.372271 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m22:18:29.378983 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:18:29.468441 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:18:29.484013 [debug] [MainThread]: Using postgres connection "master"
[0m22:18:29.484506 [debug] [MainThread]: On master: BEGIN
[0m22:18:29.484866 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:18:29.993999 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:18:29.994996 [debug] [MainThread]: Using postgres connection "master"
[0m22:18:29.995950 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:18:30.079966 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m22:18:30.083230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b26c4da-0771-477d-adcd-7bf57a522d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110aa9610>]}
[0m22:18:30.084148 [debug] [MainThread]: On master: ROLLBACK
[0m22:18:30.155377 [debug] [MainThread]: Using postgres connection "master"
[0m22:18:30.156146 [debug] [MainThread]: On master: BEGIN
[0m22:18:30.266920 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:18:30.267768 [debug] [MainThread]: On master: COMMIT
[0m22:18:30.268114 [debug] [MainThread]: Using postgres connection "master"
[0m22:18:30.268457 [debug] [MainThread]: On master: COMMIT
[0m22:18:30.316765 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:18:30.318177 [debug] [MainThread]: On master: Close
[0m22:18:30.320303 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:18:30.321132 [info ] [MainThread]: 
[0m22:18:30.331229 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:18:30.331992 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m22:18:30.332909 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:18:30.333294 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:18:30.352853 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:30.353470 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:18:30.333552 => 22:18:30.353335
[0m22:18:30.353701 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:18:30.374834 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:30.375309 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:30.375477 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:18:30.375635 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:18:30.928285 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:18:30.930008 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:30.931220 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-01-01'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m22:18:52.240904 [debug] [Thread-1 (]: SQL status: SELECT 498183 in 21.0 seconds
[0m22:18:52.252777 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:52.253394 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:18:52.289943 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:18:52.295298 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:52.295913 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:18:52.337671 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:18:52.362243 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:18:52.362618 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:52.362887 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:18:52.427852 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:18:52.436033 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:18:52.436477 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:18:52.519309 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:18:52.524545 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:18:30.353833 => 22:18:52.524146
[0m22:18:52.525371 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:18:52.527411 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b26c4da-0771-477d-adcd-7bf57a522d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dabfd0>]}
[0m22:18:52.528583 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 498183[0m in 22.19s]
[0m22:18:52.529791 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:18:52.530574 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:18:52.531786 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m22:18:52.532892 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:18:52.533371 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:18:52.544609 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:18:52.546327 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:18:52.533684 => 22:18:52.546125
[0m22:18:52.546665 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:18:52.550187 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:18:52.550722 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:18:52.550971 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:18:52.551200 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:18:53.757510 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:18:53.757937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:18:53.758415 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select 
            
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
            "left"(matomo_actions.eventname::text, 2) as country_code, 
            lower(sitename) as campaign_name, 
            campaignname as ga_campaign_name, 
            CASE 
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
                when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
            count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
            NULL as cost
        from "deep-analysis-console"."console"."matomo_actions" matomo_actions
        left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
        on matomo_actions.matomo_visit_id=matomo_visits.id
        where matomo_actions.type = 'event' 
            AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
            --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
            AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
        group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
        union all
        select 
            day as date, 
            geo as country_code, 
            console_campaign_name as campaign_name, 
            lower(campaign) as ga_campaign_name, 
            CASE 
                when campaign_names_mapping.campaign_vertical='casino' then 'casino'
                when campaign_names_mapping.campaign_vertical='sports' then 'sports'
                else 'other'
            END as campaign_vertical,
            NULL as brand_name, 
            NULL as unique_outclicks, 
            sum(cost) as cost
        from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
        left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
        where day >'2023-01-01'
            -- campaign_names_mapping.campaign_vertical='casino'
            -- and day >'2023-12-31' --matomo

        group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m22:19:06.805815 [debug] [Thread-1 (]: SQL status: SELECT 141993 in 13.0 seconds
[0m22:19:06.811597 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:19:06.812031 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m22:19:06.887495 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:19:06.890425 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:19:06.890755 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:19:06.966689 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:19:06.969286 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:19:06.969768 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:19:06.970091 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:19:07.045647 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:19:07.050094 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:19:07.050697 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:19:07.146420 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:19:07.149887 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:18:52.546874 => 22:19:07.149582
[0m22:19:07.150695 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:19:07.151926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b26c4da-0771-477d-adcd-7bf57a522d87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f48a50>]}
[0m22:19:07.152660 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 141993[0m in 14.62s]
[0m22:19:07.153381 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:19:07.153844 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:19:07.154413 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m22:19:07.155647 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m22:19:07.156049 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:19:07.167324 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:19:07.169946 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 22:19:07.156269 => 22:19:07.169781
[0m22:19:07.170208 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:19:07.179232 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:19:07.179897 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:19:07.180107 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m22:19:07.180295 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:19:08.084139 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:19:08.085179 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:19:08.085772 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m22:19:08.311798 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:19:08.313953 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 22:19:07.170362 => 22:19:08.313779
[0m22:19:08.314246 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m22:19:08.390598 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m22:19:08.391614 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 1.24s]
[0m22:19:08.392163 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:19:08.392496 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:19:08.392871 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m22:19:08.393516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m22:19:08.393810 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:19:08.398740 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:19:08.399429 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 22:19:08.393995 => 22:19:08.399288
[0m22:19:08.399674 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:19:08.401112 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:19:08.401527 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:19:08.401744 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m22:19:08.401947 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:19:09.803782 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:19:09.806370 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:19:09.807215 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m22:19:10.585467 [debug] [Thread-1 (]: SQL status: SELECT 1 in 1.0 seconds
[0m22:19:10.589007 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 22:19:08.399845 => 22:19:10.588617
[0m22:19:10.589661 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m22:19:10.676600 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m22:19:10.679823 [error] [Thread-1 (]: 4 of 6 FAIL 89584 unique_outclick_by_brand_int_id .............................. [[31mFAIL 89584[0m in 2.29s]
[0m22:19:10.680936 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:19:10.681718 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:19:10.682689 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m22:19:10.684013 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m22:19:10.684537 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:19:10.691445 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:19:10.694604 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 22:19:10.684923 => 22:19:10.694092
[0m22:19:10.695275 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:19:10.697914 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:19:10.698745 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:19:10.699108 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m22:19:10.699446 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:19:11.673434 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:19:11.675151 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:19:11.676391 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m22:19:11.795630 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:19:11.797903 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 22:19:10.695557 => 22:19:11.797538
[0m22:19:11.798712 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m22:19:11.885892 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m22:19:11.889157 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 1.21s]
[0m22:19:11.890478 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:19:11.891265 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:19:11.892094 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m22:19:11.893476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m22:19:11.894217 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:19:11.900466 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:19:11.901634 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 22:19:11.894644 => 22:19:11.901434
[0m22:19:11.902037 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:19:11.904960 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:19:11.906132 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:19:11.906562 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m22:19:11.906911 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:19:13.980672 [debug] [Thread-1 (]: SQL status: BEGIN in 2.0 seconds
[0m22:19:13.982182 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:19:13.983543 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m22:19:14.162890 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:19:14.167293 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 22:19:11.902759 => 22:19:14.166843
[0m22:19:14.167972 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m22:19:14.247936 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m22:19:14.250347 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 2.36s]
[0m22:19:14.251890 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:19:14.254678 [debug] [MainThread]: Using postgres connection "master"
[0m22:19:14.255340 [debug] [MainThread]: On master: BEGIN
[0m22:19:14.255793 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:19:14.894307 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:19:14.895350 [debug] [MainThread]: On master: COMMIT
[0m22:19:14.895862 [debug] [MainThread]: Using postgres connection "master"
[0m22:19:14.896291 [debug] [MainThread]: On master: COMMIT
[0m22:19:14.973532 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:19:14.974530 [debug] [MainThread]: On master: Close
[0m22:19:14.976500 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:19:14.977063 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m22:19:14.977715 [info ] [MainThread]: 
[0m22:19:14.978420 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 48.01 seconds (48.01s).
[0m22:19:14.980575 [debug] [MainThread]: Command end result
[0m22:19:14.995197 [info ] [MainThread]: 
[0m22:19:14.995882 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:19:14.996229 [info ] [MainThread]: 
[0m22:19:14.996552 [error] [MainThread]: [31mFailure in test unique_outclick_by_brand_int_id (models/brand_performance/schema.yml)[0m
[0m22:19:14.996856 [error] [MainThread]:   Got 89584 results, configured to fail if != 0
[0m22:19:14.997142 [info ] [MainThread]: 
[0m22:19:14.997418 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_by_brand_int_id.sql
[0m22:19:14.997721 [info ] [MainThread]: 
[0m22:19:14.998060 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m22:19:14.998722 [debug] [MainThread]: Command `dbt build` failed at 22:19:14.998610 after 48.13 seconds
[0m22:19:14.999106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104938f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104936410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049364d0>]}
[0m22:19:14.999445 [debug] [MainThread]: Flushing usage events
[0m22:37:18.574051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e770d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d5cd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e89650>]}


============================== 22:37:18.575987 | 27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720 ==============================
[0m22:37:18.575987 [info ] [MainThread]: Running with dbt=1.5.4
[0m22:37:18.576294 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'fail_fast': 'False', 'use_colors': 'True', 'no_print': 'None', 'printer_width': '80', 'introspect': 'True', 'cache_selected_only': 'False', 'static_parser': 'True', 'target_path': 'None', 'debug': 'False', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'log_format': 'default', 'version_check': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True'}
[0m22:37:18.608651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eb25d0>]}
[0m22:37:18.615353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106290390>]}
[0m22:37:18.615845 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m22:37:18.626153 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m22:37:18.656635 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:37:18.656857 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:37:18.657103 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m22:37:18.659642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106633690>]}
[0m22:37:18.663625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1062c04d0>]}
[0m22:37:18.663886 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m22:37:18.664757 [info ] [MainThread]: 
[0m22:37:18.665151 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:37:18.665635 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:37:18.670270 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:37:18.670483 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:37:18.670604 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:37:19.648209 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.0 seconds
[0m22:37:19.650840 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:37:19.653523 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:37:19.660681 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:37:19.661345 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:37:19.661631 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:37:20.882913 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m22:37:20.884370 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:37:20.885141 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m22:37:21.233482 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m22:37:21.237597 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:37:21.313368 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:37:21.324190 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:21.324773 [debug] [MainThread]: On master: BEGIN
[0m22:37:21.325008 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:37:22.162239 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:37:22.162826 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:22.163142 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:37:22.260620 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m22:37:22.264509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ec3450>]}
[0m22:37:22.265225 [debug] [MainThread]: On master: ROLLBACK
[0m22:37:22.347249 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:22.348179 [debug] [MainThread]: On master: BEGIN
[0m22:37:22.508274 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:37:22.509262 [debug] [MainThread]: On master: COMMIT
[0m22:37:22.510180 [debug] [MainThread]: Using postgres connection "master"
[0m22:37:22.511041 [debug] [MainThread]: On master: COMMIT
[0m22:37:23.074846 [debug] [MainThread]: SQL status: COMMIT in 1.0 seconds
[0m22:37:23.075567 [debug] [MainThread]: On master: Close
[0m22:37:23.077296 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:37:23.078067 [info ] [MainThread]: 
[0m22:37:23.086723 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:37:23.087553 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m22:37:23.088516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:37:23.089052 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:37:23.108808 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:23.110291 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:37:23.089327 => 22:37:23.110057
[0m22:37:23.110578 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:37:23.134506 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:23.135248 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:23.135457 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:37:23.135626 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:37:24.326474 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:37:24.327578 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:24.328372 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, sum(cpa_count) as cpa_count, sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-01-01'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m22:37:42.909165 [debug] [Thread-1 (]: SQL status: SELECT 498185 in 19.0 seconds
[0m22:37:42.921532 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:42.922310 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:37:43.001696 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:37:43.008560 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:43.009255 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:37:43.089447 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:37:43.115976 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:37:43.116788 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:43.117115 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:37:43.198379 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:37:43.206149 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:37:43.206808 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:37:43.320219 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:37:43.323786 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:37:23.110732 => 22:37:43.323458
[0m22:37:43.324408 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:37:43.325687 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106653690>]}
[0m22:37:43.326380 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 498185[0m in 20.24s]
[0m22:37:43.327395 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:37:43.328176 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:37:43.329698 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m22:37:43.331131 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:37:43.331736 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:37:43.341439 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:37:43.342746 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:37:43.332085 => 22:37:43.342565
[0m22:37:43.343006 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:37:43.345708 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:37:43.346797 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:37:43.347091 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:37:43.347296 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:37:43.891655 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:37:43.893927 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:37:43.895058 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m22:37:53.963170 [debug] [Thread-1 (]: SQL status: SELECT 141995 in 10.0 seconds
[0m22:37:53.971891 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:37:53.972748 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m22:37:54.045353 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:37:54.052176 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:37:54.053018 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:37:54.123410 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:37:54.127697 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:37:54.128400 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:37:54.128896 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:37:54.183246 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:37:54.188960 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:37:54.189787 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:37:54.250253 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:37:54.252602 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:37:43.343141 => 22:37:54.252332
[0m22:37:54.253482 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:37:54.254961 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '27adecee-cdb0-4c1c-a5a6-7d1a5c7fb720', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106784050>]}
[0m22:37:54.256216 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 141995[0m in 10.92s]
[0m22:37:54.257343 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:37:54.258051 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:37:54.258723 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m22:37:54.259761 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m22:37:54.260146 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:37:54.275321 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:37:54.277617 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 22:37:54.260354 => 22:37:54.277301
[0m22:37:54.277966 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:37:54.289013 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:37:54.289911 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:37:54.290206 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m22:37:54.290439 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:37:56.598284 [debug] [Thread-1 (]: SQL status: BEGIN in 2.0 seconds
[0m22:37:56.600399 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:37:56.600986 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m22:37:56.817732 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:37:56.822992 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 22:37:54.278137 => 22:37:56.822434
[0m22:37:56.823863 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m22:37:56.907354 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m22:37:56.910576 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 2.65s]
[0m22:37:56.911975 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:37:56.912781 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:37:56.913608 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m22:37:56.914906 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m22:37:56.915558 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:37:56.926428 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:37:56.927549 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 22:37:56.916035 => 22:37:56.927387
[0m22:37:56.927917 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:37:56.930399 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:37:56.930993 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:37:56.931289 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m22:37:56.931503 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:37:57.436217 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:37:57.437651 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:37:57.438592 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m22:37:58.733805 [debug] [Thread-1 (]: SQL status: SELECT 1 in 1.0 seconds
[0m22:37:58.737892 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 22:37:56.928159 => 22:37:58.737451
[0m22:37:58.738555 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m22:37:58.805565 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m22:37:58.808296 [error] [Thread-1 (]: 4 of 6 FAIL 777 unique_outclick_by_brand_int_id ................................ [[31mFAIL 777[0m in 1.89s]
[0m22:37:58.809482 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:37:58.810319 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:37:58.811128 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m22:37:58.812425 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m22:37:58.812870 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:37:58.820063 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:37:58.821819 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 22:37:58.813123 => 22:37:58.821507
[0m22:37:58.822257 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:37:58.825302 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:37:58.826448 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:37:58.826874 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m22:37:58.827218 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:00.579749 [debug] [Thread-1 (]: SQL status: BEGIN in 2.0 seconds
[0m22:38:00.580346 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:38:00.580648 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m22:38:00.694673 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:38:00.698444 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 22:37:58.822472 => 22:38:00.698059
[0m22:38:00.699055 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m22:38:00.780703 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m22:38:00.783566 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 1.97s]
[0m22:38:00.784707 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:38:00.785131 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:38:00.785587 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m22:38:00.786871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m22:38:00.787581 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:38:00.794246 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:38:00.795538 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 22:38:00.787937 => 22:38:00.795267
[0m22:38:00.795937 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:38:00.798954 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:38:00.800097 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:38:00.800374 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m22:38:00.800594 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:01.305040 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:38:01.306724 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:38:01.307529 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m22:38:01.459569 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:38:01.463446 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 22:38:00.796164 => 22:38:01.463008
[0m22:38:01.464303 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m22:38:01.510779 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m22:38:01.513397 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.73s]
[0m22:38:01.514604 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:38:01.516658 [debug] [MainThread]: Using postgres connection "master"
[0m22:38:01.517003 [debug] [MainThread]: On master: BEGIN
[0m22:38:01.517208 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:38:01.962054 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:38:01.962705 [debug] [MainThread]: On master: COMMIT
[0m22:38:01.963676 [debug] [MainThread]: Using postgres connection "master"
[0m22:38:01.964140 [debug] [MainThread]: On master: COMMIT
[0m22:38:02.037617 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:38:02.038355 [debug] [MainThread]: On master: Close
[0m22:38:02.040651 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:38:02.041208 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m22:38:02.041690 [info ] [MainThread]: 
[0m22:38:02.042239 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 43.38 seconds (43.38s).
[0m22:38:02.043839 [debug] [MainThread]: Command end result
[0m22:38:02.059153 [info ] [MainThread]: 
[0m22:38:02.059577 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:38:02.059864 [info ] [MainThread]: 
[0m22:38:02.060073 [error] [MainThread]: [31mFailure in test unique_outclick_by_brand_int_id (models/brand_performance/schema.yml)[0m
[0m22:38:02.060258 [error] [MainThread]:   Got 777 results, configured to fail if != 0
[0m22:38:02.060424 [info ] [MainThread]: 
[0m22:38:02.060586 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_by_brand_int_id.sql
[0m22:38:02.060763 [info ] [MainThread]: 
[0m22:38:02.061069 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m22:38:02.061575 [debug] [MainThread]: Command `dbt build` failed at 22:38:02.061493 after 43.50 seconds
[0m22:38:02.061862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1016de4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1016de410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d5d350>]}
[0m22:38:02.062136 [debug] [MainThread]: Flushing usage events
[0m22:48:57.171219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c6fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c869d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c871d0>]}


============================== 22:48:57.173209 | c02d4211-9d96-4064-80aa-9a969c77f2a6 ==============================
[0m22:48:57.173209 [info ] [MainThread]: Running with dbt=1.5.4
[0m22:48:57.173533 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'write_json': 'True', 'no_print': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'version_check': 'True', 'target_path': 'None', 'printer_width': '80', 'log_format': 'default', 'debug': 'False', 'introspect': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/Users/danila/.dbt'}
[0m22:48:57.205676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c02d4211-9d96-4064-80aa-9a969c77f2a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c78c50>]}
[0m22:48:57.212564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c02d4211-9d96-4064-80aa-9a969c77f2a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fd7cd0>]}
[0m22:48:57.213075 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m22:48:57.224365 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m22:48:57.259260 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:48:57.259480 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:48:57.259713 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m22:48:57.262148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c02d4211-9d96-4064-80aa-9a969c77f2a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070ca090>]}
[0m22:48:57.266509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c02d4211-9d96-4064-80aa-9a969c77f2a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107005690>]}
[0m22:48:57.266751 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m22:48:57.267531 [info ] [MainThread]: 
[0m22:48:57.267870 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:48:57.268322 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:48:57.272381 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:48:57.272528 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:48:57.272644 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:48:58.173276 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.0 seconds
[0m22:48:58.176627 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:48:58.179686 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:48:58.188086 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:48:58.188583 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:48:58.188829 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:49:00.033691 [debug] [ThreadPool]: SQL status: BEGIN in 2.0 seconds
[0m22:49:00.034383 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:49:00.034761 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m22:49:01.363775 [debug] [ThreadPool]: SQL status: SELECT 19 in 1.0 seconds
[0m22:49:01.367285 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:49:01.729988 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:49:01.735299 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:01.735614 [debug] [MainThread]: On master: BEGIN
[0m22:49:01.735927 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:49:02.306557 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m22:49:02.307853 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:02.309032 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:49:02.383829 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m22:49:02.388192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c02d4211-9d96-4064-80aa-9a969c77f2a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c9f090>]}
[0m22:49:02.389209 [debug] [MainThread]: On master: ROLLBACK
[0m22:49:02.462629 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:02.463902 [debug] [MainThread]: On master: BEGIN
[0m22:49:02.610825 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:49:02.612400 [debug] [MainThread]: On master: COMMIT
[0m22:49:02.613016 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:02.613559 [debug] [MainThread]: On master: COMMIT
[0m22:49:02.686260 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:49:02.687268 [debug] [MainThread]: On master: Close
[0m22:49:02.689150 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:49:02.689518 [info ] [MainThread]: 
[0m22:49:02.698295 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:49:02.699050 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m22:49:02.700199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:49:02.700927 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:49:02.722872 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:02.724622 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:49:02.701243 => 22:49:02.724355
[0m22:49:02.724973 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:49:02.748964 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:02.749697 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:02.749893 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:49:02.750058 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:49:04.976082 [debug] [Thread-1 (]: SQL status: BEGIN in 2.0 seconds
[0m22:49:04.976783 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:04.977483 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-01-01'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date_parsed, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m22:49:25.189256 [debug] [Thread-1 (]: SQL status: SELECT 498185 in 20.0 seconds
[0m22:49:25.200938 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:25.201654 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:49:25.280269 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:49:25.284506 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:25.285243 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:49:25.363610 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:49:25.385636 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:49:25.385969 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:25.386115 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:49:25.465347 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:49:25.468550 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:49:25.468788 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:49:25.580525 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:49:25.584262 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:49:02.725146 => 22:49:25.583880
[0m22:49:25.585169 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:49:25.587084 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c02d4211-9d96-4064-80aa-9a969c77f2a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070de510>]}
[0m22:49:25.588155 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 498185[0m in 22.89s]
[0m22:49:25.589239 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:49:25.589961 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:49:25.590800 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m22:49:25.591718 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:49:25.592164 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:49:25.603388 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:49:25.605669 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:49:25.592465 => 22:49:25.605408
[0m22:49:25.606053 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:49:25.608957 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:49:25.609524 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:49:25.609775 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:49:25.610019 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:49:26.190652 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:49:26.192283 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:49:26.193648 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m22:49:39.594910 [debug] [Thread-1 (]: SQL status: SELECT 141995 in 13.0 seconds
[0m22:49:39.608685 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:49:39.609740 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m22:49:39.680313 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:49:39.684107 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:49:39.684563 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:49:39.747335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:49:39.750663 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:49:39.751243 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:49:39.751762 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:49:39.818988 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:49:39.824752 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:49:39.825654 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:49:39.920923 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:49:39.925589 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:49:25.606257 => 22:49:39.925278
[0m22:49:39.926214 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:49:39.927814 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c02d4211-9d96-4064-80aa-9a969c77f2a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071e4a90>]}
[0m22:49:39.928539 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 141995[0m in 14.34s]
[0m22:49:39.928944 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:49:39.929382 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:49:39.929955 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m22:49:39.930903 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m22:49:39.931136 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:49:39.940710 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:49:39.943720 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 22:49:39.931280 => 22:49:39.943488
[0m22:49:39.944052 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:49:39.953532 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:49:39.954303 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:49:39.954514 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m22:49:39.954710 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:49:41.153163 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:49:41.153979 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m22:49:41.154384 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m22:49:41.414821 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:49:41.418868 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 22:49:39.944239 => 22:49:41.418478
[0m22:49:41.419516 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m22:49:41.494774 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m22:49:41.497784 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 1.57s]
[0m22:49:41.498665 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m22:49:41.499161 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:49:41.499650 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m22:49:41.500683 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m22:49:41.501350 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:49:41.510889 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:49:41.512117 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 22:49:41.501686 => 22:49:41.511752
[0m22:49:41.512600 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:49:41.515710 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:49:41.517062 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:49:41.517556 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m22:49:41.517873 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:49:42.046735 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:49:42.047855 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m22:49:42.048242 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m22:49:43.276370 [debug] [Thread-1 (]: SQL status: SELECT 1 in 1.0 seconds
[0m22:49:43.279822 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 22:49:41.512794 => 22:49:43.279554
[0m22:49:43.280210 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m22:49:43.398163 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m22:49:43.400671 [error] [Thread-1 (]: 4 of 6 FAIL 777 unique_outclick_by_brand_int_id ................................ [[31mFAIL 777[0m in 1.90s]
[0m22:49:43.401905 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m22:49:43.402525 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:49:43.403026 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m22:49:43.404235 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m22:49:43.404801 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:49:43.411762 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:49:43.414421 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 22:49:43.405135 => 22:49:43.413869
[0m22:49:43.415192 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:49:43.419651 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:49:43.421416 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:49:43.421813 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m22:49:43.422110 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:49:44.912559 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:49:44.914192 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m22:49:44.915003 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m22:49:45.035278 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:49:45.037413 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 22:49:43.415570 => 22:49:45.037038
[0m22:49:45.038374 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m22:49:45.125494 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m22:49:45.127891 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 1.72s]
[0m22:49:45.129255 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m22:49:45.129909 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:49:45.130573 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m22:49:45.131413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m22:49:45.131825 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:49:45.138856 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:49:45.140281 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 22:49:45.132166 => 22:49:45.139844
[0m22:49:45.141061 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:49:45.144513 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:49:45.145504 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:49:45.145692 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m22:49:45.145830 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:49:45.655154 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:49:45.656070 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m22:49:45.656518 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m22:49:45.828660 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m22:49:45.832795 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 22:49:45.141652 => 22:49:45.832343
[0m22:49:45.833522 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m22:49:45.898457 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m22:49:45.900366 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.77s]
[0m22:49:45.901474 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m22:49:45.903591 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:45.904120 [debug] [MainThread]: On master: BEGIN
[0m22:49:45.904417 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:49:46.376999 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:49:46.378059 [debug] [MainThread]: On master: COMMIT
[0m22:49:46.378562 [debug] [MainThread]: Using postgres connection "master"
[0m22:49:46.379027 [debug] [MainThread]: On master: COMMIT
[0m22:49:46.450927 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:49:46.451932 [debug] [MainThread]: On master: Close
[0m22:49:46.453375 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:49:46.453765 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m22:49:46.454221 [info ] [MainThread]: 
[0m22:49:46.454680 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 49.19 seconds (49.19s).
[0m22:49:46.456724 [debug] [MainThread]: Command end result
[0m22:49:46.471342 [info ] [MainThread]: 
[0m22:49:46.471803 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:49:46.472051 [info ] [MainThread]: 
[0m22:49:46.472373 [error] [MainThread]: [31mFailure in test unique_outclick_by_brand_int_id (models/brand_performance/schema.yml)[0m
[0m22:49:46.472679 [error] [MainThread]:   Got 777 results, configured to fail if != 0
[0m22:49:46.472955 [info ] [MainThread]: 
[0m22:49:46.473229 [info ] [MainThread]:   compiled Code at target/compiled/campaign_perfomance/models/brand_performance/schema.yml/unique_outclick_by_brand_int_id.sql
[0m22:49:46.473533 [info ] [MainThread]: 
[0m22:49:46.473857 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m22:49:46.474407 [debug] [MainThread]: Command `dbt build` failed at 22:49:46.474341 after 49.31 seconds
[0m22:49:46.474641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1011724d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101172410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c9ab50>]}
[0m22:49:46.474862 [debug] [MainThread]: Flushing usage events
[0m23:24:55.046777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a477bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a489650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a49cbd0>]}


============================== 23:24:55.048518 | b00d9328-a6cb-4b8d-87bb-3d4b6a042aed ==============================
[0m23:24:55.048518 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:24:55.048850 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'profiles_dir': '/Users/danila/.dbt', 'log_cache_events': 'False', 'use_colors': 'True', 'introspect': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'use_experimental_parser': 'False', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'debug': 'False', 'printer_width': '80', 'write_json': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'fail_fast': 'False'}
[0m23:24:55.085826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b00d9328-a6cb-4b8d-87bb-3d4b6a042aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4b0290>]}
[0m23:24:55.092534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b00d9328-a6cb-4b8d-87bb-3d4b6a042aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c3950>]}
[0m23:24:55.093063 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:24:55.104968 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:24:55.151485 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:24:55.151786 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:24:55.152081 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m23:24:55.154925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b00d9328-a6cb-4b8d-87bb-3d4b6a042aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae14e90>]}
[0m23:24:55.159769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b00d9328-a6cb-4b8d-87bb-3d4b6a042aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a48c450>]}
[0m23:24:55.159985 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:24:55.160673 [info ] [MainThread]: 
[0m23:24:55.161017 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:24:55.161464 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:24:55.165749 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:24:55.165895 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:24:55.166016 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:24:55.907773 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.0 seconds
[0m23:24:55.911622 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:24:55.915690 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:24:55.924252 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:24:55.924850 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:24:55.925131 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:24:56.185983 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:24:56.187536 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:24:56.188566 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:24:56.224273 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m23:24:56.228952 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:24:56.260156 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:24:56.267658 [debug] [MainThread]: Using postgres connection "master"
[0m23:24:56.268088 [debug] [MainThread]: On master: BEGIN
[0m23:24:56.268354 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:24:56.787553 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m23:24:56.789241 [debug] [MainThread]: Using postgres connection "master"
[0m23:24:56.790713 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:24:56.844784 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m23:24:56.849235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b00d9328-a6cb-4b8d-87bb-3d4b6a042aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e10e90>]}
[0m23:24:56.849921 [debug] [MainThread]: On master: ROLLBACK
[0m23:24:56.902928 [debug] [MainThread]: Using postgres connection "master"
[0m23:24:56.903993 [debug] [MainThread]: On master: BEGIN
[0m23:24:57.030227 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:24:57.031624 [debug] [MainThread]: On master: COMMIT
[0m23:24:57.032266 [debug] [MainThread]: Using postgres connection "master"
[0m23:24:57.032669 [debug] [MainThread]: On master: COMMIT
[0m23:24:57.102852 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:24:57.104229 [debug] [MainThread]: On master: Close
[0m23:24:57.105886 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:24:57.106578 [info ] [MainThread]: 
[0m23:24:57.116298 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:24:57.117253 [info ] [Thread-1 (]: 1 of 3 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:24:57.118287 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_cost_int)
[0m23:24:57.119617 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:24:57.142563 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:24:57.144302 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:24:57.120149 => 23:24:57.144044
[0m23:24:57.144641 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:24:57.169334 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:24:57.170509 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:24:57.170745 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:24:57.170915 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:24:57.602494 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:24:57.604255 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:24:57.605339 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:25:07.491650 [debug] [Thread-1 (]: SQL status: SELECT 142006 in 10.0 seconds
[0m23:25:07.502814 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:25:07.503468 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:25:07.576829 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:25:07.581959 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:25:07.582388 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:25:07.657321 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:25:07.680592 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:25:07.681196 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:25:07.681469 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:25:07.754721 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:25:07.764049 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:25:07.764783 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:25:07.848152 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:25:07.851324 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:24:57.144805 => 23:25:07.851000
[0m23:25:07.852010 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:25:07.853380 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b00d9328-a6cb-4b8d-87bb-3d4b6a042aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae959d0>]}
[0m23:25:07.854275 [info ] [Thread-1 (]: 1 of 3 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142006[0m in 10.74s]
[0m23:25:07.854945 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:25:07.856244 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:25:07.856875 [info ] [Thread-1 (]: 2 of 3 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m23:25:07.857854 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m23:25:07.858204 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:25:07.871026 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:25:07.873567 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 23:25:07.858458 => 23:25:07.873314
[0m23:25:07.873905 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:25:07.885016 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:25:07.885853 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:25:07.886141 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m23:25:07.886373 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:25:08.144501 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:25:08.145775 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:25:08.146186 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m23:25:08.209372 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:25:08.213943 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 23:25:07.874100 => 23:25:08.213636
[0m23:25:08.214631 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m23:25:08.245433 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m23:25:08.247535 [info ] [Thread-1 (]: 2 of 3 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.39s]
[0m23:25:08.248929 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:25:08.249600 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:25:08.250360 [info ] [Thread-1 (]: 3 of 3 START test unique_outclick_cost_int_id .................................. [RUN]
[0m23:25:08.251658 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m23:25:08.252227 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:25:08.263097 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:25:08.264770 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 23:25:08.252558 => 23:25:08.264295
[0m23:25:08.265286 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:25:08.267793 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:25:08.268684 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:25:08.268948 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m23:25:08.269195 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:25:08.525390 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:25:08.526424 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:25:08.527100 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m23:25:08.658366 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:25:08.661551 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 23:25:08.265656 => 23:25:08.661100
[0m23:25:08.662305 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m23:25:08.693575 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m23:25:08.695736 [info ] [Thread-1 (]: 3 of 3 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.44s]
[0m23:25:08.696440 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:25:08.698255 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:08.698869 [debug] [MainThread]: On master: BEGIN
[0m23:25:08.699330 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:25:09.270011 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m23:25:09.270885 [debug] [MainThread]: On master: COMMIT
[0m23:25:09.271160 [debug] [MainThread]: Using postgres connection "master"
[0m23:25:09.271538 [debug] [MainThread]: On master: COMMIT
[0m23:25:09.312133 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:25:09.313543 [debug] [MainThread]: On master: Close
[0m23:25:09.314884 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:25:09.315460 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m23:25:09.315956 [info ] [MainThread]: 
[0m23:25:09.316553 [info ] [MainThread]: Finished running 1 table model, 2 tests in 0 hours 0 minutes and 14.15 seconds (14.15s).
[0m23:25:09.318137 [debug] [MainThread]: Command end result
[0m23:25:09.331356 [info ] [MainThread]: 
[0m23:25:09.331881 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:25:09.332145 [info ] [MainThread]: 
[0m23:25:09.332449 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m23:25:09.333000 [debug] [MainThread]: Command `dbt build` succeeded at 23:25:09.332911 after 14.30 seconds
[0m23:25:09.333290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a35d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10608c450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10608a790>]}
[0m23:25:09.333572 [debug] [MainThread]: Flushing usage events
[0m23:31:33.938793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10976c710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109781650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109794fd0>]}


============================== 23:31:33.941329 | 8bc1e555-f4f4-4ce5-84c2-9db10bc46956 ==============================
[0m23:31:33.941329 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:31:33.941776 [debug] [MainThread]: running dbt with arguments {'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'quiet': 'False', 'partial_parse': 'True', 'no_print': 'None', 'indirect_selection': 'eager', 'fail_fast': 'False', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'log_format': 'default', 'static_parser': 'True', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'use_colors': 'True', 'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'write_json': 'True'}
[0m23:31:33.976948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8bc1e555-f4f4-4ce5-84c2-9db10bc46956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090dc550>]}
[0m23:31:33.984322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8bc1e555-f4f4-4ce5-84c2-9db10bc46956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097bb350>]}
[0m23:31:33.985087 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:31:33.997367 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:31:34.030860 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:31:34.031100 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:31:34.031355 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m23:31:34.033922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8bc1e555-f4f4-4ce5-84c2-9db10bc46956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b72e10>]}
[0m23:31:34.038733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8bc1e555-f4f4-4ce5-84c2-9db10bc46956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ac46d0>]}
[0m23:31:34.038998 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:31:34.039849 [info ] [MainThread]: 
[0m23:31:34.040246 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:31:34.040734 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:31:34.045285 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:31:34.045513 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:31:34.045635 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:31:34.421102 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m23:31:34.424138 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:31:34.426160 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:31:34.434489 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:31:34.435071 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:31:34.435310 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:31:34.689420 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:31:34.690647 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:31:34.691244 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:31:34.725315 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m23:31:34.730303 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:31:34.761624 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:31:34.773393 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:34.773964 [debug] [MainThread]: On master: BEGIN
[0m23:31:34.774253 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:31:35.044569 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:31:35.045317 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:35.045768 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:31:35.087400 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m23:31:35.091924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8bc1e555-f4f4-4ce5-84c2-9db10bc46956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109b23f10>]}
[0m23:31:35.092703 [debug] [MainThread]: On master: ROLLBACK
[0m23:31:35.123971 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:35.124732 [debug] [MainThread]: On master: BEGIN
[0m23:31:35.186470 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:31:35.187950 [debug] [MainThread]: On master: COMMIT
[0m23:31:35.188884 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:35.189348 [debug] [MainThread]: On master: COMMIT
[0m23:31:35.220509 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:31:35.221403 [debug] [MainThread]: On master: Close
[0m23:31:35.223229 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:31:35.223895 [info ] [MainThread]: 
[0m23:31:35.232588 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:31:35.233336 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:31:35.234438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:31:35.234986 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:31:35.255627 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:31:35.257260 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:31:35.235209 => 23:31:35.257071
[0m23:31:35.257532 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:31:35.281352 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:31:35.282226 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:31:35.282464 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:31:35.282652 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:31:35.589080 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:31:35.590508 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:31:35.591903 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (

    with main as (select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
    where date_parsed > '2023-01-01'
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main


    select 
        'records' as source,
        date_parsed as date, 
        geo as country_code, 
        CASE  
            WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
            WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
            WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
            ELSE campaign_name
        END as campaign_name, 
        lower(adgroup_name) as ga_campaign_name, 
        CASE 
            when right(brand_name,6)<>'sports' then 'casino'
            when right(brand_name,6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        CASE
            WHEN campaign_name::text = 'email' THEN brand_name || ' email'
            WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
            ELSE brand_name
        END as brand_name, 
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from "deep-analysis-console"."console"."records" records
    where date_parsed > '2023-01-01'
  );
  
[0m23:31:35.626823 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "select"
LINE 139:     select 
              ^

[0m23:31:35.627670 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: ROLLBACK
[0m23:31:35.659936 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:31:35.257680 => 23:31:35.659123
[0m23:31:35.660861 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:31:35.671617 [debug] [Thread-1 (]: Database Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)
  syntax error at or near "select"
  LINE 139:     select 
                ^
  compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m23:31:35.672592 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8bc1e555-f4f4-4ce5-84c2-9db10bc46956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a84d90>]}
[0m23:31:35.673851 [error] [Thread-1 (]: 1 of 6 ERROR creating sql table model danila.outclick_by_brand_int ............. [[31mERROR[0m in 0.44s]
[0m23:31:35.674449 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:31:35.674913 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:31:35.675774 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:31:35.676685 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:31:35.677099 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:31:35.685204 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:31:35.687394 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:31:35.677308 => 23:31:35.687126
[0m23:31:35.687722 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:31:35.690865 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:31:35.691764 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:31:35.692060 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:31:35.692277 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:31:35.963546 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:31:35.965097 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:31:35.966104 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:31:45.294163 [debug] [Thread-1 (]: SQL status: SELECT 142006 in 9.0 seconds
[0m23:31:45.305668 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:31:45.306363 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:31:45.336735 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:31:45.342107 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:31:45.342640 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:31:45.373908 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:31:45.397366 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:31:45.397851 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:31:45.398125 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:31:45.428856 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:31:45.433105 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:31:45.433401 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:31:45.481338 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:31:45.482369 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:31:35.687956 => 23:31:45.482253
[0m23:31:45.482567 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:31:45.483109 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8bc1e555-f4f4-4ce5-84c2-9db10bc46956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a85010>]}
[0m23:31:45.483369 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142006[0m in 9.81s]
[0m23:31:45.483648 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:31:45.483808 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m23:31:45.483957 [info ] [Thread-1 (]: 3 of 6 SKIP test not_null_outclick_by_brand_int_id ............................. [[33mSKIP[0m]
[0m23:31:45.484317 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m23:31:45.484539 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m23:31:45.484738 [info ] [Thread-1 (]: 4 of 6 SKIP test unique_outclick_by_brand_int_id ............................... [[33mSKIP[0m]
[0m23:31:45.484961 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m23:31:45.485131 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:31:45.485274 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m23:31:45.485576 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m23:31:45.485739 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:31:45.492842 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:31:45.494762 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 23:31:45.485832 => 23:31:45.494636
[0m23:31:45.494945 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:31:45.501470 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:31:45.502119 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:31:45.502291 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m23:31:45.502428 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:31:45.854624 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:31:45.855231 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:31:45.855543 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m23:31:45.931537 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:31:45.932934 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 23:31:45.495044 => 23:31:45.932804
[0m23:31:45.933151 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m23:31:45.974857 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m23:31:45.975571 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.49s]
[0m23:31:45.975925 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:31:45.976129 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:31:45.976370 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m23:31:45.976774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m23:31:45.976948 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:31:45.980585 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:31:45.981158 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 23:31:45.977060 => 23:31:45.981055
[0m23:31:45.981332 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:31:45.982975 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:31:45.983612 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:31:45.983807 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m23:31:45.983964 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:31:46.256150 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:31:46.256520 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:31:46.256748 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m23:31:46.384950 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:31:46.386138 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 23:31:45.981445 => 23:31:46.385991
[0m23:31:46.386381 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m23:31:46.419789 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m23:31:46.420681 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.44s]
[0m23:31:46.421077 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:31:46.422165 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:46.422569 [debug] [MainThread]: On master: BEGIN
[0m23:31:46.422980 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:31:46.694722 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:31:46.695351 [debug] [MainThread]: On master: COMMIT
[0m23:31:46.695600 [debug] [MainThread]: Using postgres connection "master"
[0m23:31:46.695873 [debug] [MainThread]: On master: COMMIT
[0m23:31:46.725996 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:31:46.726845 [debug] [MainThread]: On master: Close
[0m23:31:46.728103 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:31:46.728395 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m23:31:46.728867 [info ] [MainThread]: 
[0m23:31:46.729484 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 12.69 seconds (12.69s).
[0m23:31:46.731019 [debug] [MainThread]: Command end result
[0m23:31:46.742593 [info ] [MainThread]: 
[0m23:31:46.743088 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m23:31:46.743311 [info ] [MainThread]: 
[0m23:31:46.743508 [error] [MainThread]: [33mDatabase Error in model outclick_by_brand_int (models/brand_performance/outclick_by_brand_int.sql)[0m
[0m23:31:46.743697 [error] [MainThread]:   syntax error at or near "select"
[0m23:31:46.743872 [error] [MainThread]:   LINE 139:     select 
[0m23:31:46.744031 [error] [MainThread]:                 ^
[0m23:31:46.744192 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/brand_performance/outclick_by_brand_int.sql
[0m23:31:46.744367 [info ] [MainThread]: 
[0m23:31:46.744573 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=2 TOTAL=6
[0m23:31:46.744992 [debug] [MainThread]: Command `dbt build` failed at 23:31:46.744923 after 12.82 seconds
[0m23:31:46.745225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10378a750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10378a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097948d0>]}
[0m23:31:46.745444 [debug] [MainThread]: Flushing usage events
[0m23:33:44.000428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a748d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a8f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a8fa10>]}


============================== 23:33:44.002352 | 57e0ef77-95e2-4cf5-a687-a569a2292494 ==============================
[0m23:33:44.002352 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:33:44.002709 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'quiet': 'False', 'fail_fast': 'False', 'write_json': 'True', 'static_parser': 'True', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'log_cache_events': 'False', 'debug': 'False', 'warn_error': 'None', 'introspect': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'partial_parse': 'True', 'log_format': 'default', 'version_check': 'True', 'cache_selected_only': 'False', 'printer_width': '80', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False'}
[0m23:33:44.034675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '57e0ef77-95e2-4cf5-a687-a569a2292494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a80e10>]}
[0m23:33:44.041448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '57e0ef77-95e2-4cf5-a687-a569a2292494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a8f210>]}
[0m23:33:44.042033 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:33:44.052983 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:33:44.085796 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:33:44.086032 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:33:44.086307 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m23:33:44.088843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57e0ef77-95e2-4cf5-a687-a569a2292494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10607f110>]}
[0m23:33:44.093043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57e0ef77-95e2-4cf5-a687-a569a2292494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a75e10>]}
[0m23:33:44.093260 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:33:44.094058 [info ] [MainThread]: 
[0m23:33:44.094422 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:33:44.094948 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:33:44.099481 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:33:44.099707 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:33:44.099838 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:33:44.389253 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m23:33:44.393588 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:33:44.396945 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:33:44.405316 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:33:44.405977 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:33:44.406310 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:33:44.660165 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:33:44.660784 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:33:44.661094 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:33:44.695228 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m23:33:44.699086 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:33:44.729743 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:33:44.741988 [debug] [MainThread]: Using postgres connection "master"
[0m23:33:44.742610 [debug] [MainThread]: On master: BEGIN
[0m23:33:44.742907 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:33:44.995507 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:33:44.996880 [debug] [MainThread]: Using postgres connection "master"
[0m23:33:44.997845 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:33:45.040082 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m23:33:45.044136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57e0ef77-95e2-4cf5-a687-a569a2292494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106038350>]}
[0m23:33:45.045132 [debug] [MainThread]: On master: ROLLBACK
[0m23:33:45.075670 [debug] [MainThread]: Using postgres connection "master"
[0m23:33:45.076887 [debug] [MainThread]: On master: BEGIN
[0m23:33:45.139691 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:33:45.140996 [debug] [MainThread]: On master: COMMIT
[0m23:33:45.141451 [debug] [MainThread]: Using postgres connection "master"
[0m23:33:45.141753 [debug] [MainThread]: On master: COMMIT
[0m23:33:45.171999 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:33:45.172664 [debug] [MainThread]: On master: Close
[0m23:33:45.173690 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:33:45.174143 [info ] [MainThread]: 
[0m23:33:45.181462 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:33:45.182268 [info ] [Thread-1 (]: 1 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:33:45.183167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:33:45.183787 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:33:45.205532 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:33:45.206766 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:33:45.184074 => 23:33:45.206571
[0m23:33:45.207081 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:33:45.231937 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:33:45.232746 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:33:45.232969 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:33:45.233151 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:33:45.542469 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:33:45.543868 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:33:45.545366 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m23:34:02.886364 [debug] [Thread-1 (]: SQL status: SELECT 497419 in 17.0 seconds
[0m23:34:02.898866 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:02.899701 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:34:02.937146 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:02.945527 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:02.946266 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:34:02.981772 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:03.008494 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:34:03.009041 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:03.009343 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:34:03.039273 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:03.044358 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:03.044709 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:34:03.106360 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:34:03.110633 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:33:45.207245 => 23:34:03.110210
[0m23:34:03.111478 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:34:03.113913 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57e0ef77-95e2-4cf5-a687-a569a2292494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106048050>]}
[0m23:34:03.115085 [info ] [Thread-1 (]: 1 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 497419[0m in 17.93s]
[0m23:34:03.116030 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:03.116617 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:34:03.117349 [info ] [Thread-1 (]: 2 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:34:03.118421 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:34:03.118794 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:34:03.129086 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:34:03.131528 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:34:03.119021 => 23:34:03.131322
[0m23:34:03.131859 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:34:03.135195 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:34:03.135792 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:03.136054 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:34:03.136309 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:03.724970 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m23:34:03.726135 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:03.727758 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:34:13.778294 [debug] [Thread-1 (]: SQL status: SELECT 142006 in 10.0 seconds
[0m23:34:13.791589 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:13.792535 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:34:13.835853 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:13.842848 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:13.843700 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:34:13.888748 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:13.892209 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:34:13.892926 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:13.893471 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:34:13.937367 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:13.944222 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:13.945231 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:34:14.007384 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:34:14.011246 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:34:03.132042 => 23:34:14.010892
[0m23:34:14.011869 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:34:14.013313 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57e0ef77-95e2-4cf5-a687-a569a2292494', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106210fd0>]}
[0m23:34:14.014325 [info ] [Thread-1 (]: 2 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142006[0m in 10.90s]
[0m23:34:14.015274 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:34:14.015826 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m23:34:14.016582 [info ] [Thread-1 (]: 3 of 6 START test not_null_outclick_by_brand_int_id ............................ [RUN]
[0m23:34:14.017435 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m23:34:14.017795 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m23:34:14.031449 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m23:34:14.034479 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 23:34:14.018025 => 23:34:14.034209
[0m23:34:14.034865 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m23:34:14.044671 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m23:34:14.045499 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m23:34:14.045723 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m23:34:14.045927 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:14.342731 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:14.344392 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m23:34:14.345334 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m23:34:14.509742 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:34:14.514909 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 23:34:14.035056 => 23:34:14.514316
[0m23:34:14.515783 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m23:34:14.547357 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m23:34:14.550530 [info ] [Thread-1 (]: 3 of 6 PASS not_null_outclick_by_brand_int_id .................................. [[32mPASS[0m in 0.53s]
[0m23:34:14.551960 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m23:34:14.552810 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m23:34:14.553827 [info ] [Thread-1 (]: 4 of 6 START test unique_outclick_by_brand_int_id .............................. [RUN]
[0m23:34:14.555399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m23:34:14.556171 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m23:34:14.565908 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m23:34:14.568421 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 23:34:14.556530 => 23:34:14.567980
[0m23:34:14.568987 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m23:34:14.571344 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m23:34:14.572327 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m23:34:14.572661 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m23:34:14.572954 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:14.831845 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:14.833068 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m23:34:14.833648 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m23:34:15.660759 [debug] [Thread-1 (]: SQL status: SELECT 1 in 1.0 seconds
[0m23:34:15.664238 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 23:34:14.569271 => 23:34:15.663815
[0m23:34:15.664887 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m23:34:15.695447 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m23:34:15.697274 [info ] [Thread-1 (]: 4 of 6 PASS unique_outclick_by_brand_int_id .................................... [[32mPASS[0m in 1.14s]
[0m23:34:15.698209 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m23:34:15.698730 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:34:15.699479 [info ] [Thread-1 (]: 5 of 6 START test not_null_outclick_cost_int_id ................................ [RUN]
[0m23:34:15.700831 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m23:34:15.701407 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:34:15.708367 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:34:15.710445 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 23:34:15.701744 => 23:34:15.709882
[0m23:34:15.711065 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:34:15.714114 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:34:15.714842 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:34:15.715078 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m23:34:15.715266 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:15.970703 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:15.972005 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m23:34:15.972793 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m23:34:16.037079 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:34:16.039824 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 23:34:15.711390 => 23:34:16.039520
[0m23:34:16.040285 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m23:34:16.071708 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m23:34:16.073212 [info ] [Thread-1 (]: 5 of 6 PASS not_null_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.37s]
[0m23:34:16.074005 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m23:34:16.074480 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:34:16.075030 [info ] [Thread-1 (]: 6 of 6 START test unique_outclick_cost_int_id .................................. [RUN]
[0m23:34:16.075949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m23:34:16.076307 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:34:16.080487 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:34:16.081582 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 23:34:16.076515 => 23:34:16.081391
[0m23:34:16.081838 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:34:16.084049 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:34:16.084846 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:34:16.085159 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m23:34:16.085443 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:16.389534 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:16.390640 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m23:34:16.391403 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m23:34:16.520127 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m23:34:16.523614 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 23:34:16.081977 => 23:34:16.523093
[0m23:34:16.524374 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m23:34:16.562326 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m23:34:16.564078 [info ] [Thread-1 (]: 6 of 6 PASS unique_outclick_cost_int_id ........................................ [[32mPASS[0m in 0.49s]
[0m23:34:16.565277 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m23:34:16.567636 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:16.568257 [debug] [MainThread]: On master: BEGIN
[0m23:34:16.568646 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:34:16.894553 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:34:16.895914 [debug] [MainThread]: On master: COMMIT
[0m23:34:16.896373 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:16.896788 [debug] [MainThread]: On master: COMMIT
[0m23:34:16.935413 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:34:16.936406 [debug] [MainThread]: On master: Close
[0m23:34:16.937351 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:34:16.938048 [debug] [MainThread]: Connection 'test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f' was properly closed.
[0m23:34:16.938603 [info ] [MainThread]: 
[0m23:34:16.939166 [info ] [MainThread]: Finished running 2 table models, 4 tests in 0 hours 0 minutes and 32.84 seconds (32.84s).
[0m23:34:16.940924 [debug] [MainThread]: Command end result
[0m23:34:16.954681 [info ] [MainThread]: 
[0m23:34:16.955218 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:34:16.955499 [info ] [MainThread]: 
[0m23:34:16.955776 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m23:34:16.956290 [debug] [MainThread]: Command `dbt build` succeeded at 23:34:16.956211 after 32.97 seconds
[0m23:34:16.956604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100bd8190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100bd6410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100bd64d0>]}
[0m23:34:16.956893 [debug] [MainThread]: Flushing usage events
[0m23:34:40.522860 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae77d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae8d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae97650>]}


============================== 23:34:40.524856 | 319ff773-2ee9-4dab-baa0-7f9da3744956 ==============================
[0m23:34:40.524856 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:34:40.525190 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'target_path': 'None', 'quiet': 'False', 'static_parser': 'True', 'version_check': 'True', 'log_cache_events': 'False', 'debug': 'False', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error': 'None', 'cache_selected_only': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'printer_width': '80', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'partial_parse': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'use_experimental_parser': 'False'}
[0m23:34:40.558618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae81210>]}
[0m23:34:40.565316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2219d0>]}
[0m23:34:40.565836 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:34:40.577522 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:34:40.621169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:34:40.621372 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:34:40.621607 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m23:34:40.624053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2fb550>]}
[0m23:34:40.628759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b24df10>]}
[0m23:34:40.628971 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:34:40.629128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107acf890>]}
[0m23:34:40.629835 [info ] [MainThread]: 
[0m23:34:40.630174 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:34:40.630656 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:34:40.635249 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:34:40.635481 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:34:40.635613 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:34:40.996386 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m23:34:40.999413 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:34:41.002806 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:34:41.011166 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:34:41.011811 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:34:41.012161 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:34:41.288248 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:34:41.289408 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:34:41.290023 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:34:41.326876 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m23:34:41.329903 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:34:41.363334 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:34:41.373359 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:41.374165 [debug] [MainThread]: On master: BEGIN
[0m23:34:41.374618 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:34:41.631455 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:34:41.632944 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:41.633663 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:34:41.674786 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m23:34:41.677467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a70ce10>]}
[0m23:34:41.678230 [debug] [MainThread]: On master: ROLLBACK
[0m23:34:41.708527 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:41.709316 [debug] [MainThread]: On master: BEGIN
[0m23:34:41.770032 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:34:41.770529 [debug] [MainThread]: On master: COMMIT
[0m23:34:41.770757 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:41.770951 [debug] [MainThread]: On master: COMMIT
[0m23:34:41.801141 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:34:41.801747 [debug] [MainThread]: On master: Close
[0m23:34:41.802599 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:34:41.802888 [info ] [MainThread]: 
[0m23:34:41.806283 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:41.806669 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:34:41.807169 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:34:41.807396 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:41.822410 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:41.823860 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:34:41.807539 => 23:34:41.823659
[0m23:34:41.824141 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:41.843770 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:41.844712 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:41.844919 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:34:41.845066 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:42.142962 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:42.143923 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:42.145509 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m23:34:59.844322 [debug] [Thread-1 (]: SQL status: SELECT 497419 in 18.0 seconds
[0m23:34:59.850225 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:59.850654 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:34:59.889903 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:59.892901 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:59.893318 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:34:59.930055 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:59.942268 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:34:59.942727 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:59.942924 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:34:59.978705 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:59.982344 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:59.983057 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:35:00.054746 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:35:00.055842 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:34:41.824267 => 23:35:00.055731
[0m23:35:00.056081 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:35:00.056671 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b31f950>]}
[0m23:35:00.057028 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 497419[0m in 18.25s]
[0m23:35:00.057721 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:35:00.058340 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:35:00.059108 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:35:00.059868 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:35:00.060207 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:35:00.067177 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:35:00.068797 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:35:00.060415 => 23:35:00.068509
[0m23:35:00.069195 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:35:00.072094 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:35:00.072629 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:35:00.072812 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:35:00.072970 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:35:00.349519 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:35:00.350691 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:35:00.351227 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:35:10.586083 [debug] [Thread-1 (]: SQL status: SELECT 142006 in 10.0 seconds
[0m23:35:10.592352 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:35:10.592859 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:35:10.623263 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:35:10.630624 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:35:10.631451 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:35:10.662542 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:35:10.664227 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:35:10.664610 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:35:10.664917 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:35:10.695742 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:35:10.700532 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:35:10.701435 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:35:10.751391 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:35:10.755491 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:35:00.069427 => 23:35:10.755116
[0m23:35:10.756133 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:35:10.757302 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '319ff773-2ee9-4dab-baa0-7f9da3744956', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b431510>]}
[0m23:35:10.757914 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142006[0m in 10.70s]
[0m23:35:10.759096 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:35:10.761070 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:10.761468 [debug] [MainThread]: On master: BEGIN
[0m23:35:10.761672 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:35:11.018517 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:35:11.019494 [debug] [MainThread]: On master: COMMIT
[0m23:35:11.019840 [debug] [MainThread]: Using postgres connection "master"
[0m23:35:11.020138 [debug] [MainThread]: On master: COMMIT
[0m23:35:11.051125 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:35:11.052607 [debug] [MainThread]: On master: Close
[0m23:35:11.054309 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:35:11.054855 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m23:35:11.055365 [info ] [MainThread]: 
[0m23:35:11.055980 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 30.43 seconds (30.43s).
[0m23:35:11.057447 [debug] [MainThread]: Command end result
[0m23:35:11.070148 [info ] [MainThread]: 
[0m23:35:11.070873 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:35:11.071284 [info ] [MainThread]: 
[0m23:35:11.071554 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m23:35:11.072096 [debug] [MainThread]: Command `dbt run` succeeded at 23:35:11.071974 after 30.56 seconds
[0m23:35:11.072518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10698c190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10698a550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10698a4d0>]}
[0m23:35:11.072776 [debug] [MainThread]: Flushing usage events
[0m23:36:58.624866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10638e8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10638d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106398b50>]}


============================== 23:36:58.626606 | 3635abc0-b2aa-41f3-93be-95df38850912 ==============================
[0m23:36:58.626606 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:36:58.626925 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'use_colors': 'True', 'introspect': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False', 'write_json': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'printer_width': '80', 'log_format': 'default', 'quiet': 'False', 'no_print': 'None'}
[0m23:36:58.658076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106381090>]}
[0m23:36:58.664707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067ebb10>]}
[0m23:36:58.665135 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:36:58.676675 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:36:58.716356 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:36:58.716549 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:36:58.716765 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m23:36:58.719187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067f74d0>]}
[0m23:36:58.723532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106820410>]}
[0m23:36:58.723763 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:36:58.723921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103147e90>]}
[0m23:36:58.724624 [info ] [MainThread]: 
[0m23:36:58.724957 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:36:58.725411 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:36:58.729734 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:36:58.729929 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:36:58.730056 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:36:59.113791 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m23:36:59.117657 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:36:59.121831 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:36:59.133302 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:36:59.133754 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:36:59.133883 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:36:59.394158 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:36:59.395002 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:36:59.395373 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:36:59.430246 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m23:36:59.434786 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:36:59.466071 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:36:59.480486 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:59.480999 [debug] [MainThread]: On master: BEGIN
[0m23:36:59.481381 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:36:59.769624 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:36:59.770903 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:59.771641 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:36:59.813178 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m23:36:59.817869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106391690>]}
[0m23:36:59.819078 [debug] [MainThread]: On master: ROLLBACK
[0m23:36:59.850023 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:59.851135 [debug] [MainThread]: On master: BEGIN
[0m23:36:59.913764 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:36:59.915444 [debug] [MainThread]: On master: COMMIT
[0m23:36:59.916529 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:59.917263 [debug] [MainThread]: On master: COMMIT
[0m23:36:59.948586 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:36:59.949899 [debug] [MainThread]: On master: Close
[0m23:36:59.951715 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:36:59.952497 [info ] [MainThread]: 
[0m23:36:59.962827 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:36:59.963851 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:36:59.965009 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:36:59.965616 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:36:59.989092 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:36:59.990697 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:36:59.966075 => 23:36:59.990526
[0m23:36:59.990954 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:37:00.012685 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:37:00.013418 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:37:00.013606 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:37:00.013762 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:37:00.271336 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:37:00.273256 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:37:00.274853 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m23:37:17.705323 [debug] [Thread-1 (]: SQL status: SELECT 497423 in 17.0 seconds
[0m23:37:17.717875 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:37:17.718553 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:37:17.750237 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:37:17.755385 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:37:17.756032 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:37:17.787816 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:37:17.810302 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:37:17.810844 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:37:17.811092 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:37:17.841481 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:37:17.846208 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:37:17.846545 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:37:17.905830 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:37:17.909639 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:36:59.991093 => 23:37:17.909252
[0m23:37:17.910413 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:37:17.912473 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106862dd0>]}
[0m23:37:17.913645 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 497423[0m in 17.95s]
[0m23:37:17.914782 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:37:17.915528 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:37:17.916392 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:37:17.917282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:37:17.917662 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:37:17.926942 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:37:17.929235 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:37:17.917897 => 23:37:17.929015
[0m23:37:17.929533 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:37:17.932778 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:37:17.933287 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:37:17.933532 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:37:17.933767 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:37:18.241919 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:37:18.243677 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:37:18.244851 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:37:28.646541 [debug] [Thread-1 (]: SQL status: SELECT 142011 in 10.0 seconds
[0m23:37:28.653286 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:37:28.653956 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:37:28.687763 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:37:28.699010 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:37:28.699822 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:37:28.733543 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:37:28.737007 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:37:28.737724 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:37:28.738175 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:37:28.771508 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:37:28.776998 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:37:28.777720 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:37:28.827645 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:37:28.831342 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:37:17.929708 => 23:37:28.830898
[0m23:37:28.832149 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:37:28.834006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3635abc0-b2aa-41f3-93be-95df38850912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a7a750>]}
[0m23:37:28.835108 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142011[0m in 10.92s]
[0m23:37:28.836331 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:37:28.838755 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:28.839213 [debug] [MainThread]: On master: BEGIN
[0m23:37:28.839547 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:37:29.121549 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:37:29.123047 [debug] [MainThread]: On master: COMMIT
[0m23:37:29.124129 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:29.124835 [debug] [MainThread]: On master: COMMIT
[0m23:37:29.156415 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:37:29.157954 [debug] [MainThread]: On master: Close
[0m23:37:29.160416 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:37:29.161071 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m23:37:29.161779 [info ] [MainThread]: 
[0m23:37:29.162524 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 30.44 seconds (30.44s).
[0m23:37:29.164029 [debug] [MainThread]: Command end result
[0m23:37:29.177321 [info ] [MainThread]: 
[0m23:37:29.178015 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:37:29.178429 [info ] [MainThread]: 
[0m23:37:29.178835 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m23:37:29.179523 [debug] [MainThread]: Command `dbt run` succeeded at 23:37:29.179410 after 30.57 seconds
[0m23:37:29.179915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10138c190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10138a410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10138a550>]}
[0m23:37:29.180302 [debug] [MainThread]: Flushing usage events
[0m23:45:37.547527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113075390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113093fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113093850>]}


============================== 23:45:37.549277 | 153a0886-bba3-4df8-b6ac-0984a0779a68 ==============================
[0m23:45:37.549277 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:45:37.549596 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'no_print': 'None', 'write_json': 'True', 'introspect': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'debug': 'False', 'log_format': 'default', 'printer_width': '80', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'static_parser': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'version_check': 'True', 'target_path': 'None', 'warn_error': 'None', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt'}
[0m23:45:37.580254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dacc10>]}
[0m23:45:37.586647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110dacc10>]}
[0m23:45:37.587049 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:45:37.597866 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:45:37.637224 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:45:37.637418 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:45:37.637637 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m23:45:37.639921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140560d0>]}
[0m23:45:37.643587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130a6b90>]}
[0m23:45:37.643764 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:45:37.643915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106234290>]}
[0m23:45:37.644605 [info ] [MainThread]: 
[0m23:45:37.644947 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:45:37.645411 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:45:37.649316 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:45:37.649445 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:45:37.649547 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:45:37.991584 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m23:45:37.995623 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:45:38.000064 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:45:38.009767 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:45:38.010174 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:45:38.010333 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:45:38.318263 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:45:38.319103 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:45:38.319484 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:45:38.359943 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m23:45:38.364131 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:45:38.401249 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:45:38.412652 [debug] [MainThread]: Using postgres connection "master"
[0m23:45:38.413069 [debug] [MainThread]: On master: BEGIN
[0m23:45:38.413351 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:45:38.671643 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:45:38.672086 [debug] [MainThread]: Using postgres connection "master"
[0m23:45:38.672404 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:45:38.713241 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m23:45:38.716564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106234090>]}
[0m23:45:38.717288 [debug] [MainThread]: On master: ROLLBACK
[0m23:45:38.747782 [debug] [MainThread]: Using postgres connection "master"
[0m23:45:38.748172 [debug] [MainThread]: On master: BEGIN
[0m23:45:38.810656 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:45:38.811007 [debug] [MainThread]: On master: COMMIT
[0m23:45:38.811303 [debug] [MainThread]: Using postgres connection "master"
[0m23:45:38.811580 [debug] [MainThread]: On master: COMMIT
[0m23:45:38.841681 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:45:38.842004 [debug] [MainThread]: On master: Close
[0m23:45:38.842612 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:45:38.842882 [info ] [MainThread]: 
[0m23:45:38.846164 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:45:38.846520 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:45:38.847037 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:45:38.847272 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:45:38.862803 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:38.863698 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:45:38.847419 => 23:45:38.863548
[0m23:45:38.863928 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:45:38.882965 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:38.884050 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:38.884223 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:45:38.884370 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:45:39.186865 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:45:39.188749 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:39.190419 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m23:45:58.113921 [debug] [Thread-1 (]: SQL status: SELECT 497426 in 19.0 seconds
[0m23:45:58.129256 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:58.130131 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:45:58.167618 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:45:58.176090 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:58.177060 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:45:58.217038 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:45:58.253298 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:45:58.253933 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:58.254323 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:45:58.291986 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:45:58.301736 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:45:58.302421 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:45:58.373485 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:45:58.378567 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:45:38.864053 => 23:45:58.378127
[0m23:45:58.379284 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:45:58.382017 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1136e2a50>]}
[0m23:45:58.383129 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 497426[0m in 19.53s]
[0m23:45:58.384300 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:45:58.385352 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:45:58.386551 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:45:58.387983 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:45:58.388567 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:45:58.403088 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:45:58.405560 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:45:58.388874 => 23:45:58.404982
[0m23:45:58.406231 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:45:58.411402 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:45:58.413322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:45:58.413781 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:45:58.414120 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:45:58.781112 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:45:58.782680 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:45:58.783437 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:46:08.556881 [debug] [Thread-1 (]: SQL status: SELECT 142013 in 10.0 seconds
[0m23:46:08.566323 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:46:08.566848 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:46:08.604603 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:46:08.616139 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:46:08.617229 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:46:08.653972 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:46:08.659065 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:46:08.660329 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:46:08.661016 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:46:08.698187 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:46:08.702971 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:46:08.703577 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:46:08.758084 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:46:08.763060 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:45:58.406558 => 23:46:08.762429
[0m23:46:08.764370 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:46:08.766628 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '153a0886-bba3-4df8-b6ac-0984a0779a68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11416c790>]}
[0m23:46:08.768554 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142013[0m in 10.38s]
[0m23:46:08.769983 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:46:08.772817 [debug] [MainThread]: Using postgres connection "master"
[0m23:46:08.773323 [debug] [MainThread]: On master: BEGIN
[0m23:46:08.773737 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:46:09.032489 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:46:09.034966 [debug] [MainThread]: On master: COMMIT
[0m23:46:09.036147 [debug] [MainThread]: Using postgres connection "master"
[0m23:46:09.037058 [debug] [MainThread]: On master: COMMIT
[0m23:46:09.068439 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:46:09.069195 [debug] [MainThread]: On master: Close
[0m23:46:09.070359 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:46:09.070679 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m23:46:09.071399 [info ] [MainThread]: 
[0m23:46:09.072500 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 31.43 seconds (31.43s).
[0m23:46:09.074092 [debug] [MainThread]: Command end result
[0m23:46:09.092736 [info ] [MainThread]: 
[0m23:46:09.093667 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:46:09.094151 [info ] [MainThread]: 
[0m23:46:09.094598 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m23:46:09.095519 [debug] [MainThread]: Command `dbt run` succeeded at 23:46:09.095383 after 31.56 seconds
[0m23:46:09.096090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113090310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ea0190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e9e4d0>]}
[0m23:46:09.096498 [debug] [MainThread]: Flushing usage events
[0m23:47:07.487238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111077a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11108d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11109ce90>]}


============================== 23:47:07.488849 | 5c806929-035b-4169-a3d9-3fa6fa492288 ==============================
[0m23:47:07.488849 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:47:07.489177 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'printer_width': '80', 'log_format': 'default', 'use_experimental_parser': 'False', 'introspect': 'True', 'target_path': 'None', 'write_json': 'True', 'debug': 'False', 'log_cache_events': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'quiet': 'False', 'cache_selected_only': 'False', 'no_print': 'None'}
[0m23:47:07.519351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c806929-035b-4169-a3d9-3fa6fa492288', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110768d0>]}
[0m23:47:07.525828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c806929-035b-4169-a3d9-3fa6fa492288', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111491550>]}
[0m23:47:07.526300 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:47:07.537471 [debug] [MainThread]: checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, vars: {}, profile: , target: prod, version: 1.5.4
[0m23:47:07.562142 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m23:47:07.562471 [debug] [MainThread]: previous checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a, current checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21
[0m23:47:07.562613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5c806929-035b-4169-a3d9-3fa6fa492288', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112887e90>]}
[0m23:47:07.887618 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m23:47:07.899884 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m23:47:07.900907 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m23:47:07.904323 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m23:47:07.942222 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m23:47:07.944211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c806929-035b-4169-a3d9-3fa6fa492288', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114e4290>]}
[0m23:47:07.947722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c806929-035b-4169-a3d9-3fa6fa492288', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129ada10>]}
[0m23:47:07.947882 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:47:07.948036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c806929-035b-4169-a3d9-3fa6fa492288', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129affd0>]}
[0m23:47:07.948576 [debug] [MainThread]: Command `dbt ls` succeeded at 23:47:07.948520 after 0.47 seconds
[0m23:47:07.948727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c0d2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c0a890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b81a50>]}
[0m23:47:07.948870 [debug] [MainThread]: Flushing usage events
[0m23:48:13.247066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10606cb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10608ba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10608bf90>]}


============================== 23:48:13.248958 | 4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd ==============================
[0m23:48:13.248958 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:48:13.249245 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'log_format': 'default', 'indirect_selection': 'eager', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'version_check': 'True', 'quiet': 'False', 'printer_width': '80', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'cache_selected_only': 'False'}
[0m23:48:13.280117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058dcb50>]}
[0m23:48:13.286766 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105815710>]}
[0m23:48:13.287280 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:48:13.298133 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:48:13.318041 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m23:48:13.318331 [debug] [MainThread]: previous checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, current checksum: 34d7f28cc5e214151443bcf8fb638f0c4d0870b1853cc19400aebba6634acd8a
[0m23:48:13.318468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065ffe10>]}
[0m23:48:13.641575 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m23:48:13.653754 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m23:48:13.654778 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m23:48:13.658153 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m23:48:13.695658 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.users
- models.brand_performance
[0m23:48:13.697689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065eae10>]}
[0m23:48:13.702014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106723110>]}
[0m23:48:13.702251 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m23:48:13.702419 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064bb450>]}
[0m23:48:13.703144 [info ] [MainThread]: 
[0m23:48:13.703478 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:48:13.703966 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:48:13.708284 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:48:13.708528 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:48:13.708658 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:48:14.134171 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m23:48:14.138936 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:48:14.142240 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:48:14.150784 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:48:14.151385 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:48:14.151726 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:48:14.432842 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:48:14.433444 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:48:14.433802 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:48:14.470729 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m23:48:14.474306 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:48:14.507635 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:48:14.520183 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:14.520742 [debug] [MainThread]: On master: BEGIN
[0m23:48:14.521127 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:48:14.798976 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:48:14.799953 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:14.800680 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:48:14.844031 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m23:48:14.845355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106574f10>]}
[0m23:48:14.845668 [debug] [MainThread]: On master: ROLLBACK
[0m23:48:14.878718 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:14.878970 [debug] [MainThread]: On master: BEGIN
[0m23:48:14.944909 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:48:14.945273 [debug] [MainThread]: On master: COMMIT
[0m23:48:14.945561 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:14.945833 [debug] [MainThread]: On master: COMMIT
[0m23:48:14.979373 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:48:14.980322 [debug] [MainThread]: On master: Close
[0m23:48:14.982254 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:48:14.983014 [info ] [MainThread]: 
[0m23:48:14.990083 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:48:14.990721 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:48:14.991466 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:48:14.991805 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:48:15.002985 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:15.004155 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:48:14.992020 => 23:48:15.003998
[0m23:48:15.004411 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:48:15.027364 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:15.028045 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:15.028267 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:48:15.028438 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:48:15.332473 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:48:15.332841 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:15.333323 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m23:48:32.522003 [debug] [Thread-1 (]: SQL status: SELECT 497426 in 17.0 seconds
[0m23:48:32.537827 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:32.538702 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:48:32.577511 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:48:32.584555 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:32.585326 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:48:32.623213 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:48:32.656997 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:48:32.657531 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:32.657898 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:48:32.694860 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:48:32.705067 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:48:32.705770 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:48:32.766896 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:48:32.770887 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:48:15.004565 => 23:48:32.770611
[0m23:48:32.772167 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:48:32.774283 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10666bfd0>]}
[0m23:48:32.776619 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 497426[0m in 17.78s]
[0m23:48:32.778284 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:48:32.779141 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:48:32.780876 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:48:32.782062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:48:32.782554 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:48:32.795625 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:48:32.797725 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:48:32.782875 => 23:48:32.797452
[0m23:48:32.798220 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:48:32.805474 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:48:32.806479 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:48:32.806871 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:48:32.807222 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:48:33.159240 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:48:33.161048 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:48:33.162947 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:48:43.044884 [debug] [Thread-1 (]: SQL status: SELECT 142013 in 10.0 seconds
[0m23:48:43.054403 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:48:43.055357 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:48:43.094885 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:48:43.102495 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:48:43.103362 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:48:43.143099 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:48:43.146676 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:48:43.147227 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:48:43.147682 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:48:43.187827 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:48:43.196443 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:48:43.197786 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:48:43.254832 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:48:43.260098 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:48:32.798547 => 23:48:43.259568
[0m23:48:43.260798 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:48:43.262331 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d3e24e9-dcc6-42d2-a1c8-437aa01e95fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064d5250>]}
[0m23:48:43.263657 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142013[0m in 10.48s]
[0m23:48:43.265789 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:48:43.269069 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:43.269558 [debug] [MainThread]: On master: BEGIN
[0m23:48:43.270015 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:48:43.665214 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:48:43.666524 [debug] [MainThread]: On master: COMMIT
[0m23:48:43.667093 [debug] [MainThread]: Using postgres connection "master"
[0m23:48:43.667526 [debug] [MainThread]: On master: COMMIT
[0m23:48:43.710296 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:48:43.711509 [debug] [MainThread]: On master: Close
[0m23:48:43.713946 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:48:43.714983 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m23:48:43.715837 [info ] [MainThread]: 
[0m23:48:43.716442 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 30.01 seconds (30.01s).
[0m23:48:43.718212 [debug] [MainThread]: Command end result
[0m23:48:43.734838 [info ] [MainThread]: 
[0m23:48:43.735806 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:48:43.736463 [info ] [MainThread]: 
[0m23:48:43.737042 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m23:48:43.737947 [debug] [MainThread]: Command `dbt run` succeeded at 23:48:43.737820 after 30.50 seconds
[0m23:48:43.738382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106084250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060882d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1011ea590>]}
[0m23:48:43.738791 [debug] [MainThread]: Flushing usage events
[0m01:02:13.257682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109695350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096ad650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096b7290>]}


============================== 01:02:13.259029 | 20d20d65-c4dc-4bab-ab17-26f136b4f228 ==============================
[0m01:02:13.259029 [info ] [MainThread]: Running with dbt=1.5.4
[0m01:02:13.259372 [debug] [MainThread]: running dbt with arguments {'warn_error': 'None', 'no_print': 'None', 'debug': 'False', 'indirect_selection': 'eager', 'fail_fast': 'False', 'introspect': 'True', 'target_path': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'profiles_dir': '/Users/danila/.dbt', 'version_check': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'printer_width': '80', 'quiet': 'False', 'write_json': 'True'}
[0m01:02:13.286570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096a0bd0>]}
[0m01:02:13.292659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096a0bd0>]}
[0m01:02:13.293145 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m01:02:13.302768 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m01:02:13.329287 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:02:13.329476 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:02:13.329692 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m01:02:13.332003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c4e9d0>]}
[0m01:02:13.335442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109adfc90>]}
[0m01:02:13.335605 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 422 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m01:02:13.335755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b70110>]}
[0m01:02:13.336429 [info ] [MainThread]: 
[0m01:02:13.336739 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:02:13.337192 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m01:02:13.341438 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m01:02:13.341594 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m01:02:13.341702 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:02:13.893819 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.0 seconds
[0m01:02:13.898991 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m01:02:13.901594 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m01:02:13.906845 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m01:02:13.907162 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m01:02:13.907359 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:02:14.270302 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:02:14.271736 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m01:02:14.272724 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m01:02:14.307951 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m01:02:14.313771 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m01:02:14.345064 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m01:02:14.356534 [debug] [MainThread]: Using postgres connection "master"
[0m01:02:14.356949 [debug] [MainThread]: On master: BEGIN
[0m01:02:14.357416 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:02:14.614455 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:02:14.616304 [debug] [MainThread]: Using postgres connection "master"
[0m01:02:14.617550 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:02:14.659500 [debug] [MainThread]: SQL status: SELECT 41 in 0.0 seconds
[0m01:02:14.663675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091fc650>]}
[0m01:02:14.664471 [debug] [MainThread]: On master: ROLLBACK
[0m01:02:14.694737 [debug] [MainThread]: Using postgres connection "master"
[0m01:02:14.695691 [debug] [MainThread]: On master: BEGIN
[0m01:02:14.756836 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:02:14.757840 [debug] [MainThread]: On master: COMMIT
[0m01:02:14.758710 [debug] [MainThread]: Using postgres connection "master"
[0m01:02:14.759486 [debug] [MainThread]: On master: COMMIT
[0m01:02:14.790302 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:02:14.790871 [debug] [MainThread]: On master: Close
[0m01:02:14.792415 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:02:14.793046 [info ] [MainThread]: 
[0m01:02:14.801375 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m01:02:14.802156 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m01:02:14.803146 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.outclick_by_brand_int)
[0m01:02:14.803565 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m01:02:14.827510 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:14.828325 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 01:02:14.803847 => 01:02:14.828161
[0m01:02:14.828606 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m01:02:14.850184 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:14.850640 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:14.850818 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m01:02:14.850986 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:02:15.130718 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:02:15.132523 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:15.134724 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m01:02:32.045363 [debug] [Thread-1 (]: SQL status: SELECT 497457 in 17.0 seconds
[0m01:02:32.059681 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:32.060536 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m01:02:32.100101 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:02:32.105550 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:32.106277 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m01:02:32.138268 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:02:32.159554 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m01:02:32.159894 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:32.160120 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m01:02:32.190752 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:02:32.194685 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m01:02:32.194974 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m01:02:32.265932 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m01:02:32.268835 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 01:02:14.828762 => 01:02:32.268488
[0m01:02:32.269580 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m01:02:32.271382 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109c35610>]}
[0m01:02:32.272525 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 497457[0m in 17.47s]
[0m01:02:32.273600 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m01:02:32.274184 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m01:02:32.274892 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m01:02:32.275830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m01:02:32.276263 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m01:02:32.287286 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m01:02:32.288287 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 01:02:32.276555 => 01:02:32.288068
[0m01:02:32.288632 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m01:02:32.292496 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m01:02:32.293107 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m01:02:32.293398 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m01:02:32.293641 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:02:32.878266 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m01:02:32.880120 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m01:02:32.882033 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m01:02:42.894171 [debug] [Thread-1 (]: SQL status: SELECT 142044 in 10.0 seconds
[0m01:02:42.900751 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m01:02:42.901337 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m01:02:43.129206 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:02:43.138908 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m01:02:43.139623 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m01:02:43.178510 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:02:43.182475 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m01:02:43.183159 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m01:02:43.183610 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m01:02:43.261470 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:02:43.267675 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m01:02:43.268272 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m01:02:43.363359 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m01:02:43.366151 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 01:02:32.288840 => 01:02:43.365896
[0m01:02:43.366631 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m01:02:43.367909 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '20d20d65-c4dc-4bab-ab17-26f136b4f228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d4a490>]}
[0m01:02:43.368733 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 142044[0m in 11.09s]
[0m01:02:43.369555 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m01:02:43.371659 [debug] [MainThread]: Using postgres connection "master"
[0m01:02:43.372057 [debug] [MainThread]: On master: BEGIN
[0m01:02:43.372385 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:02:44.838130 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m01:02:44.839687 [debug] [MainThread]: On master: COMMIT
[0m01:02:44.840611 [debug] [MainThread]: Using postgres connection "master"
[0m01:02:44.841383 [debug] [MainThread]: On master: COMMIT
[0m01:02:44.871566 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:02:44.872151 [debug] [MainThread]: On master: Close
[0m01:02:44.873459 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:02:44.873852 [debug] [MainThread]: Connection 'model.campaign_perfomance.outclick_cost_int' was properly closed.
[0m01:02:44.874365 [info ] [MainThread]: 
[0m01:02:44.874955 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 31.54 seconds (31.54s).
[0m01:02:44.876313 [debug] [MainThread]: Command end result
[0m01:02:44.888447 [info ] [MainThread]: 
[0m01:02:44.889150 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:02:44.889530 [info ] [MainThread]: 
[0m01:02:44.889964 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m01:02:44.890718 [debug] [MainThread]: Command `dbt run` succeeded at 01:02:44.890596 after 31.65 seconds
[0m01:02:44.891163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057dc290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057da510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057da5d0>]}
[0m01:02:44.891549 [debug] [MainThread]: Flushing usage events
[0m14:07:05.419217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b9a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11140bb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111ba3d10>]}


============================== 14:07:05.420799 | d76a0074-10fb-4fef-8551-0e7590938624 ==============================
[0m14:07:05.420799 [info ] [MainThread]: Running with dbt=1.5.4
[0m14:07:05.421108 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'target_path': 'None', 'indirect_selection': 'eager', 'log_format': 'default', 'quiet': 'False', 'version_check': 'True', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_cache_events': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'no_print': 'None', 'debug': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False'}
[0m14:07:05.431926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd76a0074-10fb-4fef-8551-0e7590938624', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bbba10>]}
[0m14:07:05.432639 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-xsf6rq2x'
[0m14:07:05.432856 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m14:07:05.549940 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m14:07:05.551203 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m14:07:05.580887 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m14:07:05.584419 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m14:07:05.693065 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m14:07:05.701491 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m14:07:06.202254 [info ] [MainThread]: Installed from version 1.1.1
[0m14:07:06.202507 [info ] [MainThread]: Up to date!
[0m14:07:06.202698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd76a0074-10fb-4fef-8551-0e7590938624', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bc6190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bfc450>]}
[0m14:07:06.202869 [info ] [MainThread]: Installing dbt-labs/codegen
[0m14:07:06.576610 [info ] [MainThread]: Installed from version 0.12.1
[0m14:07:06.577164 [info ] [MainThread]: Up to date!
[0m14:07:06.577513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd76a0074-10fb-4fef-8551-0e7590938624', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b8bbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bc6190>]}
[0m14:07:06.578554 [debug] [MainThread]: Command `dbt deps` succeeded at 14:07:06.578437 after 1.17 seconds
[0m14:07:06.578812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105484e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10547f090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10547f150>]}
[0m14:07:06.579026 [debug] [MainThread]: Flushing usage events
[0m14:08:56.715688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f1fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f326d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f32d90>]}


============================== 14:08:56.717171 | 0d3d7ac1-6efb-458e-a3c0-34d77671306b ==============================
[0m14:08:56.717171 [info ] [MainThread]: Running with dbt=1.5.4
[0m14:08:56.717392 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'write_json': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'warn_error': 'None', 'no_print': 'None', 'quiet': 'True', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False', 'static_parser': 'True', 'use_colors': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'introspect': 'True', 'cache_selected_only': 'False', 'partial_parse': 'True', 'log_format': 'default', 'fail_fast': 'False'}
[0m14:08:56.748834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0d3d7ac1-6efb-458e-a3c0-34d77671306b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104df4450>]}
[0m14:08:56.755147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0d3d7ac1-6efb-458e-a3c0-34d77671306b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053a8610>]}
[0m14:08:56.755570 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m14:08:56.767719 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m14:08:56.785488 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m14:08:56.785745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0d3d7ac1-6efb-458e-a3c0-34d77671306b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bd4d0>]}
[0m14:08:57.133573 [debug] [MainThread]: 1699: static parser successfully parsed staging/scraper/stg_scraper__records.sql
[0m14:08:57.138422 [debug] [MainThread]: 1699: static parser successfully parsed brand_performance/test.sql
[0m14:08:57.139456 [debug] [MainThread]: 1699: static parser successfully parsed brand_performance/clicks_to_clients_fct.sql
[0m14:08:57.140494 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m14:08:57.148448 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m14:08:57.148983 [debug] [MainThread]: 1699: static parser successfully parsed brand_performance/deals_dimension.sql
[0m14:08:57.150390 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m14:08:57.153703 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m14:08:57.190964 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m14:08:57.192855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0d3d7ac1-6efb-458e-a3c0-34d77671306b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054f4a50>]}
[0m14:08:57.196564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0d3d7ac1-6efb-458e-a3c0-34d77671306b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055604d0>]}
[0m14:08:57.196756 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m14:08:57.196870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d3d7ac1-6efb-458e-a3c0-34d77671306b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105427050>]}
[0m14:08:57.197148 [debug] [MainThread]: Acquiring new postgres connection 'macro_generate_model_yaml'
[0m14:08:57.197269 [debug] [MainThread]: Using postgres connection "macro_generate_model_yaml"
[0m14:08:57.197369 [debug] [MainThread]: On macro_generate_model_yaml: BEGIN
[0m14:08:57.197467 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:08:57.766178 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m14:08:57.767905 [debug] [MainThread]: On macro_generate_model_yaml: COMMIT
[0m14:08:57.768919 [debug] [MainThread]: Using postgres connection "macro_generate_model_yaml"
[0m14:08:57.769794 [debug] [MainThread]: On macro_generate_model_yaml: COMMIT
[0m14:08:57.821898 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:08:57.824046 [debug] [MainThread]: Postgres adapter: Error running SQL: macro generate_model_yaml
[0m14:08:57.824236 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m14:08:57.824409 [debug] [MainThread]: On macro_generate_model_yaml: Close
[0m14:08:57.824891 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  macro 'dbt_macro__generate_model_yaml' takes no keyword argument 'model_name'
[0m14:08:57.828494 [debug] [MainThread]: Traceback (most recent call last):
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 302, in exception_handler
    yield
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/jinja2/runtime.py", line 752, in __call__
    raise TypeError(
TypeError: macro 'dbt_macro__generate_model_yaml' takes no keyword argument 'model_name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/task/run_operation.py", line 47, in run
    self._run_unsafe()
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/task/run_operation.py", line 37, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/adapters/base/impl.py", line 1043, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 255, in call_macro
    with self.exception_handler():
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 304, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt.exceptions.CaughtMacroErrorWithNodeError: Compilation Error
  macro 'dbt_macro__generate_model_yaml' takes no keyword argument 'model_name'

[0m14:08:57.828832 [debug] [MainThread]: Command `dbt run-operation` failed at 14:08:57.828771 after 1.12 seconds
[0m14:08:57.828972 [debug] [MainThread]: Connection 'macro_generate_model_yaml' was properly closed.
[0m14:08:57.829121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104de3e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105410910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b1e890>]}
[0m14:08:57.829294 [debug] [MainThread]: Flushing usage events
[0m14:14:39.935350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106799ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a33d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a3a50>]}


============================== 14:14:39.936888 | e2c4b37e-7438-4214-ad5e-e3aec197d7d3 ==============================
[0m14:14:39.936888 [info ] [MainThread]: Running with dbt=1.5.4
[0m14:14:39.937198 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'version_check': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs', 'partial_parse': 'True', 'log_cache_events': 'False', 'log_format': 'default', 'write_json': 'True', 'quiet': 'False', 'target_path': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'profiles_dir': '/Users/danila/.dbt', 'warn_error': 'None', 'fail_fast': 'False', 'printer_width': '80'}
[0m14:14:39.967813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e2c4b37e-7438-4214-ad5e-e3aec197d7d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106256910>]}
[0m14:14:39.974157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e2c4b37e-7438-4214-ad5e-e3aec197d7d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10679c2d0>]}
[0m14:14:39.974651 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m14:14:39.988146 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m14:14:40.012193 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading campaign_perfomance: staging/scraper/stg_scraper__records_2.yml - Runtime Error
    unacceptable character #x001b: control characters are not allowed
      in "<unicode string>", position 0
[0m14:14:40.012585 [debug] [MainThread]: Command `dbt run-operation` failed at 14:14:40.012526 after 0.09 seconds
[0m14:14:40.012745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10679dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a3790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bf4190>]}
[0m14:14:40.012906 [debug] [MainThread]: Flushing usage events
[0m14:15:01.888164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107104a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10710b650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10710bd10>]}


============================== 14:15:01.889403 | 0ad68029-8718-4592-829f-78654e45c54d ==============================
[0m14:15:01.889403 [info ] [MainThread]: Running with dbt=1.5.4
[0m14:15:01.889752 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_colors': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'static_parser': 'True', 'warn_error': 'None', 'indirect_selection': 'eager', 'no_print': 'None', 'introspect': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'log_format': 'default', 'write_json': 'True', 'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'target_path': 'None', 'version_check': 'True', 'quiet': 'False', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'fail_fast': 'False'}
[0m14:15:01.917382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0ad68029-8718-4592-829f-78654e45c54d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107146750>]}
[0m14:15:01.923575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0ad68029-8718-4592-829f-78654e45c54d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106bedb10>]}
[0m14:15:01.923833 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m14:15:01.936355 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m14:15:01.973733 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m14:15:01.976306 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.brand_performance
- models.users
[0m14:15:01.978964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0ad68029-8718-4592-829f-78654e45c54d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10757de50>]}
[0m14:15:01.982861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0ad68029-8718-4592-829f-78654e45c54d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075be610>]}
[0m14:15:01.983076 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 7 sources, 0 exposures, 0 metrics, 0 groups
[0m14:15:01.983249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0ad68029-8718-4592-829f-78654e45c54d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107104a90>]}
[0m14:15:01.983555 [debug] [MainThread]: Acquiring new postgres connection 'macro_generate_source'
[0m14:15:01.983678 [debug] [MainThread]: Using postgres connection "macro_generate_source"
[0m14:15:01.983776 [debug] [MainThread]: On macro_generate_source: BEGIN
[0m14:15:01.983861 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:15:02.467316 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:15:02.469235 [debug] [MainThread]: On macro_generate_source: COMMIT
[0m14:15:02.470212 [debug] [MainThread]: Using postgres connection "macro_generate_source"
[0m14:15:02.471114 [debug] [MainThread]: On macro_generate_source: COMMIT
[0m14:15:02.518159 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:15:02.529836 [debug] [MainThread]: Postgres adapter: Error running SQL: macro generate_source
[0m14:15:02.530334 [debug] [MainThread]: Postgres adapter: Rolling back transaction.
[0m14:15:02.530651 [debug] [MainThread]: On macro_generate_source: Close
[0m14:15:02.531425 [error] [MainThread]: Encountered an error while running operation: Compilation Error
  macro 'dbt_macro__generate_source' takes no keyword argument 'table_name'
[0m14:15:02.536186 [debug] [MainThread]: Traceback (most recent call last):
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 302, in exception_handler
    yield
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 257, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/jinja2/runtime.py", line 752, in __call__
    raise TypeError(
TypeError: macro 'dbt_macro__generate_source' takes no keyword argument 'table_name'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/task/run_operation.py", line 47, in run
    self._run_unsafe()
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/task/run_operation.py", line 37, in _run_unsafe
    res = adapter.execute_macro(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/adapters/base/impl.py", line 1043, in execute_macro
    result = macro_function(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 330, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 255, in call_macro
    with self.exception_handler():
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/opt/anaconda3/envs/dbt_env2/lib/python3.11/site-packages/dbt/clients/jinja.py", line 304, in exception_handler
    raise CaughtMacroErrorWithNodeError(exc=e, node=self.macro)
dbt.exceptions.CaughtMacroErrorWithNodeError: Compilation Error
  macro 'dbt_macro__generate_source' takes no keyword argument 'table_name'

[0m14:15:02.536814 [debug] [MainThread]: Command `dbt run-operation` failed at 14:15:02.536714 after 0.66 seconds
[0m14:15:02.537063 [debug] [MainThread]: Connection 'macro_generate_source' was properly closed.
[0m14:15:02.537330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103135d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a70590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fbffd0>]}
[0m14:15:02.537628 [debug] [MainThread]: Flushing usage events
[0m15:38:00.471768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f967d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a89950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa7d50>]}


============================== 15:38:00.473269 | a5b0ac84-897f-4f3e-9eca-c321467ff44a ==============================
[0m15:38:00.473269 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:38:00.473575 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'no_print': 'None', 'version_check': 'True', 'warn_error': 'None', 'quiet': 'False', 'target_path': 'None', 'log_format': 'default', 'fail_fast': 'False', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'debug': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'write_json': 'True', 'introspect': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'indirect_selection': 'eager'}
[0m15:38:00.504922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b4a290>]}
[0m15:38:00.511084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fb7dd0>]}
[0m15:38:00.511508 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:38:00.525189 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:38:00.566338 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:38:00.566550 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:38:00.566846 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.brand_performance
- models.users
- models.staging/scraper
[0m15:38:00.569306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105548410>]}
[0m15:38:00.574364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10546fe90>]}
[0m15:38:00.574554 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:38:00.574715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10246a710>]}
[0m15:38:00.575493 [info ] [MainThread]: 
[0m15:38:00.575815 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:38:00.576286 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:38:00.580474 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:38:00.580702 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:38:00.580836 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:38:01.133057 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m15:38:01.137983 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:38:01.141553 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:38:01.149870 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:38:01.150439 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:38:01.150755 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:01.645452 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:38:01.647088 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:38:01.648213 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:38:01.700675 [debug] [ThreadPool]: SQL status: SELECT 19 in 0.0 seconds
[0m15:38:01.702441 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:38:01.751808 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:38:01.758001 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:01.758236 [debug] [MainThread]: On master: BEGIN
[0m15:38:01.758416 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:38:02.140018 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:38:02.141600 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:02.142399 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:38:02.196671 [debug] [MainThread]: SQL status: SELECT 46 in 0.0 seconds
[0m15:38:02.201877 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa2310>]}
[0m15:38:02.202782 [debug] [MainThread]: On master: ROLLBACK
[0m15:38:02.248730 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:02.249815 [debug] [MainThread]: On master: BEGIN
[0m15:38:02.342167 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:38:02.343200 [debug] [MainThread]: On master: COMMIT
[0m15:38:02.343828 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:02.344354 [debug] [MainThread]: On master: COMMIT
[0m15:38:02.390198 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:38:02.391261 [debug] [MainThread]: On master: Close
[0m15:38:02.394041 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:38:02.394748 [info ] [MainThread]: 
[0m15:38:02.404159 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:38:02.404842 [info ] [Thread-1 (]: 1 of 6 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m15:38:02.405711 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m15:38:02.406085 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m15:38:02.412370 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:38:02.413306 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 15:38:02.406321 => 15:38:02.413102
[0m15:38:02.413635 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m15:38:02.437679 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:38:02.438208 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:38:02.438383 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m15:38:02.438555 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:02.864943 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:02.866859 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:38:02.868060 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m15:38:02.925092 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:38:02.940337 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:38:02.940980 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m15:38:02.993448 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:03.015215 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:38:03.015634 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:38:03.015947 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:38:03.068137 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:38:03.077535 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:38:03.078100 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m15:38:03.155996 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:38:03.160433 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 15:38:02.413840 => 15:38:03.159812
[0m15:38:03.161629 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m15:38:03.163363 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105645d10>]}
[0m15:38:03.164190 [info ] [Thread-1 (]: 1 of 6 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.76s]
[0m15:38:03.165216 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:38:03.165693 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m15:38:03.166295 [info ] [Thread-1 (]: 2 of 6 START sql view model danila.deals_dimension ............................. [RUN]
[0m15:38:03.167098 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m15:38:03.167466 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m15:38:03.169255 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m15:38:03.170120 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 15:38:03.167701 => 15:38:03.169924
[0m15:38:03.170445 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m15:38:03.174183 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m15:38:03.174833 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:38:03.175090 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m15:38:03.175332 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:03.579211 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:03.580437 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:38:03.581736 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group
        , gap_campaign_name as google_ads_campaign_id
        -- , traffic_types as betting_type
        -- , traffic_sources
    from deals
)

select * from main
where id=2085
-- select betting_type, traffic_sources, count(id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m15:38:03.635449 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:38:03.641626 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:38:03.642143 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m15:38:03.691468 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:03.693947 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:38:03.694430 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:38:03.694851 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:38:03.744040 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:38:03.748492 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:38:03.749117 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m15:38:03.798698 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:38:03.801483 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 15:38:03.170643 => 15:38:03.801158
[0m15:38:03.802168 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m15:38:03.803819 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1054cbf50>]}
[0m15:38:03.804824 [info ] [Thread-1 (]: 2 of 6 OK created sql view model danila.deals_dimension ........................ [[32mCREATE VIEW[0m in 0.64s]
[0m15:38:03.805883 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m15:38:03.806600 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m15:38:03.807433 [info ] [Thread-1 (]: 3 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m15:38:03.808419 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m15:38:03.808898 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m15:38:03.828975 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:03.831072 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 15:38:03.809235 => 15:38:03.830881
[0m15:38:03.831369 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m15:38:03.845449 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:03.846332 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:03.846543 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m15:38:03.846738 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:04.229590 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:04.231246 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:04.233016 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:38:19.735097 [debug] [Thread-1 (]: SQL status: SELECT 508856 in 16.0 seconds
[0m15:38:19.741373 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:19.742792 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m15:38:19.790559 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:19.798635 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:19.799109 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m15:38:19.844876 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:19.865556 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:38:19.866467 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:19.866982 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:38:19.913494 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:38:19.919601 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:38:19.920813 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m15:38:19.994421 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:38:19.999860 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 15:38:03.831538 => 15:38:19.999263
[0m15:38:20.000279 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m15:38:20.001310 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105693650>]}
[0m15:38:20.002724 [info ] [Thread-1 (]: 3 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 508856[0m in 16.19s]
[0m15:38:20.003404 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m15:38:20.003884 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m15:38:20.004466 [info ] [Thread-1 (]: 4 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m15:38:20.005494 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m15:38:20.006071 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m15:38:20.016853 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m15:38:20.019499 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 15:38:20.006616 => 15:38:20.019101
[0m15:38:20.020007 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m15:38:20.025496 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m15:38:20.026586 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:38:20.027229 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m15:38:20.027845 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:20.523417 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:20.524937 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:38:20.526767 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:38:28.948820 [debug] [Thread-1 (]: SQL status: SELECT 145589 in 8.0 seconds
[0m15:38:28.957765 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:38:28.958959 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:38:29.013470 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:29.017486 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:38:29.018085 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:38:29.072190 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:29.078824 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:38:29.080056 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:38:29.081002 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:38:29.135488 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:38:29.139850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:38:29.141245 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:38:29.221631 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:38:29.224088 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 15:38:20.020257 => 15:38:29.223869
[0m15:38:29.224606 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m15:38:29.225715 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10540bc50>]}
[0m15:38:29.226501 [info ] [Thread-1 (]: 4 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 145589[0m in 9.22s]
[0m15:38:29.227103 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m15:38:29.227532 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:38:29.228578 [info ] [Thread-1 (]: 5 of 6 START sql view model danila.stg_scraper__records ........................ [RUN]
[0m15:38:29.229688 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m15:38:29.230016 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:38:29.235913 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:38:29.237400 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:38:29.230202 => 15:38:29.237055
[0m15:38:29.237825 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:38:29.243063 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:38:29.244529 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:38:29.245195 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:38:29.245732 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:29.695764 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:29.697508 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:38:29.699428 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  create view "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
[0m15:38:29.760283 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:38:29.767128 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:38:29.767856 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:38:29.820882 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:29.823998 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:38:29.824612 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:38:29.825039 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:38:29.878125 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:38:29.886121 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:38:29.887446 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop view if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:38:29.941953 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:38:29.946984 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:38:29.238093 => 15:38:29.946374
[0m15:38:29.948144 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:38:29.950995 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056ac790>]}
[0m15:38:29.952951 [info ] [Thread-1 (]: 5 of 6 OK created sql view model danila.stg_scraper__records ................... [[32mCREATE VIEW[0m in 0.72s]
[0m15:38:29.954846 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:38:29.956258 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:38:29.957077 [info ] [Thread-1 (]: 6 of 6 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:38:29.959059 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m15:38:29.959884 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:38:29.968858 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:38:29.970784 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:38:29.960331 => 15:38:29.970415
[0m15:38:29.971435 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:38:29.977998 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:38:29.979809 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:38:29.980332 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:38:29.980722 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:30.396631 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:30.398167 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:38:30.399421 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        id--grain_id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        and deposited_first_time > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
)
  );
[0m15:38:30.448385 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near ")"
LINE 43:   );
           ^

[0m15:38:30.449740 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: ROLLBACK
[0m15:38:30.497842 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:38:29.971847 => 15:38:30.496784
[0m15:38:30.499363 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:38:30.513723 [debug] [Thread-1 (]: Database Error in model first_deposits_fct (models/marts/first_deposits_fct.sql)
  syntax error at or near ")"
  LINE 43:   );
             ^
  compiled Code at target/run/campaign_perfomance/models/marts/first_deposits_fct.sql
[0m15:38:30.514756 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5b0ac84-897f-4f3e-9eca-c321467ff44a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056e92d0>]}
[0m15:38:30.515598 [error] [Thread-1 (]: 6 of 6 ERROR creating sql view model danila.first_deposits_fct ................. [[31mERROR[0m in 0.56s]
[0m15:38:30.516339 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:38:30.518296 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:30.518737 [debug] [MainThread]: On master: BEGIN
[0m15:38:30.518988 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:38:30.897824 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:38:30.899087 [debug] [MainThread]: On master: COMMIT
[0m15:38:30.899435 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:30.899694 [debug] [MainThread]: On master: COMMIT
[0m15:38:30.946153 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:38:30.947177 [debug] [MainThread]: On master: Close
[0m15:38:30.948593 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:38:30.949618 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:38:30.950585 [info ] [MainThread]: 
[0m15:38:30.951670 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 30.37 seconds (30.37s).
[0m15:38:30.953747 [debug] [MainThread]: Command end result
[0m15:38:30.972160 [info ] [MainThread]: 
[0m15:38:30.973461 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:38:30.974103 [info ] [MainThread]: 
[0m15:38:30.974612 [error] [MainThread]: [33mDatabase Error in model first_deposits_fct (models/marts/first_deposits_fct.sql)[0m
[0m15:38:30.975203 [error] [MainThread]:   syntax error at or near ")"
[0m15:38:30.975578 [error] [MainThread]:   LINE 43:   );
[0m15:38:30.975855 [error] [MainThread]:              ^
[0m15:38:30.976142 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/marts/first_deposits_fct.sql
[0m15:38:30.976478 [info ] [MainThread]: 
[0m15:38:30.976856 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m15:38:30.978008 [debug] [MainThread]: Command `dbt run` failed at 15:38:30.977777 after 30.52 seconds
[0m15:38:30.978579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100fcb150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100fcb090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fb7610>]}
[0m15:38:30.979040 [debug] [MainThread]: Flushing usage events
[0m15:39:09.659503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108804c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10881af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10881b5d0>]}


============================== 15:39:09.660767 | dab7199d-e13a-46c6-ac56-216f389a8475 ==============================
[0m15:39:09.660767 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:39:09.661096 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'introspect': 'True', 'indirect_selection': 'eager', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'partial_parse': 'True', 'debug': 'False', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'write_json': 'True', 'printer_width': '80', 'quiet': 'False', 'fail_fast': 'False', 'warn_error': 'None', 'log_format': 'default', 'cache_selected_only': 'False', 'static_parser': 'True', 'profiles_dir': '/Users/danila/.dbt'}
[0m15:39:09.689822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108804dd0>]}
[0m15:39:09.696431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10834a710>]}
[0m15:39:09.696724 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:39:09.709521 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:39:09.739676 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:39:09.739874 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:39:09.740168 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.users
- models.brand_performance
- models.staging/scraper
[0m15:39:09.742702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087a9190>]}
[0m15:39:09.746897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c892d0>]}
[0m15:39:09.747075 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:39:09.747237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105cda710>]}
[0m15:39:09.747954 [info ] [MainThread]: 
[0m15:39:09.748261 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:39:09.748740 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:39:09.752820 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:39:09.752974 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:39:09.753081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:39:10.172938 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:39:10.176490 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:39:10.180385 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:39:10.188879 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:39:10.189409 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:39:10.189668 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:39:10.571102 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:39:10.573025 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:39:10.574264 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:39:10.674597 [debug] [ThreadPool]: SQL status: SELECT 22 in 0.0 seconds
[0m15:39:10.679138 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:39:10.751367 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:39:10.766718 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:10.767204 [debug] [MainThread]: On master: BEGIN
[0m15:39:10.767443 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:39:11.149194 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:39:11.151152 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:11.152158 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:39:11.206023 [debug] [MainThread]: SQL status: SELECT 49 in 0.0 seconds
[0m15:39:11.210716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10881a010>]}
[0m15:39:11.211817 [debug] [MainThread]: On master: ROLLBACK
[0m15:39:11.258394 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:11.259323 [debug] [MainThread]: On master: BEGIN
[0m15:39:11.369159 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:39:11.370596 [debug] [MainThread]: On master: COMMIT
[0m15:39:11.371060 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:11.371354 [debug] [MainThread]: On master: COMMIT
[0m15:39:11.417628 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:39:11.419216 [debug] [MainThread]: On master: Close
[0m15:39:11.421670 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:39:11.422503 [info ] [MainThread]: 
[0m15:39:11.429575 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:39:11.430608 [info ] [Thread-1 (]: 1 of 6 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m15:39:11.431759 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m15:39:11.432326 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m15:39:11.439558 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:11.440633 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 15:39:11.432580 => 15:39:11.440405
[0m15:39:11.441008 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m15:39:11.466863 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:11.467413 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:11.467609 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m15:39:11.467793 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:11.865156 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:39:11.866477 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:11.867403 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m15:39:11.919876 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:39:11.933462 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:11.934345 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m15:39:11.984231 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:11.991224 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:11.991906 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m15:39:12.041141 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:12.063453 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:39:12.063948 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:12.064271 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:39:12.113274 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:39:12.120601 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:39:12.121005 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m15:39:12.171025 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:39:12.174410 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 15:39:11.441216 => 15:39:12.174078
[0m15:39:12.175161 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m15:39:12.176759 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d33650>]}
[0m15:39:12.177888 [info ] [Thread-1 (]: 1 of 6 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.75s]
[0m15:39:12.178896 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:39:12.179468 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m15:39:12.180118 [info ] [Thread-1 (]: 2 of 6 START sql view model danila.deals_dimension ............................. [RUN]
[0m15:39:12.180967 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m15:39:12.181362 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m15:39:12.184398 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m15:39:12.185549 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 15:39:12.181620 => 15:39:12.185365
[0m15:39:12.185957 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m15:39:12.190646 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m15:39:12.191483 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:39:12.191832 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m15:39:12.192130 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:12.574767 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:39:12.576351 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:39:12.577564 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group
        , gap_campaign_name as google_ads_campaign_id
        -- , traffic_types as betting_type
        -- , traffic_sources
    from deals
)

select * from main
where id=2085
-- select betting_type, traffic_sources, count(id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m15:39:12.628231 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:39:12.635718 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:39:12.636393 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m15:39:12.683629 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:12.691141 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:39:12.691908 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m15:39:12.738609 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:12.741028 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:39:12.741487 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:39:12.741847 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:39:12.788701 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:39:12.795344 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:39:12.796214 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m15:39:12.844347 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:39:12.847995 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 15:39:12.186203 => 15:39:12.847651
[0m15:39:12.848648 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m15:39:12.849939 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cd1ad0>]}
[0m15:39:12.850854 [info ] [Thread-1 (]: 2 of 6 OK created sql view model danila.deals_dimension ........................ [[32mCREATE VIEW[0m in 0.67s]
[0m15:39:12.851781 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m15:39:12.852329 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m15:39:12.852959 [info ] [Thread-1 (]: 3 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m15:39:12.854006 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m15:39:12.854478 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m15:39:12.876572 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:12.877470 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 15:39:12.854941 => 15:39:12.877291
[0m15:39:12.877783 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m15:39:12.893290 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:12.893844 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:12.894041 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m15:39:12.894220 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:13.278130 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:39:13.279576 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:13.280744 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:39:28.753943 [debug] [Thread-1 (]: SQL status: SELECT 508856 in 15.0 seconds
[0m15:39:28.761622 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:28.762383 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m15:39:28.809679 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:28.817179 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:28.817883 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m15:39:28.864983 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:28.873241 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:39:28.873749 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:28.874035 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:39:28.920536 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:39:28.926815 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:39:28.927705 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m15:39:29.007682 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:39:29.009383 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 15:39:12.877960 => 15:39:29.009192
[0m15:39:29.009988 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m15:39:29.011115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108df8290>]}
[0m15:39:29.011913 [info ] [Thread-1 (]: 3 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 508856[0m in 16.16s]
[0m15:39:29.012879 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m15:39:29.013546 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m15:39:29.014384 [info ] [Thread-1 (]: 4 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m15:39:29.015530 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m15:39:29.016095 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m15:39:29.028970 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m15:39:29.030113 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 15:39:29.016448 => 15:39:29.029901
[0m15:39:29.030480 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m15:39:29.034320 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m15:39:29.035085 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:39:29.035385 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m15:39:29.035661 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:29.504289 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:39:29.505146 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:39:29.505752 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:39:38.174727 [debug] [Thread-1 (]: SQL status: SELECT 145589 in 9.0 seconds
[0m15:39:38.181039 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:39:38.181524 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:39:38.228230 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:38.233765 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:39:38.234636 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:39:38.281465 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:38.283752 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:39:38.284201 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:39:38.284558 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:39:38.331392 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:39:38.335697 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:39:38.336219 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:39:38.409325 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:39:38.412320 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 15:39:29.030688 => 15:39:38.412081
[0m15:39:38.412962 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m15:39:38.414594 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108829450>]}
[0m15:39:38.415606 [info ] [Thread-1 (]: 4 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 145589[0m in 9.40s]
[0m15:39:38.416584 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m15:39:38.417247 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:39:38.418041 [info ] [Thread-1 (]: 5 of 6 START sql view model danila.stg_scraper__records ........................ [RUN]
[0m15:39:38.419251 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m15:39:38.419840 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:39:38.424823 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:39:38.425901 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:39:38.420130 => 15:39:38.425682
[0m15:39:38.426249 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:39:38.431020 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:39:38.432017 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:39:38.432347 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:39:38.432646 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:38.931848 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:39:38.933236 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:39:38.934457 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  create view "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
[0m15:39:39.002536 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:39:39.010294 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:39:39.010858 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:39:39.071754 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:39.078064 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:39:39.078782 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:39:39.139983 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:39:39.144439 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:39:39.145246 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:39:39.145775 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:39:39.207310 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:39:39.213850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:39:39.214492 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop view if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:39:39.277344 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:39:39.280893 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:39:38.426617 => 15:39:39.280624
[0m15:39:39.281480 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:39:39.282692 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108eebc10>]}
[0m15:39:39.283476 [info ] [Thread-1 (]: 5 of 6 OK created sql view model danila.stg_scraper__records ................... [[32mCREATE VIEW[0m in 0.86s]
[0m15:39:39.284206 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:39:39.285363 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:39:39.285899 [info ] [Thread-1 (]: 6 of 6 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:39:39.286779 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m15:39:39.287166 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:39:39.291047 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:39:39.291952 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:39:39.287421 => 15:39:39.291723
[0m15:39:39.292329 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:39:39.296150 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:39:39.296795 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:39:39.297089 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:39:39.297371 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:39:39.723067 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:39:39.724090 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:39:39.724986 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        id--grain_id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        and deposited_first_time > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
)


select * from transformed
  );
[0m15:39:39.779837 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "date_parsed" does not exist
LINE 19:         , date_parsed as date_cet
                   ^

[0m15:39:39.780843 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: ROLLBACK
[0m15:39:39.834392 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:39:39.292563 => 15:39:39.833966
[0m15:39:39.835216 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:39:39.842652 [debug] [Thread-1 (]: Database Error in model first_deposits_fct (models/marts/first_deposits_fct.sql)
  column "date_parsed" does not exist
  LINE 19:         , date_parsed as date_cet
                     ^
  compiled Code at target/run/campaign_perfomance/models/marts/first_deposits_fct.sql
[0m15:39:39.843611 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dab7199d-e13a-46c6-ac56-216f389a8475', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f6fc90>]}
[0m15:39:39.844415 [error] [Thread-1 (]: 6 of 6 ERROR creating sql view model danila.first_deposits_fct ................. [[31mERROR[0m in 0.56s]
[0m15:39:39.845188 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:39:39.847308 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:39.847748 [debug] [MainThread]: On master: BEGIN
[0m15:39:39.848101 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:39:40.276988 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:39:40.278544 [debug] [MainThread]: On master: COMMIT
[0m15:39:40.279285 [debug] [MainThread]: Using postgres connection "master"
[0m15:39:40.279631 [debug] [MainThread]: On master: COMMIT
[0m15:39:40.332075 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:39:40.332718 [debug] [MainThread]: On master: Close
[0m15:39:40.333844 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:39:40.334148 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:39:40.335052 [info ] [MainThread]: 
[0m15:39:40.335781 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 30.59 seconds (30.59s).
[0m15:39:40.337621 [debug] [MainThread]: Command end result
[0m15:39:40.348169 [info ] [MainThread]: 
[0m15:39:40.348781 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:39:40.349271 [info ] [MainThread]: 
[0m15:39:40.349996 [error] [MainThread]: [33mDatabase Error in model first_deposits_fct (models/marts/first_deposits_fct.sql)[0m
[0m15:39:40.350407 [error] [MainThread]:   column "date_parsed" does not exist
[0m15:39:40.350781 [error] [MainThread]:   LINE 19:         , date_parsed as date_cet
[0m15:39:40.351116 [error] [MainThread]:                      ^
[0m15:39:40.351435 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/marts/first_deposits_fct.sql
[0m15:39:40.351785 [info ] [MainThread]: 
[0m15:39:40.352187 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m15:39:40.352864 [debug] [MainThread]: Command `dbt run` failed at 15:39:40.352745 after 30.70 seconds
[0m15:39:40.353258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047ba090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047ba2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108828350>]}
[0m15:39:40.353639 [debug] [MainThread]: Flushing usage events
[0m22:54:18.329825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599a010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10548d950>]}


============================== 22:54:18.331418 | f4863de9-f574-4713-9d04-c249f1eb8576 ==============================
[0m22:54:18.331418 [info ] [MainThread]: Running with dbt=1.5.4
[0m22:54:18.331717 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'introspect': 'True', 'warn_error': 'None', 'version_check': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'write_json': 'True', 'printer_width': '80', 'partial_parse': 'True', 'quiet': 'False', 'static_parser': 'True'}
[0m22:54:18.362065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059cd690>]}
[0m22:54:18.368556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059cd690>]}
[0m22:54:18.369040 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m22:54:18.382847 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m22:54:18.420344 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:54:18.420529 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:54:18.420810 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 3 unused configuration paths:
- models.users
- models.brand_performance
- models.staging/scraper
[0m22:54:18.423241 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e70650>]}
[0m22:54:18.427581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9e7d0>]}
[0m22:54:18.427801 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m22:54:18.427966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1028ea750>]}
[0m22:54:18.428809 [info ] [MainThread]: 
[0m22:54:18.429176 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:54:18.429641 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m22:54:18.433614 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m22:54:18.433774 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m22:54:18.433890 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:54:18.948107 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m22:54:18.952601 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m22:54:18.956796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m22:54:18.964854 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:54:18.965627 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m22:54:18.966002 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:54:19.410471 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m22:54:19.412340 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m22:54:19.413049 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m22:54:19.463332 [debug] [ThreadPool]: SQL status: SELECT 22 in 0.0 seconds
[0m22:54:19.467935 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m22:54:19.515069 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m22:54:19.528745 [debug] [MainThread]: Using postgres connection "master"
[0m22:54:19.529160 [debug] [MainThread]: On master: BEGIN
[0m22:54:19.529498 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:54:19.980934 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:54:19.981456 [debug] [MainThread]: Using postgres connection "master"
[0m22:54:19.981753 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:54:20.043743 [debug] [MainThread]: SQL status: SELECT 49 in 0.0 seconds
[0m22:54:20.045171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e9e7d0>]}
[0m22:54:20.045503 [debug] [MainThread]: On master: ROLLBACK
[0m22:54:20.101993 [debug] [MainThread]: Using postgres connection "master"
[0m22:54:20.102238 [debug] [MainThread]: On master: BEGIN
[0m22:54:20.212207 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:54:20.213644 [debug] [MainThread]: On master: COMMIT
[0m22:54:20.214374 [debug] [MainThread]: Using postgres connection "master"
[0m22:54:20.214863 [debug] [MainThread]: On master: COMMIT
[0m22:54:20.269991 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:54:20.270897 [debug] [MainThread]: On master: Close
[0m22:54:20.273263 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m22:54:20.273992 [info ] [MainThread]: 
[0m22:54:20.283937 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m22:54:20.284724 [info ] [Thread-1 (]: 1 of 6 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m22:54:20.285678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m22:54:20.286144 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m22:54:20.293381 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.294625 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 22:54:20.286447 => 22:54:20.294391
[0m22:54:20.294968 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m22:54:20.319514 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.320067 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.320261 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m22:54:20.320440 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:54:20.706893 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:54:20.708533 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.709274 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m22:54:20.759948 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:54:20.775116 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.775821 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m22:54:20.824313 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:20.830624 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.831334 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m22:54:20.878608 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:20.899639 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m22:54:20.900069 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.900380 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m22:54:20.946779 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:54:20.955074 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m22:54:20.955502 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m22:54:21.003378 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:54:21.006515 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 22:54:20.295147 => 22:54:21.006141
[0m22:54:21.007264 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m22:54:21.009186 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e88110>]}
[0m22:54:21.010375 [info ] [Thread-1 (]: 1 of 6 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.72s]
[0m22:54:21.011557 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m22:54:21.012204 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m22:54:21.012986 [info ] [Thread-1 (]: 2 of 6 START sql view model danila.deals_dimension ............................. [RUN]
[0m22:54:21.013939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m22:54:21.014399 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m22:54:21.017075 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m22:54:21.018459 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 22:54:21.014703 => 22:54:21.018267
[0m22:54:21.018876 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m22:54:21.023427 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m22:54:21.024412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m22:54:21.024734 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m22:54:21.025032 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:54:21.502473 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:54:21.504395 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m22:54:21.505753 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group
        , gap_campaign_name as google_ads_campaign_id
        -- , traffic_types as betting_type
        -- , traffic_sources
    from deals
)

select * from main
where id=2085
-- select betting_type, traffic_sources, count(id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m22:54:21.568008 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:54:21.575590 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m22:54:21.576113 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m22:54:21.634964 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:21.640907 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m22:54:21.641542 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m22:54:21.699883 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:21.703757 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m22:54:21.704444 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m22:54:21.705010 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m22:54:21.763467 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:54:21.767815 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m22:54:21.768321 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m22:54:21.828032 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:54:21.832075 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 22:54:21.019137 => 22:54:21.831735
[0m22:54:21.832744 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m22:54:21.834363 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f96390>]}
[0m22:54:21.835256 [info ] [Thread-1 (]: 2 of 6 OK created sql view model danila.deals_dimension ........................ [[32mCREATE VIEW[0m in 0.82s]
[0m22:54:21.836105 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m22:54:21.836640 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m22:54:21.837251 [info ] [Thread-1 (]: 3 of 6 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m22:54:21.838053 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m22:54:21.838413 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m22:54:21.858125 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:21.860715 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 22:54:21.838657 => 22:54:21.860534
[0m22:54:21.860992 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m22:54:21.876289 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:21.877075 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:21.877285 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m22:54:21.877464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:54:22.355038 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:54:22.356965 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:22.358596 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m22:54:37.981167 [debug] [Thread-1 (]: SQL status: SELECT 509382 in 16.0 seconds
[0m22:54:37.988516 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:37.989222 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m22:54:38.048217 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:38.054425 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:38.055071 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m22:54:38.113259 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:38.123887 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:54:38.124408 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:38.124838 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m22:54:38.182831 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:54:38.188390 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m22:54:38.189069 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m22:54:38.280401 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:54:38.283129 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 22:54:21.861150 => 22:54:38.282785
[0m22:54:38.283973 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m22:54:38.285473 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106919790>]}
[0m22:54:38.286281 [info ] [Thread-1 (]: 3 of 6 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 509382[0m in 16.45s]
[0m22:54:38.287065 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m22:54:38.287581 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m22:54:38.288205 [info ] [Thread-1 (]: 4 of 6 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m22:54:38.289090 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m22:54:38.289500 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m22:54:38.299958 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m22:54:38.302417 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 22:54:38.290044 => 22:54:38.302232
[0m22:54:38.302710 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m22:54:38.305885 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m22:54:38.306426 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:54:38.306681 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m22:54:38.306923 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:54:38.785528 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:54:38.787059 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:54:38.788404 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m22:54:47.913602 [debug] [Thread-1 (]: SQL status: SELECT 145629 in 9.0 seconds
[0m22:54:47.921518 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:54:47.922293 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m22:54:47.977095 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:47.983171 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:54:47.983812 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m22:54:48.038739 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:48.043090 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:54:48.043729 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:54:48.044285 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m22:54:48.100981 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:54:48.105323 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m22:54:48.105840 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m22:54:48.184346 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m22:54:48.186449 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 22:54:38.302892 => 22:54:48.186168
[0m22:54:48.186916 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m22:54:48.188325 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059a7650>]}
[0m22:54:48.189302 [info ] [Thread-1 (]: 4 of 6 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 145629[0m in 9.90s]
[0m22:54:48.190314 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m22:54:48.190982 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m22:54:48.191848 [info ] [Thread-1 (]: 5 of 6 START sql view model danila.stg_scraper__records ........................ [RUN]
[0m22:54:48.192926 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m22:54:48.193394 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m22:54:48.198583 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m22:54:48.201384 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 22:54:48.193723 => 22:54:48.201164
[0m22:54:48.202222 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m22:54:48.207187 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m22:54:48.208310 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m22:54:48.208585 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m22:54:48.208837 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:54:48.976396 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m22:54:48.978260 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m22:54:48.979710 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  create view "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
[0m22:54:49.043303 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:54:49.054744 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m22:54:49.055290 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m22:54:49.111170 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:49.117636 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m22:54:49.118272 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m22:54:49.173926 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:49.178250 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m22:54:49.178850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m22:54:49.179424 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m22:54:49.234607 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:54:49.239601 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m22:54:49.240046 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop view if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m22:54:49.297784 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:54:49.301263 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 22:54:48.202608 => 22:54:49.300936
[0m22:54:49.302206 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m22:54:49.304137 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106924310>]}
[0m22:54:49.305228 [info ] [Thread-1 (]: 5 of 6 OK created sql view model danila.stg_scraper__records ................... [[32mCREATE VIEW[0m in 1.11s]
[0m22:54:49.306372 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m22:54:49.307874 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m22:54:49.308608 [info ] [Thread-1 (]: 6 of 6 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m22:54:49.309679 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m22:54:49.310331 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m22:54:49.315720 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m22:54:49.317898 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 22:54:49.310664 => 22:54:49.317702
[0m22:54:49.318211 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m22:54:49.322297 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m22:54:49.322925 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m22:54:49.323183 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m22:54:49.323421 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:54:49.727297 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m22:54:49.729097 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m22:54:49.730131 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m22:54:49.783960 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m22:54:49.790831 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m22:54:49.791522 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m22:54:49.840854 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m22:54:49.844988 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m22:54:49.845759 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m22:54:49.846391 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m22:54:49.895523 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m22:54:49.901388 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m22:54:49.901923 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m22:54:49.950958 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m22:54:49.953391 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 22:54:49.318387 => 22:54:49.953121
[0m22:54:49.953889 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m22:54:49.955240 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4863de9-f574-4713-9d04-c249f1eb8576', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068b4d90>]}
[0m22:54:49.956104 [info ] [Thread-1 (]: 6 of 6 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.65s]
[0m22:54:49.957146 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m22:54:49.958598 [debug] [MainThread]: Using postgres connection "master"
[0m22:54:49.958905 [debug] [MainThread]: On master: BEGIN
[0m22:54:49.959190 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:54:50.438068 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m22:54:50.439723 [debug] [MainThread]: On master: COMMIT
[0m22:54:50.440706 [debug] [MainThread]: Using postgres connection "master"
[0m22:54:50.441426 [debug] [MainThread]: On master: COMMIT
[0m22:54:50.500104 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m22:54:50.501271 [debug] [MainThread]: On master: Close
[0m22:54:50.503968 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:54:50.504508 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m22:54:50.505141 [info ] [MainThread]: 
[0m22:54:50.505853 [info ] [MainThread]: Finished running 4 view models, 2 table models in 0 hours 0 minutes and 32.08 seconds (32.08s).
[0m22:54:50.508229 [debug] [MainThread]: Command end result
[0m22:54:50.521994 [info ] [MainThread]: 
[0m22:54:50.522721 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:54:50.523030 [info ] [MainThread]: 
[0m22:54:50.523328 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m22:54:50.523762 [debug] [MainThread]: Command `dbt run` succeeded at 22:54:50.523698 after 32.21 seconds
[0m22:54:50.523970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101164e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10115f090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10115f150>]}
[0m22:54:50.524149 [debug] [MainThread]: Flushing usage events
[0m23:28:34.479688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b5de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b627d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b62e90>]}


============================== 23:28:34.481420 | e9bc5e98-fe16-417a-81f2-61b5c827b4ba ==============================
[0m23:28:34.481420 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:28:34.481755 [debug] [MainThread]: running dbt with arguments {'log_path': '/Users/danila/github/dbt/logs', 'no_print': 'None', 'static_parser': 'True', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'introspect': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_colors': 'True', 'cache_selected_only': 'False', 'debug': 'False', 'version_check': 'True', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'write_json': 'True', 'partial_parse': 'True', 'warn_error': 'None', 'printer_width': '80', 'target_path': 'None', 'indirect_selection': 'eager', 'send_anonymous_usage_stats': 'True', 'log_format': 'default'}
[0m23:28:34.493009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e9bc5e98-fe16-417a-81f2-61b5c827b4ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b73c90>]}
[0m23:28:34.545768 [debug] [MainThread]: Command `dbt clean` succeeded at 23:28:34.545700 after 0.08 seconds
[0m23:28:34.545953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b87090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b05310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b06090>]}
[0m23:28:34.546561 [debug] [MainThread]: Flushing usage events
[0m23:28:41.171148 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10559ed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10525fe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10559fd10>]}


============================== 23:28:41.172377 | 2df3772b-7d88-4bc4-82af-e55099d63c25 ==============================
[0m23:28:41.172377 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:28:41.172680 [debug] [MainThread]: running dbt with arguments {'introspect': 'True', 'log_format': 'default', 'printer_width': '80', 'quiet': 'False', 'debug': 'False', 'partial_parse': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'version_check': 'True', 'write_json': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'static_parser': 'True'}
[0m23:28:41.183535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2df3772b-7d88-4bc4-82af-e55099d63c25', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b7cd0>]}
[0m23:28:41.184527 [debug] [MainThread]: Set downloads directory='/var/folders/9d/1bclhjt976d6zrfg9c7vq1fm0000gn/T/dbt-downloads-m_vubtj9'
[0m23:28:41.184732 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m23:28:41.277302 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m23:28:41.278505 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m23:28:41.306927 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m23:28:41.309924 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m23:28:41.450023 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m23:28:41.465855 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m23:28:41.902681 [info ] [MainThread]: Installed from version 1.1.1
[0m23:28:41.902963 [info ] [MainThread]: Up to date!
[0m23:28:41.903184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '2df3772b-7d88-4bc4-82af-e55099d63c25', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10559f810>]}
[0m23:28:41.903376 [info ] [MainThread]: Installing dbt-labs/codegen
[0m23:28:42.206732 [info ] [MainThread]: Installed from version 0.12.1
[0m23:28:42.207248 [info ] [MainThread]: Up to date!
[0m23:28:42.207562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '2df3772b-7d88-4bc4-82af-e55099d63c25', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055d8810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b7b10>]}
[0m23:28:42.208854 [debug] [MainThread]: Command `dbt deps` succeeded at 23:28:42.208720 after 1.05 seconds
[0m23:28:42.209128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100ecb150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e49310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100e49f10>]}
[0m23:28:42.209355 [debug] [MainThread]: Flushing usage events
[0m23:28:48.243749 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
[0m23:28:51.676131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d84c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d85e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d97cd0>]}


============================== 23:28:51.677331 | df322297-6526-494d-8773-b9a320266ee0 ==============================
[0m23:28:51.677331 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:28:51.677638 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'introspect': 'True', 'no_print': 'None', 'write_json': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'warn_error': 'None', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'profiles_dir': '/Users/danila/.dbt', 'quiet': 'False', 'static_parser': 'True', 'log_cache_events': 'False', 'debug': 'False', 'partial_parse': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True'}
[0m23:28:51.709718 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d86b90>]}
[0m23:28:51.715987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108da7450>]}
[0m23:28:51.716441 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:28:51.729934 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:28:51.730365 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m23:28:51.730567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109208610>]}
[0m23:28:52.104158 [debug] [MainThread]: 1699: static parser successfully parsed staging/scraper/stg_scraper__records.sql
[0m23:28:52.109005 [debug] [MainThread]: 1699: static parser successfully parsed marts/first_deposits_fct.sql
[0m23:28:52.110104 [debug] [MainThread]: 1699: static parser successfully parsed brand_performance/test.sql
[0m23:28:52.111100 [debug] [MainThread]: 1699: static parser successfully parsed brand_performance/clicks_to_clients_fct.sql
[0m23:28:52.112118 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_cost_int.sql
[0m23:28:52.120432 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_cost_int.sql
[0m23:28:52.120983 [debug] [MainThread]: 1699: static parser successfully parsed brand_performance/deals_dimension.sql
[0m23:28:52.122345 [debug] [MainThread]: 1603: static parser failed on brand_performance/outclick_by_brand_int.sql
[0m23:28:52.125807 [debug] [MainThread]: 1602: parser fallback to jinja rendering on brand_performance/outclick_by_brand_int.sql
[0m23:28:52.168738 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.marts
- models.staging.scraper
- models.brand_performance
- models.users
[0m23:28:52.170764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10928f850>]}
[0m23:28:52.175268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109374e50>]}
[0m23:28:52.175493 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:28:52.175674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10625a6d0>]}
[0m23:28:52.176519 [info ] [MainThread]: 
[0m23:28:52.176853 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:28:52.177384 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:28:52.181584 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:28:52.181762 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:28:52.181872 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:28:52.875505 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m23:28:52.878170 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:28:52.880823 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:28:52.887008 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:28:52.887386 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:28:52.887647 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:28:53.271854 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:28:53.273512 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:28:53.274608 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:28:53.441753 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m23:28:53.446672 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:28:53.494052 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:28:53.509762 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:53.510272 [debug] [MainThread]: On master: BEGIN
[0m23:28:53.510623 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:28:53.896408 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:28:53.897520 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:53.898376 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:28:53.954661 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m23:28:53.960681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092051d0>]}
[0m23:28:53.961661 [debug] [MainThread]: On master: ROLLBACK
[0m23:28:54.008364 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:54.009616 [debug] [MainThread]: On master: BEGIN
[0m23:28:54.103137 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:28:54.104339 [debug] [MainThread]: On master: COMMIT
[0m23:28:54.105059 [debug] [MainThread]: Using postgres connection "master"
[0m23:28:54.105670 [debug] [MainThread]: On master: COMMIT
[0m23:28:54.152838 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:28:54.154244 [debug] [MainThread]: On master: Close
[0m23:28:54.157119 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:28:54.157978 [info ] [MainThread]: 
[0m23:28:54.166605 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m23:28:54.167128 [info ] [Thread-1 (]: 1 of 7 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m23:28:54.167856 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m23:28:54.168243 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m23:28:54.174521 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.175807 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 23:28:54.168491 => 23:28:54.175597
[0m23:28:54.176143 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m23:28:54.200786 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.201594 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.201795 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m23:28:54.201959 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:28:54.632643 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:28:54.633912 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.634621 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m23:28:54.691322 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:28:54.703616 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.704096 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m23:28:54.756649 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:28:54.765435 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.766053 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m23:28:54.818594 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:28:54.831692 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m23:28:54.831987 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.832197 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m23:28:54.884133 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:28:54.888557 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:28:54.888887 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m23:28:54.942133 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:28:54.944854 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 23:28:54.176345 => 23:28:54.944424
[0m23:28:54.945394 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m23:28:54.946906 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109391a10>]}
[0m23:28:54.947684 [info ] [Thread-1 (]: 1 of 7 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.78s]
[0m23:28:54.948420 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m23:28:54.948963 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m23:28:54.949583 [info ] [Thread-1 (]: 2 of 7 START sql view model danila.deals_dimension ............................. [RUN]
[0m23:28:54.950293 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m23:28:54.950625 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m23:28:54.953019 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m23:28:54.954129 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 23:28:54.950858 => 23:28:54.953875
[0m23:28:54.954573 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m23:28:54.958245 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m23:28:54.959044 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:28:54.959350 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m23:28:54.959640 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:28:55.340746 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:28:55.342007 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:28:55.342829 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group
        , gap_campaign_name as google_ads_campaign_id
        -- , traffic_types as betting_type
        -- , traffic_sources
    from deals
)

select * from main
where id=2085
-- select betting_type, traffic_sources, count(id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m23:28:55.392873 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:28:55.400375 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:28:55.401971 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m23:28:55.449457 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:28:55.454181 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:28:55.454739 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m23:28:55.502120 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:28:55.505650 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m23:28:55.506273 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:28:55.506781 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m23:28:55.553054 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:28:55.557656 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:28:55.558286 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m23:28:55.606830 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:28:55.609545 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 23:28:54.954837 => 23:28:55.609217
[0m23:28:55.610211 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m23:28:55.611927 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109480d50>]}
[0m23:28:55.612938 [info ] [Thread-1 (]: 2 of 7 OK created sql view model danila.deals_dimension ........................ [[32mCREATE VIEW[0m in 0.66s]
[0m23:28:55.614047 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m23:28:55.614799 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:28:55.615723 [info ] [Thread-1 (]: 3 of 7 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:28:55.616946 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:28:55.617461 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:28:55.627214 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:28:55.628359 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:28:55.617819 => 23:28:55.628111
[0m23:28:55.628713 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:28:55.646400 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:28:55.646944 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:28:55.647143 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:28:55.647329 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:28:56.027595 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:28:56.029257 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:28:56.030784 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m23:29:11.600445 [debug] [Thread-1 (]: SQL status: SELECT 509395 in 16.0 seconds
[0m23:29:11.608269 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:29:11.609025 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:29:11.656626 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:11.666323 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:29:11.667029 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:29:11.714120 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:11.723130 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:29:11.723699 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:29:11.724149 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:29:11.771398 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:29:11.777522 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:29:11.778213 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:29:11.858650 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:29:11.862476 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:28:55.628917 => 23:29:11.862114
[0m23:29:11.863192 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:29:11.865018 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e31d0>]}
[0m23:29:11.866075 [info ] [Thread-1 (]: 3 of 7 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 509395[0m in 16.25s]
[0m23:29:11.867144 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:29:11.867775 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:29:11.868541 [info ] [Thread-1 (]: 4 of 7 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:29:11.869489 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:29:11.869982 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:29:11.881154 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:29:11.882232 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:29:11.870311 => 23:29:11.882025
[0m23:29:11.882543 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:29:11.885808 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:29:11.886362 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:29:11.886617 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:29:11.886857 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:29:12.319403 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:29:12.321235 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:29:12.322579 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:29:21.225589 [debug] [Thread-1 (]: SQL status: SELECT 145642 in 9.0 seconds
[0m23:29:21.233351 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:29:21.233972 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:29:21.281668 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:21.289064 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:29:21.289743 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:29:21.337671 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:21.341738 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:29:21.342372 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:29:21.342920 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:29:21.390260 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:29:21.395625 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:29:21.396082 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:29:21.470740 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:29:21.474479 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:29:11.882720 => 23:29:21.474106
[0m23:29:21.475163 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:29:21.476950 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109208a50>]}
[0m23:29:21.478055 [info ] [Thread-1 (]: 4 of 7 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 145642[0m in 9.61s]
[0m23:29:21.479164 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:29:21.479913 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m23:29:21.480783 [info ] [Thread-1 (]: 5 of 7 START sql view model danila.stg_scraper__records ........................ [RUN]
[0m23:29:21.481871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m23:29:21.482347 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m23:29:21.486884 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m23:29:21.488604 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 23:29:21.482651 => 23:29:21.488211
[0m23:29:21.489057 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m23:29:21.493714 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m23:29:21.494660 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:29:21.494975 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m23:29:21.495269 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:29:22.996143 [debug] [Thread-1 (]: SQL status: BEGIN in 2.0 seconds
[0m23:29:22.996579 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:29:22.997058 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  create view "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
[0m23:29:23.064812 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:29:23.070361 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:29:23.070855 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m23:29:23.133165 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:23.142589 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:29:23.143072 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m23:29:23.205046 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:23.207843 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m23:29:23.208384 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:29:23.209005 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m23:29:23.270633 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:29:23.276668 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:29:23.277244 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop view if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m23:29:23.339699 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:29:23.343050 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 23:29:21.489310 => 23:29:23.342674
[0m23:29:23.343664 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m23:29:23.345028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109549890>]}
[0m23:29:23.345768 [info ] [Thread-1 (]: 5 of 7 OK created sql view model danila.stg_scraper__records ................... [[32mCREATE VIEW[0m in 1.86s]
[0m23:29:23.346534 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m23:29:23.347205 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m23:29:23.348012 [info ] [Thread-1 (]: 6 of 7 START sql view model danila.test ........................................ [RUN]
[0m23:29:23.348921 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.test)
[0m23:29:23.349221 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m23:29:23.350791 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m23:29:23.351765 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 23:29:23.349408 => 23:29:23.351537
[0m23:29:23.352134 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m23:29:23.355672 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m23:29:23.356407 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:29:23.356692 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m23:29:23.356974 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:29:23.873651 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m23:29:23.875448 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:29:23.876958 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    -- with main as (
--     select
--         id
--         , user_id
--         , conversion_timestamp
--         , registrations
--         , deal_id
--         , date_parsed as date_cet
--         --, click_id
--         , geo as country_code
--         -- , registrations as signed_up
--         --, cpa_count as deposited_first_time
--         -- , gtee_count
--         , cpa_commissions as acquisition_commission
--         -- , total_commission
--         -- , gtee_commissions
--         -- , net_revenue
--         -- , revshare_commissions
--         , lower(adgroup_name) as ga_campaign_name
--         , case
--             when right(brand_name, 6) <> 'sports' then 'casino'
--             when right(brand_name, 6) = 'sports' then 'sports'
--             else 'other'
--         end as campaign_vertical
--         , case
--             when campaign_name::text = 'email' then brand_name || ' email'
--             when campaign_name::text = 'PA' then brand_name || ' PA'
--             else brand_name
--         end as brand_name

--         , case
--             when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
--             when campaign_name = 'ficashstormslots' then 'cashstormslots'
--             when campaign_name = 'goldenlion' then 'goldenliongames'
--             else campaign_name
--         end as campaign_name
--     from records
--     where
--         date_parsed > '2024-03-31'
--         and cpa_count > 0.5
--         --and deal_id is null
--         --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
--     --and user_id='ae4eb2f5ad8ebf29'
--     order by user_id, deal_id, date_parsed
-- )




-- select * from main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


SELECT id, user_id, date_parsed, date, brand_name, cpa_count, registrations, conversion_timestamp
FROM records
WHERE id='5393572' or id= '5393571'--date_parsed = '2024-05-16' AND user_id = '51a4a42eaaeb12f7'
--GROUP BY user_id, conversion_timestamp, date_parsed, brand_name, cpa_count, registrations
--HAVING COUNT(*) = 1
  );
[0m23:29:23.940237 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:29:23.948344 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:29:23.948993 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m23:29:24.008114 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:24.013854 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:29:24.014475 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m23:29:24.073827 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:24.078141 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:29:24.078801 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:29:24.079365 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:29:24.138432 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:29:24.144456 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:29:24.145093 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m23:29:24.205857 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:29:24.209239 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 23:29:23.352363 => 23:29:24.208922
[0m23:29:24.209887 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m23:29:24.211559 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093da6d0>]}
[0m23:29:24.212462 [info ] [Thread-1 (]: 6 of 7 OK created sql view model danila.test ................................... [[32mCREATE VIEW[0m in 0.86s]
[0m23:29:24.213287 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m23:29:24.213858 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m23:29:24.214539 [info ] [Thread-1 (]: 7 of 7 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m23:29:24.215444 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.first_deposits_fct)
[0m23:29:24.215905 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m23:29:24.219789 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m23:29:24.221196 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 23:29:24.216233 => 23:29:24.220826
[0m23:29:24.221657 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m23:29:24.226100 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m23:29:24.226970 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:29:24.227290 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m23:29:24.227577 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:29:24.681166 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:29:24.682152 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:29:24.682600 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m23:29:24.740044 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:29:24.742703 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:29:24.743047 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m23:29:24.795119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:29:24.797781 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m23:29:24.798243 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:29:24.798570 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m23:29:24.851235 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:29:24.853200 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:29:24.853613 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m23:29:24.905689 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:29:24.906954 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 23:29:24.221900 => 23:29:24.906778
[0m23:29:24.907283 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m23:29:24.908084 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df322297-6526-494d-8773-b9a320266ee0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109567e90>]}
[0m23:29:24.908582 [info ] [Thread-1 (]: 7 of 7 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.69s]
[0m23:29:24.909158 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m23:29:24.910485 [debug] [MainThread]: Using postgres connection "master"
[0m23:29:24.910785 [debug] [MainThread]: On master: BEGIN
[0m23:29:24.911009 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:29:25.295257 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:29:25.296246 [debug] [MainThread]: On master: COMMIT
[0m23:29:25.296964 [debug] [MainThread]: Using postgres connection "master"
[0m23:29:25.297886 [debug] [MainThread]: On master: COMMIT
[0m23:29:25.344218 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:29:25.344843 [debug] [MainThread]: On master: Close
[0m23:29:25.347093 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:29:25.347758 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m23:29:25.348438 [info ] [MainThread]: 
[0m23:29:25.349191 [info ] [MainThread]: Finished running 5 view models, 2 table models in 0 hours 0 minutes and 33.17 seconds (33.17s).
[0m23:29:25.351870 [debug] [MainThread]: Command end result
[0m23:29:25.369309 [info ] [MainThread]: 
[0m23:29:25.369899 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:29:25.370204 [info ] [MainThread]: 
[0m23:29:25.370547 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m23:29:25.371156 [debug] [MainThread]: Command `dbt run` succeeded at 23:29:25.371055 after 33.71 seconds
[0m23:29:25.371503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107548fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dc0e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dbb150>]}
[0m23:29:25.371833 [debug] [MainThread]: Flushing usage events
[0m23:34:17.225280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116a4b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116a7d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116b3050>]}


============================== 23:34:17.226982 | 30ba4b34-1db5-43fa-aada-a6d1256970df ==============================
[0m23:34:17.226982 [info ] [MainThread]: Running with dbt=1.5.4
[0m23:34:17.227319 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'introspect': 'True', 'quiet': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'target_path': 'None', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'write_json': 'True', 'debug': 'False', 'no_print': 'None', 'version_check': 'True', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'warn_error': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'fail_fast': 'False', 'log_cache_events': 'False', 'log_path': '/Users/danila/github/dbt/logs'}
[0m23:34:17.258221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116be8d0>]}
[0m23:34:17.264631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111e3350>]}
[0m23:34:17.265161 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m23:34:17.278442 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m23:34:17.306768 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:34:17.306944 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:34:17.307262 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.brand_performance
- models.marts
- models.staging.scraper
- models.users
[0m23:34:17.310050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a1ac50>]}
[0m23:34:17.314534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c1f90>]}
[0m23:34:17.314708 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m23:34:17.314867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a2a710>]}
[0m23:34:17.315646 [info ] [MainThread]: 
[0m23:34:17.315962 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:34:17.316491 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m23:34:17.320593 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m23:34:17.320775 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m23:34:17.320884 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:34:17.817115 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m23:34:17.820858 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m23:34:17.825218 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m23:34:17.833517 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:34:17.834104 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m23:34:17.834422 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:34:18.224399 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m23:34:18.226137 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m23:34:18.227273 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m23:34:18.279614 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m23:34:18.283472 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m23:34:18.330588 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m23:34:18.346846 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:18.347341 [debug] [MainThread]: On master: BEGIN
[0m23:34:18.347677 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:34:18.774593 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:34:18.777050 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:18.777937 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:34:18.838638 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m23:34:18.845398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a1d2d0>]}
[0m23:34:18.846593 [debug] [MainThread]: On master: ROLLBACK
[0m23:34:18.899116 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:18.900401 [debug] [MainThread]: On master: BEGIN
[0m23:34:19.006579 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:34:19.008202 [debug] [MainThread]: On master: COMMIT
[0m23:34:19.008941 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:19.009554 [debug] [MainThread]: On master: COMMIT
[0m23:34:19.062127 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:34:19.063440 [debug] [MainThread]: On master: Close
[0m23:34:19.065730 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:34:19.066547 [info ] [MainThread]: 
[0m23:34:19.076995 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m23:34:19.077883 [info ] [Thread-1 (]: 1 of 7 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m23:34:19.078569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m23:34:19.078818 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m23:34:19.085576 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.086425 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 23:34:19.078961 => 23:34:19.086205
[0m23:34:19.086779 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m23:34:19.111607 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.112188 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.112390 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m23:34:19.112575 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:19.516081 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:19.517373 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.518199 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m23:34:19.571315 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:34:19.580291 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.580597 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m23:34:19.629539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:19.635434 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.636058 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m23:34:19.686630 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:19.711095 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m23:34:19.711485 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.711784 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m23:34:19.761369 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:19.769707 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m23:34:19.770224 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m23:34:19.821023 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:34:19.824749 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 23:34:19.086971 => 23:34:19.824268
[0m23:34:19.825502 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m23:34:19.827432 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111dabed0>]}
[0m23:34:19.828533 [info ] [Thread-1 (]: 1 of 7 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.75s]
[0m23:34:19.829423 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m23:34:19.830042 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m23:34:19.830848 [info ] [Thread-1 (]: 2 of 7 START sql view model danila.deals_dimension ............................. [RUN]
[0m23:34:19.831746 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m23:34:19.832187 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m23:34:19.834500 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m23:34:19.835453 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 23:34:19.832551 => 23:34:19.835280
[0m23:34:19.835731 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m23:34:19.839651 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m23:34:19.840254 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:34:19.840530 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m23:34:19.840730 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:20.228186 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:20.230012 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:34:20.230912 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group
        , gap_campaign_name as google_ads_campaign_id
        -- , traffic_types as betting_type
        -- , traffic_sources
    from deals
)

select * from main
where id=2085
-- select betting_type, traffic_sources, count(id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m23:34:20.283147 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:34:20.291516 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:34:20.292464 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m23:34:20.341242 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:20.348552 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:34:20.349251 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m23:34:20.397434 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:20.401804 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m23:34:20.402500 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:34:20.403078 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m23:34:20.450805 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:20.457133 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m23:34:20.457820 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m23:34:20.506444 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:34:20.510180 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 23:34:19.835897 => 23:34:20.509797
[0m23:34:20.510891 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m23:34:20.512640 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a4f890>]}
[0m23:34:20.513675 [info ] [Thread-1 (]: 2 of 7 OK created sql view model danila.deals_dimension ........................ [[32mCREATE VIEW[0m in 0.68s]
[0m23:34:20.514694 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m23:34:20.515310 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:20.516088 [info ] [Thread-1 (]: 3 of 7 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m23:34:20.517061 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m23:34:20.517542 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:20.536873 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:20.538929 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 23:34:20.517969 => 23:34:20.538770
[0m23:34:20.539175 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:20.554469 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:20.555218 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:20.555420 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m23:34:20.555595 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:21.038782 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:21.040262 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:21.041910 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m23:34:36.707467 [debug] [Thread-1 (]: SQL status: SELECT 509401 in 16.0 seconds
[0m23:34:36.715208 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:36.716021 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m23:34:36.775667 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:36.782357 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:36.783080 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m23:34:36.842039 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:36.852281 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:34:36.852894 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:36.853456 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m23:34:36.914109 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:36.920160 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m23:34:36.920900 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m23:34:37.011059 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:34:37.014930 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 23:34:20.539328 => 23:34:37.014548
[0m23:34:37.015687 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m23:34:37.017507 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111df0490>]}
[0m23:34:37.018639 [info ] [Thread-1 (]: 3 of 7 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 509401[0m in 16.50s]
[0m23:34:37.019910 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m23:34:37.020720 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m23:34:37.021722 [info ] [Thread-1 (]: 4 of 7 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m23:34:37.022832 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m23:34:37.023302 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m23:34:37.034656 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m23:34:37.035605 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 23:34:37.023649 => 23:34:37.035422
[0m23:34:37.035911 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m23:34:37.039636 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m23:34:37.040116 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:37.040288 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m23:34:37.040441 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:37.517082 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:37.518910 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:37.520671 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m23:34:46.129760 [debug] [Thread-1 (]: SQL status: SELECT 145648 in 9.0 seconds
[0m23:34:46.138817 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:46.139630 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m23:34:46.194800 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:46.201515 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:46.202221 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m23:34:46.258296 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:46.263551 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:34:46.264330 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:46.264954 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m23:34:46.320236 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:46.326557 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m23:34:46.327203 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m23:34:46.411069 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m23:34:46.415377 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 23:34:37.036116 => 23:34:46.414779
[0m23:34:46.416214 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m23:34:46.418135 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a9d050>]}
[0m23:34:46.419238 [info ] [Thread-1 (]: 4 of 7 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 145648[0m in 9.40s]
[0m23:34:46.420393 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m23:34:46.421087 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m23:34:46.421853 [info ] [Thread-1 (]: 5 of 7 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m23:34:46.422874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m23:34:46.423343 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m23:34:46.428758 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m23:34:46.429890 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 23:34:46.423669 => 23:34:46.429646
[0m23:34:46.430289 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m23:34:46.434258 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m23:34:46.435083 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:34:46.435377 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m23:34:46.435654 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:46.959176 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m23:34:46.961097 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:34:46.962740 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql




with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m23:34:49.506983 [debug] [Thread-1 (]: SQL status: SELECT 69176 in 3.0 seconds
[0m23:34:49.518852 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:34:49.519665 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m23:34:49.578732 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:49.586336 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:34:49.587089 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m23:34:49.645021 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:49.649653 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m23:34:49.650551 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:34:49.651208 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m23:34:49.709586 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:49.717020 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m23:34:49.717830 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop view if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m23:34:49.777773 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:34:49.781573 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 23:34:46.430526 => 23:34:49.781156
[0m23:34:49.782272 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m23:34:49.784082 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e43810>]}
[0m23:34:49.785125 [info ] [Thread-1 (]: 5 of 7 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 69176[0m in 3.36s]
[0m23:34:49.786393 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m23:34:49.787208 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m23:34:49.788139 [info ] [Thread-1 (]: 6 of 7 START sql view model danila.test ........................................ [RUN]
[0m23:34:49.789066 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.test)
[0m23:34:49.789519 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m23:34:49.792623 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m23:34:49.793844 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 23:34:49.789821 => 23:34:49.793664
[0m23:34:49.794220 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m23:34:49.798877 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m23:34:49.799839 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:34:49.800174 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m23:34:49.800465 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:50.278356 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:50.279923 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:34:50.281442 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    -- with main as (
--     select
--         id
--         , user_id
--         , conversion_timestamp
--         , registrations
--         , deal_id
--         , date_parsed as date_cet
--         --, click_id
--         , geo as country_code
--         -- , registrations as signed_up
--         --, cpa_count as deposited_first_time
--         -- , gtee_count
--         , cpa_commissions as acquisition_commission
--         -- , total_commission
--         -- , gtee_commissions
--         -- , net_revenue
--         -- , revshare_commissions
--         , lower(adgroup_name) as ga_campaign_name
--         , case
--             when right(brand_name, 6) <> 'sports' then 'casino'
--             when right(brand_name, 6) = 'sports' then 'sports'
--             else 'other'
--         end as campaign_vertical
--         , case
--             when campaign_name::text = 'email' then brand_name || ' email'
--             when campaign_name::text = 'PA' then brand_name || ' PA'
--             else brand_name
--         end as brand_name

--         , case
--             when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
--             when campaign_name = 'ficashstormslots' then 'cashstormslots'
--             when campaign_name = 'goldenlion' then 'goldenliongames'
--             else campaign_name
--         end as campaign_name
--     from records
--     where
--         date_parsed > '2024-03-31'
--         and cpa_count > 0.5
--         --and deal_id is null
--         --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
--     --and user_id='ae4eb2f5ad8ebf29'
--     order by user_id, deal_id, date_parsed
-- )




-- select * from main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


SELECT id, user_id, date_parsed, date, brand_name, cpa_count, registrations, conversion_timestamp
FROM records
WHERE id='5393572' or id= '5393571'--date_parsed = '2024-05-16' AND user_id = '51a4a42eaaeb12f7'
--GROUP BY user_id, conversion_timestamp, date_parsed, brand_name, cpa_count, registrations
--HAVING COUNT(*) = 1
  );
[0m23:34:50.344470 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:34:50.352815 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:34:50.353451 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m23:34:50.413345 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:50.420302 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:34:50.421031 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m23:34:50.480674 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:50.485872 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:34:50.486718 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:34:50.487368 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m23:34:50.546322 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:50.553076 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m23:34:50.553934 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m23:34:50.614388 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:34:50.618407 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 23:34:49.794471 => 23:34:50.618043
[0m23:34:50.619119 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m23:34:50.620902 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e42e50>]}
[0m23:34:50.621905 [info ] [Thread-1 (]: 6 of 7 OK created sql view model danila.test ................................... [[32mCREATE VIEW[0m in 0.83s]
[0m23:34:50.623007 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m23:34:50.623770 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m23:34:50.624685 [info ] [Thread-1 (]: 7 of 7 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m23:34:50.625715 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.first_deposits_fct)
[0m23:34:50.626199 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m23:34:50.631258 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m23:34:50.632380 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 23:34:50.626527 => 23:34:50.632130
[0m23:34:50.632789 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m23:34:50.637122 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m23:34:50.637934 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:34:50.638249 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m23:34:50.638540 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:34:51.022541 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m23:34:51.024693 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:34:51.026187 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m23:34:51.077754 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m23:34:51.085108 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:34:51.085871 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m23:34:51.133548 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m23:34:51.138368 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m23:34:51.139131 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:34:51.139736 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m23:34:51.187504 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m23:34:51.196790 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m23:34:51.197394 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m23:34:51.249343 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m23:34:51.252906 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 23:34:50.633026 => 23:34:51.252529
[0m23:34:51.253620 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m23:34:51.255359 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '30ba4b34-1db5-43fa-aada-a6d1256970df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e54350>]}
[0m23:34:51.256387 [info ] [Thread-1 (]: 7 of 7 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.63s]
[0m23:34:51.257469 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m23:34:51.259805 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:51.260248 [debug] [MainThread]: On master: BEGIN
[0m23:34:51.260602 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:34:51.743664 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m23:34:51.745262 [debug] [MainThread]: On master: COMMIT
[0m23:34:51.746290 [debug] [MainThread]: Using postgres connection "master"
[0m23:34:51.747213 [debug] [MainThread]: On master: COMMIT
[0m23:34:51.806376 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m23:34:51.807975 [debug] [MainThread]: On master: Close
[0m23:34:51.809777 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:34:51.810354 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m23:34:51.811057 [info ] [MainThread]: 
[0m23:34:51.811766 [info ] [MainThread]: Finished running 4 view models, 3 table models in 0 hours 0 minutes and 34.50 seconds (34.50s).
[0m23:34:51.814574 [debug] [MainThread]: Command end result
[0m23:34:51.828406 [info ] [MainThread]: 
[0m23:34:51.828991 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:34:51.829343 [info ] [MainThread]: 
[0m23:34:51.829697 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m23:34:51.830354 [debug] [MainThread]: Command `dbt run` succeeded at 23:34:51.830251 after 34.62 seconds
[0m23:34:51.830721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103418e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103413090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103413150>]}
[0m23:34:51.831049 [debug] [MainThread]: Flushing usage events
[0m15:15:02.720643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10689a190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10689f590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10689fc50>]}


============================== 15:15:02.722571 | d736e6de-afeb-43c8-a24b-44a34306e71a ==============================
[0m15:15:02.722571 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:15:02.722878 [debug] [MainThread]: running dbt with arguments {'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'printer_width': '80', 'use_experimental_parser': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'introspect': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'partial_parse': 'True', 'quiet': 'False', 'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'warn_error': 'None', 'fail_fast': 'False', 'log_cache_events': 'False', 'no_print': 'None', 'debug': 'False', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'version_check': 'True', 'static_parser': 'True'}
[0m15:15:02.760420 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068af890>]}
[0m15:15:02.766660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d134d0>]}
[0m15:15:02.767121 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:15:02.783131 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:15:02.826818 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:15:02.827025 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:15:02.827323 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.staging.scraper
- models.marts
- models.brand_performance
- models.users
[0m15:15:02.829798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e6e090>]}
[0m15:15:02.834891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d03b10>]}
[0m15:15:02.835115 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:15:02.835283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103d624d0>]}
[0m15:15:02.835955 [info ] [MainThread]: 
[0m15:15:02.836299 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:15:02.836850 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:15:02.841104 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:15:02.841316 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:15:02.841437 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:15:03.388012 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m15:15:03.392709 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:15:03.397108 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:15:03.406357 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:15:03.406956 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:15:03.407276 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:15:03.875364 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:15:03.877145 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:15:03.878306 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:15:03.936964 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:15:03.942414 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:15:03.995959 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:15:04.011348 [debug] [MainThread]: Using postgres connection "master"
[0m15:15:04.011957 [debug] [MainThread]: On master: BEGIN
[0m15:15:04.012284 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:15:04.493977 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:15:04.495184 [debug] [MainThread]: Using postgres connection "master"
[0m15:15:04.495822 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:15:04.563252 [debug] [MainThread]: SQL status: SELECT 52 in 0.0 seconds
[0m15:15:04.568264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d4fb90>]}
[0m15:15:04.569064 [debug] [MainThread]: On master: ROLLBACK
[0m15:15:04.627506 [debug] [MainThread]: Using postgres connection "master"
[0m15:15:04.628285 [debug] [MainThread]: On master: BEGIN
[0m15:15:04.745923 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:15:04.747054 [debug] [MainThread]: On master: COMMIT
[0m15:15:04.747663 [debug] [MainThread]: Using postgres connection "master"
[0m15:15:04.748183 [debug] [MainThread]: On master: COMMIT
[0m15:15:04.806893 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:15:04.808786 [debug] [MainThread]: On master: Close
[0m15:15:04.811434 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:15:04.812278 [info ] [MainThread]: 
[0m15:15:04.821541 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:15:04.822404 [info ] [Thread-1 (]: 1 of 5 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m15:15:04.823439 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m15:15:04.823900 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m15:15:04.831251 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:04.833163 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 15:15:04.824200 => 15:15:04.832922
[0m15:15:04.833536 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m15:15:04.858190 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:04.858751 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:04.858954 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m15:15:04.859131 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:15:05.361433 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:15:05.363181 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:05.363972 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m15:15:05.428012 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:15:05.444228 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:05.444853 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m15:15:05.504776 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:05.511123 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:05.511847 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m15:15:05.570400 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:05.593227 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:15:05.593716 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:05.594071 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:15:05.653008 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:15:05.663342 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:15:05.663969 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m15:15:05.723465 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:15:05.728024 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 15:15:04.833748 => 15:15:05.727554
[0m15:15:05.728924 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m15:15:05.731150 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d43b90>]}
[0m15:15:05.732505 [info ] [Thread-1 (]: 1 of 5 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.91s]
[0m15:15:05.733631 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:15:05.734296 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m15:15:05.735127 [info ] [Thread-1 (]: 2 of 5 START sql view model danila.deals_dimension ............................. [RUN]
[0m15:15:05.736253 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m15:15:05.736768 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m15:15:05.740047 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m15:15:05.741100 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 15:15:05.737130 => 15:15:05.740855
[0m15:15:05.741505 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m15:15:05.745894 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m15:15:05.746642 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:15:05.746939 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m15:15:05.747216 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:15:06.237671 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:15:06.238956 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:15:06.239893 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select
        id as deal_id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group -- campaign_name? 
        , gap_campaign_name as google_ads_campaign_id -- ga_campaign_name? 
        -- , traffic_types as betting_type (vertical)
        -- , traffic_sources (FB, Google, etc)
    from deals
)

select * from main
where id = 2085
-- select betting_type, traffic_sources, count(id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m15:15:06.296805 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column "id" does not exist
LINE 25: where id = 2085
               ^

[0m15:15:06.298314 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: ROLLBACK
[0m15:15:06.354663 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 15:15:05.741738 => 15:15:06.353544
[0m15:15:06.355955 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m15:15:06.370585 [debug] [Thread-1 (]: Database Error in model deals_dimension (models/brand_performance/deals_dimension.sql)
  column "id" does not exist
  LINE 25: where id = 2085
                 ^
  compiled Code at target/run/campaign_perfomance/models/brand_performance/deals_dimension.sql
[0m15:15:06.371410 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106d1ab50>]}
[0m15:15:06.372124 [error] [Thread-1 (]: 2 of 5 ERROR creating sql view model danila.deals_dimension .................... [[31mERROR[0m in 0.64s]
[0m15:15:06.372735 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m15:15:06.373192 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m15:15:06.373773 [info ] [Thread-1 (]: 3 of 5 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m15:15:06.374566 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m15:15:06.374924 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m15:15:06.391610 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:06.395165 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 15:15:06.375160 => 15:15:06.394973
[0m15:15:06.395446 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m15:15:06.409212 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:06.413852 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:06.414060 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m15:15:06.414241 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:15:06.822172 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:15:06.823901 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:06.825199 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:15:22.182678 [debug] [Thread-1 (]: SQL status: SELECT 512089 in 15.0 seconds
[0m15:15:22.190275 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:22.190865 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m15:15:22.240473 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:22.247716 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:22.248289 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m15:15:22.297807 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:22.306354 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:15:22.306915 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:22.307332 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:15:22.357737 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:15:22.367103 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:15:22.367819 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m15:15:22.451019 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:15:22.455430 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 15:15:06.395605 => 15:15:22.455092
[0m15:15:22.456106 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m15:15:22.457880 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107028bd0>]}
[0m15:15:22.458927 [info ] [Thread-1 (]: 3 of 5 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 512089[0m in 16.08s]
[0m15:15:22.460005 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m15:15:22.460746 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m15:15:22.461654 [info ] [Thread-1 (]: 4 of 5 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m15:15:22.462916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m15:15:22.463393 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m15:15:22.475800 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m15:15:22.477180 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 15:15:22.463713 => 15:15:22.476926
[0m15:15:22.477586 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m15:15:22.481323 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m15:15:22.481867 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:15:22.482121 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m15:15:22.482367 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:15:22.914353 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:15:22.916060 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:15:22.917517 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:15:31.293354 [debug] [Thread-1 (]: SQL status: SELECT 146372 in 8.0 seconds
[0m15:15:31.299820 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:15:31.300408 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:15:31.350093 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:31.356512 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:15:31.357216 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:15:31.406246 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:31.407722 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:15:31.407973 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:15:31.408174 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:15:31.456915 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:15:31.461755 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:15:31.462521 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:15:31.535788 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:15:31.539633 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 15:15:22.477806 => 15:15:31.539296
[0m15:15:31.540278 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m15:15:31.541884 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e23a90>]}
[0m15:15:31.542858 [info ] [Thread-1 (]: 4 of 5 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 146372[0m in 9.08s]
[0m15:15:31.543883 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m15:15:31.544545 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m15:15:31.545446 [info ] [Thread-1 (]: 5 of 5 START sql view model danila.test ........................................ [RUN]
[0m15:15:31.546399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.test)
[0m15:15:31.546821 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m15:15:31.549815 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m15:15:31.550977 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 15:15:31.547085 => 15:15:31.550779
[0m15:15:31.551330 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m15:15:31.556271 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m15:15:31.557213 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:15:31.557583 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m15:15:31.557913 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:15:31.991333 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:15:31.991977 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:15:31.992473 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    -- with main as (
--     select
--         id
--         , user_id
--         , conversion_timestamp
--         , registrations
--         , deal_id
--         , date_parsed as date_cet
--         --, click_id
--         , geo as country_code
--         -- , registrations as signed_up
--         --, cpa_count as deposited_first_time
--         -- , gtee_count
--         , cpa_commissions as acquisition_commission
--         -- , total_commission
--         -- , gtee_commissions
--         -- , net_revenue
--         -- , revshare_commissions
--         , lower(adgroup_name) as ga_campaign_name
--         , case
--             when right(brand_name, 6) <> 'sports' then 'casino'
--             when right(brand_name, 6) = 'sports' then 'sports'
--             else 'other'
--         end as campaign_vertical
--         , case
--             when campaign_name::text = 'email' then brand_name || ' email'
--             when campaign_name::text = 'PA' then brand_name || ' PA'
--             else brand_name
--         end as brand_name

--         , case
--             when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
--             when campaign_name = 'ficashstormslots' then 'cashstormslots'
--             when campaign_name = 'goldenlion' then 'goldenliongames'
--             else campaign_name
--         end as campaign_name
--     from records
--     where
--         date_parsed > '2024-03-31'
--         and cpa_count > 0.5
--         --and deal_id is null
--         --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
--     --and user_id='ae4eb2f5ad8ebf29'
--     order by user_id, deal_id, date_parsed
-- )




-- select * from main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


SELECT id, user_id, date_parsed, date, brand_name, cpa_count, registrations, conversion_timestamp
FROM records
WHERE id='5393572' or id= '5393571'--date_parsed = '2024-05-16' AND user_id = '51a4a42eaaeb12f7'
--GROUP BY user_id, conversion_timestamp, date_parsed, brand_name, cpa_count, registrations
--HAVING COUNT(*) = 1
  );
[0m15:15:32.049553 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:15:32.054201 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:15:32.054743 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m15:15:32.107579 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:32.113235 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:15:32.113848 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m15:15:32.166796 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:15:32.171311 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:15:32.172212 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:15:32.172907 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:15:32.225645 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:15:32.231920 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:15:32.232546 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m15:15:32.286420 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:15:32.291024 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 15:15:31.551597 => 15:15:32.290531
[0m15:15:32.291573 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m15:15:32.293116 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd736e6de-afeb-43c8-a24b-44a34306e71a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f47a90>]}
[0m15:15:32.293907 [info ] [Thread-1 (]: 5 of 5 OK created sql view model danila.test ................................... [[32mCREATE VIEW[0m in 0.75s]
[0m15:15:32.294722 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m15:15:32.297001 [debug] [MainThread]: Using postgres connection "master"
[0m15:15:32.297459 [debug] [MainThread]: On master: BEGIN
[0m15:15:32.297751 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:15:32.784168 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:15:32.785275 [debug] [MainThread]: On master: COMMIT
[0m15:15:32.785893 [debug] [MainThread]: Using postgres connection "master"
[0m15:15:32.786419 [debug] [MainThread]: On master: COMMIT
[0m15:15:32.882006 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:15:32.882544 [debug] [MainThread]: On master: Close
[0m15:15:32.883366 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:15:32.883629 [debug] [MainThread]: Connection 'model.campaign_perfomance.test' was properly closed.
[0m15:15:32.883941 [info ] [MainThread]: 
[0m15:15:32.884293 [info ] [MainThread]: Finished running 3 view models, 2 table models in 0 hours 0 minutes and 30.05 seconds (30.05s).
[0m15:15:32.885347 [debug] [MainThread]: Command end result
[0m15:15:32.894221 [info ] [MainThread]: 
[0m15:15:32.894585 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:15:32.894821 [info ] [MainThread]: 
[0m15:15:32.895050 [error] [MainThread]: [33mDatabase Error in model deals_dimension (models/brand_performance/deals_dimension.sql)[0m
[0m15:15:32.895264 [error] [MainThread]:   column "id" does not exist
[0m15:15:32.895465 [error] [MainThread]:   LINE 25: where id = 2085
[0m15:15:32.895665 [error] [MainThread]:                  ^
[0m15:15:32.895856 [error] [MainThread]:   compiled Code at target/run/campaign_perfomance/models/brand_performance/deals_dimension.sql
[0m15:15:32.896060 [info ] [MainThread]: 
[0m15:15:32.896301 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m15:15:32.896720 [debug] [MainThread]: Command `dbt run` failed at 15:15:32.896649 after 30.19 seconds
[0m15:15:32.896969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1028c3190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1028c30d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10687f490>]}
[0m15:15:32.897200 [debug] [MainThread]: Flushing usage events
[0m15:18:40.960930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a55c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a5edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a5f490>]}


============================== 15:18:40.962841 | ce7bd8b5-1aa4-4806-ab44-7993505b3cbe ==============================
[0m15:18:40.962841 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:18:40.963170 [debug] [MainThread]: running dbt with arguments {'debug': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'version_check': 'True', 'static_parser': 'True', 'printer_width': '80', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'use_colors': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'log_format': 'default', 'partial_parse': 'True', 'no_print': 'None', 'quiet': 'False', 'warn_error': 'None', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False', 'fail_fast': 'False', 'introspect': 'True'}
[0m15:18:40.994554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e96190>]}
[0m15:18:41.001255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a80e10>]}
[0m15:18:41.001845 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:18:41.017009 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:18:41.060694 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:18:41.060897 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:18:41.061204 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.users
- models.marts
- models.brand_performance
- models.staging.scraper
[0m15:18:41.063708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fa08d0>]}
[0m15:18:41.069312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f04710>]}
[0m15:18:41.069570 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:18:41.069739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103f1e550>]}
[0m15:18:41.070657 [info ] [MainThread]: 
[0m15:18:41.071048 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:18:41.071605 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:18:41.075759 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:18:41.075934 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:18:41.076057 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:18:41.608673 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m15:18:41.610519 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:18:41.612273 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:18:41.616953 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:18:41.617233 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:18:41.617409 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:18:41.998384 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:18:41.999440 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:18:42.000189 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:18:42.051692 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:18:42.055516 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:18:42.102164 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:18:42.115898 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:42.116527 [debug] [MainThread]: On master: BEGIN
[0m15:18:42.116836 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:18:42.544081 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:42.544596 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:42.544984 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:18:42.605374 [debug] [MainThread]: SQL status: SELECT 52 in 0.0 seconds
[0m15:18:42.608087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ecbe50>]}
[0m15:18:42.608588 [debug] [MainThread]: On master: ROLLBACK
[0m15:18:42.661375 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:42.662399 [debug] [MainThread]: On master: BEGIN
[0m15:18:42.768724 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:18:42.769154 [debug] [MainThread]: On master: COMMIT
[0m15:18:42.769407 [debug] [MainThread]: Using postgres connection "master"
[0m15:18:42.769638 [debug] [MainThread]: On master: COMMIT
[0m15:18:42.822283 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:18:42.822924 [debug] [MainThread]: On master: Close
[0m15:18:42.823917 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:18:42.824308 [info ] [MainThread]: 
[0m15:18:42.829380 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:18:42.829784 [info ] [Thread-1 (]: 1 of 7 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m15:18:42.830369 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m15:18:42.830639 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m15:18:42.835375 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:42.835944 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 15:18:42.830811 => 15:18:42.835804
[0m15:18:42.836178 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m15:18:42.858269 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:42.858803 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:42.858985 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m15:18:42.859154 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:18:43.333430 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:43.334157 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:43.334634 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m15:18:43.395434 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:18:43.404990 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:43.405472 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m15:18:43.463373 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:18:43.467732 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:43.468257 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m15:18:43.526529 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:18:43.542743 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:18:43.543102 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:43.543329 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:18:43.601809 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:18:43.606200 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:18:43.606524 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m15:18:43.664900 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:18:43.666515 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 15:18:42.836324 => 15:18:43.666326
[0m15:18:43.666873 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m15:18:43.667784 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ff2310>]}
[0m15:18:43.668356 [info ] [Thread-1 (]: 1 of 7 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.84s]
[0m15:18:43.668885 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:18:43.669217 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m15:18:43.669672 [info ] [Thread-1 (]: 2 of 7 START sql view model danila.deals_dimension ............................. [RUN]
[0m15:18:43.670338 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m15:18:43.670634 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m15:18:43.672149 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m15:18:43.672860 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 15:18:43.670820 => 15:18:43.672703
[0m15:18:43.673132 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m15:18:43.676013 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m15:18:43.676467 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:18:43.676682 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m15:18:43.676892 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:18:44.101858 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:44.103312 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:18:44.104122 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select
        id as deal_id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group -- campaign_name? 
        , gap_campaign_name as google_ads_campaign_id -- ga_campaign_name? 
        , traffic_types as betting_type --(vertical) tables with the names
        , traffic_sources --(FB, Google, etc) tables with names
    from deals
)

select * from main
--where deal_id = 2085


-- select betting_type, traffic_sources, count(deal_id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m15:18:44.160493 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:18:44.168961 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:18:44.169818 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m15:18:44.223245 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:18:44.228589 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:18:44.229313 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m15:18:44.282741 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:18:44.286315 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:18:44.286956 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:18:44.287430 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:18:44.340144 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:18:44.349176 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:18:44.350145 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m15:18:44.404851 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:18:44.408265 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 15:18:43.673300 => 15:18:44.407924
[0m15:18:44.409084 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m15:18:44.410931 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ff2cd0>]}
[0m15:18:44.411871 [info ] [Thread-1 (]: 2 of 7 OK created sql view model danila.deals_dimension ........................ [[32mCREATE VIEW[0m in 0.74s]
[0m15:18:44.412739 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m15:18:44.413338 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m15:18:44.414050 [info ] [Thread-1 (]: 3 of 7 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m15:18:44.415047 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m15:18:44.415501 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m15:18:44.434206 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:18:44.436567 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 15:18:44.416098 => 15:18:44.436393
[0m15:18:44.436839 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m15:18:44.451740 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:18:44.452690 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:18:44.452951 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m15:18:44.453135 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:18:44.838347 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:18:44.839828 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:18:44.841099 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:19:00.213693 [debug] [Thread-1 (]: SQL status: SELECT 512089 in 15.0 seconds
[0m15:19:00.222633 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:00.223193 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m15:19:00.270196 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:00.276102 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:00.276618 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m15:19:00.323570 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:00.333300 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:19:00.333998 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:00.334427 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:19:00.380988 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:00.385904 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:00.386459 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m15:19:00.465782 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:19:00.469092 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 15:18:44.436998 => 15:19:00.468774
[0m15:19:00.469659 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m15:19:00.471825 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107197310>]}
[0m15:19:00.472781 [info ] [Thread-1 (]: 3 of 7 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 512089[0m in 16.06s]
[0m15:19:00.473714 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m15:19:00.474331 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m15:19:00.475136 [info ] [Thread-1 (]: 4 of 7 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m15:19:00.476075 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m15:19:00.476491 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m15:19:00.487915 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m15:19:00.489698 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 15:19:00.476936 => 15:19:00.489502
[0m15:19:00.490007 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m15:19:00.493340 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m15:19:00.493889 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:00.494144 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m15:19:00.494395 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:01.213921 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:19:01.215550 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:01.217224 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:19:09.985849 [debug] [Thread-1 (]: SQL status: SELECT 146372 in 9.0 seconds
[0m15:19:09.993661 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:09.994274 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:19:10.047766 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:10.053583 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:10.054159 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:19:10.106886 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:10.111605 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:19:10.112249 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:10.112979 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:19:10.166044 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:10.172086 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:10.172727 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:19:10.255256 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:19:10.259615 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 15:19:00.490191 => 15:19:10.258988
[0m15:19:10.260781 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m15:19:10.262834 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10702dd90>]}
[0m15:19:10.263823 [info ] [Thread-1 (]: 4 of 7 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 146372[0m in 9.79s]
[0m15:19:10.264726 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m15:19:10.265342 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:19:10.266101 [info ] [Thread-1 (]: 5 of 7 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:19:10.267067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m15:19:10.267552 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:19:10.272199 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:19:10.275450 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:19:10.267867 => 15:19:10.275088
[0m15:19:10.275903 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:19:10.279977 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:19:10.281208 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:10.281569 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:19:10.281829 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:10.713304 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:19:10.714805 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:10.716180 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:19:13.295701 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:19:13.306806 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:13.307395 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:19:13.360471 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:13.366987 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:13.367676 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:19:13.420795 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:13.425632 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:19:13.426155 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:13.426602 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:19:13.479338 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:13.483990 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:13.484815 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:19:13.558356 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:19:13.563610 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:19:10.276135 => 15:19:13.563156
[0m15:19:13.564379 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:19:13.566140 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f78dd0>]}
[0m15:19:13.567029 [info ] [Thread-1 (]: 5 of 7 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.30s]
[0m15:19:13.567940 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:19:13.568545 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m15:19:13.569489 [info ] [Thread-1 (]: 6 of 7 START sql view model danila.test ........................................ [RUN]
[0m15:19:13.570399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.test)
[0m15:19:13.570841 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m15:19:13.573953 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m15:19:13.576409 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 15:19:13.571149 => 15:19:13.576123
[0m15:19:13.576866 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m15:19:13.581061 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m15:19:13.581684 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:19:13.581980 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m15:19:13.582262 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:14.059980 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:19:14.061995 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:19:14.063362 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    -- with main as (
--     select
--         id
--         , user_id
--         , conversion_timestamp
--         , registrations
--         , deal_id
--         , date_parsed as date_cet
--         --, click_id
--         , geo as country_code
--         -- , registrations as signed_up
--         --, cpa_count as deposited_first_time
--         -- , gtee_count
--         , cpa_commissions as acquisition_commission
--         -- , total_commission
--         -- , gtee_commissions
--         -- , net_revenue
--         -- , revshare_commissions
--         , lower(adgroup_name) as ga_campaign_name
--         , case
--             when right(brand_name, 6) <> 'sports' then 'casino'
--             when right(brand_name, 6) = 'sports' then 'sports'
--             else 'other'
--         end as campaign_vertical
--         , case
--             when campaign_name::text = 'email' then brand_name || ' email'
--             when campaign_name::text = 'PA' then brand_name || ' PA'
--             else brand_name
--         end as brand_name

--         , case
--             when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
--             when campaign_name = 'ficashstormslots' then 'cashstormslots'
--             when campaign_name = 'goldenlion' then 'goldenliongames'
--             else campaign_name
--         end as campaign_name
--     from records
--     where
--         date_parsed > '2024-03-31'
--         and cpa_count > 0.5
--         --and deal_id is null
--         --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
--     --and user_id='ae4eb2f5ad8ebf29'
--     order by user_id, deal_id, date_parsed
-- )




-- select * from main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


SELECT id, user_id, date_parsed, date, brand_name, cpa_count, registrations, conversion_timestamp
FROM records
WHERE id='5393572' or id= '5393571'--date_parsed = '2024-05-16' AND user_id = '51a4a42eaaeb12f7'
--GROUP BY user_id, conversion_timestamp, date_parsed, brand_name, cpa_count, registrations
--HAVING COUNT(*) = 1
  );
[0m15:19:14.126192 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:19:14.130336 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:19:14.130747 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m15:19:14.189614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:14.191888 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:19:14.192141 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m15:19:14.250215 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:14.251728 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:19:14.252044 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:19:14.252330 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:19:14.312039 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:14.318026 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:19:14.318638 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m15:19:14.379499 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:19:14.382920 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 15:19:13.577122 => 15:19:14.382573
[0m15:19:14.383589 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m15:19:14.385492 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1070f7bd0>]}
[0m15:19:14.386633 [info ] [Thread-1 (]: 6 of 7 OK created sql view model danila.test ................................... [[32mCREATE VIEW[0m in 0.82s]
[0m15:19:14.387768 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m15:19:14.388560 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:19:14.389512 [info ] [Thread-1 (]: 7 of 7 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:19:14.390623 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.first_deposits_fct)
[0m15:19:14.391105 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:19:14.395501 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:19:14.397633 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:19:14.391418 => 15:19:14.397313
[0m15:19:14.398092 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:19:14.403012 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:19:14.403760 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:19:14.404077 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:19:14.404356 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:14.939908 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:19:14.941759 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:19:14.943329 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:19:15.014989 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:19:15.023172 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:19:15.023721 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:19:15.089775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:15.094419 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:19:15.095179 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:19:15.095821 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:19:15.161292 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:15.172278 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:19:15.172851 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:19:15.239308 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:19:15.243212 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:19:14.398348 => 15:19:15.242869
[0m15:19:15.243880 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:19:15.245870 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce7bd8b5-1aa4-4806-ab44-7993505b3cbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a49250>]}
[0m15:19:15.246980 [info ] [Thread-1 (]: 7 of 7 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.86s]
[0m15:19:15.248129 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:19:15.250516 [debug] [MainThread]: Using postgres connection "master"
[0m15:19:15.250932 [debug] [MainThread]: On master: BEGIN
[0m15:19:15.251291 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:19:15.776412 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m15:19:15.777993 [debug] [MainThread]: On master: COMMIT
[0m15:19:15.779309 [debug] [MainThread]: Using postgres connection "master"
[0m15:19:15.780401 [debug] [MainThread]: On master: COMMIT
[0m15:19:15.845906 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:19:15.847364 [debug] [MainThread]: On master: Close
[0m15:19:15.850115 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:19:15.850722 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:19:15.851461 [info ] [MainThread]: 
[0m15:19:15.852214 [info ] [MainThread]: Finished running 4 view models, 3 table models in 0 hours 0 minutes and 34.78 seconds (34.78s).
[0m15:19:15.854873 [debug] [MainThread]: Command end result
[0m15:19:15.867994 [info ] [MainThread]: 
[0m15:19:15.868497 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:19:15.868821 [info ] [MainThread]: 
[0m15:19:15.869162 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m15:19:15.869775 [debug] [MainThread]: Command `dbt run` succeeded at 15:19:15.869671 after 34.92 seconds
[0m15:19:15.870122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a84d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f7b050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102a7f0d0>]}
[0m15:19:15.870448 [debug] [MainThread]: Flushing usage events
[0m15:19:29.161562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060927d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106092010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060aac10>]}


============================== 15:19:29.163122 | 99b11bb0-d891-4ebf-87fb-7aaa088efa4e ==============================
[0m15:19:29.163122 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:19:29.163449 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'log_cache_events': 'False', 'profiles_dir': '/Users/danila/.dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'warn_error': 'None', 'log_format': 'default', 'indirect_selection': 'eager', 'introspect': 'True', 'write_json': 'True', 'version_check': 'True', 'use_colors': 'True', 'no_print': 'None', 'partial_parse': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'printer_width': '80', 'fail_fast': 'False', 'static_parser': 'True', 'target_path': 'None', 'quiet': 'False', 'send_anonymous_usage_stats': 'True'}
[0m15:19:29.192969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a4e350>]}
[0m15:19:29.199512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060b7f10>]}
[0m15:19:29.199959 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:19:29.214074 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:19:29.251678 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:19:29.251878 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:19:29.252196 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.brand_performance
- models.staging.scraper
- models.marts
- models.users
[0m15:19:29.254885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064edb50>]}
[0m15:19:29.259392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063fc790>]}
[0m15:19:29.259566 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:19:29.259719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1024ea950>]}
[0m15:19:29.260504 [info ] [MainThread]: 
[0m15:19:29.260822 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:19:29.261338 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:19:29.265269 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:19:29.265409 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:19:29.265521 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:19:29.773278 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m15:19:29.778249 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:19:29.782448 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:19:29.790082 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:19:29.790690 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:19:29.791206 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:19:30.296302 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:19:30.297913 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:19:30.299025 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:19:30.364609 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:19:30.367810 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:19:30.429375 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:19:30.437201 [debug] [MainThread]: Using postgres connection "master"
[0m15:19:30.437480 [debug] [MainThread]: On master: BEGIN
[0m15:19:30.437686 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:19:30.820632 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:19:30.822100 [debug] [MainThread]: Using postgres connection "master"
[0m15:19:30.822874 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:19:30.877003 [debug] [MainThread]: SQL status: SELECT 52 in 0.0 seconds
[0m15:19:30.882394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a09a10>]}
[0m15:19:30.883464 [debug] [MainThread]: On master: ROLLBACK
[0m15:19:30.930924 [debug] [MainThread]: Using postgres connection "master"
[0m15:19:30.931771 [debug] [MainThread]: On master: BEGIN
[0m15:19:31.025769 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:19:31.026964 [debug] [MainThread]: On master: COMMIT
[0m15:19:31.027651 [debug] [MainThread]: Using postgres connection "master"
[0m15:19:31.028216 [debug] [MainThread]: On master: COMMIT
[0m15:19:31.074823 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:19:31.075843 [debug] [MainThread]: On master: Close
[0m15:19:31.077725 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:19:31.078465 [info ] [MainThread]: 
[0m15:19:31.089344 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:19:31.090063 [info ] [Thread-1 (]: 1 of 7 START sql view model danila.clicks_to_clients_fct ....................... [RUN]
[0m15:19:31.091166 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m15:19:31.091726 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m15:19:31.098889 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.099812 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 15:19:31.092002 => 15:19:31.099608
[0m15:19:31.100153 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m15:19:31.124983 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.125555 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.125757 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m15:19:31.125935 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:31.560094 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:19:31.560411 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.560618 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m15:19:31.617320 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:19:31.622762 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.623009 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m15:19:31.676900 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:31.679634 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.679956 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m15:19:31.732962 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:31.753855 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:19:31.754146 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.754392 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:19:31.807039 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:31.814965 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:19:31.815400 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m15:19:31.870402 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:19:31.874827 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 15:19:31.100356 => 15:19:31.874455
[0m15:19:31.875527 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m15:19:31.877256 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f57f90>]}
[0m15:19:31.878268 [info ] [Thread-1 (]: 1 of 7 OK created sql view model danila.clicks_to_clients_fct .................. [[32mCREATE VIEW[0m in 0.79s]
[0m15:19:31.879214 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:19:31.879791 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m15:19:31.880559 [info ] [Thread-1 (]: 2 of 7 START sql view model danila.deals_dimension ............................. [RUN]
[0m15:19:31.881637 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m15:19:31.882081 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m15:19:31.884747 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m15:19:31.885834 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 15:19:31.882359 => 15:19:31.885584
[0m15:19:31.886254 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m15:19:31.890287 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m15:19:31.891335 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:19:31.891680 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m15:19:31.891971 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:32.280998 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:19:32.282975 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:19:32.284359 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select
        id as deal_id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group -- campaign_name? 
        , gap_campaign_name as google_ads_campaign_id -- ga_campaign_name? 
        , traffic_types as betting_type --(vertical) tables with the names
        , traffic_sources --(FB, Google, etc) tables with names
    from deals
)

select * from main
--where deal_id = 2085


-- select betting_type, traffic_sources, count(deal_id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m15:19:32.335410 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:19:32.344577 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:19:32.345134 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m15:19:32.392943 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:32.398678 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:19:32.399402 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m15:19:32.447916 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:32.452681 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:19:32.453296 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:19:32.453803 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:19:32.501007 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:32.507954 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:19:32.508820 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m15:19:32.557864 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:19:32.562689 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 15:19:31.886500 => 15:19:32.562061
[0m15:19:32.563577 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m15:19:32.565031 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063d3750>]}
[0m15:19:32.565833 [info ] [Thread-1 (]: 2 of 7 OK created sql view model danila.deals_dimension ........................ [[32mCREATE VIEW[0m in 0.68s]
[0m15:19:32.566757 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m15:19:32.567505 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m15:19:32.568331 [info ] [Thread-1 (]: 3 of 7 START sql table model danila.outclick_by_brand_int ...................... [RUN]
[0m15:19:32.569156 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m15:19:32.569521 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m15:19:32.586343 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:32.587789 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 15:19:32.569763 => 15:19:32.587618
[0m15:19:32.588031 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m15:19:32.602872 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:32.603314 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:32.603490 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m15:19:32.603653 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:33.036694 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:19:33.038608 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:33.040898 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:19:48.625852 [debug] [Thread-1 (]: SQL status: SELECT 512089 in 16.0 seconds
[0m15:19:48.639380 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:48.640159 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m15:19:48.694027 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:48.704001 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:48.705019 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m15:19:48.758498 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:48.772742 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:19:48.773459 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:48.774217 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:19:48.827162 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:48.836386 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:19:48.837353 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m15:19:48.922569 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:19:48.927649 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 15:19:32.588179 => 15:19:48.927004
[0m15:19:48.928803 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m15:19:48.931089 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106668610>]}
[0m15:19:48.932452 [info ] [Thread-1 (]: 3 of 7 OK created sql table model danila.outclick_by_brand_int ................. [[32mSELECT 512089[0m in 16.36s]
[0m15:19:48.933532 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m15:19:48.934256 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m15:19:48.935177 [info ] [Thread-1 (]: 4 of 7 START sql table model danila.outclick_cost_int .......................... [RUN]
[0m15:19:48.936516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m15:19:48.937135 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m15:19:48.950944 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m15:19:48.953751 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 15:19:48.937524 => 15:19:48.953400
[0m15:19:48.954267 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m15:19:48.958653 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m15:19:48.959390 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:48.959697 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m15:19:48.959991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:49.548281 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:19:49.551412 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:49.553039 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:19:58.215937 [debug] [Thread-1 (]: SQL status: SELECT 146372 in 9.0 seconds
[0m15:19:58.227250 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:58.228100 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:19:58.284519 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:58.291790 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:58.293031 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:19:58.349228 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:19:58.351844 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:19:58.352347 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:58.352755 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:19:58.408022 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:19:58.412101 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:19:58.412637 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:19:58.499044 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:19:58.503912 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 15:19:48.954545 => 15:19:58.503288
[0m15:19:58.505071 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m15:19:58.507716 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064387d0>]}
[0m15:19:58.508864 [info ] [Thread-1 (]: 4 of 7 OK created sql table model danila.outclick_cost_int ..................... [[32mSELECT 146372[0m in 9.57s]
[0m15:19:58.509489 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m15:19:58.509898 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:19:58.510371 [info ] [Thread-1 (]: 5 of 7 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:19:58.511035 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m15:19:58.511335 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:19:58.518169 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:19:58.520936 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:19:58.511521 => 15:19:58.520543
[0m15:19:58.521539 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:19:58.527264 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:19:58.528602 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:58.529284 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:19:58.529636 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:19:59.109358 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:19:59.111138 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:19:59.112934 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:20:01.800138 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:20:01.812312 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:20:01.813140 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:20:01.866676 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:20:01.876583 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:20:01.877494 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:20:01.931277 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:20:01.937469 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:20:01.938670 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:20:01.939580 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:20:01.992468 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:20:02.001684 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:20:02.002693 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:20:02.081732 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:20:02.086773 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:19:58.521916 => 15:20:02.086163
[0m15:20:02.087946 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:20:02.090817 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064fff50>]}
[0m15:20:02.092526 [info ] [Thread-1 (]: 5 of 7 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.58s]
[0m15:20:02.094129 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:20:02.095036 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m15:20:02.096391 [info ] [Thread-1 (]: 6 of 7 START sql view model danila.test ........................................ [RUN]
[0m15:20:02.097921 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.test)
[0m15:20:02.098669 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m15:20:02.103118 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m15:20:02.104773 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 15:20:02.099205 => 15:20:02.104455
[0m15:20:02.105336 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m15:20:02.110855 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m15:20:02.112204 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:20:02.112642 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m15:20:02.113037 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:20:02.962293 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:20:02.964049 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:20:02.965525 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    -- with main as (
--     select
--         id
--         , user_id
--         , conversion_timestamp
--         , registrations
--         , deal_id
--         , date_parsed as date_cet
--         --, click_id
--         , geo as country_code
--         -- , registrations as signed_up
--         --, cpa_count as deposited_first_time
--         -- , gtee_count
--         , cpa_commissions as acquisition_commission
--         -- , total_commission
--         -- , gtee_commissions
--         -- , net_revenue
--         -- , revshare_commissions
--         , lower(adgroup_name) as ga_campaign_name
--         , case
--             when right(brand_name, 6) <> 'sports' then 'casino'
--             when right(brand_name, 6) = 'sports' then 'sports'
--             else 'other'
--         end as campaign_vertical
--         , case
--             when campaign_name::text = 'email' then brand_name || ' email'
--             when campaign_name::text = 'PA' then brand_name || ' PA'
--             else brand_name
--         end as brand_name

--         , case
--             when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
--             when campaign_name = 'ficashstormslots' then 'cashstormslots'
--             when campaign_name = 'goldenlion' then 'goldenliongames'
--             else campaign_name
--         end as campaign_name
--     from records
--     where
--         date_parsed > '2024-03-31'
--         and cpa_count > 0.5
--         --and deal_id is null
--         --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
--     --and user_id='ae4eb2f5ad8ebf29'
--     order by user_id, deal_id, date_parsed
-- )




-- select * from main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


SELECT id, user_id, date_parsed, date, brand_name, cpa_count, registrations, conversion_timestamp
FROM records
WHERE id='5393572' or id= '5393571'--date_parsed = '2024-05-16' AND user_id = '51a4a42eaaeb12f7'
--GROUP BY user_id, conversion_timestamp, date_parsed, brand_name, cpa_count, registrations
--HAVING COUNT(*) = 1
  );
[0m15:20:03.021648 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:20:03.029703 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:20:03.030793 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m15:20:03.084640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:20:03.094761 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:20:03.095636 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m15:20:03.149371 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:20:03.155070 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:20:03.156211 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:20:03.157278 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:20:03.210807 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:20:03.220350 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:20:03.221582 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m15:20:03.275972 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:20:03.280551 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 15:20:02.105666 => 15:20:03.279961
[0m15:20:03.281638 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m15:20:03.284212 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106648850>]}
[0m15:20:03.285886 [info ] [Thread-1 (]: 6 of 7 OK created sql view model danila.test ................................... [[32mCREATE VIEW[0m in 1.19s]
[0m15:20:03.287507 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m15:20:03.288424 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:20:03.289464 [info ] [Thread-1 (]: 7 of 7 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:20:03.291004 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now model.campaign_perfomance.first_deposits_fct)
[0m15:20:03.291713 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:20:03.298196 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:20:03.299566 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:20:03.292215 => 15:20:03.299335
[0m15:20:03.300024 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:20:03.305779 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:20:03.307196 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:20:03.307624 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:20:03.308005 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:20:03.723272 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:20:03.724337 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:20:03.724955 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:20:03.777600 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:20:03.786504 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:20:03.787218 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:20:03.834382 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:20:03.839936 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:20:03.841066 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:20:03.842060 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:20:03.890209 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:20:03.905196 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:20:03.906386 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:20:03.953373 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:20:03.957724 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:20:03.300311 => 15:20:03.957146
[0m15:20:03.958817 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:20:03.961544 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '99b11bb0-d891-4ebf-87fb-7aaa088efa4e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106879e90>]}
[0m15:20:03.963267 [info ] [Thread-1 (]: 7 of 7 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.67s]
[0m15:20:03.964865 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:20:03.967986 [debug] [MainThread]: Using postgres connection "master"
[0m15:20:03.968512 [debug] [MainThread]: On master: BEGIN
[0m15:20:03.968937 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:20:04.448005 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:20:04.448803 [debug] [MainThread]: On master: COMMIT
[0m15:20:04.449160 [debug] [MainThread]: Using postgres connection "master"
[0m15:20:04.449427 [debug] [MainThread]: On master: COMMIT
[0m15:20:04.508221 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:20:04.509291 [debug] [MainThread]: On master: Close
[0m15:20:04.511745 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:20:04.512555 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:20:04.513561 [info ] [MainThread]: 
[0m15:20:04.514674 [info ] [MainThread]: Finished running 4 view models, 3 table models in 0 hours 0 minutes and 35.25 seconds (35.25s).
[0m15:20:04.518416 [debug] [MainThread]: Command end result
[0m15:20:04.537049 [info ] [MainThread]: 
[0m15:20:04.537996 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:20:04.538479 [info ] [MainThread]: 
[0m15:20:04.538939 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m15:20:04.540196 [debug] [MainThread]: Command `dbt run` succeeded at 15:20:04.539965 after 35.39 seconds
[0m15:20:04.540805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f682d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045b44d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100dc4e50>]}
[0m15:20:04.541251 [debug] [MainThread]: Flushing usage events
[0m15:26:42.912317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b5e210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b52010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b63c90>]}


============================== 15:26:42.913942 | a7628635-0fa6-4c74-b79f-9572532a0ec7 ==============================
[0m15:26:42.913942 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:26:42.914236 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'warn_error': 'None', 'write_json': 'True', 'static_parser': 'True', 'partial_parse': 'True', 'version_check': 'True', 'printer_width': '80', 'log_path': '/Users/danila/github/dbt/logs', 'cache_selected_only': 'False', 'profiles_dir': '/Users/danila/.dbt', 'debug': 'False', 'send_anonymous_usage_stats': 'True', 'quiet': 'False', 'target_path': 'None', 'introspect': 'True', 'log_cache_events': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_format': 'default', 'use_colors': 'True', 'indirect_selection': 'eager'}
[0m15:26:42.946044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b50dd0>]}
[0m15:26:42.952660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b73850>]}
[0m15:26:42.953113 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:26:42.967848 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:26:43.011974 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:26:43.012230 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:26:43.012553 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.staging.scraper
- models.brand_performance
- models.marts
- models.users
[0m15:26:43.015140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090e4810>]}
[0m15:26:43.022322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10902b810>]}
[0m15:26:43.022654 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:26:43.022832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106026710>]}
[0m15:26:43.023517 [info ] [MainThread]: 
[0m15:26:43.023872 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:26:43.024322 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:26:43.029067 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:26:43.029320 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:26:43.029447 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:26:43.638322 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m15:26:43.642956 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:26:43.646090 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:26:43.653564 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:26:43.654050 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:26:43.654314 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:44.180682 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:26:44.181373 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:26:44.181748 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:26:44.256677 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:26:44.260529 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:26:44.325311 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:26:44.341236 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:44.341972 [debug] [MainThread]: On master: BEGIN
[0m15:26:44.342412 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:26:44.768904 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:26:44.770161 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:44.770894 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:26:44.825987 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:26:44.830820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b5e1d0>]}
[0m15:26:44.832211 [debug] [MainThread]: On master: ROLLBACK
[0m15:26:44.879005 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:44.880027 [debug] [MainThread]: On master: BEGIN
[0m15:26:44.973593 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:26:44.974633 [debug] [MainThread]: On master: COMMIT
[0m15:26:44.975539 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:44.976458 [debug] [MainThread]: On master: COMMIT
[0m15:26:45.022790 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:26:45.023351 [debug] [MainThread]: On master: Close
[0m15:26:45.025808 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:26:45.026920 [info ] [MainThread]: 
[0m15:26:45.035795 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:26:45.036610 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:26:45.037660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.stg_scraper__records)
[0m15:26:45.038125 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:26:45.048243 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:26:45.049627 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:26:45.038456 => 15:26:45.049330
[0m15:26:45.050050 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:26:45.076816 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:26:45.077850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:45.078087 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:26:45.078263 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:26:45.465613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:26:45.465982 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:45.466349 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:26:48.168510 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:26:48.182761 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:48.183348 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:26:48.230200 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:26:48.236738 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:48.237487 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:26:48.285005 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:26:48.312945 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:26:48.313430 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:48.313768 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:26:48.360239 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:26:48.368788 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:48.369260 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:26:48.437684 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:26:48.442431 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:26:45.050291 => 15:26:48.442057
[0m15:26:48.443235 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:26:48.445396 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109215b50>]}
[0m15:26:48.446665 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.41s]
[0m15:26:48.447885 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:26:48.449545 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:26:48.450173 [info ] [Thread-1 (]: 2 of 2 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:26:48.451140 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m15:26:48.451599 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:26:48.456118 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:26:48.457343 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:26:48.451913 => 15:26:48.457087
[0m15:26:48.457761 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:26:48.474755 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:26:48.475307 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:26:48.475532 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:26:48.475740 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:26:49.002917 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:26:49.004584 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:26:49.005949 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:26:49.075279 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:26:49.083212 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:26:49.083727 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:26:49.148782 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:26:49.151427 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:26:49.152000 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:26:49.152435 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:26:49.216922 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:26:49.223500 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:26:49.223971 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:26:49.288758 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:26:49.293108 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:26:48.458038 => 15:26:49.292490
[0m15:26:49.294276 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:26:49.296797 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7628635-0fa6-4c74-b79f-9572532a0ec7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109201e90>]}
[0m15:26:49.297612 [info ] [Thread-1 (]: 2 of 2 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.85s]
[0m15:26:49.298518 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:26:49.300524 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:49.300856 [debug] [MainThread]: On master: BEGIN
[0m15:26:49.301133 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:26:49.774621 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:26:49.775206 [debug] [MainThread]: On master: COMMIT
[0m15:26:49.775541 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:49.775828 [debug] [MainThread]: On master: COMMIT
[0m15:26:49.833349 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:26:49.833790 [debug] [MainThread]: On master: Close
[0m15:26:49.834632 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:26:49.834940 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:26:49.835272 [info ] [MainThread]: 
[0m15:26:49.835668 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.81 seconds (6.81s).
[0m15:26:49.836533 [debug] [MainThread]: Command end result
[0m15:26:49.848436 [info ] [MainThread]: 
[0m15:26:49.848878 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:26:49.849160 [info ] [MainThread]: 
[0m15:26:49.849451 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:26:49.849982 [debug] [MainThread]: Command `dbt run` succeeded at 15:26:49.849897 after 6.95 seconds
[0m15:26:49.850280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b73350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b8ced0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b87210>]}
[0m15:26:49.850567 [debug] [MainThread]: Flushing usage events
[0m15:26:55.502136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dce210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dc2010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dd37d0>]}


============================== 15:26:55.503439 | 8e884d25-f90d-4f10-b23e-aac06c9b7088 ==============================
[0m15:26:55.503439 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:26:55.503757 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'log_format': 'default', 'version_check': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'partial_parse': 'True', 'quiet': 'False', 'indirect_selection': 'eager', 'printer_width': '80', 'use_colors': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'no_print': 'None', 'introspect': 'True', 'static_parser': 'True', 'cache_selected_only': 'False', 'log_cache_events': 'False', 'debug': 'False', 'profiles_dir': '/Users/danila/.dbt'}
[0m15:26:55.531598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dc1110>]}
[0m15:26:55.537853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10924d3d0>]}
[0m15:26:55.538108 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:26:55.552126 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:26:55.589987 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:26:55.590222 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:26:55.590569 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.campaign_performance.marts
- models.campaign_performance.staging.scraper
- models.campaign_performance.users
- models.campaign_performance.brand_performance
[0m15:26:55.593044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10923ff10>]}
[0m15:26:55.597527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10929bfd0>]}
[0m15:26:55.597742 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:26:55.597910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106296710>]}
[0m15:26:55.598517 [info ] [MainThread]: 
[0m15:26:55.598842 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:26:55.599257 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:26:55.603027 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:26:55.603147 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:26:55.603246 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:26:55.992524 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:26:55.996025 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:26:55.999350 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:26:56.007478 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:26:56.007932 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:26:56.008159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:56.483399 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:26:56.484951 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:26:56.485669 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:26:56.897981 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:26:56.901504 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:26:56.959661 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:26:56.973632 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:56.974078 [debug] [MainThread]: On master: BEGIN
[0m15:26:56.974424 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:26:57.407087 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:26:57.408677 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:57.410046 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:26:57.472137 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:26:57.478262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109285490>]}
[0m15:26:57.479196 [debug] [MainThread]: On master: ROLLBACK
[0m15:26:57.532086 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:57.533148 [debug] [MainThread]: On master: BEGIN
[0m15:26:57.639200 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:26:57.640397 [debug] [MainThread]: On master: COMMIT
[0m15:26:57.641338 [debug] [MainThread]: Using postgres connection "master"
[0m15:26:57.642037 [debug] [MainThread]: On master: COMMIT
[0m15:26:57.694352 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:26:57.695389 [debug] [MainThread]: On master: Close
[0m15:26:57.698022 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:26:57.698731 [info ] [MainThread]: 
[0m15:26:57.707491 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:26:57.708270 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:26:57.709245 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.stg_scraper__records)
[0m15:26:57.709712 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:26:57.719587 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:26:57.721054 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:26:57.710030 => 15:26:57.720826
[0m15:26:57.721438 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:26:57.746812 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:26:57.747308 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:57.747488 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:26:57.747655 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:26:58.151239 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:26:58.153135 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:26:58.154787 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:27:00.720615 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:27:00.735501 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:27:00.736113 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:27:00.785634 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:27:00.791880 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:27:00.792541 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:27:00.842115 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:27:00.865640 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:27:00.866068 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:27:00.866305 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:27:00.915438 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:27:00.921008 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:27:00.921404 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:27:00.993672 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:27:00.997642 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:26:57.721628 => 15:27:00.997334
[0m15:27:00.998337 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:27:00.999938 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10947d110>]}
[0m15:27:01.000861 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.29s]
[0m15:27:01.001678 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:27:01.002926 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:27:01.003635 [info ] [Thread-1 (]: 2 of 2 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:27:01.004569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m15:27:01.004959 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:27:01.008295 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:27:01.009381 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:27:01.005215 => 15:27:01.009186
[0m15:27:01.009709 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:27:01.024387 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:27:01.024904 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:27:01.025128 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:27:01.025334 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:27:01.520483 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:27:01.521585 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:27:01.522289 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:27:01.587264 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:27:01.595165 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:27:01.596030 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:27:01.657710 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:27:01.662436 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:27:01.663554 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:27:01.664663 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:27:01.725658 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:27:01.732154 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:27:01.732902 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:27:01.794643 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:27:01.798786 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:27:01.009908 => 15:27:01.798428
[0m15:27:01.799497 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:27:01.801524 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8e884d25-f90d-4f10-b23e-aac06c9b7088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109449c90>]}
[0m15:27:01.802632 [info ] [Thread-1 (]: 2 of 2 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.80s]
[0m15:27:01.803811 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:27:01.806324 [debug] [MainThread]: Using postgres connection "master"
[0m15:27:01.806796 [debug] [MainThread]: On master: BEGIN
[0m15:27:01.807191 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:27:02.263041 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:27:02.264715 [debug] [MainThread]: On master: COMMIT
[0m15:27:02.265532 [debug] [MainThread]: Using postgres connection "master"
[0m15:27:02.266139 [debug] [MainThread]: On master: COMMIT
[0m15:27:02.321355 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:27:02.322472 [debug] [MainThread]: On master: Close
[0m15:27:02.325191 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:27:02.325975 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:27:02.326433 [info ] [MainThread]: 
[0m15:27:02.326983 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.73 seconds (6.73s).
[0m15:27:02.328099 [debug] [MainThread]: Command end result
[0m15:27:02.341158 [info ] [MainThread]: 
[0m15:27:02.341698 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:27:02.342011 [info ] [MainThread]: 
[0m15:27:02.342354 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:27:02.342982 [debug] [MainThread]: Command `dbt run` succeeded at 15:27:02.342878 after 6.85 seconds
[0m15:27:02.343350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c98390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104dfced0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104df7150>]}
[0m15:27:02.343675 [debug] [MainThread]: Flushing usage events
[0m15:28:25.509072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107639810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10763fd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107643350>]}


============================== 15:28:25.510902 | 2cdfd912-4487-41ee-af17-404281280a34 ==============================
[0m15:28:25.510902 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:28:25.511254 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'indirect_selection': 'eager', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'fail_fast': 'False', 'printer_width': '80', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'use_colors': 'True', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'version_check': 'True', 'target_path': 'None', 'no_print': 'None', 'write_json': 'True', 'profiles_dir': '/Users/danila/.dbt', 'send_anonymous_usage_stats': 'True'}
[0m15:28:25.542624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107665190>]}
[0m15:28:25.549050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107abad10>]}
[0m15:28:25.549534 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:28:25.563535 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:28:25.611659 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:28:25.611878 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:28:25.612203 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.campaign_performance.staging.scraper
- models.campaign_performance.marts
- models.campaign_performance.brand_performance
- models.campaign_performance.users
[0m15:28:25.614797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bc03d0>]}
[0m15:28:25.620149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107aeb810>]}
[0m15:28:25.620389 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:28:25.620555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b02710>]}
[0m15:28:25.621237 [info ] [MainThread]: 
[0m15:28:25.621598 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:28:25.622090 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:28:25.626296 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:28:25.626467 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:28:25.626588 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:28:26.134628 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m15:28:26.138376 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:28:26.142140 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:28:26.150319 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:28:26.150662 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:28:26.150912 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:28:26.648199 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:28:26.649876 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:28:26.650461 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:28:26.715732 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:28:26.719471 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:28:26.780781 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:28:26.788421 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:26.788667 [debug] [MainThread]: On master: BEGIN
[0m15:28:26.788785 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:28:27.235644 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:28:27.236231 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:27.236668 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:28:27.302810 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:28:27.307114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b0fe50>]}
[0m15:28:27.307945 [debug] [MainThread]: On master: ROLLBACK
[0m15:28:27.361844 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:27.362634 [debug] [MainThread]: On master: BEGIN
[0m15:28:27.472015 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:28:27.472991 [debug] [MainThread]: On master: COMMIT
[0m15:28:27.473962 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:27.474481 [debug] [MainThread]: On master: COMMIT
[0m15:28:27.528940 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:28:27.529561 [debug] [MainThread]: On master: Close
[0m15:28:27.531201 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:28:27.532403 [info ] [MainThread]: 
[0m15:28:27.541600 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:28:27.542412 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:28:27.543450 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.stg_scraper__records)
[0m15:28:27.543937 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:28:27.553820 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:28:27.554994 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:28:27.544264 => 15:28:27.554773
[0m15:28:27.555374 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:28:27.581836 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:28:27.583027 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:27.583260 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:28:27.583459 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:28:28.055082 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:28:28.056997 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:28.058737 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:28:30.701378 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:28:30.716198 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:30.716814 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:28:30.772713 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:28:30.778179 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:30.778931 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:28:30.834381 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:28:30.862142 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:28:30.862544 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:30.862822 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:28:30.917171 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:28:30.923004 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:30.923406 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:28:31.006952 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:28:31.011791 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:28:27.555590 => 15:28:31.011477
[0m15:28:31.012432 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:28:31.014033 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107121b50>]}
[0m15:28:31.014980 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.47s]
[0m15:28:31.015782 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:28:31.017099 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:28:31.017948 [info ] [Thread-1 (]: 2 of 2 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:28:31.018857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m15:28:31.019239 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:28:31.022465 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:28:31.023394 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:28:31.019490 => 15:28:31.023197
[0m15:28:31.023726 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:28:31.038717 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:28:31.042852 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:31.043109 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:28:31.043321 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:28:31.468604 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:28:31.468871 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:31.469046 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:28:31.525312 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:28:31.526769 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:31.526927 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:28:31.578575 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:28:31.579337 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:28:31.579480 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:31.579605 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:28:31.651161 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:28:31.652518 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:31.652706 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:28:31.705135 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:28:31.706316 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:28:31.023923 => 15:28:31.706184
[0m15:28:31.706562 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:28:31.707173 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2cdfd912-4487-41ee-af17-404281280a34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b04d90>]}
[0m15:28:31.707538 [info ] [Thread-1 (]: 2 of 2 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.69s]
[0m15:28:31.707931 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:28:31.708790 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:31.709014 [debug] [MainThread]: On master: BEGIN
[0m15:28:31.709188 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:28:32.140583 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:28:32.141767 [debug] [MainThread]: On master: COMMIT
[0m15:28:32.142300 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:32.142767 [debug] [MainThread]: On master: COMMIT
[0m15:28:32.194725 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:28:32.195641 [debug] [MainThread]: On master: Close
[0m15:28:32.197109 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:28:32.197522 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:28:32.197994 [info ] [MainThread]: 
[0m15:28:32.198529 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.58 seconds (6.58s).
[0m15:28:32.199673 [debug] [MainThread]: Command end result
[0m15:28:32.213890 [info ] [MainThread]: 
[0m15:28:32.214418 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:28:32.214702 [info ] [MainThread]: 
[0m15:28:32.215007 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:28:32.215506 [debug] [MainThread]: Command `dbt run` succeeded at 15:28:32.215418 after 6.72 seconds
[0m15:28:32.215800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107504050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d86ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103598b10>]}
[0m15:28:32.216078 [debug] [MainThread]: Flushing usage events
[0m15:28:34.658625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea2210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea7550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea7c10>]}


============================== 15:28:34.659833 | 6c9091af-04a1-4432-b16c-74b4559732be ==============================
[0m15:28:34.659833 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:28:34.660133 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'indirect_selection': 'eager', 'introspect': 'True', 'printer_width': '80', 'quiet': 'False', 'cache_selected_only': 'False', 'no_print': 'None', 'static_parser': 'True', 'target_path': 'None', 'debug': 'False', 'log_cache_events': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/Users/danila/.dbt', 'use_experimental_parser': 'False', 'use_colors': 'True', 'partial_parse': 'True', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_path': '/Users/danila/github/dbt/logs'}
[0m15:28:34.688509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105eb7f90>]}
[0m15:28:34.695203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1061cf150>]}
[0m15:28:34.695495 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:28:34.707890 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:28:34.736245 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:28:34.736423 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:28:34.736719 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.users
- models.staging.scraper
- models.brand_performance
- models.marts
[0m15:28:34.739133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea1f90>]}
[0m15:28:34.745519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10622ffd0>]}
[0m15:28:34.745751 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:28:34.745913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102b2a710>]}
[0m15:28:34.746540 [info ] [MainThread]: 
[0m15:28:34.746873 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:28:34.747346 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:28:34.751383 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:28:34.751525 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:28:34.751635 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:28:35.191998 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:28:35.197315 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:28:35.201720 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:28:35.210011 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:28:35.210588 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:28:35.210904 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:28:35.716386 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:28:35.717484 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:28:35.718094 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:28:35.774437 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:28:35.778514 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:28:35.830687 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:28:35.845807 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:35.846376 [debug] [MainThread]: On master: BEGIN
[0m15:28:35.846776 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:28:36.324564 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:28:36.326312 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:36.327428 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:28:36.395085 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:28:36.401223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102b2a7d0>]}
[0m15:28:36.402013 [debug] [MainThread]: On master: ROLLBACK
[0m15:28:36.460265 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:36.461745 [debug] [MainThread]: On master: BEGIN
[0m15:28:36.578937 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:28:36.580833 [debug] [MainThread]: On master: COMMIT
[0m15:28:36.581829 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:36.582702 [debug] [MainThread]: On master: COMMIT
[0m15:28:36.641535 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:28:36.642752 [debug] [MainThread]: On master: Close
[0m15:28:36.645793 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:28:36.646537 [info ] [MainThread]: 
[0m15:28:36.653569 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:28:36.654283 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:28:36.655250 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.stg_scraper__records)
[0m15:28:36.655949 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:28:36.665330 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:28:36.666174 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:28:36.656381 => 15:28:36.665979
[0m15:28:36.666470 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:28:36.691811 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:28:36.692373 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:36.692558 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:28:36.692727 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:28:37.078239 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:28:37.079908 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:37.081695 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:28:39.826090 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:28:39.840930 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:39.841538 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:28:39.888693 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:28:39.894587 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:39.895196 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:28:39.942387 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:28:39.970843 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:28:39.971330 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:39.971645 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:28:40.017740 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:28:40.025425 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:28:40.025860 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:28:40.094095 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:28:40.097259 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:28:36.666641 => 15:28:40.096720
[0m15:28:40.098122 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:28:40.099903 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10653bd90>]}
[0m15:28:40.100813 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.44s]
[0m15:28:40.101694 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:28:40.103201 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:28:40.103816 [info ] [Thread-1 (]: 2 of 2 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:28:40.104721 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m15:28:40.105158 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:28:40.110410 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:28:40.111589 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:28:40.105489 => 15:28:40.111267
[0m15:28:40.112050 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:28:40.128846 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:28:40.129736 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:40.129991 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:28:40.130209 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:28:40.515816 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:28:40.517440 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:40.518518 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:28:40.571540 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:28:40.579138 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:40.579783 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:28:40.627094 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:28:40.631597 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:28:40.632092 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:40.632504 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:28:40.679455 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:28:40.685316 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:28:40.685810 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:28:40.733920 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:28:40.738234 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:28:40.112302 => 15:28:40.737897
[0m15:28:40.738937 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:28:40.740564 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6c9091af-04a1-4432-b16c-74b4559732be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064c20d0>]}
[0m15:28:40.741406 [info ] [Thread-1 (]: 2 of 2 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.64s]
[0m15:28:40.742277 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:28:40.744303 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:40.744677 [debug] [MainThread]: On master: BEGIN
[0m15:28:40.745011 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:28:41.305221 [debug] [MainThread]: SQL status: BEGIN in 1.0 seconds
[0m15:28:41.306793 [debug] [MainThread]: On master: COMMIT
[0m15:28:41.307733 [debug] [MainThread]: Using postgres connection "master"
[0m15:28:41.308479 [debug] [MainThread]: On master: COMMIT
[0m15:28:41.355233 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:28:41.356180 [debug] [MainThread]: On master: Close
[0m15:28:41.357887 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:28:41.358381 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:28:41.358857 [info ] [MainThread]: 
[0m15:28:41.359452 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.61 seconds (6.61s).
[0m15:28:41.360773 [debug] [MainThread]: Command end result
[0m15:28:41.373353 [info ] [MainThread]: 
[0m15:28:41.373643 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:28:41.373803 [info ] [MainThread]: 
[0m15:28:41.373962 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:28:41.374247 [debug] [MainThread]: Command `dbt run` succeeded at 15:28:41.374195 after 6.72 seconds
[0m15:28:41.374396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea2910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ea0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1013f0ed0>]}
[0m15:28:41.374531 [debug] [MainThread]: Flushing usage events
[0m15:30:04.372434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a6e190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a72fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a73690>]}


============================== 15:30:04.374183 | d612a4b2-679c-431a-8f15-7fc19da25729 ==============================
[0m15:30:04.374183 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:30:04.374472 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'cache_selected_only': 'False', 'version_check': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'target_path': 'None', 'use_colors': 'True', 'quiet': 'False', 'partial_parse': 'True', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'static_parser': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '/Users/danila/.dbt'}
[0m15:30:04.374691 [info ] [MainThread]: dbt version: 1.5.4
[0m15:30:04.374848 [info ] [MainThread]: python version: 3.11.9
[0m15:30:04.374997 [info ] [MainThread]: python path: /opt/anaconda3/envs/dbt_env2/bin/python3.11
[0m15:30:04.375132 [info ] [MainThread]: os info: macOS-14.4.1-arm64-arm-64bit
[0m15:30:04.375260 [info ] [MainThread]: Using profiles.yml file at /Users/danila/.dbt/profiles.yml
[0m15:30:04.375397 [info ] [MainThread]: Using dbt_project.yml file at /Users/danila/github/dbt/dbt_project.yml
[0m15:30:04.375515 [info ] [MainThread]: Configuration:
[0m15:30:04.398288 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m15:30:04.408186 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m15:30:04.408409 [info ] [MainThread]: Required dependencies:
[0m15:30:04.408579 [debug] [MainThread]: Executing "git --help"
[0m15:30:04.419584 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m15:30:04.420147 [debug] [MainThread]: STDERR: "b''"
[0m15:30:04.420309 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m15:30:04.420482 [info ] [MainThread]: Connection:
[0m15:30:04.420668 [info ] [MainThread]:   host: pg10-deepanalysis-db-do-user-3167072-0.b.db.ondigitalocean.com
[0m15:30:04.420799 [info ] [MainThread]:   port: 25060
[0m15:30:04.420922 [info ] [MainThread]:   user: doadmin
[0m15:30:04.421039 [info ] [MainThread]:   database: deep-analysis-console
[0m15:30:04.421163 [info ] [MainThread]:   schema: danila
[0m15:30:04.421281 [info ] [MainThread]:   search_path: None
[0m15:30:04.421394 [info ] [MainThread]:   keepalives_idle: 0
[0m15:30:04.421511 [info ] [MainThread]:   sslmode: require
[0m15:30:04.422012 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:30:04.424771 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m15:30:04.425132 [debug] [MainThread]: Using postgres connection "debug"
[0m15:30:04.425245 [debug] [MainThread]: On debug: select 1 as id
[0m15:30:04.425386 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:30:04.883982 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m15:30:04.887975 [debug] [MainThread]: On debug: Close
[0m15:30:04.889276 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m15:30:04.890120 [info ] [MainThread]: [32mAll checks passed![0m
[0m15:30:04.891468 [debug] [MainThread]: Command `dbt debug` succeeded at 15:30:04.891271 after 0.53 seconds
[0m15:30:04.891995 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m15:30:04.892509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103471ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100a9ce10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a6af90>]}
[0m15:30:04.893158 [debug] [MainThread]: Flushing usage events
[0m15:30:20.140969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093f2210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093e6010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f9a550>]}


============================== 15:30:20.142274 | 292cc8ac-f931-4940-9e1e-4dcbe77d2a3d ==============================
[0m15:30:20.142274 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:30:20.142580 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'version_check': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'target_path': 'None', 'profiles_dir': '/Users/danila/.dbt', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'log_cache_events': 'False', 'quiet': 'False', 'write_json': 'True', 'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'partial_parse': 'True'}
[0m15:30:20.173652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109407550>]}
[0m15:30:20.180674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098702d0>]}
[0m15:30:20.181235 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:30:20.197702 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:30:20.239628 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:30:20.239825 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:30:20.240109 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.staging.scraper
- models.brand_performance
- models.marts
- models.users
[0m15:30:20.242500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109994150>]}
[0m15:30:20.247684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109880310>]}
[0m15:30:20.247898 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:30:20.248072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ba710>]}
[0m15:30:20.248730 [info ] [MainThread]: 
[0m15:30:20.249083 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:30:20.249539 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:30:20.253536 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:30:20.253657 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:30:20.253758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:30:20.708939 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:30:20.713491 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:30:20.716946 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:30:20.725280 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:30:20.725855 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:30:20.726133 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:30:21.112463 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:30:21.114096 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:30:21.115136 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:30:21.166239 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:30:21.172513 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:30:21.220075 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:30:21.232327 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:21.232772 [debug] [MainThread]: On master: BEGIN
[0m15:30:21.233070 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:30:21.669493 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:21.669900 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:21.670217 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:30:21.749325 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:30:21.751670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10940b8d0>]}
[0m15:30:21.752076 [debug] [MainThread]: On master: ROLLBACK
[0m15:30:21.804832 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:21.805752 [debug] [MainThread]: On master: BEGIN
[0m15:30:21.982532 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:21.983927 [debug] [MainThread]: On master: COMMIT
[0m15:30:21.984959 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:21.985793 [debug] [MainThread]: On master: COMMIT
[0m15:30:22.038391 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:30:22.039344 [debug] [MainThread]: On master: Close
[0m15:30:22.041067 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:30:22.041746 [info ] [MainThread]: 
[0m15:30:22.048121 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:30:22.048721 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:30:22.049536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.stg_scraper__records)
[0m15:30:22.049851 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:30:22.057143 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:30:22.058618 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:30:22.050056 => 15:30:22.058446
[0m15:30:22.058903 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:30:22.082985 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:30:22.084311 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:30:22.084538 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:30:22.084713 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:30:22.533976 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:30:22.535303 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:30:22.536643 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:30:25.290493 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:30:25.305578 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:30:25.306144 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:30:25.361602 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:25.367818 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:30:25.368624 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:30:25.424088 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:25.450504 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:30:25.450868 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:30:25.451134 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:30:25.506765 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:30:25.515076 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:30:25.515509 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:30:25.595773 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:30:25.600890 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:30:22.059068 => 15:30:25.600516
[0m15:30:25.601563 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:30:25.603362 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098a1b50>]}
[0m15:30:25.604370 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.55s]
[0m15:30:25.605227 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:30:25.606676 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:30:25.607381 [info ] [Thread-1 (]: 2 of 2 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:30:25.608290 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.first_deposits_fct)
[0m15:30:25.608697 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:30:25.612040 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:30:25.613013 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:30:25.608967 => 15:30:25.612808
[0m15:30:25.613332 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:30:25.628189 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:30:25.628823 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:30:25.629054 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:30:25.629261 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:30:26.027475 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:30:26.029093 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:30:26.030670 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:30:26.083185 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:30:26.091125 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:30:26.091678 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:30:26.138716 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:26.142273 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:30:26.142931 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:30:26.143499 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:30:26.190266 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:30:26.196247 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:30:26.196794 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:30:26.245047 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:30:26.249570 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:30:25.613539 => 15:30:26.249186
[0m15:30:26.250311 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:30:26.252408 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '292cc8ac-f931-4940-9e1e-4dcbe77d2a3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10997a2d0>]}
[0m15:30:26.253528 [info ] [Thread-1 (]: 2 of 2 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 0.64s]
[0m15:30:26.254722 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:30:26.257189 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:26.257592 [debug] [MainThread]: On master: BEGIN
[0m15:30:26.257937 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:30:26.735799 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:26.736828 [debug] [MainThread]: On master: COMMIT
[0m15:30:26.737444 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:26.738015 [debug] [MainThread]: On master: COMMIT
[0m15:30:26.797361 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:30:26.798470 [debug] [MainThread]: On master: Close
[0m15:30:26.800114 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:30:26.800656 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:30:26.801236 [info ] [MainThread]: 
[0m15:30:26.801830 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 6.55 seconds (6.55s).
[0m15:30:26.803084 [debug] [MainThread]: Command end result
[0m15:30:26.816087 [info ] [MainThread]: 
[0m15:30:26.816718 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:30:26.817054 [info ] [MainThread]: 
[0m15:30:26.817375 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:30:26.817902 [debug] [MainThread]: Command `dbt run` succeeded at 15:30:26.817815 after 6.68 seconds
[0m15:30:26.818193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f28410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541b210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105421c50>]}
[0m15:30:26.818466 [debug] [MainThread]: Flushing usage events
[0m15:30:32.188666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108970c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108977350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108977a10>]}


============================== 15:30:32.189858 | f6330fee-3121-4467-b65c-8ccc187a163c ==============================
[0m15:30:32.189858 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:30:32.190168 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'log_format': 'default', 'version_check': 'True', 'quiet': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'use_colors': 'True', 'use_experimental_parser': 'False', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'static_parser': 'True', 'fail_fast': 'False', 'cache_selected_only': 'False', 'write_json': 'True', 'profiles_dir': '/Users/danila/.dbt', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'debug': 'False', 'partial_parse': 'True'}
[0m15:30:32.218072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dd7dd0>]}
[0m15:30:32.224505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108994a50>]}
[0m15:30:32.224849 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:30:32.237331 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:30:32.271025 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:30:32.271207 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:30:32.271493 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.brand_performance
- models.marts
- models.staging.scraper
- models.users
[0m15:30:32.274049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ef2190>]}
[0m15:30:32.278898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e37d90>]}
[0m15:30:32.279118 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:30:32.280049 [info ] [MainThread]: 
[0m15:30:32.280379 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:30:32.280883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:30:32.284799 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:30:32.284939 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:30:32.285052 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:30:32.735367 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:30:32.738669 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:30:32.741996 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:30:32.749929 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:30:32.750451 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:30:32.750753 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:30:33.184426 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:30:33.185830 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:30:33.186758 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:30:33.243180 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:30:33.246275 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:30:33.298709 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:30:33.310303 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:33.310822 [debug] [MainThread]: On master: BEGIN
[0m15:30:33.311119 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:30:33.759348 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:33.760928 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:33.761784 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:30:33.826644 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:30:33.831402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108987c10>]}
[0m15:30:33.832257 [debug] [MainThread]: On master: ROLLBACK
[0m15:30:33.887166 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:33.887873 [debug] [MainThread]: On master: BEGIN
[0m15:30:33.997017 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:30:33.998058 [debug] [MainThread]: On master: COMMIT
[0m15:30:33.998856 [debug] [MainThread]: Using postgres connection "master"
[0m15:30:33.999318 [debug] [MainThread]: On master: COMMIT
[0m15:30:34.055150 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:30:34.056341 [debug] [MainThread]: On master: Close
[0m15:30:34.058330 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:30:34.059029 [info ] [MainThread]: 
[0m15:30:34.068180 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:30:34.068876 [info ] [Thread-1 (]: 1 of 12 START sql view model danila.clicks_to_clients_fct ...................... [RUN]
[0m15:30:34.069818 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_perfomance.clicks_to_clients_fct)
[0m15:30:34.070243 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.clicks_to_clients_fct
[0m15:30:34.077472 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.079130 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (compile): 15:30:34.070534 => 15:30:34.078897
[0m15:30:34.079493 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.clicks_to_clients_fct
[0m15:30:34.104635 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.105634 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.105888 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: BEGIN
[0m15:30:34.106079 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:30:34.582950 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:30:34.584664 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.585633 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m15:30:34.647591 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:30:34.661689 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.662325 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m15:30:34.720835 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:34.727400 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.728017 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m15:30:34.787262 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:34.811180 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:30:34.811629 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.811942 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: COMMIT
[0m15:30:34.870479 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:30:34.879537 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.clicks_to_clients_fct"
[0m15:30:34.880193 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m15:30:34.939004 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:30:34.940629 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.clicks_to_clients_fct (execute): 15:30:34.079706 => 15:30:34.940472
[0m15:30:34.940916 [debug] [Thread-1 (]: On model.campaign_perfomance.clicks_to_clients_fct: Close
[0m15:30:34.941634 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108987690>]}
[0m15:30:34.942070 [info ] [Thread-1 (]: 1 of 12 OK created sql view model danila.clicks_to_clients_fct ................. [[32mCREATE VIEW[0m in 0.87s]
[0m15:30:34.942501 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.clicks_to_clients_fct
[0m15:30:34.942769 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.deals_dimension
[0m15:30:34.943082 [info ] [Thread-1 (]: 2 of 12 START sql view model danila.deals_dimension ............................ [RUN]
[0m15:30:34.943502 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.clicks_to_clients_fct, now model.campaign_perfomance.deals_dimension)
[0m15:30:34.943698 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.deals_dimension
[0m15:30:34.944962 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.deals_dimension"
[0m15:30:34.945684 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (compile): 15:30:34.943828 => 15:30:34.945530
[0m15:30:34.945923 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.deals_dimension
[0m15:30:34.948361 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.deals_dimension"
[0m15:30:34.949561 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:30:34.949813 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: BEGIN
[0m15:30:34.950010 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:30:35.435281 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:30:35.436858 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:30:35.438015 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select
        id as deal_id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group -- campaign_name? 
        , gap_campaign_name as google_ads_campaign_id -- ga_campaign_name? 
        , traffic_types as betting_type --(vertical) tables with the names
        , traffic_sources --(FB, Google, etc) tables with names
    from deals
)

select * from main
--where deal_id = 2085


-- select betting_type, traffic_sources, count(deal_id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m15:30:35.490085 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:30:35.497924 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:30:35.498574 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m15:30:35.579757 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:35.586456 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:30:35.586916 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m15:30:35.690640 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:35.695211 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:30:35.695836 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:30:35.696384 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: COMMIT
[0m15:30:35.826591 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:30:35.832009 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.deals_dimension"
[0m15:30:35.832513 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m15:30:35.883253 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:30:35.886713 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.deals_dimension (execute): 15:30:34.946065 => 15:30:35.886459
[0m15:30:35.887361 [debug] [Thread-1 (]: On model.campaign_perfomance.deals_dimension: Close
[0m15:30:35.888756 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10901b850>]}
[0m15:30:35.889581 [info ] [Thread-1 (]: 2 of 12 OK created sql view model danila.deals_dimension ....................... [[32mCREATE VIEW[0m in 0.95s]
[0m15:30:35.890353 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.deals_dimension
[0m15:30:35.890840 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_by_brand_int
[0m15:30:35.891452 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m15:30:35.892535 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.deals_dimension, now model.campaign_perfomance.outclick_by_brand_int)
[0m15:30:35.893280 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_by_brand_int
[0m15:30:35.910674 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:35.912819 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (compile): 15:30:35.893572 => 15:30:35.912657
[0m15:30:35.913072 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_by_brand_int
[0m15:30:35.927511 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:35.927952 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:35.928129 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: BEGIN
[0m15:30:35.928293 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:30:36.435791 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:30:36.437607 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:36.439982 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:30:51.760405 [debug] [Thread-1 (]: SQL status: SELECT 512090 in 15.0 seconds
[0m15:30:51.770818 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:51.771496 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m15:30:51.824278 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:51.830875 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:51.831568 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m15:30:51.884806 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:30:51.895111 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:30:51.895663 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:51.896108 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: COMMIT
[0m15:30:51.950535 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:30:51.956758 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_by_brand_int"
[0m15:30:51.957234 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m15:30:52.039951 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:30:52.044308 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_by_brand_int (execute): 15:30:35.913225 => 15:30:52.043604
[0m15:30:52.044879 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_by_brand_int: Close
[0m15:30:52.046410 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090b3c10>]}
[0m15:30:52.047262 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 512090[0m in 16.15s]
[0m15:30:52.048060 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_by_brand_int
[0m15:30:52.048598 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.outclick_cost_int
[0m15:30:52.049623 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m15:30:52.050830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_by_brand_int, now model.campaign_perfomance.outclick_cost_int)
[0m15:30:52.051665 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.outclick_cost_int
[0m15:30:52.061893 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.outclick_cost_int"
[0m15:30:52.063495 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (compile): 15:30:52.051978 => 15:30:52.063324
[0m15:30:52.063795 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.outclick_cost_int
[0m15:30:52.066995 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.outclick_cost_int"
[0m15:30:52.067839 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:30:52.068180 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: BEGIN
[0m15:30:52.068421 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:30:52.589960 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:30:52.592660 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:30:52.594664 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:31:01.569022 [debug] [Thread-1 (]: SQL status: SELECT 146373 in 9.0 seconds
[0m15:31:01.576595 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:31:01.577357 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:31:01.635891 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:31:01.642792 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:31:01.643494 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:31:01.702807 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:31:01.708369 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:31:01.709144 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:31:01.709686 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: COMMIT
[0m15:31:01.767944 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:31:01.773456 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.outclick_cost_int"
[0m15:31:01.773949 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:31:01.860923 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:31:01.865479 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.outclick_cost_int (execute): 15:30:52.063978 => 15:31:01.864824
[0m15:31:01.866558 [debug] [Thread-1 (]: On model.campaign_perfomance.outclick_cost_int: Close
[0m15:31:01.868269 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f3de50>]}
[0m15:31:01.869309 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 146373[0m in 9.82s]
[0m15:31:01.870413 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.outclick_cost_int
[0m15:31:01.871387 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.stg_scraper__records
[0m15:31:01.872496 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.stg_scraper__records ...................... [RUN]
[0m15:31:01.873476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.outclick_cost_int, now model.campaign_perfomance.stg_scraper__records)
[0m15:31:01.873948 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.stg_scraper__records
[0m15:31:01.879074 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.stg_scraper__records"
[0m15:31:01.880815 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (compile): 15:31:01.874275 => 15:31:01.880236
[0m15:31:01.881511 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.stg_scraper__records
[0m15:31:01.886482 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.stg_scraper__records"
[0m15:31:01.887459 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:31:01.887790 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: BEGIN
[0m15:31:01.888091 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:02.324432 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:02.325824 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:31:02.327105 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:31:04.866892 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:31:04.877192 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:31:04.877790 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:31:04.930624 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:31:04.936049 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:31:04.936691 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:31:04.989457 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:31:04.992798 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:31:04.993448 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:31:04.994194 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: COMMIT
[0m15:31:05.046776 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:31:05.052322 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.stg_scraper__records"
[0m15:31:05.052945 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:31:05.127289 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:31:05.130598 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.stg_scraper__records (execute): 15:31:01.881799 => 15:31:05.130202
[0m15:31:05.131254 [debug] [Thread-1 (]: On model.campaign_perfomance.stg_scraper__records: Close
[0m15:31:05.132913 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090cc6d0>]}
[0m15:31:05.133950 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.stg_scraper__records ................. [[32mSELECT 72414[0m in 3.26s]
[0m15:31:05.134925 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.stg_scraper__records
[0m15:31:05.135517 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.test
[0m15:31:05.136310 [info ] [Thread-1 (]: 6 of 12 START sql view model danila.test ....................................... [RUN]
[0m15:31:05.137149 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.stg_scraper__records, now model.campaign_perfomance.test)
[0m15:31:05.137547 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.test
[0m15:31:05.140246 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.test"
[0m15:31:05.141390 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (compile): 15:31:05.137839 => 15:31:05.141147
[0m15:31:05.141785 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.test
[0m15:31:05.145877 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.test"
[0m15:31:05.146463 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:31:05.146757 [debug] [Thread-1 (]: On model.campaign_perfomance.test: BEGIN
[0m15:31:05.147032 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:05.531180 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:05.532877 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:31:05.534078 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    -- with main as (
--     select
--         id
--         , user_id
--         , conversion_timestamp
--         , registrations
--         , deal_id
--         , date_parsed as date_cet
--         --, click_id
--         , geo as country_code
--         -- , registrations as signed_up
--         --, cpa_count as deposited_first_time
--         -- , gtee_count
--         , cpa_commissions as acquisition_commission
--         -- , total_commission
--         -- , gtee_commissions
--         -- , net_revenue
--         -- , revshare_commissions
--         , lower(adgroup_name) as ga_campaign_name
--         , case
--             when right(brand_name, 6) <> 'sports' then 'casino'
--             when right(brand_name, 6) = 'sports' then 'sports'
--             else 'other'
--         end as campaign_vertical
--         , case
--             when campaign_name::text = 'email' then brand_name || ' email'
--             when campaign_name::text = 'PA' then brand_name || ' PA'
--             else brand_name
--         end as brand_name

--         , case
--             when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
--             when campaign_name = 'ficashstormslots' then 'cashstormslots'
--             when campaign_name = 'goldenlion' then 'goldenliongames'
--             else campaign_name
--         end as campaign_name
--     from records
--     where
--         date_parsed > '2024-03-31'
--         and cpa_count > 0.5
--         --and deal_id is null
--         --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
--     --and user_id='ae4eb2f5ad8ebf29'
--     order by user_id, deal_id, date_parsed
-- )




-- select * from main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


SELECT id, user_id, date_parsed, date, brand_name, cpa_count, registrations, conversion_timestamp
FROM records
WHERE id='5393572' or id= '5393571'--date_parsed = '2024-05-16' AND user_id = '51a4a42eaaeb12f7'
--GROUP BY user_id, conversion_timestamp, date_parsed, brand_name, cpa_count, registrations
--HAVING COUNT(*) = 1
  );
[0m15:31:05.583931 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:31:05.592635 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:31:05.593272 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m15:31:05.640624 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:31:05.646421 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:31:05.646950 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m15:31:05.694415 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:31:05.697483 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:31:05.698036 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:31:05.698479 [debug] [Thread-1 (]: On model.campaign_perfomance.test: COMMIT
[0m15:31:05.745313 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:31:05.752042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.test"
[0m15:31:05.752804 [debug] [Thread-1 (]: On model.campaign_perfomance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m15:31:05.800409 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:31:05.804201 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.test (execute): 15:31:05.142036 => 15:31:05.803910
[0m15:31:05.804822 [debug] [Thread-1 (]: On model.campaign_perfomance.test: Close
[0m15:31:05.806532 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f1e750>]}
[0m15:31:05.807918 [info ] [Thread-1 (]: 6 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.67s]
[0m15:31:05.809151 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.test
[0m15:31:05.810018 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:31:05.810935 [info ] [Thread-1 (]: 7 of 12 START test not_null_outclick_by_brand_int_id ........................... [RUN]
[0m15:31:05.812062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_perfomance.test, now test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m15:31:05.812560 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:31:05.827746 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:31:05.829081 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 15:31:05.812902 => 15:31:05.828890
[0m15:31:05.829399 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:31:05.839245 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:31:05.839844 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:31:05.840079 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m15:31:05.840291 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:06.291259 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:06.292857 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:31:06.294179 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m15:31:06.527385 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:06.532469 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 15:31:05.829581 => 15:31:06.532116
[0m15:31:06.533048 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m15:31:06.589091 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m15:31:06.592485 [info ] [Thread-1 (]: 7 of 12 PASS not_null_outclick_by_brand_int_id ................................. [[32mPASS[0m in 0.78s]
[0m15:31:06.593984 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:31:06.594915 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:31:06.595930 [info ] [Thread-1 (]: 8 of 12 START test unique_outclick_by_brand_int_id ............................. [RUN]
[0m15:31:06.597403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b)
[0m15:31:06.597988 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:31:06.607849 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:31:06.609061 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (compile): 15:31:06.598333 => 15:31:06.608821
[0m15:31:06.609465 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:31:06.613851 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:31:06.614519 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:31:06.614827 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m15:31:06.615115 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:07.049493 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:07.051074 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:31:07.051929 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:31:07.825788 [debug] [Thread-1 (]: SQL status: SELECT 1 in 1.0 seconds
[0m15:31:07.830120 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b (execute): 15:31:06.609676 => 15:31:07.829686
[0m15:31:07.830910 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m15:31:07.884073 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m15:31:07.886783 [info ] [Thread-1 (]: 8 of 12 PASS unique_outclick_by_brand_int_id ................................... [[32mPASS[0m in 1.29s]
[0m15:31:07.888148 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:31:07.888942 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:31:07.889849 [info ] [Thread-1 (]: 9 of 12 START test not_null_outclick_cost_int_id ............................... [RUN]
[0m15:31:07.891160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m15:31:07.891811 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:31:07.898745 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:31:07.900208 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 15:31:07.892231 => 15:31:07.899996
[0m15:31:07.900647 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:31:07.904052 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:31:07.905276 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:31:07.905627 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m15:31:07.905929 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:08.337527 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:08.338971 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:31:08.339852 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m15:31:08.448800 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:08.451656 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 15:31:07.900941 => 15:31:08.451312
[0m15:31:08.452455 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m15:31:08.505620 [debug] [Thread-1 (]: On test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m15:31:08.506816 [info ] [Thread-1 (]: 9 of 12 PASS not_null_outclick_cost_int_id ..................................... [[32mPASS[0m in 0.62s]
[0m15:31:08.507553 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:31:08.508019 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m15:31:08.508541 [info ] [Thread-1 (]: 10 of 12 START test unique_outclick_cost_int_id ................................ [RUN]
[0m15:31:08.509429 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f)
[0m15:31:08.509839 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m15:31:08.514334 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m15:31:08.515233 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (compile): 15:31:08.510097 => 15:31:08.515019
[0m15:31:08.515597 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m15:31:08.518241 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m15:31:08.518950 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m15:31:08.519307 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m15:31:08.519652 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:09.013444 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:09.013996 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"
[0m15:31:09.014360 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:31:09.194583 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:09.197044 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f (execute): 15:31:08.515825 => 15:31:09.196727
[0m15:31:09.197479 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m15:31:09.258948 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f: Close
[0m15:31:09.262090 [info ] [Thread-1 (]: 10 of 12 PASS unique_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.75s]
[0m15:31:09.262953 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f
[0m15:31:09.263609 [debug] [Thread-1 (]: Began running node test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:31:09.264472 [info ] [Thread-1 (]: 11 of 12 START test unique_stg_scraper__records_grain_id ....................... [RUN]
[0m15:31:09.265734 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_outclick_cost_int_id.3afb93741f, now test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36)
[0m15:31:09.266309 [debug] [Thread-1 (]: Began compiling node test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:31:09.272842 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:31:09.274238 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36 (compile): 15:31:09.266697 => 15:31:09.273976
[0m15:31:09.274656 [debug] [Thread-1 (]: Began executing node test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:31:09.277624 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:31:09.278748 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:31:09.279160 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36: BEGIN
[0m15:31:09.279518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:09.715471 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:09.717078 [debug] [Thread-1 (]: Using postgres connection "test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:31:09.717770 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    grain_id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."stg_scraper__records"
where grain_id is not null
group by grain_id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:31:09.836730 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:31:09.840690 [debug] [Thread-1 (]: Timing info for test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36 (execute): 15:31:09.274920 => 15:31:09.840190
[0m15:31:09.841533 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36: ROLLBACK
[0m15:31:09.894314 [debug] [Thread-1 (]: On test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36: Close
[0m15:31:09.896851 [info ] [Thread-1 (]: 11 of 12 PASS unique_stg_scraper__records_grain_id ............................. [[32mPASS[0m in 0.63s]
[0m15:31:09.898101 [debug] [Thread-1 (]: Finished running node test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:31:09.899974 [debug] [Thread-1 (]: Began running node model.campaign_perfomance.first_deposits_fct
[0m15:31:09.900859 [info ] [Thread-1 (]: 12 of 12 START sql view model danila.first_deposits_fct ........................ [RUN]
[0m15:31:09.902157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_perfomance.unique_stg_scraper__records_grain_id.0452796a36, now model.campaign_perfomance.first_deposits_fct)
[0m15:31:09.902782 [debug] [Thread-1 (]: Began compiling node model.campaign_perfomance.first_deposits_fct
[0m15:31:09.908613 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_perfomance.first_deposits_fct"
[0m15:31:09.910155 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (compile): 15:31:09.903227 => 15:31:09.909932
[0m15:31:09.910621 [debug] [Thread-1 (]: Began executing node model.campaign_perfomance.first_deposits_fct
[0m15:31:09.916146 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_perfomance.first_deposits_fct"
[0m15:31:09.917251 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:31:09.917602 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: BEGIN
[0m15:31:09.917898 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:31:10.369035 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:31:10.371042 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:31:10.372202 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:31:10.432187 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:31:10.439699 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:31:10.440403 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:31:10.495541 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:31:10.500307 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:31:10.500850 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:31:10.501290 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: COMMIT
[0m15:31:10.556702 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:31:10.562588 [debug] [Thread-1 (]: Using postgres connection "model.campaign_perfomance.first_deposits_fct"
[0m15:31:10.563269 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_perfomance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:31:10.619398 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:31:10.623077 [debug] [Thread-1 (]: Timing info for model.campaign_perfomance.first_deposits_fct (execute): 15:31:09.910902 => 15:31:10.622710
[0m15:31:10.623761 [debug] [Thread-1 (]: On model.campaign_perfomance.first_deposits_fct: Close
[0m15:31:10.625654 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f6330fee-3121-4467-b65c-8ccc187a163c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10909c810>]}
[0m15:31:10.626683 [info ] [Thread-1 (]: 12 of 12 OK created sql view model danila.first_deposits_fct ................... [[32mCREATE VIEW[0m in 0.72s]
[0m15:31:10.627788 [debug] [Thread-1 (]: Finished running node model.campaign_perfomance.first_deposits_fct
[0m15:31:10.630591 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:10.631010 [debug] [MainThread]: On master: BEGIN
[0m15:31:10.631372 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:31:11.081829 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:31:11.083044 [debug] [MainThread]: On master: COMMIT
[0m15:31:11.083676 [debug] [MainThread]: Using postgres connection "master"
[0m15:31:11.084240 [debug] [MainThread]: On master: COMMIT
[0m15:31:11.138985 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:31:11.140184 [debug] [MainThread]: On master: Close
[0m15:31:11.142009 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:31:11.143508 [debug] [MainThread]: Connection 'model.campaign_perfomance.first_deposits_fct' was properly closed.
[0m15:31:11.144506 [info ] [MainThread]: 
[0m15:31:11.145456 [info ] [MainThread]: Finished running 4 view models, 3 table models, 5 tests in 0 hours 0 minutes and 38.86 seconds (38.86s).
[0m15:31:11.149280 [debug] [MainThread]: Command end result
[0m15:31:11.165169 [info ] [MainThread]: 
[0m15:31:11.165704 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:31:11.166030 [info ] [MainThread]: 
[0m15:31:11.166388 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m15:31:11.166963 [debug] [MainThread]: Command `dbt build` succeeded at 15:31:11.166884 after 38.99 seconds
[0m15:31:11.167248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10499ce10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049971d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104997150>]}
[0m15:31:11.167519 [debug] [MainThread]: Flushing usage events
[0m15:32:46.001079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f7e410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f6de10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f83f90>]}


============================== 15:32:46.002907 | ad003fdb-15e0-4c84-94b1-09b9e5f30d7a ==============================
[0m15:32:46.002907 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:32:46.003225 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'version_check': 'True', 'log_cache_events': 'False', 'write_json': 'True', 'introspect': 'True', 'cache_selected_only': 'False', 'log_format': 'default', 'partial_parse': 'True', 'indirect_selection': 'eager', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'printer_width': '80', 'debug': 'False', 'warn_error': 'None', 'static_parser': 'True', 'quiet': 'False', 'log_path': '/Users/danila/github/dbt/logs'}
[0m15:32:46.034516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ad003fdb-15e0-4c84-94b1-09b9e5f30d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b22290>]}
[0m15:32:46.040980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ad003fdb-15e0-4c84-94b1-09b9e5f30d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f9b750>]}
[0m15:32:46.041562 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:32:46.056944 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:32:46.103620 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:32:46.103835 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:32:46.104153 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.brand_performance
- models.staging.scraper
- models.marts
- models.users
[0m15:32:46.106677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad003fdb-15e0-4c84-94b1-09b9e5f30d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089df950>]}
[0m15:32:46.112516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad003fdb-15e0-4c84-94b1-09b9e5f30d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f99050>]}
[0m15:32:46.112775 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:32:46.112950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad003fdb-15e0-4c84-94b1-09b9e5f30d7a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f6f290>]}
[0m15:32:46.113604 [debug] [MainThread]: Command `dbt ls` succeeded at 15:32:46.113546 after 0.13 seconds
[0m15:32:46.113768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa8e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa3090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fa3150>]}
[0m15:32:46.113903 [debug] [MainThread]: Flushing usage events
[0m15:35:07.670113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105363e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105373cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105373f90>]}


============================== 15:35:07.671605 | 88b338e8-2a09-40b4-bb7c-7f88db76bde5 ==============================
[0m15:35:07.671605 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:35:07.671904 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'introspect': 'True', 'cache_selected_only': 'False', 'no_print': 'None', 'fail_fast': 'False', 'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'target_path': 'None', 'write_json': 'True', 'quiet': 'False', 'log_cache_events': 'False', 'version_check': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'static_parser': 'True', 'use_colors': 'True', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'indirect_selection': 'eager', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'use_experimental_parser': 'False', 'log_format': 'default'}
[0m15:35:07.702838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '88b338e8-2a09-40b4-bb7c-7f88db76bde5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105227fd0>]}
[0m15:35:07.709486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '88b338e8-2a09-40b4-bb7c-7f88db76bde5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057eca50>]}
[0m15:35:07.709978 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:35:07.723088 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:35:07.751880 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:07.752076 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:07.752361 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.brand_performance
- models.marts
- models.users
- models.staging.scraper
[0m15:35:07.754729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '88b338e8-2a09-40b4-bb7c-7f88db76bde5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058f43d0>]}
[0m15:35:07.759879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '88b338e8-2a09-40b4-bb7c-7f88db76bde5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10583bc50>]}
[0m15:35:07.760125 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:35:07.760289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '88b338e8-2a09-40b4-bb7c-7f88db76bde5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10581e710>]}
[0m15:35:07.760885 [debug] [MainThread]: Command `dbt ls` succeeded at 15:35:07.760831 after 0.10 seconds
[0m15:35:07.761041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10139ce10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101397090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101397150>]}
[0m15:35:07.761163 [debug] [MainThread]: Flushing usage events
[0m15:35:16.902384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11989bd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11975ff10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198af090>]}


============================== 15:35:16.903994 | 3d6e30ed-7023-4dae-a895-b3a55b09375f ==============================
[0m15:35:16.903994 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:35:16.904285 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'version_check': 'True', 'write_json': 'True', 'no_print': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'introspect': 'True', 'printer_width': '80', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'quiet': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'log_format': 'default', 'debug': 'False'}
[0m15:35:16.934603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198d1b10>]}
[0m15:35:16.940830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119de4d90>]}
[0m15:35:16.941290 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:35:16.956188 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:35:16.988160 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:16.988354 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:16.988648 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.staging.scraper
- models.brand_performance
- models.marts
- models.users
[0m15:35:16.991049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1192e2ed0>]}
[0m15:35:16.995383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119e27cd0>]}
[0m15:35:16.995593 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:35:16.995767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e2a150>]}
[0m15:35:16.996391 [info ] [MainThread]: 
[0m15:35:16.996737 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:35:16.997244 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:35:17.001614 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:35:17.001858 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:35:17.001982 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:17.493925 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:35:17.496690 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:35:17.500024 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:35:17.508337 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:35:17.508782 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:35:17.509036 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:35:17.966996 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:35:17.968439 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:35:17.969089 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:35:18.019849 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:35:18.025913 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:35:18.072971 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:35:18.087183 [debug] [MainThread]: Using postgres connection "master"
[0m15:35:18.087751 [debug] [MainThread]: On master: BEGIN
[0m15:35:18.088117 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:35:18.509692 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:35:18.511071 [debug] [MainThread]: Using postgres connection "master"
[0m15:35:18.512041 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:35:18.570250 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:35:18.575406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1198aac10>]}
[0m15:35:18.576267 [debug] [MainThread]: On master: ROLLBACK
[0m15:35:18.625999 [debug] [MainThread]: Using postgres connection "master"
[0m15:35:18.626798 [debug] [MainThread]: On master: BEGIN
[0m15:35:18.724809 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:35:18.725597 [debug] [MainThread]: On master: COMMIT
[0m15:35:18.726047 [debug] [MainThread]: Using postgres connection "master"
[0m15:35:18.726437 [debug] [MainThread]: On master: COMMIT
[0m15:35:18.774961 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:35:18.776220 [debug] [MainThread]: On master: Close
[0m15:35:18.778772 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:35:18.779480 [info ] [MainThread]: 
[0m15:35:18.788668 [debug] [Thread-1 (]: Began running node model.campaign_performance.stg_scraper__records
[0m15:35:18.789455 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:35:18.790460 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_performance.stg_scraper__records)
[0m15:35:18.790884 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.stg_scraper__records
[0m15:35:18.800598 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.stg_scraper__records"
[0m15:35:18.801865 [debug] [Thread-1 (]: Timing info for model.campaign_performance.stg_scraper__records (compile): 15:35:18.791187 => 15:35:18.801655
[0m15:35:18.802212 [debug] [Thread-1 (]: Began executing node model.campaign_performance.stg_scraper__records
[0m15:35:18.828620 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.stg_scraper__records"
[0m15:35:18.829895 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:35:18.830154 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: BEGIN
[0m15:35:18.830340 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:35:19.585530 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:35:19.587528 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:35:19.589431 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:35:22.361947 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:35:22.376582 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:35:22.377205 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:35:22.437670 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:35:22.445311 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:35:22.445899 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:35:22.505769 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:35:22.528691 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: COMMIT
[0m15:35:22.529094 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:35:22.529336 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: COMMIT
[0m15:35:22.589011 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:35:22.596891 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:35:22.597322 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:35:22.680269 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:35:22.685203 [debug] [Thread-1 (]: Timing info for model.campaign_performance.stg_scraper__records (execute): 15:35:18.802415 => 15:35:22.684681
[0m15:35:22.686016 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: Close
[0m15:35:22.687780 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a012710>]}
[0m15:35:22.688780 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.90s]
[0m15:35:22.689743 [debug] [Thread-1 (]: Finished running node model.campaign_performance.stg_scraper__records
[0m15:35:22.691038 [debug] [Thread-1 (]: Began running node model.campaign_performance.first_deposits_fct
[0m15:35:22.691779 [info ] [Thread-1 (]: 2 of 2 START sql view model danila.first_deposits_fct .......................... [RUN]
[0m15:35:22.692646 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.stg_scraper__records, now model.campaign_performance.first_deposits_fct)
[0m15:35:22.693048 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.first_deposits_fct
[0m15:35:22.697088 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.first_deposits_fct"
[0m15:35:22.698407 [debug] [Thread-1 (]: Timing info for model.campaign_performance.first_deposits_fct (compile): 15:35:22.693330 => 15:35:22.698155
[0m15:35:22.698754 [debug] [Thread-1 (]: Began executing node model.campaign_performance.first_deposits_fct
[0m15:35:22.714322 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.first_deposits_fct"
[0m15:35:22.714957 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:35:22.715187 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: BEGIN
[0m15:35:22.715399 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:35:23.430752 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:35:23.432340 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:35:23.433250 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:35:23.496285 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:35:23.503838 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:35:23.504402 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:35:23.563588 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:35:23.568201 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: COMMIT
[0m15:35:23.568911 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:35:23.569452 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: COMMIT
[0m15:35:23.627065 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:35:23.633072 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:35:23.633738 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:35:23.691275 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:35:23.695565 [debug] [Thread-1 (]: Timing info for model.campaign_performance.first_deposits_fct (execute): 15:35:22.698963 => 15:35:23.694941
[0m15:35:23.696306 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: Close
[0m15:35:23.698110 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d6e30ed-7023-4dae-a895-b3a55b09375f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a013490>]}
[0m15:35:23.699092 [info ] [Thread-1 (]: 2 of 2 OK created sql view model danila.first_deposits_fct ..................... [[32mCREATE VIEW[0m in 1.01s]
[0m15:35:23.699984 [debug] [Thread-1 (]: Finished running node model.campaign_performance.first_deposits_fct
[0m15:35:23.702212 [debug] [MainThread]: Using postgres connection "master"
[0m15:35:23.702613 [debug] [MainThread]: On master: BEGIN
[0m15:35:23.702955 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:35:24.102294 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:35:24.103956 [debug] [MainThread]: On master: COMMIT
[0m15:35:24.104962 [debug] [MainThread]: Using postgres connection "master"
[0m15:35:24.105685 [debug] [MainThread]: On master: COMMIT
[0m15:35:24.152659 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:35:24.153827 [debug] [MainThread]: On master: Close
[0m15:35:24.156037 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:24.156535 [debug] [MainThread]: Connection 'model.campaign_performance.first_deposits_fct' was properly closed.
[0m15:35:24.157070 [info ] [MainThread]: 
[0m15:35:24.157727 [info ] [MainThread]: Finished running 1 table model, 1 view model in 0 hours 0 minutes and 7.16 seconds (7.16s).
[0m15:35:24.159171 [debug] [MainThread]: Command end result
[0m15:35:24.176322 [info ] [MainThread]: 
[0m15:35:24.176860 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:35:24.177180 [info ] [MainThread]: 
[0m15:35:24.177518 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:35:24.178123 [debug] [MainThread]: Command `dbt run` succeeded at 15:35:24.178020 after 7.29 seconds
[0m15:35:24.178476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10388cf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119f51810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1038872d0>]}
[0m15:35:24.178803 [debug] [MainThread]: Flushing usage events
[0m15:36:42.634835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105593ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105597550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105591e10>]}


============================== 15:36:42.636384 | 6f7bea37-988f-4dc2-9db5-1aa1ea195d8f ==============================
[0m15:36:42.636384 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:36:42.636680 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'profiles_dir': '/Users/danila/.dbt', 'partial_parse': 'True', 'warn_error': 'None', 'quiet': 'False', 'cache_selected_only': 'False', 'version_check': 'True', 'fail_fast': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'printer_width': '80', 'write_json': 'True', 'indirect_selection': 'eager', 'target_path': 'None', 'static_parser': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'log_format': 'default'}
[0m15:36:42.667539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055a6a10>]}
[0m15:36:42.674160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b3a10>]}
[0m15:36:42.674671 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:36:42.689314 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:36:42.731455 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:36:42.731637 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:36:42.731922 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.marts
- models.users
- models.staging.scraper
- models.brand_performance
[0m15:36:42.734320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105535190>]}
[0m15:36:42.739044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105840510>]}
[0m15:36:42.739272 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:36:42.740225 [info ] [MainThread]: 
[0m15:36:42.740585 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:36:42.741166 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:36:42.745289 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:36:42.745435 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:36:42.745553 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:36:43.677869 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.0 seconds
[0m15:36:43.681172 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:36:43.687231 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:36:43.695825 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:36:43.696199 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:36:43.696417 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:36:44.425812 [debug] [ThreadPool]: SQL status: BEGIN in 1.0 seconds
[0m15:36:44.427081 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:36:44.427988 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:36:44.483576 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:36:44.486931 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:36:44.533251 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:36:44.547736 [debug] [MainThread]: Using postgres connection "master"
[0m15:36:44.548231 [debug] [MainThread]: On master: BEGIN
[0m15:36:44.548482 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:36:44.977963 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:36:44.979423 [debug] [MainThread]: Using postgres connection "master"
[0m15:36:44.980228 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:36:45.040291 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:36:45.043477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048b6dd0>]}
[0m15:36:45.044123 [debug] [MainThread]: On master: ROLLBACK
[0m15:36:45.096227 [debug] [MainThread]: Using postgres connection "master"
[0m15:36:45.097171 [debug] [MainThread]: On master: BEGIN
[0m15:36:45.201596 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:36:45.202638 [debug] [MainThread]: On master: COMMIT
[0m15:36:45.203534 [debug] [MainThread]: Using postgres connection "master"
[0m15:36:45.204340 [debug] [MainThread]: On master: COMMIT
[0m15:36:45.256761 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:36:45.257984 [debug] [MainThread]: On master: Close
[0m15:36:45.260602 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:36:45.261300 [info ] [MainThread]: 
[0m15:36:45.270560 [debug] [Thread-1 (]: Began running node model.campaign_performance.clicks_to_clients_fct
[0m15:36:45.271267 [info ] [Thread-1 (]: 1 of 12 START sql view model danila.clicks_to_clients_fct ...................... [RUN]
[0m15:36:45.272249 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_performance.clicks_to_clients_fct)
[0m15:36:45.272694 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.clicks_to_clients_fct
[0m15:36:45.280497 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:45.281698 [debug] [Thread-1 (]: Timing info for model.campaign_performance.clicks_to_clients_fct (compile): 15:36:45.272989 => 15:36:45.281477
[0m15:36:45.282068 [debug] [Thread-1 (]: Began executing node model.campaign_performance.clicks_to_clients_fct
[0m15:36:45.307361 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:45.307964 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:45.308167 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: BEGIN
[0m15:36:45.308341 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:36:45.767366 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:36:45.769368 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:45.770298 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.clicks_to_clients_fct"} */

  create view "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp"
    
    
  as (
    select
    timestamp as timestamp_cet
    , deal_id
    , user_id
    , brand_name as brand_id
    , geo as country_code
    -- , campaign_group_id
    , event_type as event_id
    -- , campaign_vertical_id
    -- , google_ads_campaign_id
    -- , traffic_source_id
    , adclickid as ad_click_id
    -- , moneypage_id
    -- , site_id
    -- , affiliate_account_id
    -- , offer_id
from postbacks_outgoing
  );
[0m15:36:45.825553 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:36:45.839887 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:45.840365 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct" rename to "clicks_to_clients_fct__dbt_backup"
[0m15:36:45.893816 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:36:45.901664 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:45.902208 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.clicks_to_clients_fct"} */
alter table "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_tmp" rename to "clicks_to_clients_fct"
[0m15:36:45.955212 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:36:45.977691 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: COMMIT
[0m15:36:45.978250 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:45.978589 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: COMMIT
[0m15:36:46.031004 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:36:46.038816 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.clicks_to_clients_fct"
[0m15:36:46.039307 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.clicks_to_clients_fct"} */
drop view if exists "deep-analysis-console"."danila"."clicks_to_clients_fct__dbt_backup" cascade
[0m15:36:46.092190 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:36:46.095513 [debug] [Thread-1 (]: Timing info for model.campaign_performance.clicks_to_clients_fct (execute): 15:36:45.282283 => 15:36:46.095120
[0m15:36:46.096260 [debug] [Thread-1 (]: On model.campaign_performance.clicks_to_clients_fct: Close
[0m15:36:46.098215 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105826390>]}
[0m15:36:46.099340 [info ] [Thread-1 (]: 1 of 12 OK created sql view model danila.clicks_to_clients_fct ................. [[32mCREATE VIEW[0m in 0.83s]
[0m15:36:46.100294 [debug] [Thread-1 (]: Finished running node model.campaign_performance.clicks_to_clients_fct
[0m15:36:46.100898 [debug] [Thread-1 (]: Began running node model.campaign_performance.deals_dimension
[0m15:36:46.101675 [info ] [Thread-1 (]: 2 of 12 START sql view model danila.deals_dimension ............................ [RUN]
[0m15:36:46.102592 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.clicks_to_clients_fct, now model.campaign_performance.deals_dimension)
[0m15:36:46.103025 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.deals_dimension
[0m15:36:46.105867 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.deals_dimension"
[0m15:36:46.106957 [debug] [Thread-1 (]: Timing info for model.campaign_performance.deals_dimension (compile): 15:36:46.103318 => 15:36:46.106727
[0m15:36:46.107337 [debug] [Thread-1 (]: Began executing node model.campaign_performance.deals_dimension
[0m15:36:46.111923 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.deals_dimension"
[0m15:36:46.112686 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.deals_dimension"
[0m15:36:46.112975 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: BEGIN
[0m15:36:46.113253 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:36:46.498256 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:36:46.500400 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.deals_dimension"
[0m15:36:46.501894 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.deals_dimension"} */

  create view "deep-analysis-console"."danila"."deals_dimension__dbt_tmp"
    
    
  as (
    with main as (
    select
        id as deal_id
        , brand_name
        , geo as country_code
        , deal_start_date as start_date
        , deal_end_date as end_date
        , deal_cpa as first_time_deposit_commission
        , deal_gtee as guaranteed_commission
        , deal_revshare as revenue_share_commission
        , campaign_name as campaign_group -- campaign_name? 
        , gap_campaign_name as google_ads_campaign_id -- ga_campaign_name? 
        , traffic_types as betting_type --(vertical) tables with the names
        , traffic_sources --(FB, Google, etc) tables with names
    from deals
)

select * from main
--where deal_id = 2085


-- select betting_type, traffic_sources, count(deal_id)
-- from main
-- group by betting_type, traffic_sources
  );
[0m15:36:46.552805 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:36:46.561824 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.deals_dimension"
[0m15:36:46.562404 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension" rename to "deals_dimension__dbt_backup"
[0m15:36:46.666429 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:36:46.673377 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.deals_dimension"
[0m15:36:46.674222 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.deals_dimension"} */
alter table "deep-analysis-console"."danila"."deals_dimension__dbt_tmp" rename to "deals_dimension"
[0m15:36:46.721741 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:36:46.725753 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: COMMIT
[0m15:36:46.726400 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.deals_dimension"
[0m15:36:46.726952 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: COMMIT
[0m15:36:46.773239 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:36:46.779443 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.deals_dimension"
[0m15:36:46.779942 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.deals_dimension"} */
drop view if exists "deep-analysis-console"."danila"."deals_dimension__dbt_backup" cascade
[0m15:36:46.827726 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:36:46.831466 [debug] [Thread-1 (]: Timing info for model.campaign_performance.deals_dimension (execute): 15:36:46.107566 => 15:36:46.831013
[0m15:36:46.832286 [debug] [Thread-1 (]: On model.campaign_performance.deals_dimension: Close
[0m15:36:46.833997 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105a55bd0>]}
[0m15:36:46.835091 [info ] [Thread-1 (]: 2 of 12 OK created sql view model danila.deals_dimension ....................... [[32mCREATE VIEW[0m in 0.73s]
[0m15:36:46.836208 [debug] [Thread-1 (]: Finished running node model.campaign_performance.deals_dimension
[0m15:36:46.837161 [debug] [Thread-1 (]: Began running node model.campaign_performance.outclick_by_brand_int
[0m15:36:46.838050 [info ] [Thread-1 (]: 3 of 12 START sql table model danila.outclick_by_brand_int ..................... [RUN]
[0m15:36:46.838969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.deals_dimension, now model.campaign_performance.outclick_by_brand_int)
[0m15:36:46.839418 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.outclick_by_brand_int
[0m15:36:46.859716 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.outclick_by_brand_int"
[0m15:36:46.860535 [debug] [Thread-1 (]: Timing info for model.campaign_performance.outclick_by_brand_int (compile): 15:36:46.839723 => 15:36:46.860366
[0m15:36:46.860822 [debug] [Thread-1 (]: Began executing node model.campaign_performance.outclick_by_brand_int
[0m15:36:46.876440 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.outclick_by_brand_int"
[0m15:36:46.876898 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_by_brand_int"
[0m15:36:46.877082 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: BEGIN
[0m15:36:46.877252 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:36:47.306691 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:36:47.308537 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_by_brand_int"
[0m15:36:47.309761 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_by_brand_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with stg_records as (
    select 
    --'records' as source,
    date_parsed as date, 
    geo as country_code, 
    CASE  
        WHEN campaign_name::text = 'jpluckyslotsonline'::text THEN 'luckyslotsonline'::character varying
        WHEN campaign_name::text = 'ficashstormslots'::text THEN 'cashstormslots'::character varying
        WHEN campaign_name::text = 'goldenlion'::text THEN 'goldenliongames'::character varying
        ELSE campaign_name
    END as campaign_name, 
    lower(adgroup_name) as ga_campaign_name, 
    CASE 
        when right(brand_name,6)<>'sports' then 'casino'
        when right(brand_name,6)='sports' then 'sports'
        else 'other'
    END as campaign_vertical,
    CASE
        WHEN campaign_name::text = 'email' THEN brand_name || ' email'
        WHEN campaign_name::text = 'PA' THEN brand_name || ' PA'
        ELSE brand_name
    END as brand_name, 
    NULL as outclicks, 
    NULL as unique_outclicks, 
    NULL as avg_list_position, 
    NULL as pos_list,
    registrations, --sum(registrations) as signups, 
    cpa_count, --sum(cpa_count) as cpa_count, 
    cpa_commissions, --sum(cpa_commissions) AS cpa_commissions,
    total_commission, -- coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
    gtee_count,
    gtee_commissions,
    deposits --sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
    --avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
from "deep-analysis-console"."console"."records" records
where date_parsed > '2023-01-01'
),

 main as (
    select 
        --date(timestamp - interval '2 hours') as date, 
        'matomo' as source,
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date,
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name,
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical, 
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(matomo_actions.id) as outclicks,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        round(avg(eventvalue), 2) AS avg_list_position,
        string_agg(DISTINCT eventvalue::character varying::text, ';'::text) AS pos_list,
        NULL as signups, NULL as cpa_count, NULL as cpa_commissions, NULL as revshare_commissions, NULL as gtee_count,
        NULL as gtee_commissions, NULL as avg_deposit_amount
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits 
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where 
        matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        --and date(timestamp - interval '2 hours') >'2023-01-01'
        and 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 >'2023-01-01'
    --[[ and parse_matomo_timestamp(timestamp) in ( select date_parsed from calendar where  ) ]]
    -- [[ and "left"(matomo_actions.eventname::text, 2) in ( select distinct geo from campaign_names_mapping WHERE  ) ]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and lower(sitename) in ( select distinct console_campaign_name from campaign_names_mapping WHERE )]]
    -- [[ and "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) in ( select distinct brand_name from records WHERE  ) ]]
    group by source, campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    /*affiliate records aggregated data from records table*/
    union all
    select 
        'records' as source,
        date, 
        country_code, 
        campaign_name, 
	    ga_campaign_name, 
        campaign_vertical, 
        brand_name,
        NULL as outclicks, 
        NULL as unique_outclicks, 
        NULL as avg_list_position, 
        NULL as pos_list,
        sum(registrations) as signups, 
        sum(cpa_count) as cpa_count, 
        sum(cpa_commissions) AS cpa_commissions,
        coalesce(sum(total_commission-cpa_commissions) filter(where total_commission-cpa_commissions<>0 and gtee_count=0),0) AS revshare_commissions,
        sum(gtee_count) as gtee_count, sum(gtee_commissions) as gtee_commissions,
        avg(deposits) FILTER(where cpa_count>0) AS avg_deposit_amount
    from stg_records 
        -- right(brand_name,6)<>'sports'
        -- and date_parsed > '2023-12-31'
    --[[ and date_parsed in ( select date_parsed from calendar where  ) ]]
    -- [[ and geo in (select distinct geo from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and campaign_name in ( select distinct console_campaign_name from campaign_names_mapping WHERE ) ]]
    -- [[ and  ]]
    group by source, date, country_code, campaign_name, ga_campaign_name, campaign_vertical, brand_name
)

select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id
from main
  );
  
[0m15:37:02.494669 [debug] [Thread-1 (]: SQL status: SELECT 512094 in 15.0 seconds
[0m15:37:02.508907 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_by_brand_int"
[0m15:37:02.509491 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int" rename to "outclick_by_brand_int__dbt_backup"
[0m15:37:02.562237 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:02.568063 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_by_brand_int"
[0m15:37:02.568769 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_by_brand_int"} */
alter table "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_tmp" rename to "outclick_by_brand_int"
[0m15:37:02.621804 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:02.632364 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: COMMIT
[0m15:37:02.632964 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_by_brand_int"
[0m15:37:02.633294 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: COMMIT
[0m15:37:02.685565 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:37:02.691347 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_by_brand_int"
[0m15:37:02.691984 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_by_brand_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_by_brand_int__dbt_backup" cascade
[0m15:37:02.777547 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:37:02.779582 [debug] [Thread-1 (]: Timing info for model.campaign_performance.outclick_by_brand_int (execute): 15:36:46.860988 => 15:37:02.779185
[0m15:37:02.779959 [debug] [Thread-1 (]: On model.campaign_performance.outclick_by_brand_int: Close
[0m15:37:02.781279 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c21f50>]}
[0m15:37:02.782053 [info ] [Thread-1 (]: 3 of 12 OK created sql table model danila.outclick_by_brand_int ................ [[32mSELECT 512094[0m in 15.94s]
[0m15:37:02.782633 [debug] [Thread-1 (]: Finished running node model.campaign_performance.outclick_by_brand_int
[0m15:37:02.783007 [debug] [Thread-1 (]: Began running node model.campaign_performance.outclick_cost_int
[0m15:37:02.783879 [info ] [Thread-1 (]: 4 of 12 START sql table model danila.outclick_cost_int ......................... [RUN]
[0m15:37:02.784454 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.outclick_by_brand_int, now model.campaign_performance.outclick_cost_int)
[0m15:37:02.784719 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.outclick_cost_int
[0m15:37:02.791750 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.outclick_cost_int"
[0m15:37:02.792390 [debug] [Thread-1 (]: Timing info for model.campaign_performance.outclick_cost_int (compile): 15:37:02.784901 => 15:37:02.792274
[0m15:37:02.792615 [debug] [Thread-1 (]: Began executing node model.campaign_performance.outclick_cost_int
[0m15:37:02.795115 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.outclick_cost_int"
[0m15:37:02.795542 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_cost_int"
[0m15:37:02.795743 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: BEGIN
[0m15:37:02.795932 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:03.329441 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:37:03.330600 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_cost_int"
[0m15:37:03.331462 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_cost_int"} */

  
    

  create  table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp"
  
  
    as
  
  (
    -- models/campaign_level_data.sql

with main as 
(
    select
        'matomo' as source, --matomo
        
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
 as date, --matomo update
        "left"(matomo_actions.eventname::text, 2) as country_code, 
        lower(sitename) as campaign_name, 
        campaignname as ga_campaign_name, 
        CASE 
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports' then 'casino'
            when right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        "right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3) as brand_name,
        count(DISTINCT matomo_visits.visitorid) AS unique_outclicks,
        NULL as cost
    from "deep-analysis-console"."console"."matomo_actions" matomo_actions
    left join "deep-analysis-console"."console"."matomo_visits" matomo_visits
    on matomo_actions.matomo_visit_id=matomo_visits.id
    where matomo_actions.type = 'event' 
        AND matomo_actions.subtitle = 'Category: "OutClicks, Action: "Click on casino banner"'
        --and right("right"(matomo_actions.eventname::text, length(matomo_actions.eventname::text) - 3),6)<>'sports'
        AND 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
>'2023-01-01' --matomo
    group by campaign_name, campaignname, campaign_vertical, 
    CASE
        WHEN DATE(timestamp - INTERVAL '2 hour') > DATE '2023-10-28' THEN DATE(timestamp - INTERVAL '2 hour')
        ELSE DATE(timestamp - INTERVAL '3 hour')
    END
, brand_name, country_code
    union all
    select
        'records_gap_campaigns' as source, --'records'
        day as date, 
        geo as country_code, 
        console_campaign_name as campaign_name, 
        lower(campaign) as ga_campaign_name, 
        CASE 
            when campaign_names_mapping.campaign_vertical='casino' then 'casino'
            when campaign_names_mapping.campaign_vertical='sports' then 'sports'
            else 'other'
        END as campaign_vertical,
        NULL as brand_name, 
        NULL as unique_outclicks, 
        sum(cost) as cost
    from "deep-analysis-console"."console"."records_gap_campaigns"  records_gap_campaigns
    left join "deep-analysis-console"."console"."campaign_names_mapping" campaign_names_mapping on campaign_names_mapping.gap_campaign_name=records_gap_campaigns.campaign
    where day >'2023-01-01'
        -- campaign_names_mapping.campaign_vertical='casino'
        -- and day >'2023-12-31' --matomo

    group by day, country_code, campaign_name, ga_campaign_name, campaign_vertical
)


select *,
md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(source as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id

from main


-- Checking for duplicates
-- test as (
--     select 
--     md5(cast(coalesce(cast(campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(ga_campaign_name as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(campaign_vertical as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(date as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(country_code as TEXT), '_dbt_utils_surrogate_key_null_') || '-' || coalesce(cast(brand_name as TEXT), '_dbt_utils_surrogate_key_null_') as TEXT)) as id, 
--     *
-- from main
-- )

-- select * 
-- from test
-- left join (select id, count(*) from test group by id having count(*)>1) as duplicates on test.id=duplicates.id
-- where duplicates.id is not null --and cost is not null and test.id='df85a909516d6442b4f696089262f04a'
  );
  
[0m15:37:12.033462 [debug] [Thread-1 (]: SQL status: SELECT 146373 in 9.0 seconds
[0m15:37:12.037696 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_cost_int"
[0m15:37:12.038162 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int" rename to "outclick_cost_int__dbt_backup"
[0m15:37:12.097724 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:12.104828 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_cost_int"
[0m15:37:12.105540 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_cost_int"} */
alter table "deep-analysis-console"."danila"."outclick_cost_int__dbt_tmp" rename to "outclick_cost_int"
[0m15:37:12.165780 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:12.170079 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: COMMIT
[0m15:37:12.170846 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_cost_int"
[0m15:37:12.171475 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: COMMIT
[0m15:37:12.231414 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:37:12.238186 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.outclick_cost_int"
[0m15:37:12.238651 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.outclick_cost_int"} */
drop table if exists "deep-analysis-console"."danila"."outclick_cost_int__dbt_backup" cascade
[0m15:37:12.325479 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:37:12.329240 [debug] [Thread-1 (]: Timing info for model.campaign_performance.outclick_cost_int (execute): 15:37:02.792743 => 15:37:12.328875
[0m15:37:12.329898 [debug] [Thread-1 (]: On model.campaign_performance.outclick_cost_int: Close
[0m15:37:12.331542 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055b2750>]}
[0m15:37:12.332389 [info ] [Thread-1 (]: 4 of 12 OK created sql table model danila.outclick_cost_int .................... [[32mSELECT 146373[0m in 9.55s]
[0m15:37:12.333411 [debug] [Thread-1 (]: Finished running node model.campaign_performance.outclick_cost_int
[0m15:37:12.334087 [debug] [Thread-1 (]: Began running node model.campaign_performance.stg_scraper__records
[0m15:37:12.335216 [info ] [Thread-1 (]: 5 of 12 START sql table model danila.stg_scraper__records ...................... [RUN]
[0m15:37:12.336269 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.outclick_cost_int, now model.campaign_performance.stg_scraper__records)
[0m15:37:12.336679 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.stg_scraper__records
[0m15:37:12.341130 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.stg_scraper__records"
[0m15:37:12.343044 [debug] [Thread-1 (]: Timing info for model.campaign_performance.stg_scraper__records (compile): 15:37:12.336932 => 15:37:12.342847
[0m15:37:12.343368 [debug] [Thread-1 (]: Began executing node model.campaign_performance.stg_scraper__records
[0m15:37:12.347090 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.stg_scraper__records"
[0m15:37:12.348300 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:37:12.348697 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: BEGIN
[0m15:37:12.348978 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:12.828394 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:37:12.829206 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:37:12.829892 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:37:15.379552 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:37:15.385335 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:37:15.385738 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:37:15.444521 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:15.446981 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:37:15.447283 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:37:15.506238 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:15.509452 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: COMMIT
[0m15:37:15.510026 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:37:15.510409 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: COMMIT
[0m15:37:15.569626 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:37:15.576628 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:37:15.577506 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:37:15.661898 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:37:15.663223 [debug] [Thread-1 (]: Timing info for model.campaign_performance.stg_scraper__records (execute): 15:37:12.343564 => 15:37:15.663051
[0m15:37:15.663535 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: Close
[0m15:37:15.664238 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c4aa90>]}
[0m15:37:15.664683 [info ] [Thread-1 (]: 5 of 12 OK created sql table model danila.stg_scraper__records ................. [[32mSELECT 72414[0m in 3.33s]
[0m15:37:15.665162 [debug] [Thread-1 (]: Finished running node model.campaign_performance.stg_scraper__records
[0m15:37:15.665472 [debug] [Thread-1 (]: Began running node model.campaign_performance.test
[0m15:37:15.665917 [info ] [Thread-1 (]: 6 of 12 START sql view model danila.test ....................................... [RUN]
[0m15:37:15.666650 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.stg_scraper__records, now model.campaign_performance.test)
[0m15:37:15.666953 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.test
[0m15:37:15.668435 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.test"
[0m15:37:15.669101 [debug] [Thread-1 (]: Timing info for model.campaign_performance.test (compile): 15:37:15.667139 => 15:37:15.668965
[0m15:37:15.669327 [debug] [Thread-1 (]: Began executing node model.campaign_performance.test
[0m15:37:15.671884 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.test"
[0m15:37:15.672314 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.test"
[0m15:37:15.672533 [debug] [Thread-1 (]: On model.campaign_performance.test: BEGIN
[0m15:37:15.672728 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:16.145765 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:37:16.146940 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.test"
[0m15:37:16.147805 [debug] [Thread-1 (]: On model.campaign_performance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.test"} */

  create view "deep-analysis-console"."danila"."test__dbt_tmp"
    
    
  as (
    -- with main as (
--     select
--         id
--         , user_id
--         , conversion_timestamp
--         , registrations
--         , deal_id
--         , date_parsed as date_cet
--         --, click_id
--         , geo as country_code
--         -- , registrations as signed_up
--         --, cpa_count as deposited_first_time
--         -- , gtee_count
--         , cpa_commissions as acquisition_commission
--         -- , total_commission
--         -- , gtee_commissions
--         -- , net_revenue
--         -- , revshare_commissions
--         , lower(adgroup_name) as ga_campaign_name
--         , case
--             when right(brand_name, 6) <> 'sports' then 'casino'
--             when right(brand_name, 6) = 'sports' then 'sports'
--             else 'other'
--         end as campaign_vertical
--         , case
--             when campaign_name::text = 'email' then brand_name || ' email'
--             when campaign_name::text = 'PA' then brand_name || ' PA'
--             else brand_name
--         end as brand_name

--         , case
--             when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
--             when campaign_name = 'ficashstormslots' then 'cashstormslots'
--             when campaign_name = 'goldenlion' then 'goldenliongames'
--             else campaign_name
--         end as campaign_name
--     from records
--     where
--         date_parsed > '2024-03-31'
--         and cpa_count > 0.5
--         --and deal_id is null
--         --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
--     --and user_id='ae4eb2f5ad8ebf29'
--     order by user_id, deal_id, date_parsed
-- )




-- select * from main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


SELECT id, user_id, date_parsed, date, brand_name, cpa_count, registrations, conversion_timestamp
FROM records
WHERE id='5393572' or id= '5393571'--date_parsed = '2024-05-16' AND user_id = '51a4a42eaaeb12f7'
--GROUP BY user_id, conversion_timestamp, date_parsed, brand_name, cpa_count, registrations
--HAVING COUNT(*) = 1
  );
[0m15:37:16.210584 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:37:16.214254 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.test"
[0m15:37:16.214668 [debug] [Thread-1 (]: On model.campaign_performance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.test"} */
alter table "deep-analysis-console"."danila"."test" rename to "test__dbt_backup"
[0m15:37:16.272964 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:16.277637 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.test"
[0m15:37:16.278171 [debug] [Thread-1 (]: On model.campaign_performance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.test"} */
alter table "deep-analysis-console"."danila"."test__dbt_tmp" rename to "test"
[0m15:37:16.337410 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:16.341520 [debug] [Thread-1 (]: On model.campaign_performance.test: COMMIT
[0m15:37:16.342316 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.test"
[0m15:37:16.342972 [debug] [Thread-1 (]: On model.campaign_performance.test: COMMIT
[0m15:37:16.401458 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:37:16.403737 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.test"
[0m15:37:16.404006 [debug] [Thread-1 (]: On model.campaign_performance.test: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.test"} */
drop view if exists "deep-analysis-console"."danila"."test__dbt_backup" cascade
[0m15:37:16.463308 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:37:16.466237 [debug] [Thread-1 (]: Timing info for model.campaign_performance.test (execute): 15:37:15.669467 => 15:37:16.466070
[0m15:37:16.466564 [debug] [Thread-1 (]: On model.campaign_performance.test: Close
[0m15:37:16.467409 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058b8750>]}
[0m15:37:16.467882 [info ] [Thread-1 (]: 6 of 12 OK created sql view model danila.test .................................. [[32mCREATE VIEW[0m in 0.80s]
[0m15:37:16.468390 [debug] [Thread-1 (]: Finished running node model.campaign_performance.test
[0m15:37:16.468786 [debug] [Thread-1 (]: Began running node test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:37:16.469372 [info ] [Thread-1 (]: 7 of 12 START test not_null_outclick_by_brand_int_id ........................... [RUN]
[0m15:37:16.470251 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.test, now test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d)
[0m15:37:16.470567 [debug] [Thread-1 (]: Began compiling node test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:37:16.486452 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:37:16.487245 [debug] [Thread-1 (]: Timing info for test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d (compile): 15:37:16.470756 => 15:37:16.487103
[0m15:37:16.487456 [debug] [Thread-1 (]: Began executing node test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:37:16.496314 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:37:16.496984 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:37:16.497182 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d: BEGIN
[0m15:37:16.497342 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:16.972444 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:37:16.973573 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d"
[0m15:37:16.974155 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is null



      
    ) dbt_internal_test
[0m15:37:17.190518 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:37:17.192826 [debug] [Thread-1 (]: Timing info for test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d (execute): 15:37:16.487580 => 15:37:17.192654
[0m15:37:17.193121 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d: ROLLBACK
[0m15:37:17.250986 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d: Close
[0m15:37:17.251953 [info ] [Thread-1 (]: 7 of 12 PASS not_null_outclick_by_brand_int_id ................................. [[32mPASS[0m in 0.78s]
[0m15:37:17.252585 [debug] [Thread-1 (]: Finished running node test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d
[0m15:37:17.252992 [debug] [Thread-1 (]: Began running node test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:37:17.253482 [info ] [Thread-1 (]: 8 of 12 START test unique_outclick_by_brand_int_id ............................. [RUN]
[0m15:37:17.254165 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_performance.not_null_outclick_by_brand_int_id.ce690b4d9d, now test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b)
[0m15:37:17.254508 [debug] [Thread-1 (]: Began compiling node test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:37:17.260050 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:37:17.260860 [debug] [Thread-1 (]: Timing info for test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b (compile): 15:37:17.254723 => 15:37:17.260687
[0m15:37:17.261143 [debug] [Thread-1 (]: Began executing node test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:37:17.264483 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:37:17.265120 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:37:17.265364 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b: BEGIN
[0m15:37:17.265583 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:17.766108 [debug] [Thread-1 (]: SQL status: BEGIN in 1.0 seconds
[0m15:37:17.767349 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b"
[0m15:37:17.767956 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_by_brand_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:37:18.571564 [debug] [Thread-1 (]: SQL status: SELECT 1 in 1.0 seconds
[0m15:37:18.574061 [debug] [Thread-1 (]: Timing info for test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b (execute): 15:37:17.261316 => 15:37:18.573789
[0m15:37:18.574798 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b: ROLLBACK
[0m15:37:18.630091 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b: Close
[0m15:37:18.631283 [info ] [Thread-1 (]: 8 of 12 PASS unique_outclick_by_brand_int_id ................................... [[32mPASS[0m in 1.38s]
[0m15:37:18.632004 [debug] [Thread-1 (]: Finished running node test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b
[0m15:37:18.632474 [debug] [Thread-1 (]: Began running node test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:37:18.633009 [info ] [Thread-1 (]: 9 of 12 START test not_null_outclick_cost_int_id ............................... [RUN]
[0m15:37:18.633856 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_performance.unique_outclick_by_brand_int_id.965b521b6b, now test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda)
[0m15:37:18.634199 [debug] [Thread-1 (]: Began compiling node test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:37:18.638244 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:37:18.639020 [debug] [Thread-1 (]: Timing info for test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda (compile): 15:37:18.634411 => 15:37:18.638838
[0m15:37:18.639337 [debug] [Thread-1 (]: Began executing node test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:37:18.641091 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:37:18.641625 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:37:18.641919 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda: BEGIN
[0m15:37:18.642164 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:19.043592 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:37:19.044950 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda"
[0m15:37:19.045575 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from "deep-analysis-console"."danila"."outclick_cost_int"
where id is null



      
    ) dbt_internal_test
[0m15:37:19.132008 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:37:19.135619 [debug] [Thread-1 (]: Timing info for test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda (execute): 15:37:18.639534 => 15:37:19.135220
[0m15:37:19.136359 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda: ROLLBACK
[0m15:37:19.205600 [debug] [Thread-1 (]: On test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda: Close
[0m15:37:19.208433 [info ] [Thread-1 (]: 9 of 12 PASS not_null_outclick_cost_int_id ..................................... [[32mPASS[0m in 0.57s]
[0m15:37:19.209731 [debug] [Thread-1 (]: Finished running node test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda
[0m15:37:19.210444 [debug] [Thread-1 (]: Began running node test.campaign_performance.unique_outclick_cost_int_id.3afb93741f
[0m15:37:19.211120 [info ] [Thread-1 (]: 10 of 12 START test unique_outclick_cost_int_id ................................ [RUN]
[0m15:37:19.212141 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_performance.not_null_outclick_cost_int_id.a7d76ffeda, now test.campaign_performance.unique_outclick_cost_int_id.3afb93741f)
[0m15:37:19.212626 [debug] [Thread-1 (]: Began compiling node test.campaign_performance.unique_outclick_cost_int_id.3afb93741f
[0m15:37:19.219253 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_performance.unique_outclick_cost_int_id.3afb93741f"
[0m15:37:19.220616 [debug] [Thread-1 (]: Timing info for test.campaign_performance.unique_outclick_cost_int_id.3afb93741f (compile): 15:37:19.212916 => 15:37:19.220357
[0m15:37:19.221027 [debug] [Thread-1 (]: Began executing node test.campaign_performance.unique_outclick_cost_int_id.3afb93741f
[0m15:37:19.223766 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_performance.unique_outclick_cost_int_id.3afb93741f"
[0m15:37:19.224678 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.unique_outclick_cost_int_id.3afb93741f"
[0m15:37:19.225019 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_cost_int_id.3afb93741f: BEGIN
[0m15:37:19.225318 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:19.611084 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:37:19.612970 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.unique_outclick_cost_int_id.3afb93741f"
[0m15:37:19.614370 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_cost_int_id.3afb93741f: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_performance.unique_outclick_cost_int_id.3afb93741f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."outclick_cost_int"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:37:19.760088 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:37:19.764635 [debug] [Thread-1 (]: Timing info for test.campaign_performance.unique_outclick_cost_int_id.3afb93741f (execute): 15:37:19.221293 => 15:37:19.764239
[0m15:37:19.765344 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_cost_int_id.3afb93741f: ROLLBACK
[0m15:37:19.812822 [debug] [Thread-1 (]: On test.campaign_performance.unique_outclick_cost_int_id.3afb93741f: Close
[0m15:37:19.816374 [info ] [Thread-1 (]: 10 of 12 PASS unique_outclick_cost_int_id ...................................... [[32mPASS[0m in 0.60s]
[0m15:37:19.817585 [debug] [Thread-1 (]: Finished running node test.campaign_performance.unique_outclick_cost_int_id.3afb93741f
[0m15:37:19.818354 [debug] [Thread-1 (]: Began running node test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:37:19.819157 [info ] [Thread-1 (]: 11 of 12 START test unique_stg_scraper__records_grain_id ....................... [RUN]
[0m15:37:19.820439 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_performance.unique_outclick_cost_int_id.3afb93741f, now test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36)
[0m15:37:19.821046 [debug] [Thread-1 (]: Began compiling node test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:37:19.828422 [debug] [Thread-1 (]: Writing injected SQL for node "test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:37:19.830323 [debug] [Thread-1 (]: Timing info for test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36 (compile): 15:37:19.821632 => 15:37:19.829948
[0m15:37:19.831023 [debug] [Thread-1 (]: Began executing node test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:37:19.833882 [debug] [Thread-1 (]: Writing runtime sql for node "test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:37:19.834905 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:37:19.835233 [debug] [Thread-1 (]: On test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36: BEGIN
[0m15:37:19.835549 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:20.220048 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:37:20.221642 [debug] [Thread-1 (]: Using postgres connection "test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36"
[0m15:37:20.222483 [debug] [Thread-1 (]: On test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    grain_id as unique_field,
    count(*) as n_records

from "deep-analysis-console"."danila"."stg_scraper__records"
where grain_id is not null
group by grain_id
having count(*) > 1



      
    ) dbt_internal_test
[0m15:37:20.344247 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m15:37:20.347077 [debug] [Thread-1 (]: Timing info for test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36 (execute): 15:37:19.831303 => 15:37:20.346705
[0m15:37:20.347784 [debug] [Thread-1 (]: On test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36: ROLLBACK
[0m15:37:20.400471 [debug] [Thread-1 (]: On test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36: Close
[0m15:37:20.402845 [info ] [Thread-1 (]: 11 of 12 PASS unique_stg_scraper__records_grain_id ............................. [[32mPASS[0m in 0.58s]
[0m15:37:20.403983 [debug] [Thread-1 (]: Finished running node test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36
[0m15:37:20.405676 [debug] [Thread-1 (]: Began running node model.campaign_performance.first_deposits_fct
[0m15:37:20.406726 [info ] [Thread-1 (]: 12 of 12 START sql view model danila.first_deposits_fct ........................ [RUN]
[0m15:37:20.407824 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.campaign_performance.unique_stg_scraper__records_grain_id.0452796a36, now model.campaign_performance.first_deposits_fct)
[0m15:37:20.408480 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.first_deposits_fct
[0m15:37:20.413972 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.first_deposits_fct"
[0m15:37:20.415471 [debug] [Thread-1 (]: Timing info for model.campaign_performance.first_deposits_fct (compile): 15:37:20.409161 => 15:37:20.415076
[0m15:37:20.415969 [debug] [Thread-1 (]: Began executing node model.campaign_performance.first_deposits_fct
[0m15:37:20.420638 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.first_deposits_fct"
[0m15:37:20.421368 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:37:20.421684 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: BEGIN
[0m15:37:20.421973 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:37:20.869906 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:37:20.871273 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:37:20.872197 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */

  create view "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
    
    
  as (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
[0m15:37:20.931851 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m15:37:20.938590 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:37:20.939416 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:37:20.995156 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:37:20.999452 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: COMMIT
[0m15:37:21.000173 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:37:21.000713 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: COMMIT
[0m15:37:21.056143 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:37:21.061430 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:37:21.062148 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */
drop view if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:37:21.117333 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m15:37:21.121026 [debug] [Thread-1 (]: Timing info for model.campaign_performance.first_deposits_fct (execute): 15:37:20.416227 => 15:37:21.120601
[0m15:37:21.121939 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: Close
[0m15:37:21.123700 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6f7bea37-988f-4dc2-9db5-1aa1ea195d8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c787d0>]}
[0m15:37:21.124652 [info ] [Thread-1 (]: 12 of 12 OK created sql view model danila.first_deposits_fct ................... [[32mCREATE VIEW[0m in 0.72s]
[0m15:37:21.125524 [debug] [Thread-1 (]: Finished running node model.campaign_performance.first_deposits_fct
[0m15:37:21.128257 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:21.128857 [debug] [MainThread]: On master: BEGIN
[0m15:37:21.129181 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:37:21.511714 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:37:21.512868 [debug] [MainThread]: On master: COMMIT
[0m15:37:21.513357 [debug] [MainThread]: Using postgres connection "master"
[0m15:37:21.513777 [debug] [MainThread]: On master: COMMIT
[0m15:37:21.560317 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:37:21.561342 [debug] [MainThread]: On master: Close
[0m15:37:21.562962 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:37:21.563605 [debug] [MainThread]: Connection 'model.campaign_performance.first_deposits_fct' was properly closed.
[0m15:37:21.564312 [info ] [MainThread]: 
[0m15:37:21.564925 [info ] [MainThread]: Finished running 4 view models, 3 table models, 5 tests in 0 hours 0 minutes and 38.82 seconds (38.82s).
[0m15:37:21.567879 [debug] [MainThread]: Command end result
[0m15:37:21.581373 [info ] [MainThread]: 
[0m15:37:21.581895 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:37:21.582206 [info ] [MainThread]: 
[0m15:37:21.582514 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=0 SKIP=0 TOTAL=12
[0m15:37:21.583247 [debug] [MainThread]: Command `dbt build` succeeded at 15:37:21.583167 after 38.96 seconds
[0m15:37:21.583573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103b9d350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100c371d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x100c3ce10>]}
[0m15:37:21.583839 [debug] [MainThread]: Flushing usage events
[0m15:37:25.311568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133a5190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133b3010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133b36d0>]}


============================== 15:37:25.313135 | 41a8a7cf-7e5b-4a55-b76d-728d99ff4381 ==============================
[0m15:37:25.313135 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:37:25.313471 [debug] [MainThread]: running dbt with arguments {'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'debug': 'False', 'warn_error': 'None', 'indirect_selection': 'eager', 'introspect': 'True', 'profiles_dir': '/Users/danila/.dbt', 'fail_fast': 'False', 'static_parser': 'True', 'write_json': 'True', 'log_path': '/Users/danila/github/dbt/logs', 'log_cache_events': 'False', 'no_print': 'None', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'quiet': 'False', 'log_format': 'default', 'cache_selected_only': 'False', 'use_colors': 'True', 'printer_width': '80', 'use_experimental_parser': 'False'}
[0m15:37:25.343948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41a8a7cf-7e5b-4a55-b76d-728d99ff4381', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11325ff90>]}
[0m15:37:25.350185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41a8a7cf-7e5b-4a55-b76d-728d99ff4381', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133c6c90>]}
[0m15:37:25.350619 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:37:25.364858 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:37:25.399091 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:37:25.399295 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:37:25.399587 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 4 unused configuration paths:
- models.users
- models.staging.scraper
- models.marts
- models.brand_performance
[0m15:37:25.402028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41a8a7cf-7e5b-4a55-b76d-728d99ff4381', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111676250>]}
[0m15:37:25.406909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41a8a7cf-7e5b-4a55-b76d-728d99ff4381', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113756e50>]}
[0m15:37:25.407127 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:37:25.407288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41a8a7cf-7e5b-4a55-b76d-728d99ff4381', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112de29d0>]}
[0m15:37:25.407905 [debug] [MainThread]: Command `dbt ls` succeeded at 15:37:25.407854 after 0.11 seconds
[0m15:37:25.408062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105050e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11373fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10504b1d0>]}
[0m15:37:25.408186 [debug] [MainThread]: Flushing usage events
[0m15:37:42.713401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a98ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118e2d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11188d950>]}


============================== 15:37:42.714831 | fdd93844-6083-4303-aac2-ad9a809c82a4 ==============================
[0m15:37:42.714831 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:37:42.715119 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'static_parser': 'True', 'write_json': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'no_print': 'None', 'send_anonymous_usage_stats': 'True', 'partial_parse': 'True', 'warn_error': 'None', 'quiet': 'False', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'printer_width': '80', 'profiles_dir': '/Users/danila/.dbt', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'version_check': 'True', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'cache_selected_only': 'False', 'log_path': '/Users/danila/github/dbt/logs'}
[0m15:37:42.744773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fdd93844-6083-4303-aac2-ad9a809c82a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d2d810>]}
[0m15:37:42.750956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fdd93844-6083-4303-aac2-ad9a809c82a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112abbad0>]}
[0m15:37:42.751372 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:37:42.763913 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:37:42.793407 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:37:42.793609 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:37:42.793888 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.campaign_performance.users
[0m15:37:42.796344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fdd93844-6083-4303-aac2-ad9a809c82a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cead10>]}
[0m15:37:42.801493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fdd93844-6083-4303-aac2-ad9a809c82a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d7bd50>]}
[0m15:37:42.801701 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:37:42.801868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fdd93844-6083-4303-aac2-ad9a809c82a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a9da90>]}
[0m15:37:42.802480 [debug] [MainThread]: Command `dbt ls` succeeded at 15:37:42.802428 after 0.10 seconds
[0m15:37:42.802629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10573f150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10573f090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1056be490>]}
[0m15:37:42.802754 [debug] [MainThread]: Flushing usage events
[0m15:38:00.422517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a2210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107872750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a7f90>]}


============================== 15:38:00.425529 | cbf5738d-9abe-4e14-b44f-b509279e98a3 ==============================
[0m15:38:00.425529 [info ] [MainThread]: Running with dbt=1.5.4
[0m15:38:00.425854 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'log_path': '/Users/danila/github/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'no_print': 'None', 'use_colors': 'True', 'profiles_dir': '/Users/danila/.dbt', 'static_parser': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'partial_parse': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'quiet': 'False', 'write_json': 'True', 'printer_width': '80', 'log_cache_events': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])'}
[0m15:38:00.458378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dfe050>]}
[0m15:38:00.464851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089b7e90>]}
[0m15:38:00.465304 [info ] [MainThread]: Registered adapter: postgres=1.5.4
[0m15:38:00.479616 [debug] [MainThread]: checksum: 5d6b65bf0937b31c1cb174f5650843d5ea9953bdf3de7df3d9ed5979670d6d21, vars: {}, profile: , target: , version: 1.5.4
[0m15:38:00.517169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:38:00.517344 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:38:00.517637 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.campaign_performance.users
[0m15:38:00.520163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f4c490>]}
[0m15:38:00.524475 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e73e90>]}
[0m15:38:00.524671 [info ] [MainThread]: Found 7 models, 5 tests, 0 snapshots, 0 analyses, 444 macros, 0 operations, 0 seed files, 14 sources, 0 exposures, 0 metrics, 0 groups
[0m15:38:00.524827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e6a710>]}
[0m15:38:00.525412 [info ] [MainThread]: 
[0m15:38:00.525723 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:38:00.526171 [debug] [ThreadPool]: Acquiring new postgres connection 'list_deep-analysis-console'
[0m15:38:00.530126 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console"
[0m15:38:00.530256 [debug] [ThreadPool]: On list_deep-analysis-console: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console"} */

    select distinct nspname from pg_namespace
  
[0m15:38:00.530365 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:38:00.973281 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.0 seconds
[0m15:38:00.978640 [debug] [ThreadPool]: On list_deep-analysis-console: Close
[0m15:38:00.981754 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_deep-analysis-console, now list_deep-analysis-console_danila)
[0m15:38:00.987377 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:38:00.987677 [debug] [ThreadPool]: On list_deep-analysis-console_danila: BEGIN
[0m15:38:00.987892 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:38:01.375548 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m15:38:01.378302 [debug] [ThreadPool]: Using postgres connection "list_deep-analysis-console_danila"
[0m15:38:01.379377 [debug] [ThreadPool]: On list_deep-analysis-console_danila: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "list_deep-analysis-console_danila"} */
select
      'deep-analysis-console' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'danila'
    union all
    select
      'deep-analysis-console' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'danila'
  
[0m15:38:01.431038 [debug] [ThreadPool]: SQL status: SELECT 23 in 0.0 seconds
[0m15:38:01.436311 [debug] [ThreadPool]: On list_deep-analysis-console_danila: ROLLBACK
[0m15:38:01.483612 [debug] [ThreadPool]: On list_deep-analysis-console_danila: Close
[0m15:38:01.497584 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:01.497989 [debug] [MainThread]: On master: BEGIN
[0m15:38:01.498299 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:38:01.881970 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:38:01.882388 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:01.882559 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:38:01.937604 [debug] [MainThread]: SQL status: SELECT 53 in 0.0 seconds
[0m15:38:01.941257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089a4a10>]}
[0m15:38:01.942168 [debug] [MainThread]: On master: ROLLBACK
[0m15:38:01.989537 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:01.990438 [debug] [MainThread]: On master: BEGIN
[0m15:38:02.083537 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:38:02.084560 [debug] [MainThread]: On master: COMMIT
[0m15:38:02.085062 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:02.085465 [debug] [MainThread]: On master: COMMIT
[0m15:38:02.132249 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:38:02.133317 [debug] [MainThread]: On master: Close
[0m15:38:02.135189 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:38:02.135865 [info ] [MainThread]: 
[0m15:38:02.144484 [debug] [Thread-1 (]: Began running node model.campaign_performance.stg_scraper__records
[0m15:38:02.145261 [info ] [Thread-1 (]: 1 of 2 START sql table model danila.stg_scraper__records ....................... [RUN]
[0m15:38:02.146164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_deep-analysis-console_danila, now model.campaign_performance.stg_scraper__records)
[0m15:38:02.146550 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.stg_scraper__records
[0m15:38:02.154888 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.stg_scraper__records"
[0m15:38:02.156086 [debug] [Thread-1 (]: Timing info for model.campaign_performance.stg_scraper__records (compile): 15:38:02.146787 => 15:38:02.155873
[0m15:38:02.156414 [debug] [Thread-1 (]: Began executing node model.campaign_performance.stg_scraper__records
[0m15:38:02.181329 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.stg_scraper__records"
[0m15:38:02.182340 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:38:02.182551 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: BEGIN
[0m15:38:02.182724 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:02.564452 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:02.566227 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:38:02.567640 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */

  
    

  create  table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql



with source as (
    select * from "deep-analysis-console"."console"."records"
)

, transformed as (
    select
        id
        , created_at
        , user_id
        , deal_id
        , date_parsed as date_cet
        , click_id
        , geo as country_code
        , registrations as signed_up
        , cpa_count as deposited_first_time
        , gtee_count
        , cpa_commissions as acquisition_commission
        , deposits as acquisition_deposit
        , total_commission
        , gtee_commissions
        , net_revenue
        , revshare_commissions
        , lower(adgroup_name) as ga_campaign_name
        , case
            when right(brand_name, 6) <> 'sports' then 'casino'
            when right(brand_name, 6) = 'sports' then 'sports'
            else 'other'
        end as campaign_vertical
        , case
            when campaign_name::text = 'email' then brand_name || ' email'
            when campaign_name::text = 'PA' then brand_name || ' PA'
            else brand_name
        end as brand_name

        , case
            when campaign_name = 'jpluckyslotsonline' then 'luckyslotsonline'
            when campaign_name = 'ficashstormslots' then 'cashstormslots'
            when campaign_name = 'goldenlion' then 'goldenliongames'
            else campaign_name
        end as campaign_name
    from source
    where
        date_parsed > '2024-03-31'
        --and cpa_count > 0.5
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    order by user_id, deal_id, date_parsed
)

-- Add grain_id

, added_grain as (
    select
        *
        , md5(user_id || deal_id || date_cet) as grain_id
    from transformed
)


-- Identify duplicates by assigning row numbers
, ranked_records as (
    select
        *
        , row_number() over (
            partition by grain_id -- columns that define a duplicate
            order by id desc -- criteria to determine which record to keep
        ) as duplicate_count
    from added_grain
)

-- Filter out duplicates, keeping only the first occurrence
, deduplicated_records as (
    select *
    from
        ranked_records
    where
        duplicate_count = 1
)

select * from deduplicated_records



--main where user_id='51a4a42eaaeb12f7' and deal_id='2609' and date_cet='2024-05-16'


-- select user_id, deal_id, date_cet, count(id) as duplicates
-- from main
-- group by user_id, deal_id, date_cet
-- having count(id)>1.1
-- select user_id, date_parsed, registrations, depositing_customers, cpa_count

-- from records
-- where user_id='931800d1c75e2834'
-- order by date_parsed


-- with main as (
--     select user_id, created_at, deal_id, date, date_parsed
--         , case
--             when date ~ '^\d{2}-\d{2}-\d{4}$' then to_date(date, 'DD-MM-YYYY')
--             when date ~ '^\d{4}-\d{2}-\d{2}$' then to_date(date, 'YYYY-MM-DD')
--             when date ~ '^\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}$' then to_timestamp(date, 'YYYY-MM-DD HH24:MI:SS')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{2} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YY HH12:MI:SS AM')::date
--             when date ~ '^\d{1,2}/\d{1,2}/\d{4} \d{1,2}:\d{2}:\d{2} (AM|PM)$' then to_timestamp(date, 'MM/DD/YYYY HH12:MI:SS AM')::date
--             when date ~ '^\d{4}\.\d{2}\.\d{2}$' then to_date(date, 'YYYY.MM.DD')
--             when date ~ '^\d{5}-\d{2}-\d{2}$' then to_date(substring(date from 1 for 4) || substring(date from 6), 'YYYY-MM-DD')
--             else null
--         end as transformed_date
--     from records
-- ),

-- comparison as 
-- (select
--     *,
--     (case
--         when date_parsed = transformed_date then 1
--         else 0
--     end) as comparison
-- from main)

-- select * from comparison where comparison = 0 and date_parsed>'2024-04-30'
-- select sum(comparison), count(comparison)
-- from comparison
-- where date_parsed>'2024-01-31'
  );
  
[0m15:38:05.283578 [debug] [Thread-1 (]: SQL status: SELECT 72414 in 3.0 seconds
[0m15:38:05.298037 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:38:05.298676 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records" rename to "stg_scraper__records__dbt_backup"
[0m15:38:05.345209 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:05.351759 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:38:05.352553 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
alter table "deep-analysis-console"."danila"."stg_scraper__records__dbt_tmp" rename to "stg_scraper__records"
[0m15:38:05.399584 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:05.425729 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: COMMIT
[0m15:38:05.426135 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:38:05.426423 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: COMMIT
[0m15:38:05.472304 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:38:05.479210 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.stg_scraper__records"
[0m15:38:05.479687 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.stg_scraper__records"} */
drop table if exists "deep-analysis-console"."danila"."stg_scraper__records__dbt_backup" cascade
[0m15:38:05.549335 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:38:05.553853 [debug] [Thread-1 (]: Timing info for model.campaign_performance.stg_scraper__records (execute): 15:38:02.156599 => 15:38:05.553484
[0m15:38:05.554806 [debug] [Thread-1 (]: On model.campaign_performance.stg_scraper__records: Close
[0m15:38:05.557029 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f3aad0>]}
[0m15:38:05.558312 [info ] [Thread-1 (]: 1 of 2 OK created sql table model danila.stg_scraper__records .................. [[32mSELECT 72414[0m in 3.41s]
[0m15:38:05.559377 [debug] [Thread-1 (]: Finished running node model.campaign_performance.stg_scraper__records
[0m15:38:05.560886 [debug] [Thread-1 (]: Began running node model.campaign_performance.first_deposits_fct
[0m15:38:05.561530 [info ] [Thread-1 (]: 2 of 2 START sql table model danila.first_deposits_fct ......................... [RUN]
[0m15:38:05.562499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.campaign_performance.stg_scraper__records, now model.campaign_performance.first_deposits_fct)
[0m15:38:05.562954 [debug] [Thread-1 (]: Began compiling node model.campaign_performance.first_deposits_fct
[0m15:38:05.567974 [debug] [Thread-1 (]: Writing injected SQL for node "model.campaign_performance.first_deposits_fct"
[0m15:38:05.570243 [debug] [Thread-1 (]: Timing info for model.campaign_performance.first_deposits_fct (compile): 15:38:05.563260 => 15:38:05.569971
[0m15:38:05.570628 [debug] [Thread-1 (]: Began executing node model.campaign_performance.first_deposits_fct
[0m15:38:05.574951 [debug] [Thread-1 (]: Writing runtime sql for node "model.campaign_performance.first_deposits_fct"
[0m15:38:05.575823 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:38:05.576139 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: BEGIN
[0m15:38:05.576387 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:38:06.028113 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m15:38:06.029258 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:38:06.030003 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */

  
    

  create  table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp"
  
  
    as
  
  (
    -- models/staging/scraper/stg_scraper__records.sql

with source as (
    select * from "deep-analysis-console"."danila"."stg_scraper__records"
)

, transformed as (
    select
        'records' as source
        , date_cet
        , country_code
        , campaign_name
        , ga_campaign_name
        , campaign_vertical
        , brand_name
        , NULL as outclicks
        , NULL as unique_outclicks
        , NULL as avg_list_position
        , NULL as pos_list
        , sum(signed_up) as signups
        , sum(deposited_first_time) as cpa_count
        , sum(acquisition_commission) as cpa_commissions
        , coalesce(
            sum(total_commission - acquisition_commission) filter
            (
                where total_commission - acquisition_commission <> 0
                and gtee_count = 0
            ), 0
        ) as revshare_commissions
        , sum(gtee_count) as gtee_count
        , sum(gtee_commissions) as gtee_commissions
        , avg(acquisition_deposit) filter
        (where deposited_first_time > 0) as avg_deposit_amount
    from source
    where
        deposited_first_time > 0.5
        -- and date_cet > '2024-03-31'
        --and deal_id is null
        --and gtee_commissions > 0 --and cpa_count>0.5 and total_commission>cpa_commissions -- noqa: LT05
    --and user_id='ae4eb2f5ad8ebf29'
    group by
        source, date_cet, country_code, campaign_name
        , ga_campaign_name, campaign_vertical, brand_name
)


select * from transformed
  );
  
[0m15:38:06.128393 [debug] [Thread-1 (]: SQL status: SELECT 2464 in 0.0 seconds
[0m15:38:06.131835 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:38:06.132228 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */
alter table "deep-analysis-console"."danila"."first_deposits_fct__dbt_tmp" rename to "first_deposits_fct"
[0m15:38:06.187906 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m15:38:06.191696 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: COMMIT
[0m15:38:06.192159 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:38:06.192504 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: COMMIT
[0m15:38:06.247406 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m15:38:06.253903 [debug] [Thread-1 (]: Using postgres connection "model.campaign_performance.first_deposits_fct"
[0m15:38:06.254773 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: /* {"app": "dbt", "dbt_version": "1.5.4", "profile_name": "piter", "target_name": "dev", "node_id": "model.campaign_performance.first_deposits_fct"} */
drop table if exists "deep-analysis-console"."danila"."first_deposits_fct__dbt_backup" cascade
[0m15:38:06.310833 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m15:38:06.314569 [debug] [Thread-1 (]: Timing info for model.campaign_performance.first_deposits_fct (execute): 15:38:05.570845 => 15:38:06.314162
[0m15:38:06.315376 [debug] [Thread-1 (]: On model.campaign_performance.first_deposits_fct: Close
[0m15:38:06.317236 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf5738d-9abe-4e14-b44f-b509279e98a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108f68690>]}
[0m15:38:06.318222 [info ] [Thread-1 (]: 2 of 2 OK created sql table model danila.first_deposits_fct .................... [[32mSELECT 2464[0m in 0.75s]
[0m15:38:06.319234 [debug] [Thread-1 (]: Finished running node model.campaign_performance.first_deposits_fct
[0m15:38:06.321807 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:06.322335 [debug] [MainThread]: On master: BEGIN
[0m15:38:06.322869 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:38:06.708983 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m15:38:06.710268 [debug] [MainThread]: On master: COMMIT
[0m15:38:06.711008 [debug] [MainThread]: Using postgres connection "master"
[0m15:38:06.711634 [debug] [MainThread]: On master: COMMIT
[0m15:38:06.758813 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m15:38:06.759230 [debug] [MainThread]: On master: Close
[0m15:38:06.759890 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:38:06.760103 [debug] [MainThread]: Connection 'model.campaign_performance.first_deposits_fct' was properly closed.
[0m15:38:06.760319 [info ] [MainThread]: 
[0m15:38:06.760554 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 6.23 seconds (6.23s).
[0m15:38:06.761368 [debug] [MainThread]: Command end result
[0m15:38:06.768089 [info ] [MainThread]: 
[0m15:38:06.768466 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:38:06.768676 [info ] [MainThread]: 
[0m15:38:06.768897 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:38:06.769277 [debug] [MainThread]: Command `dbt run` succeeded at 15:38:06.769212 after 6.36 seconds
[0m15:38:06.769493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077c8650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049d0ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1049cb210>]}
[0m15:38:06.769705 [debug] [MainThread]: Flushing usage events
